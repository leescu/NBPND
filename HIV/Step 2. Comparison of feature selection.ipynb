{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "50559d19-ab40-4880-bae7-44a3dbe180a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Others\n",
    "import random\n",
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "from pandas import Series\n",
    "import numpy as np\n",
    "import math\n",
    "import os\n",
    "import warnings\n",
    "import optuna\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "70ff5d38-60c9-476d-a509-9e1419bea2b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing packages\n",
    "#Sklearn\n",
    "from sklearn import model_selection, linear_model\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.feature_selection import RFECV,SelectFromModel\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV,RandomizedSearchCV,RepeatedStratifiedKFold,cross_validate\n",
    "from sklearn.metrics import accuracy_score,precision_score,recall_score,f1_score,auc,roc_auc_score,roc_curve,classification_report\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.linear_model import Ridge, LinearRegression, Lasso\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a6baca9e-4a5b-4e5f-9cd3-2db48c543dc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LassoCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bc75945b-ce4f-4650-8380-f7bfb5ff1b51",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"C:/Users/A/Desktop/Bioactive/HIV\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "12865361-291e-449c-8ca4-53ed95b92f16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1919, 3764)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MW</th>\n",
       "      <th>AMW</th>\n",
       "      <th>Sv</th>\n",
       "      <th>Se</th>\n",
       "      <th>Sp</th>\n",
       "      <th>Si</th>\n",
       "      <th>Mv</th>\n",
       "      <th>Me</th>\n",
       "      <th>Mp</th>\n",
       "      <th>Mi</th>\n",
       "      <th>...</th>\n",
       "      <th>s1_numAroBonds</th>\n",
       "      <th>s2_numAroBonds</th>\n",
       "      <th>s3_numAroBonds</th>\n",
       "      <th>s4_numAroBonds</th>\n",
       "      <th>s34_size</th>\n",
       "      <th>s34_relSize</th>\n",
       "      <th>s34_phSize</th>\n",
       "      <th>s34_phRelSize</th>\n",
       "      <th>chiralMoment</th>\n",
       "      <th>chiralPhMoment</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cid</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>395575</th>\n",
       "      <td>636.75</td>\n",
       "      <td>7.404070</td>\n",
       "      <td>53.3988</td>\n",
       "      <td>87.2723</td>\n",
       "      <td>55.2275</td>\n",
       "      <td>96.6074</td>\n",
       "      <td>0.620916</td>\n",
       "      <td>1.014794</td>\n",
       "      <td>0.642180</td>\n",
       "      <td>1.123342</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>39.333333</td>\n",
       "      <td>0.855072</td>\n",
       "      <td>9.75</td>\n",
       "      <td>0.211957</td>\n",
       "      <td>50.709583</td>\n",
       "      <td>12.622331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15604702</th>\n",
       "      <td>360.26</td>\n",
       "      <td>10.595882</td>\n",
       "      <td>22.5817</td>\n",
       "      <td>34.8944</td>\n",
       "      <td>23.9490</td>\n",
       "      <td>38.3759</td>\n",
       "      <td>0.664168</td>\n",
       "      <td>1.026306</td>\n",
       "      <td>0.704382</td>\n",
       "      <td>1.128703</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16045493</th>\n",
       "      <td>444.27</td>\n",
       "      <td>10.577857</td>\n",
       "      <td>31.2089</td>\n",
       "      <td>43.7417</td>\n",
       "      <td>31.3978</td>\n",
       "      <td>47.2140</td>\n",
       "      <td>0.743069</td>\n",
       "      <td>1.041469</td>\n",
       "      <td>0.747567</td>\n",
       "      <td>1.124143</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146894788</th>\n",
       "      <td>637.90</td>\n",
       "      <td>6.786170</td>\n",
       "      <td>57.0290</td>\n",
       "      <td>93.3738</td>\n",
       "      <td>60.8359</td>\n",
       "      <td>106.0483</td>\n",
       "      <td>0.606691</td>\n",
       "      <td>0.993338</td>\n",
       "      <td>0.647190</td>\n",
       "      <td>1.128173</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>11.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>0.872340</td>\n",
       "      <td>8.50</td>\n",
       "      <td>0.180851</td>\n",
       "      <td>39.957758</td>\n",
       "      <td>9.293476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69480289</th>\n",
       "      <td>425.50</td>\n",
       "      <td>7.736364</td>\n",
       "      <td>35.1015</td>\n",
       "      <td>55.8469</td>\n",
       "      <td>36.1480</td>\n",
       "      <td>62.2394</td>\n",
       "      <td>0.638209</td>\n",
       "      <td>1.015398</td>\n",
       "      <td>0.657236</td>\n",
       "      <td>1.131625</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 3764 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               MW        AMW       Sv       Se       Sp        Si        Mv  \\\n",
       "cid                                                                           \n",
       "395575     636.75   7.404070  53.3988  87.2723  55.2275   96.6074  0.620916   \n",
       "15604702   360.26  10.595882  22.5817  34.8944  23.9490   38.3759  0.664168   \n",
       "16045493   444.27  10.577857  31.2089  43.7417  31.3978   47.2140  0.743069   \n",
       "146894788  637.90   6.786170  57.0290  93.3738  60.8359  106.0483  0.606691   \n",
       "69480289   425.50   7.736364  35.1015  55.8469  36.1480   62.2394  0.638209   \n",
       "\n",
       "                 Me        Mp        Mi  ...  s1_numAroBonds  s2_numAroBonds  \\\n",
       "cid                                      ...                                   \n",
       "395575     1.014794  0.642180  1.123342  ...             0.0        1.333333   \n",
       "15604702   1.026306  0.704382  1.128703  ...             0.0        0.000000   \n",
       "16045493   1.041469  0.747567  1.124143  ...             0.0        0.000000   \n",
       "146894788  0.993338  0.647190  1.128173  ...             0.0        0.000000   \n",
       "69480289   1.015398  0.657236  1.131625  ...             0.0        0.000000   \n",
       "\n",
       "           s3_numAroBonds  s4_numAroBonds   s34_size  s34_relSize  s34_phSize  \\\n",
       "cid                                                                             \n",
       "395575                0.0             5.0  39.333333     0.855072        9.75   \n",
       "15604702              0.0             0.0   0.000000     0.000000        0.00   \n",
       "16045493              0.0             0.0   0.000000     0.000000        0.00   \n",
       "146894788            11.0            11.0  41.000000     0.872340        8.50   \n",
       "69480289              0.0             0.0   0.000000     0.000000        0.00   \n",
       "\n",
       "           s34_phRelSize  chiralMoment  chiralPhMoment  \n",
       "cid                                                     \n",
       "395575          0.211957     50.709583       12.622331  \n",
       "15604702        0.000000      0.000000        0.000000  \n",
       "16045493        0.000000      0.000000        0.000000  \n",
       "146894788       0.180851     39.957758        9.293476  \n",
       "69480289        0.000000      0.000000        0.000000  \n",
       "\n",
       "[5 rows x 3764 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Reading the data\n",
    "ML_data= pd.read_csv(\"./ML_data.csv\",header=0,index_col=0)\n",
    "X_NAomit_data= pd.read_csv(\"./X_NAomit_data.csv\",header=0,index_col=0)\n",
    "Raw_data = pd.read_csv('./Original_data.csv',index_col=0)\n",
    "\n",
    "#original data(descriptors= 4175）\n",
    "print(X_NAomit_data.shape)\n",
    "X_NAomit_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a68cc910-dca6-4b63-ae90-8fac100e1ac6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MW</th>\n",
       "      <th>AMW</th>\n",
       "      <th>Sv</th>\n",
       "      <th>Se</th>\n",
       "      <th>Sp</th>\n",
       "      <th>Si</th>\n",
       "      <th>Mv</th>\n",
       "      <th>Me</th>\n",
       "      <th>Mp</th>\n",
       "      <th>Mi</th>\n",
       "      <th>...</th>\n",
       "      <th>s1_numAroBonds</th>\n",
       "      <th>s2_numAroBonds</th>\n",
       "      <th>s3_numAroBonds</th>\n",
       "      <th>s4_numAroBonds</th>\n",
       "      <th>s34_size</th>\n",
       "      <th>s34_relSize</th>\n",
       "      <th>s34_phSize</th>\n",
       "      <th>s34_phRelSize</th>\n",
       "      <th>chiralMoment</th>\n",
       "      <th>chiralPhMoment</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cid</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>395575</th>\n",
       "      <td>636.75</td>\n",
       "      <td>7.404070</td>\n",
       "      <td>53.3988</td>\n",
       "      <td>87.2723</td>\n",
       "      <td>55.2275</td>\n",
       "      <td>96.6074</td>\n",
       "      <td>0.620916</td>\n",
       "      <td>1.014794</td>\n",
       "      <td>0.642180</td>\n",
       "      <td>1.123342</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>39.333333</td>\n",
       "      <td>0.855072</td>\n",
       "      <td>9.75</td>\n",
       "      <td>0.211957</td>\n",
       "      <td>50.709583</td>\n",
       "      <td>12.622331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15604702</th>\n",
       "      <td>360.26</td>\n",
       "      <td>10.595882</td>\n",
       "      <td>22.5817</td>\n",
       "      <td>34.8944</td>\n",
       "      <td>23.9490</td>\n",
       "      <td>38.3759</td>\n",
       "      <td>0.664168</td>\n",
       "      <td>1.026306</td>\n",
       "      <td>0.704382</td>\n",
       "      <td>1.128703</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16045493</th>\n",
       "      <td>444.27</td>\n",
       "      <td>10.577857</td>\n",
       "      <td>31.2089</td>\n",
       "      <td>43.7417</td>\n",
       "      <td>31.3978</td>\n",
       "      <td>47.2140</td>\n",
       "      <td>0.743069</td>\n",
       "      <td>1.041469</td>\n",
       "      <td>0.747567</td>\n",
       "      <td>1.124143</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146894788</th>\n",
       "      <td>637.90</td>\n",
       "      <td>6.786170</td>\n",
       "      <td>57.0290</td>\n",
       "      <td>93.3738</td>\n",
       "      <td>60.8359</td>\n",
       "      <td>106.0483</td>\n",
       "      <td>0.606691</td>\n",
       "      <td>0.993338</td>\n",
       "      <td>0.647190</td>\n",
       "      <td>1.128173</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>11.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>0.872340</td>\n",
       "      <td>8.50</td>\n",
       "      <td>0.180851</td>\n",
       "      <td>39.957758</td>\n",
       "      <td>9.293476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69480289</th>\n",
       "      <td>425.50</td>\n",
       "      <td>7.736364</td>\n",
       "      <td>35.1015</td>\n",
       "      <td>55.8469</td>\n",
       "      <td>36.1480</td>\n",
       "      <td>62.2394</td>\n",
       "      <td>0.638209</td>\n",
       "      <td>1.015398</td>\n",
       "      <td>0.657236</td>\n",
       "      <td>1.131625</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44582935</th>\n",
       "      <td>363.30</td>\n",
       "      <td>10.091667</td>\n",
       "      <td>24.6575</td>\n",
       "      <td>36.0216</td>\n",
       "      <td>26.7957</td>\n",
       "      <td>39.8740</td>\n",
       "      <td>0.684931</td>\n",
       "      <td>1.000600</td>\n",
       "      <td>0.744325</td>\n",
       "      <td>1.107611</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>3.00</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>16.492423</td>\n",
       "      <td>5.196152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44583099</th>\n",
       "      <td>330.30</td>\n",
       "      <td>8.927027</td>\n",
       "      <td>24.3195</td>\n",
       "      <td>37.1053</td>\n",
       "      <td>26.6763</td>\n",
       "      <td>41.2525</td>\n",
       "      <td>0.657284</td>\n",
       "      <td>1.002846</td>\n",
       "      <td>0.720981</td>\n",
       "      <td>1.114932</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>17.333333</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>2.00</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>20.753807</td>\n",
       "      <td>3.464102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44583063</th>\n",
       "      <td>324.45</td>\n",
       "      <td>9.270000</td>\n",
       "      <td>23.8712</td>\n",
       "      <td>35.5670</td>\n",
       "      <td>25.5116</td>\n",
       "      <td>39.4224</td>\n",
       "      <td>0.682034</td>\n",
       "      <td>1.016200</td>\n",
       "      <td>0.728903</td>\n",
       "      <td>1.126354</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>2.00</td>\n",
       "      <td>0.095238</td>\n",
       "      <td>16.492423</td>\n",
       "      <td>3.464102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497216</th>\n",
       "      <td>322.43</td>\n",
       "      <td>9.770606</td>\n",
       "      <td>23.3444</td>\n",
       "      <td>33.6834</td>\n",
       "      <td>24.7502</td>\n",
       "      <td>37.0072</td>\n",
       "      <td>0.707406</td>\n",
       "      <td>1.020709</td>\n",
       "      <td>0.750006</td>\n",
       "      <td>1.121430</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>2.00</td>\n",
       "      <td>0.095238</td>\n",
       "      <td>16.492423</td>\n",
       "      <td>3.464102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11977753</th>\n",
       "      <td>469.58</td>\n",
       "      <td>7.958983</td>\n",
       "      <td>40.5630</td>\n",
       "      <td>58.7887</td>\n",
       "      <td>42.3356</td>\n",
       "      <td>65.4377</td>\n",
       "      <td>0.687508</td>\n",
       "      <td>0.996419</td>\n",
       "      <td>0.717553</td>\n",
       "      <td>1.109114</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1919 rows × 3764 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               MW        AMW       Sv       Se       Sp        Si        Mv  \\\n",
       "cid                                                                           \n",
       "395575     636.75   7.404070  53.3988  87.2723  55.2275   96.6074  0.620916   \n",
       "15604702   360.26  10.595882  22.5817  34.8944  23.9490   38.3759  0.664168   \n",
       "16045493   444.27  10.577857  31.2089  43.7417  31.3978   47.2140  0.743069   \n",
       "146894788  637.90   6.786170  57.0290  93.3738  60.8359  106.0483  0.606691   \n",
       "69480289   425.50   7.736364  35.1015  55.8469  36.1480   62.2394  0.638209   \n",
       "...           ...        ...      ...      ...      ...       ...       ...   \n",
       "44582935   363.30  10.091667  24.6575  36.0216  26.7957   39.8740  0.684931   \n",
       "44583099   330.30   8.927027  24.3195  37.1053  26.6763   41.2525  0.657284   \n",
       "44583063   324.45   9.270000  23.8712  35.5670  25.5116   39.4224  0.682034   \n",
       "497216     322.43   9.770606  23.3444  33.6834  24.7502   37.0072  0.707406   \n",
       "11977753   469.58   7.958983  40.5630  58.7887  42.3356   65.4377  0.687508   \n",
       "\n",
       "                 Me        Mp        Mi  ...  s1_numAroBonds  s2_numAroBonds  \\\n",
       "cid                                      ...                                   \n",
       "395575     1.014794  0.642180  1.123342  ...             0.0        1.333333   \n",
       "15604702   1.026306  0.704382  1.128703  ...             0.0        0.000000   \n",
       "16045493   1.041469  0.747567  1.124143  ...             0.0        0.000000   \n",
       "146894788  0.993338  0.647190  1.128173  ...             0.0        0.000000   \n",
       "69480289   1.015398  0.657236  1.131625  ...             0.0        0.000000   \n",
       "...             ...       ...       ...  ...             ...             ...   \n",
       "44582935   1.000600  0.744325  1.107611  ...             0.0        0.000000   \n",
       "44583099   1.002846  0.720981  1.114932  ...             0.0        0.000000   \n",
       "44583063   1.016200  0.728903  1.126354  ...             0.0        0.000000   \n",
       "497216     1.020709  0.750006  1.121430  ...             0.0        0.000000   \n",
       "11977753   0.996419  0.717553  1.109114  ...             0.0        0.000000   \n",
       "\n",
       "           s3_numAroBonds  s4_numAroBonds   s34_size  s34_relSize  s34_phSize  \\\n",
       "cid                                                                             \n",
       "395575                0.0             5.0  39.333333     0.855072        9.75   \n",
       "15604702              0.0             0.0   0.000000     0.000000        0.00   \n",
       "16045493              0.0             0.0   0.000000     0.000000        0.00   \n",
       "146894788            11.0            11.0  41.000000     0.872340        8.50   \n",
       "69480289              0.0             0.0   0.000000     0.000000        0.00   \n",
       "...                   ...             ...        ...          ...         ...   \n",
       "44582935              6.0             6.0  18.000000     0.857143        3.00   \n",
       "44583099              2.0             4.0  17.333333     0.866667        2.00   \n",
       "44583063              6.0             5.0  18.000000     0.857143        2.00   \n",
       "497216                6.0             6.0  18.000000     0.857143        2.00   \n",
       "11977753              0.0             0.0   0.000000     0.000000        0.00   \n",
       "\n",
       "           s34_phRelSize  chiralMoment  chiralPhMoment  \n",
       "cid                                                     \n",
       "395575          0.211957     50.709583       12.622331  \n",
       "15604702        0.000000      0.000000        0.000000  \n",
       "16045493        0.000000      0.000000        0.000000  \n",
       "146894788       0.180851     39.957758        9.293476  \n",
       "69480289        0.000000      0.000000        0.000000  \n",
       "...                  ...           ...             ...  \n",
       "44582935        0.142857     16.492423        5.196152  \n",
       "44583099        0.100000     20.753807        3.464102  \n",
       "44583063        0.095238     16.492423        3.464102  \n",
       "497216          0.095238     16.492423        3.464102  \n",
       "11977753        0.000000      0.000000        0.000000  \n",
       "\n",
       "[1919 rows x 3764 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_NAomit_data= pd.read_csv(\"./X_NAomit_data.csv\",header=0,index_col=0)\n",
    "X_NAomit_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e1c89e32-9d35-4229-a7fd-6dc4bc6e3b4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "col_data= pd.read_csv(\"./X_NAomit_data.csv\",header=0,index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c075c2f5-c839-4ab6-8f1d-ee4e808c3238",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MW</th>\n",
       "      <th>AMW</th>\n",
       "      <th>Sv</th>\n",
       "      <th>Se</th>\n",
       "      <th>Sp</th>\n",
       "      <th>Si</th>\n",
       "      <th>Mv</th>\n",
       "      <th>Me</th>\n",
       "      <th>Mp</th>\n",
       "      <th>Mi</th>\n",
       "      <th>...</th>\n",
       "      <th>s1_numAroBonds</th>\n",
       "      <th>s2_numAroBonds</th>\n",
       "      <th>s3_numAroBonds</th>\n",
       "      <th>s4_numAroBonds</th>\n",
       "      <th>s34_size</th>\n",
       "      <th>s34_relSize</th>\n",
       "      <th>s34_phSize</th>\n",
       "      <th>s34_phRelSize</th>\n",
       "      <th>chiralMoment</th>\n",
       "      <th>chiralPhMoment</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cid</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>395575</th>\n",
       "      <td>636.75</td>\n",
       "      <td>7.404070</td>\n",
       "      <td>53.3988</td>\n",
       "      <td>87.2723</td>\n",
       "      <td>55.2275</td>\n",
       "      <td>96.6074</td>\n",
       "      <td>0.620916</td>\n",
       "      <td>1.014794</td>\n",
       "      <td>0.642180</td>\n",
       "      <td>1.123342</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>39.333333</td>\n",
       "      <td>0.855072</td>\n",
       "      <td>9.75</td>\n",
       "      <td>0.211957</td>\n",
       "      <td>50.709583</td>\n",
       "      <td>12.622331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15604702</th>\n",
       "      <td>360.26</td>\n",
       "      <td>10.595882</td>\n",
       "      <td>22.5817</td>\n",
       "      <td>34.8944</td>\n",
       "      <td>23.9490</td>\n",
       "      <td>38.3759</td>\n",
       "      <td>0.664168</td>\n",
       "      <td>1.026306</td>\n",
       "      <td>0.704382</td>\n",
       "      <td>1.128703</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16045493</th>\n",
       "      <td>444.27</td>\n",
       "      <td>10.577857</td>\n",
       "      <td>31.2089</td>\n",
       "      <td>43.7417</td>\n",
       "      <td>31.3978</td>\n",
       "      <td>47.2140</td>\n",
       "      <td>0.743069</td>\n",
       "      <td>1.041469</td>\n",
       "      <td>0.747567</td>\n",
       "      <td>1.124143</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146894788</th>\n",
       "      <td>637.90</td>\n",
       "      <td>6.786170</td>\n",
       "      <td>57.0290</td>\n",
       "      <td>93.3738</td>\n",
       "      <td>60.8359</td>\n",
       "      <td>106.0483</td>\n",
       "      <td>0.606691</td>\n",
       "      <td>0.993338</td>\n",
       "      <td>0.647190</td>\n",
       "      <td>1.128173</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>11.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>0.872340</td>\n",
       "      <td>8.50</td>\n",
       "      <td>0.180851</td>\n",
       "      <td>39.957758</td>\n",
       "      <td>9.293476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69480289</th>\n",
       "      <td>425.50</td>\n",
       "      <td>7.736364</td>\n",
       "      <td>35.1015</td>\n",
       "      <td>55.8469</td>\n",
       "      <td>36.1480</td>\n",
       "      <td>62.2394</td>\n",
       "      <td>0.638209</td>\n",
       "      <td>1.015398</td>\n",
       "      <td>0.657236</td>\n",
       "      <td>1.131625</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44582935</th>\n",
       "      <td>363.30</td>\n",
       "      <td>10.091667</td>\n",
       "      <td>24.6575</td>\n",
       "      <td>36.0216</td>\n",
       "      <td>26.7957</td>\n",
       "      <td>39.8740</td>\n",
       "      <td>0.684931</td>\n",
       "      <td>1.000600</td>\n",
       "      <td>0.744325</td>\n",
       "      <td>1.107611</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>3.00</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>16.492423</td>\n",
       "      <td>5.196152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44583099</th>\n",
       "      <td>330.30</td>\n",
       "      <td>8.927027</td>\n",
       "      <td>24.3195</td>\n",
       "      <td>37.1053</td>\n",
       "      <td>26.6763</td>\n",
       "      <td>41.2525</td>\n",
       "      <td>0.657284</td>\n",
       "      <td>1.002846</td>\n",
       "      <td>0.720981</td>\n",
       "      <td>1.114932</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>17.333333</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>2.00</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>20.753807</td>\n",
       "      <td>3.464102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44583063</th>\n",
       "      <td>324.45</td>\n",
       "      <td>9.270000</td>\n",
       "      <td>23.8712</td>\n",
       "      <td>35.5670</td>\n",
       "      <td>25.5116</td>\n",
       "      <td>39.4224</td>\n",
       "      <td>0.682034</td>\n",
       "      <td>1.016200</td>\n",
       "      <td>0.728903</td>\n",
       "      <td>1.126354</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>2.00</td>\n",
       "      <td>0.095238</td>\n",
       "      <td>16.492423</td>\n",
       "      <td>3.464102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497216</th>\n",
       "      <td>322.43</td>\n",
       "      <td>9.770606</td>\n",
       "      <td>23.3444</td>\n",
       "      <td>33.6834</td>\n",
       "      <td>24.7502</td>\n",
       "      <td>37.0072</td>\n",
       "      <td>0.707406</td>\n",
       "      <td>1.020709</td>\n",
       "      <td>0.750006</td>\n",
       "      <td>1.121430</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>2.00</td>\n",
       "      <td>0.095238</td>\n",
       "      <td>16.492423</td>\n",
       "      <td>3.464102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11977753</th>\n",
       "      <td>469.58</td>\n",
       "      <td>7.958983</td>\n",
       "      <td>40.5630</td>\n",
       "      <td>58.7887</td>\n",
       "      <td>42.3356</td>\n",
       "      <td>65.4377</td>\n",
       "      <td>0.687508</td>\n",
       "      <td>0.996419</td>\n",
       "      <td>0.717553</td>\n",
       "      <td>1.109114</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1919 rows × 3764 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               MW        AMW       Sv       Se       Sp        Si        Mv  \\\n",
       "cid                                                                           \n",
       "395575     636.75   7.404070  53.3988  87.2723  55.2275   96.6074  0.620916   \n",
       "15604702   360.26  10.595882  22.5817  34.8944  23.9490   38.3759  0.664168   \n",
       "16045493   444.27  10.577857  31.2089  43.7417  31.3978   47.2140  0.743069   \n",
       "146894788  637.90   6.786170  57.0290  93.3738  60.8359  106.0483  0.606691   \n",
       "69480289   425.50   7.736364  35.1015  55.8469  36.1480   62.2394  0.638209   \n",
       "...           ...        ...      ...      ...      ...       ...       ...   \n",
       "44582935   363.30  10.091667  24.6575  36.0216  26.7957   39.8740  0.684931   \n",
       "44583099   330.30   8.927027  24.3195  37.1053  26.6763   41.2525  0.657284   \n",
       "44583063   324.45   9.270000  23.8712  35.5670  25.5116   39.4224  0.682034   \n",
       "497216     322.43   9.770606  23.3444  33.6834  24.7502   37.0072  0.707406   \n",
       "11977753   469.58   7.958983  40.5630  58.7887  42.3356   65.4377  0.687508   \n",
       "\n",
       "                 Me        Mp        Mi  ...  s1_numAroBonds  s2_numAroBonds  \\\n",
       "cid                                      ...                                   \n",
       "395575     1.014794  0.642180  1.123342  ...             0.0        1.333333   \n",
       "15604702   1.026306  0.704382  1.128703  ...             0.0        0.000000   \n",
       "16045493   1.041469  0.747567  1.124143  ...             0.0        0.000000   \n",
       "146894788  0.993338  0.647190  1.128173  ...             0.0        0.000000   \n",
       "69480289   1.015398  0.657236  1.131625  ...             0.0        0.000000   \n",
       "...             ...       ...       ...  ...             ...             ...   \n",
       "44582935   1.000600  0.744325  1.107611  ...             0.0        0.000000   \n",
       "44583099   1.002846  0.720981  1.114932  ...             0.0        0.000000   \n",
       "44583063   1.016200  0.728903  1.126354  ...             0.0        0.000000   \n",
       "497216     1.020709  0.750006  1.121430  ...             0.0        0.000000   \n",
       "11977753   0.996419  0.717553  1.109114  ...             0.0        0.000000   \n",
       "\n",
       "           s3_numAroBonds  s4_numAroBonds   s34_size  s34_relSize  s34_phSize  \\\n",
       "cid                                                                             \n",
       "395575                0.0             5.0  39.333333     0.855072        9.75   \n",
       "15604702              0.0             0.0   0.000000     0.000000        0.00   \n",
       "16045493              0.0             0.0   0.000000     0.000000        0.00   \n",
       "146894788            11.0            11.0  41.000000     0.872340        8.50   \n",
       "69480289              0.0             0.0   0.000000     0.000000        0.00   \n",
       "...                   ...             ...        ...          ...         ...   \n",
       "44582935              6.0             6.0  18.000000     0.857143        3.00   \n",
       "44583099              2.0             4.0  17.333333     0.866667        2.00   \n",
       "44583063              6.0             5.0  18.000000     0.857143        2.00   \n",
       "497216                6.0             6.0  18.000000     0.857143        2.00   \n",
       "11977753              0.0             0.0   0.000000     0.000000        0.00   \n",
       "\n",
       "           s34_phRelSize  chiralMoment  chiralPhMoment  \n",
       "cid                                                     \n",
       "395575          0.211957     50.709583       12.622331  \n",
       "15604702        0.000000      0.000000        0.000000  \n",
       "16045493        0.000000      0.000000        0.000000  \n",
       "146894788       0.180851     39.957758        9.293476  \n",
       "69480289        0.000000      0.000000        0.000000  \n",
       "...                  ...           ...             ...  \n",
       "44582935        0.142857     16.492423        5.196152  \n",
       "44583099        0.100000     20.753807        3.464102  \n",
       "44583063        0.095238     16.492423        3.464102  \n",
       "497216          0.095238     16.492423        3.464102  \n",
       "11977753        0.000000      0.000000        0.000000  \n",
       "\n",
       "[1919 rows x 3764 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_NAomit_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8129de55-e5e1-44df-bea5-1de439f32345",
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 0.99  # 如果列中 0 的比例超过 90%，则移除该列\n",
    "non_zero_threshold = X_NAomit_data.shape[0] * (1 - threshold)\n",
    "X_NAomit_data =X_NAomit_data.loc[:, (X_NAomit_data != 0).sum(axis=0) > non_zero_threshold]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "25db298a-25a8-4f41-ba0a-23d279862cce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MW</th>\n",
       "      <th>AMW</th>\n",
       "      <th>Sv</th>\n",
       "      <th>Se</th>\n",
       "      <th>Sp</th>\n",
       "      <th>Si</th>\n",
       "      <th>Mv</th>\n",
       "      <th>Me</th>\n",
       "      <th>Mp</th>\n",
       "      <th>Mi</th>\n",
       "      <th>...</th>\n",
       "      <th>s4_numRotBonds</th>\n",
       "      <th>s2_numAroBonds</th>\n",
       "      <th>s3_numAroBonds</th>\n",
       "      <th>s4_numAroBonds</th>\n",
       "      <th>s34_size</th>\n",
       "      <th>s34_relSize</th>\n",
       "      <th>s34_phSize</th>\n",
       "      <th>s34_phRelSize</th>\n",
       "      <th>chiralMoment</th>\n",
       "      <th>chiralPhMoment</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cid</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>395575</th>\n",
       "      <td>636.75</td>\n",
       "      <td>7.404070</td>\n",
       "      <td>53.3988</td>\n",
       "      <td>87.2723</td>\n",
       "      <td>55.2275</td>\n",
       "      <td>96.6074</td>\n",
       "      <td>0.620916</td>\n",
       "      <td>1.014794</td>\n",
       "      <td>0.642180</td>\n",
       "      <td>1.123342</td>\n",
       "      <td>...</td>\n",
       "      <td>4.666667</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>39.333333</td>\n",
       "      <td>0.855072</td>\n",
       "      <td>9.75</td>\n",
       "      <td>0.211957</td>\n",
       "      <td>50.709583</td>\n",
       "      <td>12.622331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15604702</th>\n",
       "      <td>360.26</td>\n",
       "      <td>10.595882</td>\n",
       "      <td>22.5817</td>\n",
       "      <td>34.8944</td>\n",
       "      <td>23.9490</td>\n",
       "      <td>38.3759</td>\n",
       "      <td>0.664168</td>\n",
       "      <td>1.026306</td>\n",
       "      <td>0.704382</td>\n",
       "      <td>1.128703</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16045493</th>\n",
       "      <td>444.27</td>\n",
       "      <td>10.577857</td>\n",
       "      <td>31.2089</td>\n",
       "      <td>43.7417</td>\n",
       "      <td>31.3978</td>\n",
       "      <td>47.2140</td>\n",
       "      <td>0.743069</td>\n",
       "      <td>1.041469</td>\n",
       "      <td>0.747567</td>\n",
       "      <td>1.124143</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146894788</th>\n",
       "      <td>637.90</td>\n",
       "      <td>6.786170</td>\n",
       "      <td>57.0290</td>\n",
       "      <td>93.3738</td>\n",
       "      <td>60.8359</td>\n",
       "      <td>106.0483</td>\n",
       "      <td>0.606691</td>\n",
       "      <td>0.993338</td>\n",
       "      <td>0.647190</td>\n",
       "      <td>1.128173</td>\n",
       "      <td>...</td>\n",
       "      <td>7.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>11.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>0.872340</td>\n",
       "      <td>8.50</td>\n",
       "      <td>0.180851</td>\n",
       "      <td>39.957758</td>\n",
       "      <td>9.293476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69480289</th>\n",
       "      <td>425.50</td>\n",
       "      <td>7.736364</td>\n",
       "      <td>35.1015</td>\n",
       "      <td>55.8469</td>\n",
       "      <td>36.1480</td>\n",
       "      <td>62.2394</td>\n",
       "      <td>0.638209</td>\n",
       "      <td>1.015398</td>\n",
       "      <td>0.657236</td>\n",
       "      <td>1.131625</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44582935</th>\n",
       "      <td>363.30</td>\n",
       "      <td>10.091667</td>\n",
       "      <td>24.6575</td>\n",
       "      <td>36.0216</td>\n",
       "      <td>26.7957</td>\n",
       "      <td>39.8740</td>\n",
       "      <td>0.684931</td>\n",
       "      <td>1.000600</td>\n",
       "      <td>0.744325</td>\n",
       "      <td>1.107611</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>3.00</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>16.492423</td>\n",
       "      <td>5.196152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44583099</th>\n",
       "      <td>330.30</td>\n",
       "      <td>8.927027</td>\n",
       "      <td>24.3195</td>\n",
       "      <td>37.1053</td>\n",
       "      <td>26.6763</td>\n",
       "      <td>41.2525</td>\n",
       "      <td>0.657284</td>\n",
       "      <td>1.002846</td>\n",
       "      <td>0.720981</td>\n",
       "      <td>1.114932</td>\n",
       "      <td>...</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>17.333333</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>2.00</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>20.753807</td>\n",
       "      <td>3.464102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44583063</th>\n",
       "      <td>324.45</td>\n",
       "      <td>9.270000</td>\n",
       "      <td>23.8712</td>\n",
       "      <td>35.5670</td>\n",
       "      <td>25.5116</td>\n",
       "      <td>39.4224</td>\n",
       "      <td>0.682034</td>\n",
       "      <td>1.016200</td>\n",
       "      <td>0.728903</td>\n",
       "      <td>1.126354</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>2.00</td>\n",
       "      <td>0.095238</td>\n",
       "      <td>16.492423</td>\n",
       "      <td>3.464102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497216</th>\n",
       "      <td>322.43</td>\n",
       "      <td>9.770606</td>\n",
       "      <td>23.3444</td>\n",
       "      <td>33.6834</td>\n",
       "      <td>24.7502</td>\n",
       "      <td>37.0072</td>\n",
       "      <td>0.707406</td>\n",
       "      <td>1.020709</td>\n",
       "      <td>0.750006</td>\n",
       "      <td>1.121430</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>2.00</td>\n",
       "      <td>0.095238</td>\n",
       "      <td>16.492423</td>\n",
       "      <td>3.464102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11977753</th>\n",
       "      <td>469.58</td>\n",
       "      <td>7.958983</td>\n",
       "      <td>40.5630</td>\n",
       "      <td>58.7887</td>\n",
       "      <td>42.3356</td>\n",
       "      <td>65.4377</td>\n",
       "      <td>0.687508</td>\n",
       "      <td>0.996419</td>\n",
       "      <td>0.717553</td>\n",
       "      <td>1.109114</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1919 rows × 2202 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               MW        AMW       Sv       Se       Sp        Si        Mv  \\\n",
       "cid                                                                           \n",
       "395575     636.75   7.404070  53.3988  87.2723  55.2275   96.6074  0.620916   \n",
       "15604702   360.26  10.595882  22.5817  34.8944  23.9490   38.3759  0.664168   \n",
       "16045493   444.27  10.577857  31.2089  43.7417  31.3978   47.2140  0.743069   \n",
       "146894788  637.90   6.786170  57.0290  93.3738  60.8359  106.0483  0.606691   \n",
       "69480289   425.50   7.736364  35.1015  55.8469  36.1480   62.2394  0.638209   \n",
       "...           ...        ...      ...      ...      ...       ...       ...   \n",
       "44582935   363.30  10.091667  24.6575  36.0216  26.7957   39.8740  0.684931   \n",
       "44583099   330.30   8.927027  24.3195  37.1053  26.6763   41.2525  0.657284   \n",
       "44583063   324.45   9.270000  23.8712  35.5670  25.5116   39.4224  0.682034   \n",
       "497216     322.43   9.770606  23.3444  33.6834  24.7502   37.0072  0.707406   \n",
       "11977753   469.58   7.958983  40.5630  58.7887  42.3356   65.4377  0.687508   \n",
       "\n",
       "                 Me        Mp        Mi  ...  s4_numRotBonds  s2_numAroBonds  \\\n",
       "cid                                      ...                                   \n",
       "395575     1.014794  0.642180  1.123342  ...        4.666667        1.333333   \n",
       "15604702   1.026306  0.704382  1.128703  ...        0.000000        0.000000   \n",
       "16045493   1.041469  0.747567  1.124143  ...        0.000000        0.000000   \n",
       "146894788  0.993338  0.647190  1.128173  ...        7.500000        0.000000   \n",
       "69480289   1.015398  0.657236  1.131625  ...        0.000000        0.000000   \n",
       "...             ...       ...       ...  ...             ...             ...   \n",
       "44582935   1.000600  0.744325  1.107611  ...        1.000000        0.000000   \n",
       "44583099   1.002846  0.720981  1.114932  ...        1.666667        0.000000   \n",
       "44583063   1.016200  0.728903  1.126354  ...        1.000000        0.000000   \n",
       "497216     1.020709  0.750006  1.121430  ...        1.000000        0.000000   \n",
       "11977753   0.996419  0.717553  1.109114  ...        0.000000        0.000000   \n",
       "\n",
       "           s3_numAroBonds  s4_numAroBonds   s34_size  s34_relSize  s34_phSize  \\\n",
       "cid                                                                             \n",
       "395575                0.0             5.0  39.333333     0.855072        9.75   \n",
       "15604702              0.0             0.0   0.000000     0.000000        0.00   \n",
       "16045493              0.0             0.0   0.000000     0.000000        0.00   \n",
       "146894788            11.0            11.0  41.000000     0.872340        8.50   \n",
       "69480289              0.0             0.0   0.000000     0.000000        0.00   \n",
       "...                   ...             ...        ...          ...         ...   \n",
       "44582935              6.0             6.0  18.000000     0.857143        3.00   \n",
       "44583099              2.0             4.0  17.333333     0.866667        2.00   \n",
       "44583063              6.0             5.0  18.000000     0.857143        2.00   \n",
       "497216                6.0             6.0  18.000000     0.857143        2.00   \n",
       "11977753              0.0             0.0   0.000000     0.000000        0.00   \n",
       "\n",
       "           s34_phRelSize  chiralMoment  chiralPhMoment  \n",
       "cid                                                     \n",
       "395575          0.211957     50.709583       12.622331  \n",
       "15604702        0.000000      0.000000        0.000000  \n",
       "16045493        0.000000      0.000000        0.000000  \n",
       "146894788       0.180851     39.957758        9.293476  \n",
       "69480289        0.000000      0.000000        0.000000  \n",
       "...                  ...           ...             ...  \n",
       "44582935        0.142857     16.492423        5.196152  \n",
       "44583099        0.100000     20.753807        3.464102  \n",
       "44583063        0.095238     16.492423        3.464102  \n",
       "497216          0.095238     16.492423        3.464102  \n",
       "11977753        0.000000      0.000000        0.000000  \n",
       "\n",
       "[1919 rows x 2202 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_NAomit_data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1cf34dcf-3f11-4e44-83ca-67542efeea48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[6.36750000e+02, 7.40406977e+00, 5.33988000e+01, ...,\n",
       "        2.11956522e-01, 5.07095829e+01, 1.26223311e+01],\n",
       "       [3.60260000e+02, 1.05958824e+01, 2.25817000e+01, ...,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "       [4.44270000e+02, 1.05778571e+01, 3.12089000e+01, ...,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "       ...,\n",
       "       [3.24450000e+02, 9.27000000e+00, 2.38712000e+01, ...,\n",
       "        9.52380952e-02, 1.64924225e+01, 3.46410162e+00],\n",
       "       [3.22430000e+02, 9.77060606e+00, 2.33444000e+01, ...,\n",
       "        9.52380952e-02, 1.64924225e+01, 3.46410162e+00],\n",
       "       [4.69580000e+02, 7.95898305e+00, 4.05630000e+01, ...,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X=np.array(X_NAomit_data)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fd096547-56ce-48a2-9a6f-210d1e31be3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MW</th>\n",
       "      <th>AMW</th>\n",
       "      <th>Sv</th>\n",
       "      <th>Se</th>\n",
       "      <th>Sp</th>\n",
       "      <th>Si</th>\n",
       "      <th>Mv</th>\n",
       "      <th>Me</th>\n",
       "      <th>Mp</th>\n",
       "      <th>Mi</th>\n",
       "      <th>...</th>\n",
       "      <th>s4_numRotBonds</th>\n",
       "      <th>s2_numAroBonds</th>\n",
       "      <th>s3_numAroBonds</th>\n",
       "      <th>s4_numAroBonds</th>\n",
       "      <th>s34_size</th>\n",
       "      <th>s34_relSize</th>\n",
       "      <th>s34_phSize</th>\n",
       "      <th>s34_phRelSize</th>\n",
       "      <th>chiralMoment</th>\n",
       "      <th>chiralPhMoment</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cid</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>395575</th>\n",
       "      <td>636.75</td>\n",
       "      <td>7.404070</td>\n",
       "      <td>53.3988</td>\n",
       "      <td>87.2723</td>\n",
       "      <td>55.2275</td>\n",
       "      <td>96.6074</td>\n",
       "      <td>0.620916</td>\n",
       "      <td>1.014794</td>\n",
       "      <td>0.642180</td>\n",
       "      <td>1.123342</td>\n",
       "      <td>...</td>\n",
       "      <td>4.666667</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>39.333333</td>\n",
       "      <td>0.855072</td>\n",
       "      <td>9.75</td>\n",
       "      <td>0.211957</td>\n",
       "      <td>50.709583</td>\n",
       "      <td>12.622331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15604702</th>\n",
       "      <td>360.26</td>\n",
       "      <td>10.595882</td>\n",
       "      <td>22.5817</td>\n",
       "      <td>34.8944</td>\n",
       "      <td>23.9490</td>\n",
       "      <td>38.3759</td>\n",
       "      <td>0.664168</td>\n",
       "      <td>1.026306</td>\n",
       "      <td>0.704382</td>\n",
       "      <td>1.128703</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16045493</th>\n",
       "      <td>444.27</td>\n",
       "      <td>10.577857</td>\n",
       "      <td>31.2089</td>\n",
       "      <td>43.7417</td>\n",
       "      <td>31.3978</td>\n",
       "      <td>47.2140</td>\n",
       "      <td>0.743069</td>\n",
       "      <td>1.041469</td>\n",
       "      <td>0.747567</td>\n",
       "      <td>1.124143</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146894788</th>\n",
       "      <td>637.90</td>\n",
       "      <td>6.786170</td>\n",
       "      <td>57.0290</td>\n",
       "      <td>93.3738</td>\n",
       "      <td>60.8359</td>\n",
       "      <td>106.0483</td>\n",
       "      <td>0.606691</td>\n",
       "      <td>0.993338</td>\n",
       "      <td>0.647190</td>\n",
       "      <td>1.128173</td>\n",
       "      <td>...</td>\n",
       "      <td>7.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>11.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>0.872340</td>\n",
       "      <td>8.50</td>\n",
       "      <td>0.180851</td>\n",
       "      <td>39.957758</td>\n",
       "      <td>9.293476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69480289</th>\n",
       "      <td>425.50</td>\n",
       "      <td>7.736364</td>\n",
       "      <td>35.1015</td>\n",
       "      <td>55.8469</td>\n",
       "      <td>36.1480</td>\n",
       "      <td>62.2394</td>\n",
       "      <td>0.638209</td>\n",
       "      <td>1.015398</td>\n",
       "      <td>0.657236</td>\n",
       "      <td>1.131625</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44582935</th>\n",
       "      <td>363.30</td>\n",
       "      <td>10.091667</td>\n",
       "      <td>24.6575</td>\n",
       "      <td>36.0216</td>\n",
       "      <td>26.7957</td>\n",
       "      <td>39.8740</td>\n",
       "      <td>0.684931</td>\n",
       "      <td>1.000600</td>\n",
       "      <td>0.744325</td>\n",
       "      <td>1.107611</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>3.00</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>16.492423</td>\n",
       "      <td>5.196152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44583099</th>\n",
       "      <td>330.30</td>\n",
       "      <td>8.927027</td>\n",
       "      <td>24.3195</td>\n",
       "      <td>37.1053</td>\n",
       "      <td>26.6763</td>\n",
       "      <td>41.2525</td>\n",
       "      <td>0.657284</td>\n",
       "      <td>1.002846</td>\n",
       "      <td>0.720981</td>\n",
       "      <td>1.114932</td>\n",
       "      <td>...</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>17.333333</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>2.00</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>20.753807</td>\n",
       "      <td>3.464102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44583063</th>\n",
       "      <td>324.45</td>\n",
       "      <td>9.270000</td>\n",
       "      <td>23.8712</td>\n",
       "      <td>35.5670</td>\n",
       "      <td>25.5116</td>\n",
       "      <td>39.4224</td>\n",
       "      <td>0.682034</td>\n",
       "      <td>1.016200</td>\n",
       "      <td>0.728903</td>\n",
       "      <td>1.126354</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>2.00</td>\n",
       "      <td>0.095238</td>\n",
       "      <td>16.492423</td>\n",
       "      <td>3.464102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497216</th>\n",
       "      <td>322.43</td>\n",
       "      <td>9.770606</td>\n",
       "      <td>23.3444</td>\n",
       "      <td>33.6834</td>\n",
       "      <td>24.7502</td>\n",
       "      <td>37.0072</td>\n",
       "      <td>0.707406</td>\n",
       "      <td>1.020709</td>\n",
       "      <td>0.750006</td>\n",
       "      <td>1.121430</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>2.00</td>\n",
       "      <td>0.095238</td>\n",
       "      <td>16.492423</td>\n",
       "      <td>3.464102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11977753</th>\n",
       "      <td>469.58</td>\n",
       "      <td>7.958983</td>\n",
       "      <td>40.5630</td>\n",
       "      <td>58.7887</td>\n",
       "      <td>42.3356</td>\n",
       "      <td>65.4377</td>\n",
       "      <td>0.687508</td>\n",
       "      <td>0.996419</td>\n",
       "      <td>0.717553</td>\n",
       "      <td>1.109114</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1919 rows × 2202 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               MW        AMW       Sv       Se       Sp        Si        Mv  \\\n",
       "cid                                                                           \n",
       "395575     636.75   7.404070  53.3988  87.2723  55.2275   96.6074  0.620916   \n",
       "15604702   360.26  10.595882  22.5817  34.8944  23.9490   38.3759  0.664168   \n",
       "16045493   444.27  10.577857  31.2089  43.7417  31.3978   47.2140  0.743069   \n",
       "146894788  637.90   6.786170  57.0290  93.3738  60.8359  106.0483  0.606691   \n",
       "69480289   425.50   7.736364  35.1015  55.8469  36.1480   62.2394  0.638209   \n",
       "...           ...        ...      ...      ...      ...       ...       ...   \n",
       "44582935   363.30  10.091667  24.6575  36.0216  26.7957   39.8740  0.684931   \n",
       "44583099   330.30   8.927027  24.3195  37.1053  26.6763   41.2525  0.657284   \n",
       "44583063   324.45   9.270000  23.8712  35.5670  25.5116   39.4224  0.682034   \n",
       "497216     322.43   9.770606  23.3444  33.6834  24.7502   37.0072  0.707406   \n",
       "11977753   469.58   7.958983  40.5630  58.7887  42.3356   65.4377  0.687508   \n",
       "\n",
       "                 Me        Mp        Mi  ...  s4_numRotBonds  s2_numAroBonds  \\\n",
       "cid                                      ...                                   \n",
       "395575     1.014794  0.642180  1.123342  ...        4.666667        1.333333   \n",
       "15604702   1.026306  0.704382  1.128703  ...        0.000000        0.000000   \n",
       "16045493   1.041469  0.747567  1.124143  ...        0.000000        0.000000   \n",
       "146894788  0.993338  0.647190  1.128173  ...        7.500000        0.000000   \n",
       "69480289   1.015398  0.657236  1.131625  ...        0.000000        0.000000   \n",
       "...             ...       ...       ...  ...             ...             ...   \n",
       "44582935   1.000600  0.744325  1.107611  ...        1.000000        0.000000   \n",
       "44583099   1.002846  0.720981  1.114932  ...        1.666667        0.000000   \n",
       "44583063   1.016200  0.728903  1.126354  ...        1.000000        0.000000   \n",
       "497216     1.020709  0.750006  1.121430  ...        1.000000        0.000000   \n",
       "11977753   0.996419  0.717553  1.109114  ...        0.000000        0.000000   \n",
       "\n",
       "           s3_numAroBonds  s4_numAroBonds   s34_size  s34_relSize  s34_phSize  \\\n",
       "cid                                                                             \n",
       "395575                0.0             5.0  39.333333     0.855072        9.75   \n",
       "15604702              0.0             0.0   0.000000     0.000000        0.00   \n",
       "16045493              0.0             0.0   0.000000     0.000000        0.00   \n",
       "146894788            11.0            11.0  41.000000     0.872340        8.50   \n",
       "69480289              0.0             0.0   0.000000     0.000000        0.00   \n",
       "...                   ...             ...        ...          ...         ...   \n",
       "44582935              6.0             6.0  18.000000     0.857143        3.00   \n",
       "44583099              2.0             4.0  17.333333     0.866667        2.00   \n",
       "44583063              6.0             5.0  18.000000     0.857143        2.00   \n",
       "497216                6.0             6.0  18.000000     0.857143        2.00   \n",
       "11977753              0.0             0.0   0.000000     0.000000        0.00   \n",
       "\n",
       "           s34_phRelSize  chiralMoment  chiralPhMoment  \n",
       "cid                                                     \n",
       "395575          0.211957     50.709583       12.622331  \n",
       "15604702        0.000000      0.000000        0.000000  \n",
       "16045493        0.000000      0.000000        0.000000  \n",
       "146894788       0.180851     39.957758        9.293476  \n",
       "69480289        0.000000      0.000000        0.000000  \n",
       "...                  ...           ...             ...  \n",
       "44582935        0.142857     16.492423        5.196152  \n",
       "44583099        0.100000     20.753807        3.464102  \n",
       "44583063        0.095238     16.492423        3.464102  \n",
       "497216          0.095238     16.492423        3.464102  \n",
       "11977753        0.000000      0.000000        0.000000  \n",
       "\n",
       "[1919 rows x 2202 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_NAomit_data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f561878b-84e9-41a4-aecf-49bd8626f377",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Activite</th>\n",
       "      <th>IsomericSMILES</th>\n",
       "      <th>Canonical_smiles</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cid</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>395575</th>\n",
       "      <td>1</td>\n",
       "      <td>CC1=CC(=O)OC2=C1C=CC3=C2[C@H]([C@H](C(O3)(C)C)...</td>\n",
       "      <td>Cc1cc(=O)oc2c3c(ccc12)OC(C)(C)[C@H](OC(=O)C12C...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15604702</th>\n",
       "      <td>1</td>\n",
       "      <td>CCCNS(=O)(=O)C1=C(NC2=C1C=C(C=C2)Br)C(=O)N</td>\n",
       "      <td>CCCNS(=O)(=O)c1c(C(N)=O)[nH]c2ccc(Br)cc12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16045493</th>\n",
       "      <td>1</td>\n",
       "      <td>C1=CC(=NC2=NNC(=C21)COC3=CC(=C(C(=C3)F)Cl)OC4=...</td>\n",
       "      <td>N#Cc1cc(Cl)cc(Oc2cc(OCc3[nH]nc4nc(N)ccc34)cc(F...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146894788</th>\n",
       "      <td>1</td>\n",
       "      <td>CCC(=O)CCCCC[C@@H](C1=NC=C(N1)C2=CC3=CC=CC=C3N...</td>\n",
       "      <td>CCC(=O)CCCCC[C@H](NC(=O)[C@H]1CC12CCN(Cc1ccc(O...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69480289</th>\n",
       "      <td>1</td>\n",
       "      <td>CN1C2=C(C(=C(C1=O)C(=O)NC3(CCCC3)CO)O)N=CC(=C2...</td>\n",
       "      <td>Cn1c(=O)c(C(=O)NC2(CO)CCCC2)c(O)c2ncc(Cc3ccc(F...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44582935</th>\n",
       "      <td>0</td>\n",
       "      <td>CC1=C(C(=CC=C1)C)C2N(C(=O)CS2)C3=NC=CC(=C3)Br</td>\n",
       "      <td>Cc1cccc(C)c1C1SCC(=O)N1c1cc(Br)ccn1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44583099</th>\n",
       "      <td>0</td>\n",
       "      <td>CCC1CCC1N2C(SCC2=O)C3=C(C=CC=C3Cl)Cl</td>\n",
       "      <td>CCC1CCC1N1C(=O)CSC1c1c(Cl)cccc1Cl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44583063</th>\n",
       "      <td>0</td>\n",
       "      <td>CC1=CC(=C(N1)N2C(SCC2=S)C3=C(C=CC=C3F)F)C</td>\n",
       "      <td>Cc1cc(C)c(N2C(=S)CSC2c2c(F)cccc2F)[nH]1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497216</th>\n",
       "      <td>0</td>\n",
       "      <td>CC1=NC(=CC=C1)N2C(SCC2=S)C3=C(C=CC=C3F)F</td>\n",
       "      <td>Cc1cccc(N2C(=S)CSC2c2c(F)cccc2F)n1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11977753</th>\n",
       "      <td>0</td>\n",
       "      <td>CC(C)(C#N)C1=CC=C(C=C1)N2C3=C4C=C(C=CC4=NC=C3N...</td>\n",
       "      <td>Cn1c(=O)n(-c2ccc(C(C)(C)C#N)cc2)c2c3cc(-c4cnc5...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1919 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Activite                                     IsomericSMILES  \\\n",
       "cid                                                                      \n",
       "395575            1  CC1=CC(=O)OC2=C1C=CC3=C2[C@H]([C@H](C(O3)(C)C)...   \n",
       "15604702          1         CCCNS(=O)(=O)C1=C(NC2=C1C=C(C=C2)Br)C(=O)N   \n",
       "16045493          1  C1=CC(=NC2=NNC(=C21)COC3=CC(=C(C(=C3)F)Cl)OC4=...   \n",
       "146894788         1  CCC(=O)CCCCC[C@@H](C1=NC=C(N1)C2=CC3=CC=CC=C3N...   \n",
       "69480289          1  CN1C2=C(C(=C(C1=O)C(=O)NC3(CCCC3)CO)O)N=CC(=C2...   \n",
       "...             ...                                                ...   \n",
       "44582935          0      CC1=C(C(=CC=C1)C)C2N(C(=O)CS2)C3=NC=CC(=C3)Br   \n",
       "44583099          0               CCC1CCC1N2C(SCC2=O)C3=C(C=CC=C3Cl)Cl   \n",
       "44583063          0          CC1=CC(=C(N1)N2C(SCC2=S)C3=C(C=CC=C3F)F)C   \n",
       "497216            0           CC1=NC(=CC=C1)N2C(SCC2=S)C3=C(C=CC=C3F)F   \n",
       "11977753          0  CC(C)(C#N)C1=CC=C(C=C1)N2C3=C4C=C(C=CC4=NC=C3N...   \n",
       "\n",
       "                                            Canonical_smiles  \n",
       "cid                                                           \n",
       "395575     Cc1cc(=O)oc2c3c(ccc12)OC(C)(C)[C@H](OC(=O)C12C...  \n",
       "15604702           CCCNS(=O)(=O)c1c(C(N)=O)[nH]c2ccc(Br)cc12  \n",
       "16045493   N#Cc1cc(Cl)cc(Oc2cc(OCc3[nH]nc4nc(N)ccc34)cc(F...  \n",
       "146894788  CCC(=O)CCCCC[C@H](NC(=O)[C@H]1CC12CCN(Cc1ccc(O...  \n",
       "69480289   Cn1c(=O)c(C(=O)NC2(CO)CCCC2)c(O)c2ncc(Cc3ccc(F...  \n",
       "...                                                      ...  \n",
       "44582935                 Cc1cccc(C)c1C1SCC(=O)N1c1cc(Br)ccn1  \n",
       "44583099                   CCC1CCC1N1C(=O)CSC1c1c(Cl)cccc1Cl  \n",
       "44583063             Cc1cc(C)c(N2C(=S)CSC2c2c(F)cccc2F)[nH]1  \n",
       "497216                    Cc1cccc(N2C(=S)CSC2c2c(F)cccc2F)n1  \n",
       "11977753   Cn1c(=O)n(-c2ccc(C(C)(C)C#N)cc2)c2c3cc(-c4cnc5...  \n",
       "\n",
       "[1919 rows x 3 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Raw_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "066559ff-aefe-4de1-98aa-04e6e2d7d8de",
   "metadata": {},
   "outputs": [],
   "source": [
    "y=Raw_data['Activite']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8f04d536-af36-4f80-8c82-b43e30cbf6d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "Cv_model= RepeatedStratifiedKFold(n_splits=5, n_repeats=10, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdf835fc-df29-4f95-ac06-6cc88fa619f2",
   "metadata": {},
   "source": [
    "# 1. LASSO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "07038cde-c52d-4ba2-b851-445a650f8dc7",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.139e-02, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.609e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.953e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.411e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.088e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.403e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.560e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.275e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.145e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.839e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.804e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.313e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.851e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.559e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.911e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.453e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.387e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.506e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.802e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.769e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.198e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.558e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.078e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.443e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.528e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.227e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.276e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.435e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.130e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.393e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.652e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.682e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.773e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.051e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.132e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.896e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.055e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.991e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.420e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.359e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.002e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.290e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.546e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.678e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.691e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.231e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.778e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.059e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.076e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.193e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.752e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.964e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.637e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.865e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.732e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.584e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.506e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.573e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.644e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.843e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.062e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.126e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.858e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.780e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.733e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.608e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.337e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.756e-02, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.049e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.726e-02, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.856e-02, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.406e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.169e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.790e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.610e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.822e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.299e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.142e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.892e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.915e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.920e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.438e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.321e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.093e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.897e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.266e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.002e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.102e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.365e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.380e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.484e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.740e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.317e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.614e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.623e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.452e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.463e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.891e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.158e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.792e-02, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.042e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.819e-02, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.071e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.251e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.179e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.583e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.102e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.818e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.686e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.091e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.957e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.954e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.245e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.967e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.826e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.147e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.386e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.032e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.115e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.087e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.079e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.039e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.115e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.082e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.157e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.379e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.641e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.064e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.684e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.064e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.044e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.114e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.936e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.830e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.470e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.434e-02, tolerance: 3.837e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.047e-01, tolerance: 3.837e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.965e-01, tolerance: 3.837e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.105e-01, tolerance: 3.837e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.531e-01, tolerance: 3.837e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.514e-01, tolerance: 3.837e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.069e-01, tolerance: 3.837e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.990e-01, tolerance: 3.837e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.075e-01, tolerance: 3.837e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.674e-01, tolerance: 3.837e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.421e-01, tolerance: 3.837e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.250e-01, tolerance: 3.837e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.919e-01, tolerance: 3.837e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.211e-01, tolerance: 3.837e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.835e-01, tolerance: 3.837e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.703e-01, tolerance: 3.837e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.653e-01, tolerance: 3.837e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.536e-01, tolerance: 3.837e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.500e-01, tolerance: 3.837e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.345e-01, tolerance: 3.837e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.535e-01, tolerance: 3.837e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.049e-01, tolerance: 3.837e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.314e-01, tolerance: 3.837e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.572e-01, tolerance: 3.837e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.555e-01, tolerance: 3.837e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.263e+00, tolerance: 3.837e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.735e+00, tolerance: 3.837e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.015e+00, tolerance: 3.837e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.242e+00, tolerance: 3.837e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.138e+00, tolerance: 3.837e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.054e+00, tolerance: 3.837e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.648e-02, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.918e-02, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.778e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.515e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.725e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.260e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.706e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.236e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.072e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.139e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.067e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.359e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.522e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.380e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.226e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.420e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.439e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.369e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.377e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.413e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.371e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.334e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.620e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.761e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.660e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.648e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.085e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.947e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.237e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.002e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.324e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.112e-02, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.391e-02, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.358e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.286e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.536e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.390e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.958e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.022e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.390e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.647e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.227e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.663e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.630e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.563e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.213e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.001e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.657e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.992e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.964e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.516e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.958e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.099e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.590e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.093e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.268e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.640e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.159e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.439e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.604e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.042e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.293e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.147e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.464e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.009e-02, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.974e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.718e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.467e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.587e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.920e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.321e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.346e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.110e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.156e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.320e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.914e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.072e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.473e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.838e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.491e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.203e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.636e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.526e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.935e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.875e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.043e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.129e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.158e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.260e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.715e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.238e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.633e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.800e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.074e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.209e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.571e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.627e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.903e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.056e-02, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.638e-02, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.987e-02, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.912e-02, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.661e-02, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.092e-02, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.873e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.272e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.324e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.347e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.478e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.674e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.235e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.153e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.775e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.013e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.185e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.591e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.988e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.127e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.535e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.932e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.303e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.096e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.472e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.969e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.286e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.340e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.365e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.130e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.688e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.231e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.717e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.092e-02, tolerance: 3.837e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.503e-02, tolerance: 3.837e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.198e-01, tolerance: 3.837e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.217e-01, tolerance: 3.837e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.033e-02, tolerance: 3.837e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.152e-02, tolerance: 3.837e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.920e-02, tolerance: 3.837e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.268e-01, tolerance: 3.837e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.814e-01, tolerance: 3.837e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.454e-01, tolerance: 3.837e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.346e-01, tolerance: 3.837e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.837e-01, tolerance: 3.837e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.995e-01, tolerance: 3.837e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.511e-01, tolerance: 3.837e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.041e-01, tolerance: 3.837e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.202e-01, tolerance: 3.837e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.091e+00, tolerance: 3.837e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.279e+00, tolerance: 3.837e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.074e+00, tolerance: 3.837e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.476e-01, tolerance: 3.837e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.942e-01, tolerance: 3.837e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.147e+00, tolerance: 3.837e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.043e+00, tolerance: 3.837e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.090e+00, tolerance: 3.837e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.651e-01, tolerance: 3.837e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.016e-01, tolerance: 3.837e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.064e+00, tolerance: 3.837e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.011e+00, tolerance: 3.837e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.054e+00, tolerance: 3.837e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.764e-01, tolerance: 3.837e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.089e+00, tolerance: 3.837e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.724e+00, tolerance: 3.837e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.338e+00, tolerance: 3.837e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.137e-02, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.072e-02, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.715e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.964e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.526e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.297e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.306e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.241e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.189e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.439e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.813e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.630e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.667e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.840e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.149e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.340e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.994e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.452e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.165e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.323e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.126e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.148e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.721e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.025e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.106e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.076e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.143e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.323e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.697e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.947e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.765e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.446e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.472e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.473e-02, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.068e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.813e-02, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.285e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.542e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.551e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.671e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.828e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.591e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.007e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.004e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.643e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.996e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.826e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.353e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.251e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.399e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.912e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.870e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.263e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.167e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.105e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.093e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.090e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.126e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.195e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.424e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.520e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.574e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.913e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.989e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.174e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.160e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.961e-02, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.084e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.277e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.433e-02, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.477e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.439e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.310e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.862e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.918e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.474e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.314e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.441e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.344e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.557e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.749e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.806e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.895e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.595e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.645e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.058e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.457e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.580e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.499e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.794e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.099e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.434e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.557e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.686e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.125e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.593e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.919e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.152e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.382e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.071e-02, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.100e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.225e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.035e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.354e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.943e-02, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.402e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.875e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.334e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.266e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.410e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.605e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.190e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.669e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.199e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.635e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.649e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.969e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.167e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.394e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.365e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.776e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.813e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.952e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.249e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.492e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.832e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.952e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.152e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.263e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.266e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.936e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.073e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.112e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.114e-01, tolerance: 3.837e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.268e-01, tolerance: 3.837e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.688e-01, tolerance: 3.837e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.493e-01, tolerance: 3.837e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.916e-01, tolerance: 3.837e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.843e-01, tolerance: 3.837e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.303e-01, tolerance: 3.837e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.652e-01, tolerance: 3.837e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.980e-01, tolerance: 3.837e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.432e-01, tolerance: 3.837e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.599e-01, tolerance: 3.837e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.071e-01, tolerance: 3.837e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.104e-01, tolerance: 3.837e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.508e-01, tolerance: 3.837e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.202e-01, tolerance: 3.837e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.591e-01, tolerance: 3.837e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.203e-01, tolerance: 3.837e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.216e-01, tolerance: 3.837e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.410e-01, tolerance: 3.837e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.574e-01, tolerance: 3.837e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.175e+00, tolerance: 3.837e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.580e+00, tolerance: 3.837e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.430e+00, tolerance: 3.837e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.349e+00, tolerance: 3.837e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.259e+00, tolerance: 3.837e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.251e+00, tolerance: 3.837e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.093e+00, tolerance: 3.837e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.051e+00, tolerance: 3.837e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.458e-01, tolerance: 3.837e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.425e+00, tolerance: 3.837e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.782e+00, tolerance: 3.837e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.857e+00, tolerance: 3.837e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.747e+00, tolerance: 3.837e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.447e-02, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.573e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.238e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.393e-02, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.251e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.587e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.179e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.596e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.635e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.719e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.160e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.046e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.492e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.003e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.068e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.242e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.146e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.570e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.115e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.408e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.888e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.009e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.294e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.636e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.018e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.101e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.295e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.472e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.667e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.115e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.287e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.918e-02, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.045e-02, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.058e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.677e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.141e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.013e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.324e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.148e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.239e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.639e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.628e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.107e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.302e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.476e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.335e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.011e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.197e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.020e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.582e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.520e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.314e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.150e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.293e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.206e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.368e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.618e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.663e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.863e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.145e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.471e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.436e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.669e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.838e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.192e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.981e-02, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.269e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.885e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.133e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.764e-02, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.128e-02, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.230e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.131e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.634e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.229e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.866e-02, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.165e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.040e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.744e-02, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.877e-02, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.791e-02, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.643e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.513e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.670e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.159e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.086e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.308e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.906e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.577e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.626e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.650e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.006e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.571e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.988e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.826e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.124e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.079e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.298e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.038e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.483e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.646e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.705e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.485e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.732e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.730e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.903e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.539e-02, tolerance: 3.837e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.224e-01, tolerance: 3.837e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.817e-01, tolerance: 3.837e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.162e-01, tolerance: 3.837e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.310e-01, tolerance: 3.837e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.423e-01, tolerance: 3.837e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.694e-01, tolerance: 3.837e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.899e-01, tolerance: 3.837e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.895e-01, tolerance: 3.837e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.126e-01, tolerance: 3.837e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.239e-01, tolerance: 3.837e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.873e-01, tolerance: 3.837e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.271e-01, tolerance: 3.837e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.152e-01, tolerance: 3.837e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.103e-01, tolerance: 3.837e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.211e-01, tolerance: 3.837e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.203e+00, tolerance: 3.837e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.199e+00, tolerance: 3.837e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.342e+00, tolerance: 3.837e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.614e+00, tolerance: 3.837e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.188e+00, tolerance: 3.837e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.561e+00, tolerance: 3.837e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.594e+00, tolerance: 3.837e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.476e+00, tolerance: 3.837e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.568e+00, tolerance: 3.837e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.604e+00, tolerance: 3.837e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.058e+00, tolerance: 3.837e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.981e+00, tolerance: 3.837e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.093e+00, tolerance: 3.837e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.947e+00, tolerance: 3.837e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.971e+00, tolerance: 3.837e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.412e-02, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.745e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.198e-02, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.504e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.668e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.457e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.300e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.698e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.089e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.498e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.295e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.723e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.956e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.982e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.119e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.149e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.282e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.670e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.099e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.022e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.342e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.266e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.291e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.780e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.891e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.672e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.314e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.106e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.458e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.522e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.669e-02, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.493e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.455e-02, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.196e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.989e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.447e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.045e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.148e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.398e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.923e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.790e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.651e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.033e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.347e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.639e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.480e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.239e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.516e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.809e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.923e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.970e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.979e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.654e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.390e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.061e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.103e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.183e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.348e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.421e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.993e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.181e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.843e-02, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.135e-02, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.486e-02, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.418e-02, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.989e-02, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.497e-02, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.928e-02, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.843e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.390e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.016e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.964e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.859e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.072e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.602e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.925e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.904e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.982e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.410e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.571e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.678e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.985e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.641e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.626e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.756e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.478e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.408e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.112e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.111e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.589e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.038e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.053e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.978e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.711e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.474e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.144e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.955e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.858e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.504e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.066e-02, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.729e-02, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.172e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.260e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.138e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.133e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.065e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.446e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.145e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.932e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.069e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.807e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.769e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.671e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.931e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.046e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.076e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.135e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.177e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.062e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.372e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.061e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.925e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.413e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.226e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.257e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.069e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.326e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.571e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.510e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.215e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.094e-02, tolerance: 3.837e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.339e-02, tolerance: 3.837e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.843e-02, tolerance: 3.837e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.863e-02, tolerance: 3.837e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.252e-02, tolerance: 3.837e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.234e-01, tolerance: 3.837e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.061e-01, tolerance: 3.837e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.326e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.297e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.671e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.858e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.066e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.255e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.064e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.861e-02, tolerance: 3.837e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.885e-02, tolerance: 3.837e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.033e-02, tolerance: 3.837e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.886e-02, tolerance: 3.837e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.792e-02, tolerance: 3.837e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.204e-02, tolerance: 3.837e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.335e-02, tolerance: 3.837e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.042e-01, tolerance: 3.837e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.283e-01, tolerance: 3.837e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.209e-01, tolerance: 3.837e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.547e-01, tolerance: 3.837e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.697e-01, tolerance: 3.837e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.673e-01, tolerance: 3.837e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.592e-01, tolerance: 3.837e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.984e-01, tolerance: 3.837e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.398e-01, tolerance: 3.837e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.719e-01, tolerance: 3.837e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.445e-01, tolerance: 3.837e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.703e-01, tolerance: 3.837e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.541e-01, tolerance: 3.837e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.818e-01, tolerance: 3.837e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.178e+00, tolerance: 3.837e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.629e+00, tolerance: 3.837e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.741e+00, tolerance: 3.837e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.554e+00, tolerance: 3.837e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.278e+00, tolerance: 3.837e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.027e+00, tolerance: 3.837e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.328e-01, tolerance: 3.837e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.146e+00, tolerance: 3.837e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.255e+00, tolerance: 3.837e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.485e+00, tolerance: 3.837e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.340e+00, tolerance: 3.837e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.618e+00, tolerance: 3.837e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.955e+00, tolerance: 3.837e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.631e-02, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.882e-02, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.385e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.926e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.266e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.391e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.832e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.738e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.202e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.371e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.720e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.344e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.753e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.292e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.022e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.989e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.030e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.459e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.141e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.391e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.133e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.487e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.724e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.674e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.348e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.247e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.373e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.520e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.743e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.062e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.772e-02, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.114e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.153e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.543e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.085e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.238e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.620e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.539e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.399e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.047e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.474e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.313e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.898e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.161e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.854e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.023e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.214e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.477e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.946e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.315e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.055e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.362e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.460e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.662e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.238e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.244e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.468e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.740e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.247e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.383e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.136e-02, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.753e-02, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.698e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.998e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.091e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.953e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.797e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.830e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.948e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.081e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.843e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.845e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.375e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.887e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.167e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.339e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.301e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.306e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.472e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.794e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.739e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.675e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.588e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.797e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.312e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.885e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.001e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.230e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.572e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.419e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.014e-02, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.176e-02, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.522e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.481e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.792e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.117e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.724e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.609e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.967e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.081e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.080e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.000e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.327e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.293e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.340e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.017e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.137e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.103e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.443e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.079e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.415e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.390e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.003e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.204e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.301e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.177e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.037e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.679e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.251e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.778e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.027e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.080e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.164e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.482e-02, tolerance: 3.837e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.681e-02, tolerance: 3.837e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.066e-02, tolerance: 3.837e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.961e-02, tolerance: 3.837e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.253e-01, tolerance: 3.837e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.556e-02, tolerance: 3.837e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.573e-01, tolerance: 3.837e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.649e-01, tolerance: 3.837e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.698e-01, tolerance: 3.837e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.644e-01, tolerance: 3.837e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.144e-01, tolerance: 3.837e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.639e-01, tolerance: 3.837e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.113e-01, tolerance: 3.837e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.140e-01, tolerance: 3.837e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.173e-01, tolerance: 3.837e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.128e-01, tolerance: 3.837e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.794e-01, tolerance: 3.837e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.409e-01, tolerance: 3.837e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.453e-01, tolerance: 3.837e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.276e-01, tolerance: 3.837e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.013e-01, tolerance: 3.837e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.183e+00, tolerance: 3.837e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.504e+00, tolerance: 3.837e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.555e+00, tolerance: 3.837e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.400e+00, tolerance: 3.837e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.374e+00, tolerance: 3.837e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.336e+00, tolerance: 3.837e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.222e+00, tolerance: 3.837e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.260e+00, tolerance: 3.837e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.458e+00, tolerance: 3.837e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.401e+00, tolerance: 3.837e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.557e+00, tolerance: 3.837e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.748e+00, tolerance: 3.837e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.884e+00, tolerance: 3.837e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.587e-02, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.040e-02, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.151e-02, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.928e-02, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.613e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.695e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.292e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.335e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.981e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.477e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.232e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.624e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.835e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.644e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.642e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.020e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.475e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.327e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.249e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.796e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.244e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.147e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.785e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.877e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.011e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.169e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.382e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.404e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.353e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.471e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.789e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.235e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.526e-02, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.758e-02, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.584e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.473e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.199e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.492e-02, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.459e-02, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.524e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.347e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.671e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.984e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.908e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.231e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.592e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.078e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.958e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.912e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.634e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.675e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.821e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.800e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.147e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.725e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.061e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.468e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.454e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.870e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.283e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.727e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.650e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.185e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.695e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.304e-02, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.629e-02, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.245e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.493e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.725e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.130e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.852e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.719e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.672e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.872e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.507e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.897e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.961e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.245e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.176e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.281e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.230e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.240e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.346e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.566e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.902e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.346e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.393e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.130e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.113e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.071e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.215e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.356e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.216e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.112e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.158e-02, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.878e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.710e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.995e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.088e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.269e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.216e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.221e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.647e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.371e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.180e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.933e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.541e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.195e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.140e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.422e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.066e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.732e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.699e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.973e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.914e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.124e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.066e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.428e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.788e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.058e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.093e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.075e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.653e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.159e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.392e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.456e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.453e-02, tolerance: 3.837e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.002e-01, tolerance: 3.837e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.512e-01, tolerance: 3.837e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.974e-02, tolerance: 3.837e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.271e-01, tolerance: 3.837e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.588e-01, tolerance: 3.837e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.085e-01, tolerance: 3.837e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.928e-01, tolerance: 3.837e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.993e-01, tolerance: 3.837e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.843e-01, tolerance: 3.837e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.988e-01, tolerance: 3.837e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.647e-01, tolerance: 3.837e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.298e-01, tolerance: 3.837e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.775e-01, tolerance: 3.837e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.670e-01, tolerance: 3.837e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.782e-01, tolerance: 3.837e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.741e-01, tolerance: 3.837e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.226e-01, tolerance: 3.837e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.027e+00, tolerance: 3.837e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.361e-01, tolerance: 3.837e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.511e-01, tolerance: 3.837e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.979e-01, tolerance: 3.837e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.324e-01, tolerance: 3.837e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.041e+00, tolerance: 3.837e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.892e-01, tolerance: 3.837e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.993e-01, tolerance: 3.837e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.030e+00, tolerance: 3.837e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.064e+00, tolerance: 3.837e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.038e+00, tolerance: 3.837e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.700e+00, tolerance: 3.837e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.159e+00, tolerance: 3.837e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.329e+00, tolerance: 3.837e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.949e-02, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.388e-02, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.251e-02, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.320e-02, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.698e-02, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.679e-02, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.112e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.162e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.425e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.323e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.218e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.899e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.700e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.817e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.622e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.725e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.827e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.911e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.980e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.650e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.839e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.837e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.186e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.263e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.633e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.004e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.492e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.639e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.059e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.701e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.764e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.397e-02, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.933e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.520e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.488e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.974e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.063e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.684e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.949e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.421e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.401e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.995e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.778e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.277e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.032e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.876e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.466e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.461e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.981e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.465e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.801e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.606e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.597e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.732e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.835e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.787e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.034e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.181e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.198e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.071e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.826e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.657e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.727e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.438e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.218e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.840e-02, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.852e-02, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.785e-02, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.561e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.980e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.072e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.089e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.850e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.973e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.487e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.634e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.563e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.922e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.484e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.321e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.505e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.856e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.222e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.259e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.252e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.452e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.607e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.398e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.323e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.084e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.257e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.423e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.520e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.471e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.929e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.200e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.657e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.137e-02, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.102e-02, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.593e-02, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.313e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.652e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.913e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.888e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.077e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.849e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.503e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.353e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.123e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.825e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.874e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.083e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.542e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.562e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.265e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.020e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.356e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.312e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.225e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.190e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.028e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.554e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.460e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.046e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.957e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.705e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.047e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.401e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.627e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.687e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.769e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.739e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.812e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.402e-02, tolerance: 3.837e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.887e-02, tolerance: 3.837e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.251e-01, tolerance: 3.837e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.155e-01, tolerance: 3.837e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.457e-01, tolerance: 3.837e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.946e-01, tolerance: 3.837e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.770e-01, tolerance: 3.837e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.889e-01, tolerance: 3.837e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.318e-01, tolerance: 3.837e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.650e-01, tolerance: 3.837e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.408e-01, tolerance: 3.837e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.321e-01, tolerance: 3.837e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.938e-01, tolerance: 3.837e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.697e-01, tolerance: 3.837e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.011e-01, tolerance: 3.837e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.415e-01, tolerance: 3.837e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.399e+00, tolerance: 3.837e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.607e+00, tolerance: 3.837e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.838e+00, tolerance: 3.837e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.053e+00, tolerance: 3.837e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.215e+00, tolerance: 3.837e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.326e+00, tolerance: 3.837e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.312e+00, tolerance: 3.837e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.893e+00, tolerance: 3.837e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.402e+00, tolerance: 3.837e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.283e+00, tolerance: 3.837e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.095e+00, tolerance: 3.837e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.417e+00, tolerance: 3.837e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.591e+00, tolerance: 3.837e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.867e+00, tolerance: 3.837e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.571e-02, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.631e-02, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.367e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.253e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.212e-02, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.111e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.805e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.850e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.315e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.488e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.357e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.042e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.054e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.129e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.545e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.816e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.110e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.713e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.809e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.709e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.334e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.048e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.549e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.631e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.793e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.736e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.151e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.528e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.696e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.947e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.883e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.594e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.844e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.293e-02, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.661e-02, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.142e-02, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.239e-02, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.173e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.047e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.239e-02, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.028e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.401e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.300e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.152e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.459e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.507e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.940e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.829e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.235e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.955e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.813e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.213e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.085e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.464e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.720e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.811e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.277e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.153e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.521e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.793e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.008e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.019e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.215e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.003e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.083e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.104e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.620e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.835e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.091e-02, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.722e-02, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.437e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.562e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.425e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.348e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.651e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.264e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.915e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.020e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.894e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.909e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.065e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.080e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.132e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.234e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.023e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.190e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.692e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.123e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.189e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.508e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.007e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.060e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.779e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.053e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.400e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.082e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.400e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.614e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.599e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.562e-02, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.365e-02, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.627e-02, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.017e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.249e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.819e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.234e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.382e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.111e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.861e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.578e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.912e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.533e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.741e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.982e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.445e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.715e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.651e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.131e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.378e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.493e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.481e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.079e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.430e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.888e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.821e-01, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.160e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.419e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.046e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.766e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.969e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.147e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.271e+00, tolerance: 3.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.102e-01, tolerance: 3.837e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.134e-01, tolerance: 3.837e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.797e-01, tolerance: 3.837e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.367e-01, tolerance: 3.837e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.428e-01, tolerance: 3.837e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.716e-01, tolerance: 3.837e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.061e-01, tolerance: 3.837e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.569e-01, tolerance: 3.837e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.588e-01, tolerance: 3.837e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.798e-01, tolerance: 3.837e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.395e-01, tolerance: 3.837e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.872e-01, tolerance: 3.837e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.802e-01, tolerance: 3.837e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.538e-01, tolerance: 3.837e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.224e+00, tolerance: 3.837e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.164e+00, tolerance: 3.837e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.266e+00, tolerance: 3.837e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.227e+00, tolerance: 3.837e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.188e+00, tolerance: 3.837e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.038e-01, tolerance: 3.837e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.059e+00, tolerance: 3.837e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.084e+00, tolerance: 3.837e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.378e+00, tolerance: 3.837e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.628e+00, tolerance: 3.837e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.704e+00, tolerance: 3.837e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.941e+00, tolerance: 3.837e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.224e+00, tolerance: 3.837e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.388e+00, tolerance: 3.837e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.429e+00, tolerance: 3.837e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.875e+00, tolerance: 3.837e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    }
   ],
   "source": [
    "model = make_pipeline(StandardScaler(), LassoCV(cv=Cv_model)).fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "402b4353-a400-45cc-ba23-bddd8b9e5d4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1d5cf10d4c0>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ymin, ymax =0, 1\n",
    "lasso = model[-1]\n",
    "plt.semilogx(lasso.alphas_, lasso.mse_path_, linestyle=\":\")\n",
    "plt.plot(\n",
    "    lasso.alphas_,\n",
    "    lasso.mse_path_.mean(axis=-1),\n",
    "    color=\"black\",\n",
    "    label=\"Average across the folds\",\n",
    "    linewidth=2,\n",
    ")\n",
    "plt.axvline(lasso.alpha_, linestyle=\"--\", color=\"black\", label=\"alpha: CV estimate\")\n",
    "\n",
    "plt.ylim(ymin, ymax)\n",
    "plt.xlabel(r\"$\\alpha$\")\n",
    "plt.ylabel(\"Mean square error\")\n",
    "plt.legend()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5d8e3935-01a9-4adb-8939-18d9e9c2c150",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.003307722125012585"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lasso.alpha_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0be9143b-967c-41fc-8e33-04f34afa9a5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "Cv_model= RepeatedStratifiedKFold(n_splits=5, n_repeats=10, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d10f1531-da2b-4bb6-b83b-3558bdac2339",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.649e+01, tolerance: 4.794e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1919, 374)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lsvc =  Lasso(alpha=lasso.alpha_).fit(X, y)\n",
    "model = SelectFromModel(lsvc, prefit=True)\n",
    "X_new = model.transform(X)\n",
    "X_new.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f7b74110-bf78-4a20-973b-7f81bf68a4a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>coef</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>MW</th>\n",
       "      <td>0.000008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AMW</th>\n",
       "      <td>-0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sv</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Se</th>\n",
       "      <td>-0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sp</th>\n",
       "      <td>-0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>s34_relSize</th>\n",
       "      <td>-0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>s34_phSize</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>s34_phRelSize</th>\n",
       "      <td>-0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chiralMoment</th>\n",
       "      <td>-0.001755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chiralPhMoment</th>\n",
       "      <td>-0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2202 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    coef\n",
       "MW              0.000008\n",
       "AMW            -0.000000\n",
       "Sv              0.000000\n",
       "Se             -0.000000\n",
       "Sp             -0.000000\n",
       "...                  ...\n",
       "s34_relSize    -0.000000\n",
       "s34_phSize      0.000000\n",
       "s34_phRelSize  -0.000000\n",
       "chiralMoment   -0.001755\n",
       "chiralPhMoment -0.000000\n",
       "\n",
       "[2202 rows x 1 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lasso_coef=pd.DataFrame(lsvc.coef_)\n",
    "lasso_coef.index=X_NAomit_data.columns\n",
    "lasso_coef.columns=[\"coef\"]\n",
    "lasso_coef\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "013bbde3-8f0e-4b0f-9f7f-8ba774658777",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>coef</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>MW</th>\n",
       "      <td>0.000008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SCBO</th>\n",
       "      <td>0.003110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RBN</th>\n",
       "      <td>0.003477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nH</th>\n",
       "      <td>-0.007232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>H%</th>\n",
       "      <td>0.006334</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          coef\n",
       "MW    0.000008\n",
       "SCBO  0.003110\n",
       "RBN   0.003477\n",
       "nH   -0.007232\n",
       "H%    0.006334"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lasso_coef_last=lasso_coef[(lasso_coef[\"coef\"]>0)|(lasso_coef[\"coef\"]<0)]\n",
    "lasso_coef_last.to_csv(\"./Supplementary Data S6.csv\",sep=',')\n",
    "lasso_coef_last.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c39feec4-a989-406f-b6a2-1c3428dc3b3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SCBO</th>\n",
       "      <th>RBN</th>\n",
       "      <th>nH</th>\n",
       "      <th>H%</th>\n",
       "      <th>N%</th>\n",
       "      <th>O%</th>\n",
       "      <th>nCsp3</th>\n",
       "      <th>nCsp2</th>\n",
       "      <th>max_conj_path</th>\n",
       "      <th>nCIR</th>\n",
       "      <th>...</th>\n",
       "      <th>arLevel3</th>\n",
       "      <th>s3_size</th>\n",
       "      <th>s4_size</th>\n",
       "      <th>s2_pathLength</th>\n",
       "      <th>s4_numSharedNeighbors</th>\n",
       "      <th>s2_numAroBonds</th>\n",
       "      <th>s3_numAroBonds</th>\n",
       "      <th>s4_numAroBonds</th>\n",
       "      <th>s34_size</th>\n",
       "      <th>chiralMoment</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cid</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>395575</th>\n",
       "      <td>61.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>46.511628</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>12.790698</td>\n",
       "      <td>22.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>7.333333</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>3.333333</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>39.333333</td>\n",
       "      <td>50.709583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15604702</th>\n",
       "      <td>29.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>41.176471</td>\n",
       "      <td>8.823529</td>\n",
       "      <td>8.823529</td>\n",
       "      <td>3.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16045493</th>\n",
       "      <td>46.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>28.571429</td>\n",
       "      <td>11.904762</td>\n",
       "      <td>4.761905</td>\n",
       "      <td>1.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146894788</th>\n",
       "      <td>65.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>5.319149</td>\n",
       "      <td>4.255319</td>\n",
       "      <td>18.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>11.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>39.957758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69480289</th>\n",
       "      <td>43.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>43.636364</td>\n",
       "      <td>5.454545</td>\n",
       "      <td>7.272727</td>\n",
       "      <td>8.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44582935</th>\n",
       "      <td>30.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>41.666667</td>\n",
       "      <td>5.555556</td>\n",
       "      <td>2.777778</td>\n",
       "      <td>4.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>16.492423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44583099</th>\n",
       "      <td>26.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>45.945946</td>\n",
       "      <td>2.702703</td>\n",
       "      <td>2.702703</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.500000</td>\n",
       "      <td>12.833333</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>17.333333</td>\n",
       "      <td>20.753807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44583063</th>\n",
       "      <td>29.5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>5.714286</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>16.492423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497216</th>\n",
       "      <td>30.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>36.363636</td>\n",
       "      <td>6.060606</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>16.492423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11977753</th>\n",
       "      <td>58.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>38.983051</td>\n",
       "      <td>8.474576</td>\n",
       "      <td>1.694915</td>\n",
       "      <td>4.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1919 rows × 374 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           SCBO   RBN    nH         H%         N%         O%  nCsp3  nCsp2  \\\n",
       "cid                                                                          \n",
       "395575     61.0   6.0  40.0  46.511628   0.000000  12.790698   22.0   13.0   \n",
       "15604702   29.0   5.0  14.0  41.176471   8.823529   8.823529    3.0    9.0   \n",
       "16045493   46.0   5.0  12.0  28.571429  11.904762   4.761905    1.0   18.0   \n",
       "146894788  65.0  15.0  47.0  50.000000   5.319149   4.255319   18.0   20.0   \n",
       "69480289   43.0   5.0  24.0  43.636364   5.454545   7.272727    8.0   15.0   \n",
       "...         ...   ...   ...        ...        ...        ...    ...    ...   \n",
       "44582935   30.0   2.0  15.0  41.666667   5.555556   2.777778    4.0   12.0   \n",
       "44583099   26.0   3.0  17.0  45.945946   2.702703   2.702703    8.0    7.0   \n",
       "44583063   29.5   2.0  14.0  40.000000   5.714286   0.000000    4.0   11.0   \n",
       "497216     30.0   2.0  12.0  36.363636   6.060606   0.000000    3.0   12.0   \n",
       "11977753   58.0   3.0  23.0  38.983051   8.474576   1.694915    4.0   25.0   \n",
       "\n",
       "           max_conj_path  nCIR  ...  arLevel3    s3_size    s4_size  \\\n",
       "cid                             ...                                   \n",
       "395575              10.0  12.0  ...  0.666667   7.333333  32.000000   \n",
       "15604702            11.0   3.0  ...  0.000000   0.000000   0.000000   \n",
       "16045493             9.0   5.0  ...  0.000000   0.000000   0.000000   \n",
       "146894788           15.0   7.0  ...  1.000000  16.000000  25.000000   \n",
       "69480289            12.0   5.0  ...  0.000000   0.000000   0.000000   \n",
       "...                  ...   ...  ...       ...        ...        ...   \n",
       "44582935             6.0   3.0  ...  4.000000   8.000000  10.000000   \n",
       "44583099             6.0   3.0  ...  1.000000   4.500000  12.833333   \n",
       "44583063             6.0   3.0  ...  4.000000   8.000000  10.000000   \n",
       "497216               6.0   3.0  ...  4.000000   8.000000  10.000000   \n",
       "11977753            20.0  10.0  ...  0.000000   0.000000   0.000000   \n",
       "\n",
       "           s2_pathLength  s4_numSharedNeighbors  s2_numAroBonds  \\\n",
       "cid                                                               \n",
       "395575          3.333333               0.666667        1.333333   \n",
       "15604702        0.000000               0.000000        0.000000   \n",
       "16045493        0.000000               0.000000        0.000000   \n",
       "146894788       4.000000               0.000000        0.000000   \n",
       "69480289        0.000000               0.000000        0.000000   \n",
       "...                  ...                    ...             ...   \n",
       "44582935        2.000000               0.000000        0.000000   \n",
       "44583099        2.000000               0.333333        0.000000   \n",
       "44583063        2.000000               0.000000        0.000000   \n",
       "497216          2.000000               0.000000        0.000000   \n",
       "11977753        0.000000               0.000000        0.000000   \n",
       "\n",
       "           s3_numAroBonds  s4_numAroBonds   s34_size  chiralMoment  \n",
       "cid                                                                 \n",
       "395575                0.0             5.0  39.333333     50.709583  \n",
       "15604702              0.0             0.0   0.000000      0.000000  \n",
       "16045493              0.0             0.0   0.000000      0.000000  \n",
       "146894788            11.0            11.0  41.000000     39.957758  \n",
       "69480289              0.0             0.0   0.000000      0.000000  \n",
       "...                   ...             ...        ...           ...  \n",
       "44582935              6.0             6.0  18.000000     16.492423  \n",
       "44583099              2.0             4.0  17.333333     20.753807  \n",
       "44583063              6.0             5.0  18.000000     16.492423  \n",
       "497216                6.0             6.0  18.000000     16.492423  \n",
       "11977753              0.0             0.0   0.000000      0.000000  \n",
       "\n",
       "[1919 rows x 374 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Lasso_data=X_NAomit_data[X_NAomit_data.columns[model.get_support()]]\n",
    "Lasso_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "afcca2a8-9ce0-4c49-88db-c3265e6374fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "Lasso_data.to_csv('./Lasso_data.csv',encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c9c9a6da-b735-4689-897c-972cd30e5f64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SCBO</th>\n",
       "      <th>RBN</th>\n",
       "      <th>nH</th>\n",
       "      <th>H%</th>\n",
       "      <th>N%</th>\n",
       "      <th>O%</th>\n",
       "      <th>nCsp3</th>\n",
       "      <th>nCsp2</th>\n",
       "      <th>max_conj_path</th>\n",
       "      <th>nCIR</th>\n",
       "      <th>...</th>\n",
       "      <th>arLevel3</th>\n",
       "      <th>s3_size</th>\n",
       "      <th>s4_size</th>\n",
       "      <th>s2_pathLength</th>\n",
       "      <th>s4_numSharedNeighbors</th>\n",
       "      <th>s2_numAroBonds</th>\n",
       "      <th>s3_numAroBonds</th>\n",
       "      <th>s4_numAroBonds</th>\n",
       "      <th>s34_size</th>\n",
       "      <th>chiralMoment</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cid</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>395575</th>\n",
       "      <td>0.102616</td>\n",
       "      <td>0.039735</td>\n",
       "      <td>0.127090</td>\n",
       "      <td>0.663154</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.423077</td>\n",
       "      <td>0.192982</td>\n",
       "      <td>0.078313</td>\n",
       "      <td>0.238095</td>\n",
       "      <td>0.164384</td>\n",
       "      <td>...</td>\n",
       "      <td>0.091954</td>\n",
       "      <td>0.099513</td>\n",
       "      <td>0.133305</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.173913</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.132743</td>\n",
       "      <td>0.125368</td>\n",
       "      <td>0.125542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15604702</th>\n",
       "      <td>0.038229</td>\n",
       "      <td>0.033113</td>\n",
       "      <td>0.040134</td>\n",
       "      <td>0.577084</td>\n",
       "      <td>0.352941</td>\n",
       "      <td>0.291855</td>\n",
       "      <td>0.026316</td>\n",
       "      <td>0.054217</td>\n",
       "      <td>0.261905</td>\n",
       "      <td>0.041096</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16045493</th>\n",
       "      <td>0.072435</td>\n",
       "      <td>0.033113</td>\n",
       "      <td>0.033445</td>\n",
       "      <td>0.373731</td>\n",
       "      <td>0.476190</td>\n",
       "      <td>0.157509</td>\n",
       "      <td>0.008772</td>\n",
       "      <td>0.108434</td>\n",
       "      <td>0.214286</td>\n",
       "      <td>0.068493</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146894788</th>\n",
       "      <td>0.110664</td>\n",
       "      <td>0.099338</td>\n",
       "      <td>0.150502</td>\n",
       "      <td>0.719431</td>\n",
       "      <td>0.212766</td>\n",
       "      <td>0.140753</td>\n",
       "      <td>0.157895</td>\n",
       "      <td>0.120482</td>\n",
       "      <td>0.357143</td>\n",
       "      <td>0.095890</td>\n",
       "      <td>...</td>\n",
       "      <td>0.137931</td>\n",
       "      <td>0.217119</td>\n",
       "      <td>0.104144</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.658986</td>\n",
       "      <td>0.292035</td>\n",
       "      <td>0.130680</td>\n",
       "      <td>0.098923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69480289</th>\n",
       "      <td>0.066398</td>\n",
       "      <td>0.033113</td>\n",
       "      <td>0.073579</td>\n",
       "      <td>0.616769</td>\n",
       "      <td>0.218182</td>\n",
       "      <td>0.240559</td>\n",
       "      <td>0.070175</td>\n",
       "      <td>0.090361</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.068493</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44582935</th>\n",
       "      <td>0.040241</td>\n",
       "      <td>0.013245</td>\n",
       "      <td>0.043478</td>\n",
       "      <td>0.584992</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.091880</td>\n",
       "      <td>0.035088</td>\n",
       "      <td>0.072289</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.041096</td>\n",
       "      <td>...</td>\n",
       "      <td>0.551724</td>\n",
       "      <td>0.108559</td>\n",
       "      <td>0.041658</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.359447</td>\n",
       "      <td>0.159292</td>\n",
       "      <td>0.057372</td>\n",
       "      <td>0.040830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44583099</th>\n",
       "      <td>0.032193</td>\n",
       "      <td>0.019868</td>\n",
       "      <td>0.050167</td>\n",
       "      <td>0.654028</td>\n",
       "      <td>0.108108</td>\n",
       "      <td>0.089397</td>\n",
       "      <td>0.070175</td>\n",
       "      <td>0.042169</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.041096</td>\n",
       "      <td>...</td>\n",
       "      <td>0.137931</td>\n",
       "      <td>0.061065</td>\n",
       "      <td>0.053461</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.016667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.119816</td>\n",
       "      <td>0.106195</td>\n",
       "      <td>0.055247</td>\n",
       "      <td>0.051380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44583063</th>\n",
       "      <td>0.039235</td>\n",
       "      <td>0.013245</td>\n",
       "      <td>0.040134</td>\n",
       "      <td>0.558104</td>\n",
       "      <td>0.228571</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.035088</td>\n",
       "      <td>0.066265</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.041096</td>\n",
       "      <td>...</td>\n",
       "      <td>0.551724</td>\n",
       "      <td>0.108559</td>\n",
       "      <td>0.041658</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.359447</td>\n",
       "      <td>0.132743</td>\n",
       "      <td>0.057372</td>\n",
       "      <td>0.040830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497216</th>\n",
       "      <td>0.040241</td>\n",
       "      <td>0.013245</td>\n",
       "      <td>0.033445</td>\n",
       "      <td>0.499440</td>\n",
       "      <td>0.242424</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.026316</td>\n",
       "      <td>0.072289</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.041096</td>\n",
       "      <td>...</td>\n",
       "      <td>0.551724</td>\n",
       "      <td>0.108559</td>\n",
       "      <td>0.041658</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.359447</td>\n",
       "      <td>0.159292</td>\n",
       "      <td>0.057372</td>\n",
       "      <td>0.040830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11977753</th>\n",
       "      <td>0.096579</td>\n",
       "      <td>0.019868</td>\n",
       "      <td>0.070234</td>\n",
       "      <td>0.541698</td>\n",
       "      <td>0.338983</td>\n",
       "      <td>0.056063</td>\n",
       "      <td>0.035088</td>\n",
       "      <td>0.150602</td>\n",
       "      <td>0.476190</td>\n",
       "      <td>0.136986</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1919 rows × 374 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               SCBO       RBN        nH        H%        N%        O%  \\\n",
       "cid                                                                     \n",
       "395575     0.102616  0.039735  0.127090  0.663154  0.000000  0.423077   \n",
       "15604702   0.038229  0.033113  0.040134  0.577084  0.352941  0.291855   \n",
       "16045493   0.072435  0.033113  0.033445  0.373731  0.476190  0.157509   \n",
       "146894788  0.110664  0.099338  0.150502  0.719431  0.212766  0.140753   \n",
       "69480289   0.066398  0.033113  0.073579  0.616769  0.218182  0.240559   \n",
       "...             ...       ...       ...       ...       ...       ...   \n",
       "44582935   0.040241  0.013245  0.043478  0.584992  0.222222  0.091880   \n",
       "44583099   0.032193  0.019868  0.050167  0.654028  0.108108  0.089397   \n",
       "44583063   0.039235  0.013245  0.040134  0.558104  0.228571  0.000000   \n",
       "497216     0.040241  0.013245  0.033445  0.499440  0.242424  0.000000   \n",
       "11977753   0.096579  0.019868  0.070234  0.541698  0.338983  0.056063   \n",
       "\n",
       "              nCsp3     nCsp2  max_conj_path      nCIR  ...  arLevel3  \\\n",
       "cid                                                     ...             \n",
       "395575     0.192982  0.078313       0.238095  0.164384  ...  0.091954   \n",
       "15604702   0.026316  0.054217       0.261905  0.041096  ...  0.000000   \n",
       "16045493   0.008772  0.108434       0.214286  0.068493  ...  0.000000   \n",
       "146894788  0.157895  0.120482       0.357143  0.095890  ...  0.137931   \n",
       "69480289   0.070175  0.090361       0.285714  0.068493  ...  0.000000   \n",
       "...             ...       ...            ...       ...  ...       ...   \n",
       "44582935   0.035088  0.072289       0.142857  0.041096  ...  0.551724   \n",
       "44583099   0.070175  0.042169       0.142857  0.041096  ...  0.137931   \n",
       "44583063   0.035088  0.066265       0.142857  0.041096  ...  0.551724   \n",
       "497216     0.026316  0.072289       0.142857  0.041096  ...  0.551724   \n",
       "11977753   0.035088  0.150602       0.476190  0.136986  ...  0.000000   \n",
       "\n",
       "            s3_size   s4_size  s2_pathLength  s4_numSharedNeighbors  \\\n",
       "cid                                                                   \n",
       "395575     0.099513  0.133305       0.416667               0.033333   \n",
       "15604702   0.000000  0.000000       0.000000               0.000000   \n",
       "16045493   0.000000  0.000000       0.000000               0.000000   \n",
       "146894788  0.217119  0.104144       0.500000               0.000000   \n",
       "69480289   0.000000  0.000000       0.000000               0.000000   \n",
       "...             ...       ...            ...                    ...   \n",
       "44582935   0.108559  0.041658       0.250000               0.000000   \n",
       "44583099   0.061065  0.053461       0.250000               0.016667   \n",
       "44583063   0.108559  0.041658       0.250000               0.000000   \n",
       "497216     0.108559  0.041658       0.250000               0.000000   \n",
       "11977753   0.000000  0.000000       0.000000               0.000000   \n",
       "\n",
       "           s2_numAroBonds  s3_numAroBonds  s4_numAroBonds  s34_size  \\\n",
       "cid                                                                   \n",
       "395575           0.173913        0.000000        0.132743  0.125368   \n",
       "15604702         0.000000        0.000000        0.000000  0.000000   \n",
       "16045493         0.000000        0.000000        0.000000  0.000000   \n",
       "146894788        0.000000        0.658986        0.292035  0.130680   \n",
       "69480289         0.000000        0.000000        0.000000  0.000000   \n",
       "...                   ...             ...             ...       ...   \n",
       "44582935         0.000000        0.359447        0.159292  0.057372   \n",
       "44583099         0.000000        0.119816        0.106195  0.055247   \n",
       "44583063         0.000000        0.359447        0.132743  0.057372   \n",
       "497216           0.000000        0.359447        0.159292  0.057372   \n",
       "11977753         0.000000        0.000000        0.000000  0.000000   \n",
       "\n",
       "           chiralMoment  \n",
       "cid                      \n",
       "395575         0.125542  \n",
       "15604702       0.000000  \n",
       "16045493       0.000000  \n",
       "146894788      0.098923  \n",
       "69480289       0.000000  \n",
       "...                 ...  \n",
       "44582935       0.040830  \n",
       "44583099       0.051380  \n",
       "44583063       0.040830  \n",
       "497216         0.040830  \n",
       "11977753       0.000000  \n",
       "\n",
       "[1919 rows x 374 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Scale data\n",
    "Scaler = preprocessing.MinMaxScaler() #StandardScaler\n",
    "Transformer =Scaler.fit(Lasso_data)\n",
    "X_scaled_data=Transformer.transform(Lasso_data)\n",
    "X_scaled_data =pd.DataFrame(X_scaled_data)\n",
    "X_scaled_data.columns=Lasso_data.columns\n",
    "X_scaled_data.index=Raw_data.index\n",
    "\n",
    "joblib.dump(Transformer, './Lasso_Scaler_transformer.pkl')\n",
    "\n",
    "X_scaled_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "2c0643c9-e6ee-441f-a6e6-f8951935a04a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Model_results(Model_clf,X_test,y,Cv_model):\n",
    "    Model_scores= cross_validate(estimator=Model_clf, X=X_test, y=y, cv=Cv_model,scoring=( 'accuracy','f1','precision','recall','roc_auc'), return_train_score=True)\n",
    "    Model_score= cross_validate(estimator=Model_clf, X=X_test, y=y, cv=Cv_model,scoring=( 'accuracy','f1','precision','recall','roc_auc'), return_train_score=False)\n",
    "#Accuracy\n",
    "    Model_Accuracy_test_mean=Model_scores['test_accuracy'].mean()\n",
    "    Model_Accuracy_test_se=(Model_scores['test_accuracy'].std()/math.sqrt(len(Model_scores['test_accuracy']))) \n",
    "    Model_Accuracy_train_mean=Model_scores['train_accuracy'].mean()\n",
    "    Model_Accuracy_train_se=(Model_scores['train_accuracy'].std()/math.sqrt(len(Model_scores['train_accuracy']))) \n",
    "#f1\n",
    "    Model_f1_mean=Model_score['test_f1'].mean()\n",
    "    Model_f1_se=(Model_score['test_f1'].std()/math.sqrt(len(Model_score['test_f1']))) \n",
    "#precision\n",
    "    Model_precision_mean=Model_score['test_precision'].mean()\n",
    "    Model_precision_se=(Model_score['test_precision'].std()/math.sqrt(len(Model_score['test_precision']))) \n",
    "#recall\n",
    "    Model_recall_mean=Model_score['test_recall'].mean()\n",
    "    Model_recall_se=(Model_score['test_recall'].std()/math.sqrt(len(Model_score['test_recall']))) \n",
    "#roc_auc\n",
    "    Model_roc_auc_mean=Model_score['test_roc_auc'].mean()\n",
    "    Model_roc_auc_se=(Model_score['test_roc_auc'].std()/math.sqrt(len(Model_score['test_roc_auc']))) \n",
    "    Model = {'Mean':[Model_Accuracy_test_mean,Model_Accuracy_train_mean,Model_f1_mean,Model_precision_mean,Model_recall_mean,Model_roc_auc_mean],\n",
    "        'Se':[Model_Accuracy_test_se,Model_Accuracy_train_se,Model_f1_se,Model_precision_se,Model_recall_se,Model_roc_auc_se]}\n",
    "    Model = pd.DataFrame(Model, index=['Accuracy_test','Accuracy_train','F1 Score','Precision','Recall','Roc_auc']) # 这里设定了 index 个数要和列表长度一致\n",
    "    return Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "0e49d1bb-d5f4-4e7f-a620-a943c578fba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setting the KFold \n",
    "Cv_optuna= RepeatedStratifiedKFold(n_splits=5, n_repeats=10, random_state=0)\n",
    "Cv_model= RepeatedStratifiedKFold(n_splits=5, n_repeats=10, random_state=0)\n",
    "Cv_RFECV= RepeatedStratifiedKFold(n_splits=5, n_repeats=10, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "8b74394b-d874-4115-b66e-0bac0d514965",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data pre-processing of models\n",
    "X=np.array(X_scaled_data)\n",
    "y=Raw_data['Activite'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d026e47-e8b2-467a-a5a0-866a1888a801",
   "metadata": {},
   "source": [
    "## 1.1 DT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e5dd9da6-318e-4a8f-8b6e-46380439376d",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf=DecisionTreeClassifier(random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "9d7e67d4-b288-4270-be5d-1598f117e05d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mean</th>\n",
       "      <th>Se</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Accuracy_test</th>\n",
       "      <td>0.817353</td>\n",
       "      <td>0.002615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Accuracy_train</th>\n",
       "      <td>0.993682</td>\n",
       "      <td>0.000167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1 Score</th>\n",
       "      <td>0.821724</td>\n",
       "      <td>0.002704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Precision</th>\n",
       "      <td>0.822451</td>\n",
       "      <td>0.002934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recall</th>\n",
       "      <td>0.821740</td>\n",
       "      <td>0.004261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Roc_auc</th>\n",
       "      <td>0.819720</td>\n",
       "      <td>0.002597</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Mean        Se\n",
       "Accuracy_test   0.817353  0.002615\n",
       "Accuracy_train  0.993682  0.000167\n",
       "F1 Score        0.821724  0.002704\n",
       "Precision       0.822451  0.002934\n",
       "Recall          0.821740  0.004261\n",
       "Roc_auc         0.819720  0.002597"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Model1 （4175 descriptors）\n",
    "Model1_clf=clf\n",
    "#Model1\n",
    "Model1=Model_results(Model1_clf,X,y,Cv_model)\n",
    "Model1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "7bb0633b-59c6-4ad7-afb1-e241f713f990",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2024-11-14 23:45:38,729]\u001b[0m A new study created in memory with name: no-name-19addbfd-b2cb-48ed-bdf3-25f0e87ec37f\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 23:45:41,619]\u001b[0m Trial 0 finished with value: 0.7331957136640557 and parameters: {'max_depth': 4, 'max_features': 17, 'min_samples_split': 16}. Best is trial 0 with value: 0.7331957136640557.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 23:45:41,867]\u001b[0m Trial 1 finished with value: 0.7287653666231505 and parameters: {'max_depth': 4, 'max_features': 14, 'min_samples_split': 17}. Best is trial 0 with value: 0.7331957136640557.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 23:45:42,116]\u001b[0m Trial 2 finished with value: 0.7290261912532636 and parameters: {'max_depth': 4, 'max_features': 19, 'min_samples_split': 25}. Best is trial 0 with value: 0.7331957136640557.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 23:45:42,333]\u001b[0m Trial 3 finished with value: 0.7264153611836381 and parameters: {'max_depth': 4, 'max_features': 18, 'min_samples_split': 14}. Best is trial 0 with value: 0.7331957136640557.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 23:45:42,555]\u001b[0m Trial 4 finished with value: 0.7380948107049607 and parameters: {'max_depth': 4, 'max_features': 20, 'min_samples_split': 3}. Best is trial 4 with value: 0.7380948107049607.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 23:45:42,775]\u001b[0m Trial 5 finished with value: 0.7148491895126198 and parameters: {'max_depth': 3, 'max_features': 10, 'min_samples_split': 21}. Best is trial 4 with value: 0.7380948107049607.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 23:45:43,008]\u001b[0m Trial 6 finished with value: 0.7542459475630985 and parameters: {'max_depth': 5, 'max_features': 19, 'min_samples_split': 25}. Best is trial 6 with value: 0.7542459475630985.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 23:45:43,224]\u001b[0m Trial 7 finished with value: 0.7581002502175805 and parameters: {'max_depth': 5, 'max_features': 15, 'min_samples_split': 20}. Best is trial 7 with value: 0.7581002502175805.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 23:45:43,456]\u001b[0m Trial 8 finished with value: 0.6817074630113141 and parameters: {'max_depth': 3, 'max_features': 17, 'min_samples_split': 5}. Best is trial 7 with value: 0.7581002502175805.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 23:45:43,673]\u001b[0m Trial 9 finished with value: 0.751224570278503 and parameters: {'max_depth': 5, 'max_features': 15, 'min_samples_split': 11}. Best is trial 7 with value: 0.7581002502175805.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 23:45:43,906]\u001b[0m Trial 10 finished with value: 0.7533100794168841 and parameters: {'max_depth': 5, 'max_features': 12, 'min_samples_split': 9}. Best is trial 7 with value: 0.7581002502175805.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 23:45:44,122]\u001b[0m Trial 11 finished with value: 0.7548709475630982 and parameters: {'max_depth': 5, 'max_features': 13, 'min_samples_split': 25}. Best is trial 7 with value: 0.7581002502175805.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 23:45:44,358]\u001b[0m Trial 12 finished with value: 0.7565867058311576 and parameters: {'max_depth': 5, 'max_features': 13, 'min_samples_split': 20}. Best is trial 7 with value: 0.7581002502175805.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 23:45:44,588]\u001b[0m Trial 13 finished with value: 0.7535150130548303 and parameters: {'max_depth': 5, 'max_features': 11, 'min_samples_split': 20}. Best is trial 7 with value: 0.7581002502175805.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 23:45:44,821]\u001b[0m Trial 14 finished with value: 0.7581002502175805 and parameters: {'max_depth': 5, 'max_features': 15, 'min_samples_split': 20}. Best is trial 7 with value: 0.7581002502175805.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 23:45:44,951]\u001b[0m Trial 15 finished with value: 0.7593512021322888 and parameters: {'max_depth': 5, 'max_features': 16, 'min_samples_split': 18}. Best is trial 15 with value: 0.7593512021322888.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 23:45:45,182]\u001b[0m Trial 16 finished with value: 0.7602398825065273 and parameters: {'max_depth': 5, 'max_features': 16, 'min_samples_split': 17}. Best is trial 16 with value: 0.7602398825065273.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 23:45:45,430]\u001b[0m Trial 17 finished with value: 0.6817074630113141 and parameters: {'max_depth': 3, 'max_features': 17, 'min_samples_split': 11}. Best is trial 16 with value: 0.7602398825065273.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 23:45:45,659]\u001b[0m Trial 18 finished with value: 0.7639411988685815 and parameters: {'max_depth': 5, 'max_features': 16, 'min_samples_split': 16}. Best is trial 18 with value: 0.7639411988685815.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 23:45:45,891]\u001b[0m Trial 19 finished with value: 0.726421480635335 and parameters: {'max_depth': 4, 'max_features': 16, 'min_samples_split': 14}. Best is trial 18 with value: 0.7639411988685815.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 23:45:46,115]\u001b[0m Trial 20 finished with value: 0.7311088446475196 and parameters: {'max_depth': 4, 'max_features': 14, 'min_samples_split': 8}. Best is trial 18 with value: 0.7639411988685815.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 23:45:46,346]\u001b[0m Trial 21 finished with value: 0.763575255657093 and parameters: {'max_depth': 5, 'max_features': 16, 'min_samples_split': 15}. Best is trial 18 with value: 0.7639411988685815.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 23:45:46,579]\u001b[0m Trial 22 finished with value: 0.763575255657093 and parameters: {'max_depth': 5, 'max_features': 16, 'min_samples_split': 15}. Best is trial 18 with value: 0.7639411988685815.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 23:45:46,814]\u001b[0m Trial 23 finished with value: 0.7546630221932115 and parameters: {'max_depth': 5, 'max_features': 18, 'min_samples_split': 12}. Best is trial 18 with value: 0.7639411988685815.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 23:45:47,092]\u001b[0m Trial 24 finished with value: 0.7513787804612707 and parameters: {'max_depth': 5, 'max_features': 14, 'min_samples_split': 15}. Best is trial 18 with value: 0.7639411988685815.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 23:45:47,375]\u001b[0m Trial 25 finished with value: 0.7642538348563969 and parameters: {'max_depth': 5, 'max_features': 16, 'min_samples_split': 13}. Best is trial 25 with value: 0.7642538348563969.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 23:45:47,652]\u001b[0m Trial 26 finished with value: 0.7605515665796344 and parameters: {'max_depth': 5, 'max_features': 18, 'min_samples_split': 9}. Best is trial 25 with value: 0.7642538348563969.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 23:45:47,916]\u001b[0m Trial 27 finished with value: 0.7421518711923412 and parameters: {'max_depth': 4, 'max_features': 15, 'min_samples_split': 12}. Best is trial 25 with value: 0.7642538348563969.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 23:45:48,197]\u001b[0m Trial 28 finished with value: 0.7584691851610096 and parameters: {'max_depth': 5, 'max_features': 17, 'min_samples_split': 6}. Best is trial 25 with value: 0.7642538348563969.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 23:45:48,465]\u001b[0m Trial 29 finished with value: 0.7262120593994779 and parameters: {'max_depth': 4, 'max_features': 16, 'min_samples_split': 22}. Best is trial 25 with value: 0.7642538348563969.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 23:45:48,657]\u001b[0m Trial 30 finished with value: 0.7620649749782418 and parameters: {'max_depth': 5, 'max_features': 17, 'min_samples_split': 18}. Best is trial 25 with value: 0.7642538348563969.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 23:45:48,931]\u001b[0m Trial 31 finished with value: 0.7639411988685815 and parameters: {'max_depth': 5, 'max_features': 16, 'min_samples_split': 16}. Best is trial 25 with value: 0.7642538348563969.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 23:45:49,210]\u001b[0m Trial 32 finished with value: 0.7517980308964317 and parameters: {'max_depth': 5, 'max_features': 15, 'min_samples_split': 16}. Best is trial 25 with value: 0.7642538348563969.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 23:45:49,474]\u001b[0m Trial 33 finished with value: 0.751954688859878 and parameters: {'max_depth': 5, 'max_features': 14, 'min_samples_split': 13}. Best is trial 25 with value: 0.7642538348563969.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 23:45:49,754]\u001b[0m Trial 34 finished with value: 0.7488261531766754 and parameters: {'max_depth': 5, 'max_features': 18, 'min_samples_split': 17}. Best is trial 25 with value: 0.7642538348563969.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 23:45:50,033]\u001b[0m Trial 35 finished with value: 0.7299605635335074 and parameters: {'max_depth': 4, 'max_features': 19, 'min_samples_split': 15}. Best is trial 25 with value: 0.7642538348563969.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 23:45:50,297]\u001b[0m Trial 36 finished with value: 0.7642538348563969 and parameters: {'max_depth': 5, 'max_features': 16, 'min_samples_split': 13}. Best is trial 25 with value: 0.7642538348563969.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 23:45:50,546]\u001b[0m Trial 37 finished with value: 0.7505930428633596 and parameters: {'max_depth': 4, 'max_features': 13, 'min_samples_split': 13}. Best is trial 25 with value: 0.7642538348563969.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 23:45:50,824]\u001b[0m Trial 38 finished with value: 0.7334561303307222 and parameters: {'max_depth': 4, 'max_features': 17, 'min_samples_split': 10}. Best is trial 25 with value: 0.7642538348563969.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 23:45:51,103]\u001b[0m Trial 39 finished with value: 0.7576895670147954 and parameters: {'max_depth': 5, 'max_features': 20, 'min_samples_split': 23}. Best is trial 25 with value: 0.7642538348563969.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 23:45:51,368]\u001b[0m Trial 40 finished with value: 0.7114644527850303 and parameters: {'max_depth': 3, 'max_features': 18, 'min_samples_split': 18}. Best is trial 25 with value: 0.7642538348563969.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 23:45:51,684]\u001b[0m Trial 41 finished with value: 0.7639411988685815 and parameters: {'max_depth': 5, 'max_features': 16, 'min_samples_split': 16}. Best is trial 25 with value: 0.7642538348563969.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 23:45:51,971]\u001b[0m Trial 42 finished with value: 0.7517980308964317 and parameters: {'max_depth': 5, 'max_features': 15, 'min_samples_split': 16}. Best is trial 25 with value: 0.7642538348563969.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 23:45:52,254]\u001b[0m Trial 43 finished with value: 0.7634732647954742 and parameters: {'max_depth': 5, 'max_features': 16, 'min_samples_split': 12}. Best is trial 25 with value: 0.7642538348563969.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 23:45:52,533]\u001b[0m Trial 44 finished with value: 0.7621684617058311 and parameters: {'max_depth': 5, 'max_features': 17, 'min_samples_split': 14}. Best is trial 25 with value: 0.7642538348563969.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 23:45:52,797]\u001b[0m Trial 45 finished with value: 0.7503354819408181 and parameters: {'max_depth': 5, 'max_features': 14, 'min_samples_split': 19}. Best is trial 25 with value: 0.7642538348563969.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 23:45:53,061]\u001b[0m Trial 46 finished with value: 0.7639411988685815 and parameters: {'max_depth': 5, 'max_features': 16, 'min_samples_split': 16}. Best is trial 25 with value: 0.7642538348563969.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 23:45:53,343]\u001b[0m Trial 47 finished with value: 0.7507037369451698 and parameters: {'max_depth': 5, 'max_features': 15, 'min_samples_split': 13}. Best is trial 25 with value: 0.7642538348563969.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 23:45:53,621]\u001b[0m Trial 48 finished with value: 0.7556541013925152 and parameters: {'max_depth': 5, 'max_features': 19, 'min_samples_split': 11}. Best is trial 25 with value: 0.7642538348563969.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 23:45:53,889]\u001b[0m Trial 49 finished with value: 0.7630030189295038 and parameters: {'max_depth': 5, 'max_features': 17, 'min_samples_split': 17}. Best is trial 25 with value: 0.7642538348563969.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 23:45:54,167]\u001b[0m Trial 50 finished with value: 0.7625866242384681 and parameters: {'max_depth': 5, 'max_features': 16, 'min_samples_split': 2}. Best is trial 25 with value: 0.7642538348563969.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 23:45:54,443]\u001b[0m Trial 51 finished with value: 0.7639411988685815 and parameters: {'max_depth': 5, 'max_features': 16, 'min_samples_split': 16}. Best is trial 25 with value: 0.7642538348563969.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 23:45:54,724]\u001b[0m Trial 52 finished with value: 0.7572159214534377 and parameters: {'max_depth': 5, 'max_features': 15, 'min_samples_split': 19}. Best is trial 25 with value: 0.7642538348563969.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 23:45:55,000]\u001b[0m Trial 53 finished with value: 0.7621684617058311 and parameters: {'max_depth': 5, 'max_features': 17, 'min_samples_split': 14}. Best is trial 25 with value: 0.7642538348563969.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 23:45:55,267]\u001b[0m Trial 54 finished with value: 0.7639411988685815 and parameters: {'max_depth': 5, 'max_features': 16, 'min_samples_split': 16}. Best is trial 25 with value: 0.7642538348563969.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 23:45:55,546]\u001b[0m Trial 55 finished with value: 0.7550271975630983 and parameters: {'max_depth': 5, 'max_features': 15, 'min_samples_split': 17}. Best is trial 25 with value: 0.7642538348563969.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 23:45:55,839]\u001b[0m Trial 56 finished with value: 0.7642523389904265 and parameters: {'max_depth': 5, 'max_features': 16, 'min_samples_split': 14}. Best is trial 25 with value: 0.7642538348563969.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 23:45:56,116]\u001b[0m Trial 57 finished with value: 0.7520048683637945 and parameters: {'max_depth': 5, 'max_features': 18, 'min_samples_split': 14}. Best is trial 25 with value: 0.7642538348563969.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 23:45:56,398]\u001b[0m Trial 58 finished with value: 0.7641480363359444 and parameters: {'max_depth': 5, 'max_features': 16, 'min_samples_split': 10}. Best is trial 25 with value: 0.7642538348563969.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 23:45:56,660]\u001b[0m Trial 59 finished with value: 0.7003645833333333 and parameters: {'max_depth': 3, 'max_features': 15, 'min_samples_split': 10}. Best is trial 25 with value: 0.7642538348563969.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 23:45:56,939]\u001b[0m Trial 60 finished with value: 0.7392932713228895 and parameters: {'max_depth': 5, 'max_features': 10, 'min_samples_split': 8}. Best is trial 25 with value: 0.7642538348563969.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 23:45:57,089]\u001b[0m Trial 61 finished with value: 0.7634732647954742 and parameters: {'max_depth': 5, 'max_features': 16, 'min_samples_split': 12}. Best is trial 25 with value: 0.7642538348563969.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 23:45:57,374]\u001b[0m Trial 62 finished with value: 0.7632622117058311 and parameters: {'max_depth': 5, 'max_features': 17, 'min_samples_split': 15}. Best is trial 25 with value: 0.7642538348563969.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 23:45:57,651]\u001b[0m Trial 63 finished with value: 0.7641480363359444 and parameters: {'max_depth': 5, 'max_features': 16, 'min_samples_split': 10}. Best is trial 25 with value: 0.7642538348563969.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 23:45:57,914]\u001b[0m Trial 64 finished with value: 0.7625333170147954 and parameters: {'max_depth': 5, 'max_features': 16, 'min_samples_split': 7}. Best is trial 25 with value: 0.7642538348563969.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 23:45:58,193]\u001b[0m Trial 65 finished with value: 0.7611258431244561 and parameters: {'max_depth': 5, 'max_features': 17, 'min_samples_split': 10}. Best is trial 25 with value: 0.7642538348563969.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 23:45:58,458]\u001b[0m Trial 66 finished with value: 0.751224570278503 and parameters: {'max_depth': 5, 'max_features': 15, 'min_samples_split': 11}. Best is trial 25 with value: 0.7642538348563969.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 23:45:58,735]\u001b[0m Trial 67 finished with value: 0.7633678742384682 and parameters: {'max_depth': 5, 'max_features': 16, 'min_samples_split': 9}. Best is trial 25 with value: 0.7642538348563969.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 23:45:59,016]\u001b[0m Trial 68 finished with value: 0.7642538348563969 and parameters: {'max_depth': 5, 'max_features': 16, 'min_samples_split': 13}. Best is trial 25 with value: 0.7642538348563969.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 23:45:59,276]\u001b[0m Trial 69 finished with value: 0.7441442286771107 and parameters: {'max_depth': 5, 'max_features': 14, 'min_samples_split': 5}. Best is trial 25 with value: 0.7642538348563969.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 23:45:59,556]\u001b[0m Trial 70 finished with value: 0.7614915143603134 and parameters: {'max_depth': 5, 'max_features': 17, 'min_samples_split': 13}. Best is trial 25 with value: 0.7642538348563969.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 23:45:59,851]\u001b[0m Trial 71 finished with value: 0.7634732647954742 and parameters: {'max_depth': 5, 'max_features': 16, 'min_samples_split': 12}. Best is trial 25 with value: 0.7642538348563969.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 23:46:00,116]\u001b[0m Trial 72 finished with value: 0.7636809181897302 and parameters: {'max_depth': 5, 'max_features': 16, 'min_samples_split': 11}. Best is trial 25 with value: 0.7642538348563969.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 23:46:00,397]\u001b[0m Trial 73 finished with value: 0.7507037369451698 and parameters: {'max_depth': 5, 'max_features': 15, 'min_samples_split': 13}. Best is trial 25 with value: 0.7642538348563969.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 23:46:00,661]\u001b[0m Trial 74 finished with value: 0.7632622117058311 and parameters: {'max_depth': 5, 'max_features': 17, 'min_samples_split': 15}. Best is trial 25 with value: 0.7642538348563969.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 23:46:00,928]\u001b[0m Trial 75 finished with value: 0.7642523389904265 and parameters: {'max_depth': 5, 'max_features': 16, 'min_samples_split': 14}. Best is trial 25 with value: 0.7642538348563969.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 23:46:01,192]\u001b[0m Trial 76 finished with value: 0.7548694516971279 and parameters: {'max_depth': 5, 'max_features': 11, 'min_samples_split': 14}. Best is trial 25 with value: 0.7642538348563969.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 23:46:01,471]\u001b[0m Trial 77 finished with value: 0.7510159649695387 and parameters: {'max_depth': 5, 'max_features': 15, 'min_samples_split': 9}. Best is trial 25 with value: 0.7642538348563969.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 23:46:01,764]\u001b[0m Trial 78 finished with value: 0.7613339044821585 and parameters: {'max_depth': 5, 'max_features': 17, 'min_samples_split': 11}. Best is trial 25 with value: 0.7642538348563969.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 23:46:02,074]\u001b[0m Trial 79 finished with value: 0.7284006473020017 and parameters: {'max_depth': 4, 'max_features': 16, 'min_samples_split': 8}. Best is trial 25 with value: 0.7642538348563969.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 23:46:02,339]\u001b[0m Trial 80 finished with value: 0.7634732647954742 and parameters: {'max_depth': 5, 'max_features': 16, 'min_samples_split': 12}. Best is trial 25 with value: 0.7642538348563969.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 23:46:02,632]\u001b[0m Trial 81 finished with value: 0.763575255657093 and parameters: {'max_depth': 5, 'max_features': 16, 'min_samples_split': 15}. Best is trial 25 with value: 0.7642538348563969.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 23:46:02,926]\u001b[0m Trial 82 finished with value: 0.7507037369451698 and parameters: {'max_depth': 5, 'max_features': 15, 'min_samples_split': 13}. Best is trial 25 with value: 0.7642538348563969.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 23:46:03,233]\u001b[0m Trial 83 finished with value: 0.751120267624021 and parameters: {'max_depth': 5, 'max_features': 15, 'min_samples_split': 10}. Best is trial 25 with value: 0.7642538348563969.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 23:46:03,496]\u001b[0m Trial 84 finished with value: 0.7593512021322888 and parameters: {'max_depth': 5, 'max_features': 16, 'min_samples_split': 18}. Best is trial 25 with value: 0.7642538348563969.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 23:46:03,773]\u001b[0m Trial 85 finished with value: 0.7621684617058311 and parameters: {'max_depth': 5, 'max_features': 17, 'min_samples_split': 14}. Best is trial 25 with value: 0.7642538348563969.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 23:46:04,052]\u001b[0m Trial 86 finished with value: 0.7642523389904265 and parameters: {'max_depth': 5, 'max_features': 16, 'min_samples_split': 14}. Best is trial 25 with value: 0.7642538348563969.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 23:46:04,316]\u001b[0m Trial 87 finished with value: 0.7634732647954742 and parameters: {'max_depth': 5, 'max_features': 16, 'min_samples_split': 12}. Best is trial 25 with value: 0.7642538348563969.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 23:46:04,578]\u001b[0m Trial 88 finished with value: 0.7621684617058311 and parameters: {'max_depth': 5, 'max_features': 17, 'min_samples_split': 14}. Best is trial 25 with value: 0.7642538348563969.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 23:46:04,859]\u001b[0m Trial 89 finished with value: 0.7507037369451698 and parameters: {'max_depth': 5, 'max_features': 15, 'min_samples_split': 13}. Best is trial 25 with value: 0.7642538348563969.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 23:46:05,154]\u001b[0m Trial 90 finished with value: 0.7632622117058311 and parameters: {'max_depth': 5, 'max_features': 17, 'min_samples_split': 15}. Best is trial 25 with value: 0.7642538348563969.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 23:46:05,417]\u001b[0m Trial 91 finished with value: 0.7639411988685815 and parameters: {'max_depth': 5, 'max_features': 16, 'min_samples_split': 16}. Best is trial 25 with value: 0.7642538348563969.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 23:46:05,713]\u001b[0m Trial 92 finished with value: 0.763575255657093 and parameters: {'max_depth': 5, 'max_features': 16, 'min_samples_split': 15}. Best is trial 25 with value: 0.7642538348563969.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 23:46:05,993]\u001b[0m Trial 93 finished with value: 0.7642538348563969 and parameters: {'max_depth': 5, 'max_features': 16, 'min_samples_split': 13}. Best is trial 25 with value: 0.7642538348563969.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 23:46:06,273]\u001b[0m Trial 94 finished with value: 0.7507037369451698 and parameters: {'max_depth': 5, 'max_features': 15, 'min_samples_split': 13}. Best is trial 25 with value: 0.7642538348563969.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 23:46:06,536]\u001b[0m Trial 95 finished with value: 0.7642523389904265 and parameters: {'max_depth': 5, 'max_features': 16, 'min_samples_split': 14}. Best is trial 25 with value: 0.7642538348563969.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 23:46:06,802]\u001b[0m Trial 96 finished with value: 0.7634732647954742 and parameters: {'max_depth': 5, 'max_features': 16, 'min_samples_split': 12}. Best is trial 25 with value: 0.7642538348563969.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 23:46:07,085]\u001b[0m Trial 97 finished with value: 0.7642523389904265 and parameters: {'max_depth': 5, 'max_features': 16, 'min_samples_split': 14}. Best is trial 25 with value: 0.7642538348563969.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 23:46:07,364]\u001b[0m Trial 98 finished with value: 0.7621684617058311 and parameters: {'max_depth': 5, 'max_features': 17, 'min_samples_split': 14}. Best is trial 25 with value: 0.7642538348563969.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 23:46:07,643]\u001b[0m Trial 99 finished with value: 0.7520048683637945 and parameters: {'max_depth': 5, 'max_features': 18, 'min_samples_split': 14}. Best is trial 25 with value: 0.7642538348563969.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "#Tuning hyperparameters\n",
    "#Step 1. Define an objective function to be maximized.\n",
    "def objective(trial):\n",
    "    param = {\n",
    "        'max_depth': trial.suggest_int('max_depth',3,5,1),\n",
    "        'max_features' : trial.suggest_int(\"max_features\",10,20,1),\n",
    "        'min_samples_split':trial.suggest_int('min_samples_split',2,25,1)\n",
    "    }\n",
    "    model = DecisionTreeClassifier(**param,random_state=1)\n",
    "\n",
    " \n",
    "# Step 2: Scoring method:\n",
    "    score = model_selection.cross_val_score(model, X, y, n_jobs=12, scoring=\"accuracy\",cv=Cv_optuna)\n",
    "    accuracy = score.mean()\n",
    "    return accuracy\n",
    " \n",
    "# Step 3: Running it\n",
    "study = optuna.create_study(direction=\"maximize\",sampler=optuna.samplers.TPESampler(seed=0))\n",
    "study.optimize(objective, n_trials=100, show_progress_bar=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "28ac7c97-6c21-4117-add1-12a7be2e8f2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best parameters are : \n",
      "{'max_depth': 5, 'max_features': 16, 'min_samples_split': 13}\n"
     ]
    }
   ],
   "source": [
    "# Getting the best parameters:\n",
    "print(f\"The best parameters are : \\n{study.best_params}\")\n",
    "# Setting the best model\n",
    "clf =DecisionTreeClassifier(max_depth = study.best_params['max_depth']\n",
    "              ,max_features = study.best_params['max_features']\n",
    "              #,n_estimators = study.best_params['n_estimators']\n",
    "              #,learning_rate = study.best_params['learning_rate']\n",
    "              ,min_samples_split= study.best_params['min_samples_split']\n",
    "              ,random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "c0b71e00-d630-4d2b-b1d4-a79589e02288",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mean</th>\n",
       "      <th>Se</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Accuracy_test</th>\n",
       "      <td>0.764254</td>\n",
       "      <td>0.003068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Accuracy_train</th>\n",
       "      <td>0.813105</td>\n",
       "      <td>0.001778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1 Score</th>\n",
       "      <td>0.774221</td>\n",
       "      <td>0.003315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Precision</th>\n",
       "      <td>0.761988</td>\n",
       "      <td>0.004693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recall</th>\n",
       "      <td>0.790473</td>\n",
       "      <td>0.007365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Roc_auc</th>\n",
       "      <td>0.820102</td>\n",
       "      <td>0.003247</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Mean        Se\n",
       "Accuracy_test   0.764254  0.003068\n",
       "Accuracy_train  0.813105  0.001778\n",
       "F1 Score        0.774221  0.003315\n",
       "Precision       0.761988  0.004693\n",
       "Recall          0.790473  0.007365\n",
       "Roc_auc         0.820102  0.003247"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Model2\n",
    "Model2=Model_results(clf,X,y,Cv_model)\n",
    "Model2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "e4359628-316f-47c6-bdef-b9471932492e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th>Method</th>\n",
       "      <th colspan=\"4\" halign=\"left\">DT</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model</th>\n",
       "      <th colspan=\"2\" halign=\"left\">Model 1</th>\n",
       "      <th colspan=\"2\" halign=\"left\">Model 2</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Values</th>\n",
       "      <th>Mean</th>\n",
       "      <th>Se</th>\n",
       "      <th>Mean</th>\n",
       "      <th>Se</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Accuracy_test</th>\n",
       "      <td>0.817353</td>\n",
       "      <td>0.002615</td>\n",
       "      <td>0.764254</td>\n",
       "      <td>0.003068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Accuracy_train</th>\n",
       "      <td>0.993682</td>\n",
       "      <td>0.000167</td>\n",
       "      <td>0.813105</td>\n",
       "      <td>0.001778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1 Score</th>\n",
       "      <td>0.821724</td>\n",
       "      <td>0.002704</td>\n",
       "      <td>0.774221</td>\n",
       "      <td>0.003315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Precision</th>\n",
       "      <td>0.822451</td>\n",
       "      <td>0.002934</td>\n",
       "      <td>0.761988</td>\n",
       "      <td>0.004693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recall</th>\n",
       "      <td>0.821740</td>\n",
       "      <td>0.004261</td>\n",
       "      <td>0.790473</td>\n",
       "      <td>0.007365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Roc_auc</th>\n",
       "      <td>0.819720</td>\n",
       "      <td>0.002597</td>\n",
       "      <td>0.820102</td>\n",
       "      <td>0.003247</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Method                DT                              \n",
       "Model            Model 1             Model 2          \n",
       "Values              Mean        Se      Mean        Se\n",
       "Accuracy_test   0.817353  0.002615  0.764254  0.003068\n",
       "Accuracy_train  0.993682  0.000167  0.813105  0.001778\n",
       "F1 Score        0.821724  0.002704  0.774221  0.003315\n",
       "Precision       0.822451  0.002934  0.761988  0.004693\n",
       "Recall          0.821740  0.004261  0.790473  0.007365\n",
       "Roc_auc         0.819720  0.002597  0.820102  0.003247"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Saving the data of model performance\n",
    "Model_data=pd.concat([Model1,Model2],axis=1)\n",
    "Model_data.columns = [['DT']*4,['Model 1','Model 1', 'Model 2','Model 2'], ['Mean', 'Se', 'Mean', 'Se']]  \n",
    "Model_data.columns.names=['Method','Model','Values']\n",
    "Model_data.to_csv(\"./DT_model_lasso_data.csv\",sep=',')\n",
    "Model_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6047485d-89ab-471b-b393-08d893b317bc",
   "metadata": {},
   "source": [
    "## 1.2 LR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "7e67efc5-4154-43ea-ad89-57f6ba68ec1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf=LogisticRegression(solver='liblinear',random_state=0,dual=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "4e72f778-0bc0-4da2-b17d-d66357ab161c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mean</th>\n",
       "      <th>Se</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Accuracy_test</th>\n",
       "      <td>0.824075</td>\n",
       "      <td>0.002447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Accuracy_train</th>\n",
       "      <td>0.850326</td>\n",
       "      <td>0.000674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1 Score</th>\n",
       "      <td>0.829883</td>\n",
       "      <td>0.002364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Precision</th>\n",
       "      <td>0.823421</td>\n",
       "      <td>0.003054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recall</th>\n",
       "      <td>0.837086</td>\n",
       "      <td>0.003535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Roc_auc</th>\n",
       "      <td>0.896388</td>\n",
       "      <td>0.001783</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Mean        Se\n",
       "Accuracy_test   0.824075  0.002447\n",
       "Accuracy_train  0.850326  0.000674\n",
       "F1 Score        0.829883  0.002364\n",
       "Precision       0.823421  0.003054\n",
       "Recall          0.837086  0.003535\n",
       "Roc_auc         0.896388  0.001783"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Model1 \n",
    "Model1_clf=clf\n",
    "#Model1\n",
    "Model1=Model_results(Model1_clf,X,y,Cv_model)\n",
    "Model1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "b9338635-62a3-4fe9-912b-6acc77ef994a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2024-11-14 23:46:16,051]\u001b[0m A new study created in memory with name: no-name-91fcac0e-9aa0-4183-869d-5f89a254bd29\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 23:46:19,174]\u001b[0m Trial 0 finished with value: 0.8106840187119235 and parameters: {'logreg_c': 0.3177840006884068, 'l1_ratio': 0.7482920440979423, 'max_iter': 100}. Best is trial 0 with value: 0.8106840187119235.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 23:46:19,860]\u001b[0m Trial 1 finished with value: 0.7931228241949522 and parameters: {'logreg_c': 0.0651621545821569, 'l1_ratio': 0.23208030173540176, 'max_iter': 275}. Best is trial 0 with value: 0.8106840187119235.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 23:46:20,358]\u001b[0m Trial 2 finished with value: 0.7643563696692776 and parameters: {'logreg_c': 0.013108749615263334, 'l1_ratio': 0.411004654338743, 'max_iter': 854}. Best is trial 0 with value: 0.8106840187119235.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 23:46:21,587]\u001b[0m Trial 3 finished with value: 0.8328289545256744 and parameters: {'logreg_c': 1.7096232052870346, 'l1_ratio': 0.4772750629629653, 'max_iter': 1402}. Best is trial 3 with value: 0.8328289545256744.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 23:46:22,148]\u001b[0m Trial 4 finished with value: 0.7698795147954743 and parameters: {'logreg_c': 0.016854407828169382, 'l1_ratio': 0.8903056927518509, 'max_iter': 152}. Best is trial 3 with value: 0.8328289545256744.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 23:46:24,441]\u001b[0m Trial 5 finished with value: 0.8531005221932113 and parameters: {'logreg_c': 10.539137268289434, 'l1_ratio': 0.4755743221304143, 'max_iter': 1162}. Best is trial 5 with value: 0.8531005221932113.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 23:46:25,082]\u001b[0m Trial 6 finished with value: 0.7413736129242819 and parameters: {'logreg_c': 0.006955392321661603, 'l1_ratio': 0.2782913401763909, 'max_iter': 1622}. Best is trial 5 with value: 0.8531005221932113.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 23:46:42,919]\u001b[0m Trial 7 finished with value: 0.860970137075718 and parameters: {'logreg_c': 645.0144652189372, 'l1_ratio': 0.38208176034331853, 'max_iter': 1416}. Best is trial 7 with value: 0.860970137075718.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 23:46:55,250]\u001b[0m Trial 8 finished with value: 0.8628985802872063 and parameters: {'logreg_c': 181.27374779133626, 'l1_ratio': 0.9051459971534626, 'max_iter': 261}. Best is trial 8 with value: 0.8628985802872063.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 23:46:55,775]\u001b[0m Trial 9 finished with value: 0.6728974923846823 and parameters: {'logreg_c': 0.001715255021408637, 'l1_ratio': 0.25284737760811204, 'max_iter': 1769}. Best is trial 8 with value: 0.8628985802872063.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 23:47:17,421]\u001b[0m Trial 10 finished with value: 0.8607612597911227 and parameters: {'logreg_c': 909.7939268284556, 'l1_ratio': 0.9808743317423054, 'max_iter': 644}. Best is trial 8 with value: 0.8628985802872063.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 23:47:38,117]\u001b[0m Trial 11 finished with value: 0.8609695931244559 and parameters: {'logreg_c': 843.2126062012203, 'l1_ratio': 0.7030698971831799, 'max_iter': 1245}. Best is trial 8 with value: 0.8628985802872063.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 23:47:46,129]\u001b[0m Trial 12 finished with value: 0.8629478078764145 and parameters: {'logreg_c': 59.11595197989844, 'l1_ratio': 0.6400356094425337, 'max_iter': 550}. Best is trial 12 with value: 0.8629478078764145.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 23:47:53,813]\u001b[0m Trial 13 finished with value: 0.8625308692341166 and parameters: {'logreg_c': 49.41418653406042, 'l1_ratio': 0.6598915883402704, 'max_iter': 612}. Best is trial 12 with value: 0.8629478078764145.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 23:48:02,096]\u001b[0m Trial 14 finished with value: 0.862895996518712 and parameters: {'logreg_c': 64.27084846652764, 'l1_ratio': 0.853478162796463, 'max_iter': 462}. Best is trial 12 with value: 0.8629478078764145.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 23:48:11,151]\u001b[0m Trial 15 finished with value: 0.863052790469974 and parameters: {'logreg_c': 77.51797518020945, 'l1_ratio': 0.6107409469002143, 'max_iter': 812}. Best is trial 15 with value: 0.863052790469974.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 23:48:15,077]\u001b[0m Trial 16 finished with value: 0.8482015611401219 and parameters: {'logreg_c': 5.9457571140752075, 'l1_ratio': 0.6000539592896698, 'max_iter': 909}. Best is trial 15 with value: 0.863052790469974.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 23:48:19,675]\u001b[0m Trial 17 finished with value: 0.855132452132289 and parameters: {'logreg_c': 11.655220360644389, 'l1_ratio': 0.7683639981317943, 'max_iter': 866}. Best is trial 15 with value: 0.863052790469974.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 23:48:21,381]\u001b[0m Trial 18 finished with value: 0.8222525021758048 and parameters: {'logreg_c': 0.8193313488397277, 'l1_ratio': 0.10522615486078746, 'max_iter': 554}. Best is trial 15 with value: 0.863052790469974.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 23:48:29,828]\u001b[0m Trial 19 finished with value: 0.8627929177545692 and parameters: {'logreg_c': 83.91714442084333, 'l1_ratio': 0.595568553434625, 'max_iter': 1008}. Best is trial 15 with value: 0.863052790469974.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 23:48:32,504]\u001b[0m Trial 20 finished with value: 0.8570603513925151 and parameters: {'logreg_c': 16.431058285985642, 'l1_ratio': 0.5281980330503036, 'max_iter': 748}. Best is trial 15 with value: 0.863052790469974.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 23:48:38,747]\u001b[0m Trial 21 finished with value: 0.8632112162750218 and parameters: {'logreg_c': 215.18416861403514, 'l1_ratio': 0.8331526957550845, 'max_iter': 348}. Best is trial 21 with value: 0.8632112162750218.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 23:48:45,092]\u001b[0m Trial 22 finished with value: 0.8632110802872063 and parameters: {'logreg_c': 232.36501538065536, 'l1_ratio': 0.7992433517399191, 'max_iter': 380}. Best is trial 21 with value: 0.8632112162750218.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 23:48:51,916]\u001b[0m Trial 23 finished with value: 0.8623255276327241 and parameters: {'logreg_c': 268.8517412808408, 'l1_ratio': 0.8066872721255497, 'max_iter': 360}. Best is trial 21 with value: 0.8632112162750218.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 23:48:58,516]\u001b[0m Trial 24 finished with value: 0.8626902469538729 and parameters: {'logreg_c': 262.1339603348062, 'l1_ratio': 0.9470062922512792, 'max_iter': 399}. Best is trial 21 with value: 0.8632112162750218.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 23:49:01,477]\u001b[0m Trial 25 finished with value: 0.8606546453437772 and parameters: {'logreg_c': 26.552249948975508, 'l1_ratio': 0.8211690718345999, 'max_iter': 740}. Best is trial 21 with value: 0.8632112162750218.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 23:49:02,717]\u001b[0m Trial 26 finished with value: 0.8379881962576153 and parameters: {'logreg_c': 2.3537835431923035, 'l1_ratio': 0.7132620448029874, 'max_iter': 274}. Best is trial 21 with value: 0.8632112162750218.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 23:49:10,022]\u001b[0m Trial 27 finished with value: 0.8613351283724978 and parameters: {'logreg_c': 324.42083332448703, 'l1_ratio': 0.7842573637668387, 'max_iter': 490}. Best is trial 21 with value: 0.8632112162750218.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 23:49:15,179]\u001b[0m Trial 28 finished with value: 0.8629507996083551 and parameters: {'logreg_c': 125.26268187615959, 'l1_ratio': 0.7049195065117762, 'max_iter': 711}. Best is trial 21 with value: 0.8632112162750218.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 23:49:15,912]\u001b[0m Trial 29 finished with value: 0.8062025402523935 and parameters: {'logreg_c': 0.2249183886409124, 'l1_ratio': 0.8925118342926769, 'max_iter': 186}. Best is trial 21 with value: 0.8632112162750218.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 23:49:19,711]\u001b[0m Trial 30 finished with value: 0.8607590839860749 and parameters: {'logreg_c': 27.428489696554706, 'l1_ratio': 0.989090737470458, 'max_iter': 110}. Best is trial 21 with value: 0.8632112162750218.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 23:49:27,736]\u001b[0m Trial 31 finished with value: 0.8628979003481289 and parameters: {'logreg_c': 115.91730897433078, 'l1_ratio': 0.7266949071998023, 'max_iter': 727}. Best is trial 21 with value: 0.8632112162750218.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 23:49:30,075]\u001b[0m Trial 32 finished with value: 0.8448142406440382 and parameters: {'logreg_c': 4.548905427574035, 'l1_ratio': 0.6650181540631543, 'max_iter': 1041}. Best is trial 21 with value: 0.8632112162750218.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 23:49:41,962]\u001b[0m Trial 33 finished with value: 0.8612830450391645 and parameters: {'logreg_c': 381.8645748331064, 'l1_ratio': 0.5569679148712418, 'max_iter': 354}. Best is trial 21 with value: 0.8632112162750218.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 23:49:51,789]\u001b[0m Trial 34 finished with value: 0.8627945496083551 and parameters: {'logreg_c': 141.94359359869537, 'l1_ratio': 0.762472704468212, 'max_iter': 675}. Best is trial 21 with value: 0.8632112162750218.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 23:49:57,069]\u001b[0m Trial 35 finished with value: 0.8614889305918189 and parameters: {'logreg_c': 37.885510035562, 'l1_ratio': 0.832993911586591, 'max_iter': 912}. Best is trial 21 with value: 0.8632112162750218.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 23:50:07,292]\u001b[0m Trial 36 finished with value: 0.8627416503481288 and parameters: {'logreg_c': 118.62738838741458, 'l1_ratio': 0.6990333728012765, 'max_iter': 784}. Best is trial 21 with value: 0.8632112162750218.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 23:50:08,521]\u001b[0m Trial 37 finished with value: 0.8008867765448217 and parameters: {'logreg_c': 0.15987250103783857, 'l1_ratio': 0.48898342406861994, 'max_iter': 411}. Best is trial 21 with value: 0.8632112162750218.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 23:50:23,963]\u001b[0m Trial 38 finished with value: 0.8613347204090515 and parameters: {'logreg_c': 472.7946991848175, 'l1_ratio': 0.3822967755718629, 'max_iter': 562}. Best is trial 21 with value: 0.8632112162750218.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 23:50:25,975]\u001b[0m Trial 39 finished with value: 0.8206369669277633 and parameters: {'logreg_c': 0.7429464195916894, 'l1_ratio': 0.6090304837655894, 'max_iter': 1261}. Best is trial 21 with value: 0.8632112162750218.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 23:50:30,756]\u001b[0m Trial 40 finished with value: 0.8470028285465623 and parameters: {'logreg_c': 5.460483493913305, 'l1_ratio': 0.8687233880107574, 'max_iter': 215}. Best is trial 21 with value: 0.8632112162750218.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 23:50:41,270]\u001b[0m Trial 41 finished with value: 0.862739746518712 and parameters: {'logreg_c': 65.4882236382812, 'l1_ratio': 0.6491450376648766, 'max_iter': 464}. Best is trial 21 with value: 0.8632112162750218.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 23:50:56,326]\u001b[0m Trial 42 finished with value: 0.8630546942993909 and parameters: {'logreg_c': 188.02766564766364, 'l1_ratio': 0.5436519632402355, 'max_iter': 528}. Best is trial 21 with value: 0.8632112162750218.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 23:51:13,216]\u001b[0m Trial 43 finished with value: 0.8630548302872063 and parameters: {'logreg_c': 208.4758430369493, 'l1_ratio': 0.43554755217053065, 'max_iter': 332}. Best is trial 21 with value: 0.8632112162750218.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 23:51:38,878]\u001b[0m Trial 44 finished with value: 0.8607091764577894 and parameters: {'logreg_c': 903.5440841533907, 'l1_ratio': 0.44549353817256626, 'max_iter': 296}. Best is trial 21 with value: 0.8632112162750218.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 23:51:53,290]\u001b[0m Trial 45 finished with value: 0.862846224978242 and parameters: {'logreg_c': 180.51216879613423, 'l1_ratio': 0.34912353726261525, 'max_iter': 1996}. Best is trial 21 with value: 0.8632112162750218.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 23:52:13,888]\u001b[0m Trial 46 finished with value: 0.8610741677545692 and parameters: {'logreg_c': 504.7638209501808, 'l1_ratio': 0.5406211110953112, 'max_iter': 305}. Best is trial 21 with value: 0.8632112162750218.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 23:52:20,476]\u001b[0m Trial 47 finished with value: 0.8587267460835509 and parameters: {'logreg_c': 20.16174643659089, 'l1_ratio': 0.3133112848586829, 'max_iter': 186}. Best is trial 21 with value: 0.8632112162750218.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 23:52:36,137]\u001b[0m Trial 48 finished with value: 0.8633673302872062 and parameters: {'logreg_c': 228.85947403332256, 'l1_ratio': 0.42723562125140574, 'max_iter': 505}. Best is trial 48 with value: 0.8633673302872062.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 23:52:52,380]\u001b[0m Trial 49 finished with value: 0.8633673302872062 and parameters: {'logreg_c': 219.19884193435894, 'l1_ratio': 0.4422909015257003, 'max_iter': 102}. Best is trial 48 with value: 0.8633673302872062.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 23:52:53,278]\u001b[0m Trial 50 finished with value: 0.7758720898607484 and parameters: {'logreg_c': 0.023614953433099054, 'l1_ratio': 0.4143018474142547, 'max_iter': 114}. Best is trial 48 with value: 0.8633673302872062.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 23:53:10,154]\u001b[0m Trial 51 finished with value: 0.8621690056570931 and parameters: {'logreg_c': 282.22805404542726, 'l1_ratio': 0.500760174937726, 'max_iter': 242}. Best is trial 48 with value: 0.8633673302872062.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 23:53:32,526]\u001b[0m Trial 52 finished with value: 0.8611787423846823 and parameters: {'logreg_c': 585.2595130643534, 'l1_ratio': 0.4293638552327336, 'max_iter': 500}. Best is trial 48 with value: 0.8633673302872062.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 23:53:47,979]\u001b[0m Trial 53 finished with value: 0.8632632996083552 and parameters: {'logreg_c': 193.32703901046668, 'l1_ratio': 0.4514675038369653, 'max_iter': 596}. Best is trial 48 with value: 0.8633673302872062.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 23:53:57,245]\u001b[0m Trial 54 finished with value: 0.8626347639251521 and parameters: {'logreg_c': 47.43558892701643, 'l1_ratio': 0.37056470308709316, 'max_iter': 606}. Best is trial 48 with value: 0.8633673302872062.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 23:54:20,065]\u001b[0m Trial 55 finished with value: 0.8610222204090513 and parameters: {'logreg_c': 672.7430819137792, 'l1_ratio': 0.18174978197929598, 'max_iter': 397}. Best is trial 48 with value: 0.8633673302872062.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 23:54:36,257]\u001b[0m Trial 56 finished with value: 0.8630549662750218 and parameters: {'logreg_c': 210.60639968490327, 'l1_ratio': 0.4466911935257306, 'max_iter': 325}. Best is trial 48 with value: 0.8633673302872062.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 23:54:47,991]\u001b[0m Trial 57 finished with value: 0.8629494397302002 and parameters: {'logreg_c': 92.87875038307139, 'l1_ratio': 0.3169407513835401, 'max_iter': 450}. Best is trial 48 with value: 0.8633673302872062.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 23:54:53,190]\u001b[0m Trial 58 finished with value: 0.8535695441688425 and parameters: {'logreg_c': 10.703331704795588, 'l1_ratio': 0.3903575857653465, 'max_iter': 169}. Best is trial 48 with value: 0.8633673302872062.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 23:55:19,133]\u001b[0m Trial 59 finished with value: 0.8602406984334203 and parameters: {'logreg_c': 994.6102312753405, 'l1_ratio': 0.5065839588670411, 'max_iter': 623}. Best is trial 48 with value: 0.8633673302872062.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 23:55:19,764]\u001b[0m Trial 60 finished with value: 0.6676336760226284 and parameters: {'logreg_c': 0.0014647914843692897, 'l1_ratio': 0.46771631152466997, 'max_iter': 241}. Best is trial 48 with value: 0.8633673302872062.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 23:55:35,073]\u001b[0m Trial 61 finished with value: 0.8630548302872063 and parameters: {'logreg_c': 205.53851802196175, 'l1_ratio': 0.44515421173356784, 'max_iter': 332}. Best is trial 48 with value: 0.8633673302872062.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 23:55:43,511]\u001b[0m Trial 62 finished with value: 0.8613846279373368 and parameters: {'logreg_c': 36.16720924569143, 'l1_ratio': 0.4648118056553878, 'max_iter': 374}. Best is trial 48 with value: 0.8633673302872062.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 23:56:01,543]\u001b[0m Trial 63 finished with value: 0.8616477643603132 and parameters: {'logreg_c': 310.36966177884545, 'l1_ratio': 0.33956679476783674, 'max_iter': 302}. Best is trial 48 with value: 0.8633673302872062.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 23:56:12,624]\u001b[0m Trial 64 finished with value: 0.8630526544821584 and parameters: {'logreg_c': 76.58910496715636, 'l1_ratio': 0.5703713750963937, 'max_iter': 104}. Best is trial 48 with value: 0.8633673302872062.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 23:56:13,274]\u001b[0m Trial 65 finished with value: 0.6944752230200174 and parameters: {'logreg_c': 0.002893514383320615, 'l1_ratio': 0.2732928938614104, 'max_iter': 435}. Best is trial 48 with value: 0.8633673302872062.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 23:56:33,086]\u001b[0m Trial 66 finished with value: 0.8611263870757181 and parameters: {'logreg_c': 439.00278257323015, 'l1_ratio': 0.9410775935215873, 'max_iter': 573}. Best is trial 48 with value: 0.8633673302872062.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 23:56:47,781]\u001b[0m Trial 67 finished with value: 0.8629505276327241 and parameters: {'logreg_c': 164.32377915972245, 'l1_ratio': 0.46418201808844783, 'max_iter': 1629}. Best is trial 48 with value: 0.8633673302872062.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 23:57:04,399]\u001b[0m Trial 68 finished with value: 0.8633153829416885 and parameters: {'logreg_c': 237.6111657193989, 'l1_ratio': 0.41508995201616505, 'max_iter': 224}. Best is trial 48 with value: 0.8633673302872062.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 23:57:23,379]\u001b[0m Trial 69 finished with value: 0.8611784704090515 and parameters: {'logreg_c': 412.56655210551713, 'l1_ratio': 0.40612627816988656, 'max_iter': 156}. Best is trial 48 with value: 0.8633673302872062.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 23:57:36,286]\u001b[0m Trial 70 finished with value: 0.8631063696692778 and parameters: {'logreg_c': 112.5215988539569, 'l1_ratio': 0.5085520962613128, 'max_iter': 244}. Best is trial 48 with value: 0.8633673302872062.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 23:57:48,247]\u001b[0m Trial 71 finished with value: 0.8628976283724978 and parameters: {'logreg_c': 98.53026281020725, 'l1_ratio': 0.35444202287517484, 'max_iter': 244}. Best is trial 48 with value: 0.8633673302872062.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 23:58:04,110]\u001b[0m Trial 72 finished with value: 0.8633673302872062 and parameters: {'logreg_c': 227.9442859019928, 'l1_ratio': 0.578842551471435, 'max_iter': 226}. Best is trial 48 with value: 0.8633673302872062.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 23:58:13,810]\u001b[0m Trial 73 finished with value: 0.8626871192341165 and parameters: {'logreg_c': 54.77405681063608, 'l1_ratio': 0.583516704745111, 'max_iter': 209}. Best is trial 48 with value: 0.8633673302872062.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 23:58:27,103]\u001b[0m Trial 74 finished with value: 0.8628985802872063 and parameters: {'logreg_c': 122.6827941538906, 'l1_ratio': 0.5122505069749567, 'max_iter': 270}. Best is trial 48 with value: 0.8633673302872062.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 23:58:50,291]\u001b[0m Trial 75 finished with value: 0.8609181897302003 and parameters: {'logreg_c': 631.5101392329814, 'l1_ratio': 0.5223964994823506, 'max_iter': 141}. Best is trial 48 with value: 0.8633673302872062.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 23:59:07,982]\u001b[0m Trial 76 finished with value: 0.8616998476936466 and parameters: {'logreg_c': 308.9126574863525, 'l1_ratio': 0.8012902117340281, 'max_iter': 397}. Best is trial 48 with value: 0.8633673302872062.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 23:59:15,903]\u001b[0m Trial 77 finished with value: 0.8615407419495213 and parameters: {'logreg_c': 30.455046953638863, 'l1_ratio': 0.9252205433384936, 'max_iter': 501}. Best is trial 48 with value: 0.8633673302872062.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 23:59:29,744]\u001b[0m Trial 78 finished with value: 0.8627423302872063 and parameters: {'logreg_c': 150.25145734460511, 'l1_ratio': 0.6258149842427817, 'max_iter': 193}. Best is trial 48 with value: 0.8633673302872062.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 23:59:46,415]\u001b[0m Trial 79 finished with value: 0.8628464969538728 and parameters: {'logreg_c': 257.9572291389467, 'l1_ratio': 0.4000765376740573, 'max_iter': 668}. Best is trial 48 with value: 0.8633673302872062.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 23:59:52,990]\u001b[0m Trial 80 finished with value: 0.8586231233681463 and parameters: {'logreg_c': 19.249946567091015, 'l1_ratio': 0.8586113537677532, 'max_iter': 274}. Best is trial 48 with value: 0.8633673302872062.\u001b[0m\n",
      "\u001b[32m[I 2024-11-15 00:00:09,647]\u001b[0m Trial 81 finished with value: 0.8633153829416885 and parameters: {'logreg_c': 235.9443144187437, 'l1_ratio': 0.4274830132303371, 'max_iter': 330}. Best is trial 48 with value: 0.8633673302872062.\u001b[0m\n",
      "\u001b[32m[I 2024-11-15 00:00:21,201]\u001b[0m Trial 82 finished with value: 0.8628973563968669 and parameters: {'logreg_c': 87.13084140767003, 'l1_ratio': 0.48669344736615494, 'max_iter': 352}. Best is trial 48 with value: 0.8633673302872062.\u001b[0m\n",
      "\u001b[32m[I 2024-11-15 00:00:40,171]\u001b[0m Trial 83 finished with value: 0.8612829090513491 and parameters: {'logreg_c': 383.7828870690973, 'l1_ratio': 0.4185634101166461, 'max_iter': 429}. Best is trial 48 with value: 0.8633673302872062.\u001b[0m\n",
      "\u001b[32m[I 2024-11-15 00:01:04,145]\u001b[0m Trial 84 finished with value: 0.8612304177545692 and parameters: {'logreg_c': 705.1742187292235, 'l1_ratio': 0.676175355071279, 'max_iter': 220}. Best is trial 48 with value: 0.8633673302872062.\u001b[0m\n",
      "\u001b[32m[I 2024-11-15 00:01:18,086]\u001b[0m Trial 85 finished with value: 0.8630548302872063 and parameters: {'logreg_c': 156.1991909548032, 'l1_ratio': 0.36956454763771435, 'max_iter': 1138}. Best is trial 48 with value: 0.8633673302872062.\u001b[0m\n",
      "\u001b[32m[I 2024-11-15 00:01:27,710]\u001b[0m Trial 86 finished with value: 0.8626871192341165 and parameters: {'logreg_c': 55.00189457411125, 'l1_ratio': 0.3242886267786492, 'max_iter': 156}. Best is trial 48 with value: 0.8633673302872062.\u001b[0m\n",
      "\u001b[32m[I 2024-11-15 00:01:48,545]\u001b[0m Trial 87 finished with value: 0.8612305537423848 and parameters: {'logreg_c': 505.93080360144614, 'l1_ratio': 0.7359362548608979, 'max_iter': 369}. Best is trial 48 with value: 0.8633673302872062.\u001b[0m\n",
      "\u001b[32m[I 2024-11-15 00:01:50,449]\u001b[0m Trial 88 finished with value: 0.8168329797650131 and parameters: {'logreg_c': 0.4897788095903558, 'l1_ratio': 0.47671312631904167, 'max_iter': 498}. Best is trial 48 with value: 0.8633673302872062.\u001b[0m\n",
      "\u001b[32m[I 2024-11-15 00:02:06,949]\u001b[0m Trial 89 finished with value: 0.8632110802872064 and parameters: {'logreg_c': 238.65221492868807, 'l1_ratio': 0.5574968580055298, 'max_iter': 273}. Best is trial 48 with value: 0.8633673302872062.\u001b[0m\n",
      "\u001b[32m[I 2024-11-15 00:02:24,231]\u001b[0m Trial 90 finished with value: 0.8632110802872063 and parameters: {'logreg_c': 244.07321505396726, 'l1_ratio': 0.5501697122298788, 'max_iter': 295}. Best is trial 48 with value: 0.8633673302872062.\u001b[0m\n",
      "\u001b[32m[I 2024-11-15 00:02:40,131]\u001b[0m Trial 91 finished with value: 0.8631591329416883 and parameters: {'logreg_c': 216.10353039980222, 'l1_ratio': 0.5475322976827183, 'max_iter': 293}. Best is trial 48 with value: 0.8633673302872062.\u001b[0m\n",
      "\u001b[32m[I 2024-11-15 00:02:42,884]\u001b[0m Trial 92 finished with value: 0.8338710291557878 and parameters: {'logreg_c': 1.8005577444187417, 'l1_ratio': 0.5890448653639291, 'max_iter': 456}. Best is trial 48 with value: 0.8633673302872062.\u001b[0m\n",
      "\u001b[32m[I 2024-11-15 00:03:00,385]\u001b[0m Trial 93 finished with value: 0.8613873476936466 and parameters: {'logreg_c': 323.86441487543567, 'l1_ratio': 0.6186050213558446, 'max_iter': 104}. Best is trial 48 with value: 0.8633673302872062.\u001b[0m\n",
      "\u001b[32m[I 2024-11-15 00:03:16,517]\u001b[0m Trial 94 finished with value: 0.8631069136205396 and parameters: {'logreg_c': 245.92219464790466, 'l1_ratio': 0.8398414397586201, 'max_iter': 328}. Best is trial 48 with value: 0.8633673302872062.\u001b[0m\n",
      "\u001b[32m[I 2024-11-15 00:03:27,525]\u001b[0m Trial 95 finished with value: 0.8631048738033072 and parameters: {'logreg_c': 73.64763081755359, 'l1_ratio': 0.5271188748434288, 'max_iter': 402}. Best is trial 48 with value: 0.8633673302872062.\u001b[0m\n",
      "\u001b[32m[I 2024-11-15 00:03:52,235]\u001b[0m Trial 96 finished with value: 0.8610220844212358 and parameters: {'logreg_c': 792.8598331180843, 'l1_ratio': 0.5693805133825169, 'max_iter': 1379}. Best is trial 48 with value: 0.8633673302872062.\u001b[0m\n",
      "\u001b[32m[I 2024-11-15 00:03:53,327]\u001b[0m Trial 97 finished with value: 0.7908295256744994 and parameters: {'logreg_c': 0.05553587663027144, 'l1_ratio': 0.4303146137821776, 'max_iter': 208}. Best is trial 48 with value: 0.8633673302872062.\u001b[0m\n",
      "\u001b[32m[I 2024-11-15 00:04:06,585]\u001b[0m Trial 98 finished with value: 0.8626902469538729 and parameters: {'logreg_c': 141.87601133033488, 'l1_ratio': 0.7694099771826101, 'max_iter': 549}. Best is trial 48 with value: 0.8633673302872062.\u001b[0m\n",
      "\u001b[32m[I 2024-11-15 00:04:25,211]\u001b[0m Trial 99 finished with value: 0.8610220844212358 and parameters: {'logreg_c': 404.0327904864534, 'l1_ratio': 0.236314021954374, 'max_iter': 278}. Best is trial 48 with value: 0.8633673302872062.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "#Tuning hyperparameters\n",
    "#Step 1. Define an objective function to be maximized.\n",
    "def objective(trial):\n",
    "    logreg_c = trial.suggest_float(\"logreg_c\", 1e-3,  1e3, log=True)\n",
    "    l1_ratio = trial.suggest_float(\"l1_ratio\",0.1,1,log=False) \n",
    "    #penalty = trial.suggest_categorical(\"penalty\",['l1','l2'])\n",
    "    max_iter = trial.suggest_int(\"max_iter\", 100,2000)\n",
    "    model =LogisticRegression(C=logreg_c,\n",
    "                              max_iter=max_iter,\n",
    "                              l1_ratio=l1_ratio,\n",
    "                              solver='liblinear',random_state=1)\n",
    "    \n",
    "# Step 2: Scoring method:\n",
    "    score = model_selection.cross_val_score(model, X, y, n_jobs=8, scoring=\"accuracy\",cv=Cv_optuna)\n",
    "    accuracy = score.mean()\n",
    "    return accuracy\n",
    "\n",
    "# Step 3: Running it\n",
    "study = optuna.create_study(direction=\"maximize\",sampler=optuna.samplers.TPESampler(seed=1))\n",
    "study.optimize(objective, n_trials=100, show_progress_bar=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "cd09afa2-c7ae-4f28-acb3-9a0c06e89504",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best parameters are : \n",
      "{'logreg_c': 228.85947403332256, 'l1_ratio': 0.42723562125140574, 'max_iter': 505}\n"
     ]
    }
   ],
   "source": [
    "# Getting the best parameters:\n",
    "print(f\"The best parameters are : \\n{study.best_params}\")\n",
    "# Setting the best model\n",
    "clf=LogisticRegression(C=study.best_params['logreg_c'],\n",
    "                              max_iter=study.best_params['max_iter'],\n",
    "                              l1_ratio=study.best_params['l1_ratio'],\n",
    "                              solver='liblinear',\n",
    "                              random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "18f98263-5b44-4a58-ad76-bd2288347abf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mean</th>\n",
       "      <th>Se</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Accuracy_test</th>\n",
       "      <td>0.863367</td>\n",
       "      <td>0.002207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Accuracy_train</th>\n",
       "      <td>0.926368</td>\n",
       "      <td>0.000659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1 Score</th>\n",
       "      <td>0.867370</td>\n",
       "      <td>0.002242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Precision</th>\n",
       "      <td>0.863241</td>\n",
       "      <td>0.002448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recall</th>\n",
       "      <td>0.872055</td>\n",
       "      <td>0.003617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Roc_auc</th>\n",
       "      <td>0.928602</td>\n",
       "      <td>0.001673</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Mean        Se\n",
       "Accuracy_test   0.863367  0.002207\n",
       "Accuracy_train  0.926368  0.000659\n",
       "F1 Score        0.867370  0.002242\n",
       "Precision       0.863241  0.002448\n",
       "Recall          0.872055  0.003617\n",
       "Roc_auc         0.928602  0.001673"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Model2\n",
    "Model2=Model_results(clf,X,y,Cv_model)\n",
    "Model2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "0eba0a05-824b-4da4-8a16-535220341d36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th>Method</th>\n",
       "      <th colspan=\"4\" halign=\"left\">LR</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model</th>\n",
       "      <th colspan=\"2\" halign=\"left\">Model 1</th>\n",
       "      <th colspan=\"2\" halign=\"left\">Model 2</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Values</th>\n",
       "      <th>Mean</th>\n",
       "      <th>Se</th>\n",
       "      <th>Mean</th>\n",
       "      <th>Se</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Accuracy_test</th>\n",
       "      <td>0.824075</td>\n",
       "      <td>0.002447</td>\n",
       "      <td>0.863367</td>\n",
       "      <td>0.002207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Accuracy_train</th>\n",
       "      <td>0.850326</td>\n",
       "      <td>0.000674</td>\n",
       "      <td>0.926368</td>\n",
       "      <td>0.000659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1 Score</th>\n",
       "      <td>0.829883</td>\n",
       "      <td>0.002364</td>\n",
       "      <td>0.867370</td>\n",
       "      <td>0.002242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Precision</th>\n",
       "      <td>0.823421</td>\n",
       "      <td>0.003054</td>\n",
       "      <td>0.863241</td>\n",
       "      <td>0.002448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recall</th>\n",
       "      <td>0.837086</td>\n",
       "      <td>0.003535</td>\n",
       "      <td>0.872055</td>\n",
       "      <td>0.003617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Roc_auc</th>\n",
       "      <td>0.896388</td>\n",
       "      <td>0.001783</td>\n",
       "      <td>0.928602</td>\n",
       "      <td>0.001673</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Method                LR                              \n",
       "Model            Model 1             Model 2          \n",
       "Values              Mean        Se      Mean        Se\n",
       "Accuracy_test   0.824075  0.002447  0.863367  0.002207\n",
       "Accuracy_train  0.850326  0.000674  0.926368  0.000659\n",
       "F1 Score        0.829883  0.002364  0.867370  0.002242\n",
       "Precision       0.823421  0.003054  0.863241  0.002448\n",
       "Recall          0.837086  0.003535  0.872055  0.003617\n",
       "Roc_auc         0.896388  0.001783  0.928602  0.001673"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Saving the data of model performance\n",
    "Model_data=pd.concat([Model1,Model2],axis=1)\n",
    "Model_data.columns = [['LR']*4,['Model 1','Model 1', 'Model 2','Model 2'], ['Mean', 'Se', 'Mean', 'Se']]  \n",
    "Model_data.columns.names=['Method','Model','Values']\n",
    "Model_data.to_csv(\"./LR_model_lasso_data.csv\",sep=',')\n",
    "Model_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0844c7c8-f6b1-410a-b253-879aedd14e57",
   "metadata": {},
   "source": [
    "## 1.3 RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "d9c4731c-bbfe-47eb-bb7f-7d8b2909ea2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf=RandomForestClassifier(random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "ffdd2f35-ec29-4ef8-8309-6a84646f4539",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mean</th>\n",
       "      <th>Se</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Accuracy_test</th>\n",
       "      <td>0.870818</td>\n",
       "      <td>0.002059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Accuracy_train</th>\n",
       "      <td>0.993682</td>\n",
       "      <td>0.000167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1 Score</th>\n",
       "      <td>0.873881</td>\n",
       "      <td>0.002078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Precision</th>\n",
       "      <td>0.874890</td>\n",
       "      <td>0.002495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recall</th>\n",
       "      <td>0.873369</td>\n",
       "      <td>0.003310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Roc_auc</th>\n",
       "      <td>0.936350</td>\n",
       "      <td>0.001440</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Mean        Se\n",
       "Accuracy_test   0.870818  0.002059\n",
       "Accuracy_train  0.993682  0.000167\n",
       "F1 Score        0.873881  0.002078\n",
       "Precision       0.874890  0.002495\n",
       "Recall          0.873369  0.003310\n",
       "Roc_auc         0.936350  0.001440"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Model1 （4175 descriptors）\n",
    "Model1_clf=clf\n",
    "#Model1\n",
    "Model1=Model_results(Model1_clf,X,y,Cv_model)\n",
    "Model1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "6f4b6d2b-6cf0-4f44-8bd5-02b5d1377add",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2024-11-15 00:06:52,528]\u001b[0m A new study created in memory with name: no-name-ec55a2af-a97d-4430-b200-d9a45740c1fd\u001b[0m\n",
      "\u001b[32m[I 2024-11-15 00:07:05,308]\u001b[0m Trial 0 finished with value: 0.5127665361183639 and parameters: {'n_estimators': 594, 'max_depth': 16, 'max_features': 20, 'min_impurity_decrease': 2.724415914984484}. Best is trial 0 with value: 0.5127665361183639.\u001b[0m\n",
      "\u001b[32m[I 2024-11-15 00:07:14,428]\u001b[0m Trial 1 finished with value: 0.5127665361183639 and parameters: {'n_estimators': 481, 'max_depth': 15, 'max_features': 16, 'min_impurity_decrease': 4.4588650039103985}. Best is trial 0 with value: 0.5127665361183639.\u001b[0m\n",
      "\u001b[32m[I 2024-11-15 00:07:36,084]\u001b[0m Trial 2 finished with value: 0.5127665361183639 and parameters: {'n_estimators': 968, 'max_depth': 11, 'max_features': 25, 'min_impurity_decrease': 2.644474598764522}. Best is trial 0 with value: 0.5127665361183639.\u001b[0m\n",
      "\u001b[32m[I 2024-11-15 00:07:45,971]\u001b[0m Trial 3 finished with value: 0.5127665361183639 and parameters: {'n_estimators': 611, 'max_depth': 19, 'max_features': 6, 'min_impurity_decrease': 0.43564649850770354}. Best is trial 0 with value: 0.5127665361183639.\u001b[0m\n",
      "\u001b[32m[I 2024-11-15 00:07:49,089]\u001b[0m Trial 4 finished with value: 0.5127665361183639 and parameters: {'n_estimators': 118, 'max_depth': 18, 'max_features': 25, 'min_impurity_decrease': 4.3500607412340955}. Best is trial 0 with value: 0.5127665361183639.\u001b[0m\n",
      "\u001b[32m[I 2024-11-15 00:08:06,703]\u001b[0m Trial 5 finished with value: 0.5127665361183639 and parameters: {'n_estimators': 981, 'max_depth': 17, 'max_features': 16, 'min_impurity_decrease': 3.902645881432277}. Best is trial 0 with value: 0.5127665361183639.\u001b[0m\n",
      "\u001b[32m[I 2024-11-15 00:08:10,360]\u001b[0m Trial 6 finished with value: 0.5127665361183639 and parameters: {'n_estimators': 206, 'max_depth': 15, 'max_features': 8, 'min_impurity_decrease': 4.7233445852479194}. Best is trial 0 with value: 0.5127665361183639.\u001b[0m\n",
      "\u001b[32m[I 2024-11-15 00:08:20,621]\u001b[0m Trial 7 finished with value: 0.5127665361183639 and parameters: {'n_estimators': 570, 'max_depth': 11, 'max_features': 11, 'min_impurity_decrease': 3.871168447171083}. Best is trial 0 with value: 0.5127665361183639.\u001b[0m\n",
      "\u001b[32m[I 2024-11-15 00:08:29,179]\u001b[0m Trial 8 finished with value: 0.5127665361183639 and parameters: {'n_estimators': 510, 'max_depth': 14, 'max_features': 5, 'min_impurity_decrease': 3.0881774853793855}. Best is trial 0 with value: 0.5127665361183639.\u001b[0m\n",
      "\u001b[32m[I 2024-11-15 00:08:43,930]\u001b[0m Trial 9 finished with value: 0.5127665361183639 and parameters: {'n_estimators': 651, 'max_depth': 14, 'max_features': 29, 'min_impurity_decrease': 3.409101495517417}. Best is trial 0 with value: 0.5127665361183639.\u001b[0m\n",
      "\u001b[32m[I 2024-11-15 00:09:00,181]\u001b[0m Trial 10 finished with value: 0.5127665361183639 and parameters: {'n_estimators': 790, 'max_depth': 7, 'max_features': 21, 'min_impurity_decrease': 1.5046577569438309}. Best is trial 0 with value: 0.5127665361183639.\u001b[0m\n",
      "\u001b[32m[I 2024-11-15 00:09:08,230]\u001b[0m Trial 11 finished with value: 0.5127665361183639 and parameters: {'n_estimators': 397, 'max_depth': 20, 'max_features': 16, 'min_impurity_decrease': 1.9887909510549393}. Best is trial 0 with value: 0.5127665361183639.\u001b[0m\n",
      "\u001b[32m[I 2024-11-15 00:09:15,635]\u001b[0m Trial 12 finished with value: 0.5127665361183639 and parameters: {'n_estimators': 353, 'max_depth': 16, 'max_features': 20, 'min_impurity_decrease': 0.702937495519433}. Best is trial 0 with value: 0.5127665361183639.\u001b[0m\n",
      "\u001b[32m[I 2024-11-15 00:09:23,371]\u001b[0m Trial 13 finished with value: 0.5127665361183639 and parameters: {'n_estimators': 411, 'max_depth': 12, 'max_features': 12, 'min_impurity_decrease': 4.931175650908394}. Best is trial 0 with value: 0.5127665361183639.\u001b[0m\n",
      "\u001b[32m[I 2024-11-15 00:09:38,642]\u001b[0m Trial 14 finished with value: 0.5127665361183639 and parameters: {'n_estimators': 743, 'max_depth': 7, 'max_features': 19, 'min_impurity_decrease': 1.5253121430442045}. Best is trial 0 with value: 0.5127665361183639.\u001b[0m\n",
      "\u001b[32m[I 2024-11-15 00:09:52,011]\u001b[0m Trial 15 finished with value: 0.5127665361183639 and parameters: {'n_estimators': 757, 'max_depth': 13, 'max_features': 12, 'min_impurity_decrease': 2.668111844473928}. Best is trial 0 with value: 0.5127665361183639.\u001b[0m\n",
      "\u001b[32m[I 2024-11-15 00:09:58,219]\u001b[0m Trial 16 finished with value: 0.5127665361183639 and parameters: {'n_estimators': 286, 'max_depth': 9, 'max_features': 24, 'min_impurity_decrease': 3.4814210246729473}. Best is trial 0 with value: 0.5127665361183639.\u001b[0m\n",
      "\u001b[32m[I 2024-11-15 00:10:14,113]\u001b[0m Trial 17 finished with value: 0.5127665361183639 and parameters: {'n_estimators': 807, 'max_depth': 5, 'max_features': 19, 'min_impurity_decrease': 1.4307627258174405}. Best is trial 0 with value: 0.5127665361183639.\u001b[0m\n",
      "\u001b[32m[I 2024-11-15 00:10:26,375]\u001b[0m Trial 18 finished with value: 0.5127665361183639 and parameters: {'n_estimators': 714, 'max_depth': 13, 'max_features': 12, 'min_impurity_decrease': 2.5740699841477164}. Best is trial 0 with value: 0.5127665361183639.\u001b[0m\n",
      "\u001b[32m[I 2024-11-15 00:10:32,905]\u001b[0m Trial 19 finished with value: 0.5127665361183639 and parameters: {'n_estimators': 291, 'max_depth': 8, 'max_features': 24, 'min_impurity_decrease': 3.3144569973486893}. Best is trial 0 with value: 0.5127665361183639.\u001b[0m\n",
      "\u001b[32m[I 2024-11-15 00:10:51,964]\u001b[0m Trial 20 finished with value: 0.5127665361183639 and parameters: {'n_estimators': 871, 'max_depth': 5, 'max_features': 29, 'min_impurity_decrease': 1.0528796896599455}. Best is trial 0 with value: 0.5127665361183639.\u001b[0m\n",
      "\u001b[32m[I 2024-11-15 00:11:04,093]\u001b[0m Trial 21 finished with value: 0.5127665361183639 and parameters: {'n_estimators': 670, 'max_depth': 10, 'max_features': 14, 'min_impurity_decrease': 2.1272690676619233}. Best is trial 0 with value: 0.5127665361183639.\u001b[0m\n",
      "\u001b[32m[I 2024-11-15 00:11:14,311]\u001b[0m Trial 22 finished with value: 0.5127665361183639 and parameters: {'n_estimators': 502, 'max_depth': 9, 'max_features': 23, 'min_impurity_decrease': 3.0212243946132658}. Best is trial 0 with value: 0.5127665361183639.\u001b[0m\n",
      "\u001b[32m[I 2024-11-15 00:11:33,610]\u001b[0m Trial 23 finished with value: 0.5127665361183639 and parameters: {'n_estimators': 871, 'max_depth': 6, 'max_features': 30, 'min_impurity_decrease': 0.8924229302747376}. Best is trial 0 with value: 0.5127665361183639.\u001b[0m\n",
      "\u001b[32m[I 2024-11-15 00:11:48,579]\u001b[0m Trial 24 finished with value: 0.5127665361183639 and parameters: {'n_estimators': 673, 'max_depth': 11, 'max_features': 28, 'min_impurity_decrease': 2.1839582613393773}. Best is trial 0 with value: 0.5127665361183639.\u001b[0m\n",
      "\u001b[32m[I 2024-11-15 00:11:59,968]\u001b[0m Trial 25 finished with value: 0.5127665361183639 and parameters: {'n_estimators': 548, 'max_depth': 9, 'max_features': 22, 'min_impurity_decrease': 2.0762642939740097}. Best is trial 0 with value: 0.5127665361183639.\u001b[0m\n",
      "\u001b[32m[I 2024-11-15 00:12:24,541]\u001b[0m Trial 26 finished with value: 0.6757144799825936 and parameters: {'n_estimators': 859, 'max_depth': 7, 'max_features': 27, 'min_impurity_decrease': 0.05016303754931073}. Best is trial 26 with value: 0.6757144799825936.\u001b[0m\n",
      "\u001b[32m[I 2024-11-15 00:13:08,336]\u001b[0m Trial 27 finished with value: 0.7972885389469104 and parameters: {'n_estimators': 889, 'max_depth': 6, 'max_features': 27, 'min_impurity_decrease': 0.0085734336612443}. Best is trial 27 with value: 0.7972885389469104.\u001b[0m\n",
      "\u001b[32m[I 2024-11-15 00:13:35,713]\u001b[0m Trial 28 finished with value: 0.6761840459094866 and parameters: {'n_estimators': 901, 'max_depth': 7, 'max_features': 27, 'min_impurity_decrease': 0.0444905724402096}. Best is trial 27 with value: 0.7972885389469104.\u001b[0m\n",
      "\u001b[32m[I 2024-11-15 00:14:00,312]\u001b[0m Trial 29 finished with value: 0.6772261205395996 and parameters: {'n_estimators': 918, 'max_depth': 7, 'max_features': 27, 'min_impurity_decrease': 0.06568686852538644}. Best is trial 27 with value: 0.7972885389469104.\u001b[0m\n",
      "\u001b[32m[I 2024-11-15 00:14:20,693]\u001b[0m Trial 30 finished with value: 0.5127665361183639 and parameters: {'n_estimators': 923, 'max_depth': 6, 'max_features': 26, 'min_impurity_decrease': 0.24852586961100467}. Best is trial 27 with value: 0.7972885389469104.\u001b[0m\n",
      "\u001b[32m[I 2024-11-15 00:14:40,282]\u001b[0m Trial 31 finished with value: 0.5127665361183639 and parameters: {'n_estimators': 866, 'max_depth': 7, 'max_features': 27, 'min_impurity_decrease': 0.18490386200494155}. Best is trial 27 with value: 0.7972885389469104.\u001b[0m\n",
      "\u001b[32m[I 2024-11-15 00:15:23,365]\u001b[0m Trial 32 finished with value: 0.8393412750217579 and parameters: {'n_estimators': 930, 'max_depth': 8, 'max_features': 27, 'min_impurity_decrease': 0.004905793398416951}. Best is trial 32 with value: 0.8393412750217579.\u001b[0m\n",
      "\u001b[32m[I 2024-11-15 00:15:43,514]\u001b[0m Trial 33 finished with value: 0.5127665361183639 and parameters: {'n_estimators': 922, 'max_depth': 8, 'max_features': 30, 'min_impurity_decrease': 0.5049670648596443}. Best is trial 32 with value: 0.8393412750217579.\u001b[0m\n",
      "\u001b[32m[I 2024-11-15 00:16:16,216]\u001b[0m Trial 34 finished with value: 0.7032808420365535 and parameters: {'n_estimators': 990, 'max_depth': 6, 'max_features': 26, 'min_impurity_decrease': 0.019636131056210752}. Best is trial 32 with value: 0.8393412750217579.\u001b[0m\n",
      "\u001b[32m[I 2024-11-15 00:16:36,843]\u001b[0m Trial 35 finished with value: 0.5127665361183639 and parameters: {'n_estimators': 990, 'max_depth': 5, 'max_features': 25, 'min_impurity_decrease': 0.46338942427376173}. Best is trial 32 with value: 0.8393412750217579.\u001b[0m\n",
      "\u001b[32m[I 2024-11-15 00:16:56,238]\u001b[0m Trial 36 finished with value: 0.5127665361183639 and parameters: {'n_estimators': 944, 'max_depth': 6, 'max_features': 23, 'min_impurity_decrease': 1.0293121320437244}. Best is trial 32 with value: 0.8393412750217579.\u001b[0m\n",
      "\u001b[32m[I 2024-11-15 00:17:14,068]\u001b[0m Trial 37 finished with value: 0.5127665361183639 and parameters: {'n_estimators': 830, 'max_depth': 8, 'max_features': 26, 'min_impurity_decrease': 0.7207674397795658}. Best is trial 32 with value: 0.8393412750217579.\u001b[0m\n",
      "\u001b[32m[I 2024-11-15 00:17:36,303]\u001b[0m Trial 38 finished with value: 0.5127665361183639 and parameters: {'n_estimators': 999, 'max_depth': 10, 'max_features': 28, 'min_impurity_decrease': 0.3146157685293402}. Best is trial 32 with value: 0.8393412750217579.\u001b[0m\n",
      "\u001b[32m[I 2024-11-15 00:17:55,789]\u001b[0m Trial 39 finished with value: 0.5127665361183639 and parameters: {'n_estimators': 945, 'max_depth': 6, 'max_features': 25, 'min_impurity_decrease': 1.2782349340929955}. Best is trial 32 with value: 0.8393412750217579.\u001b[0m\n",
      "\u001b[32m[I 2024-11-15 00:18:12,469]\u001b[0m Trial 40 finished with value: 0.5127665361183639 and parameters: {'n_estimators': 801, 'max_depth': 5, 'max_features': 22, 'min_impurity_decrease': 0.6678433546618794}. Best is trial 32 with value: 0.8393412750217579.\u001b[0m\n",
      "\u001b[32m[I 2024-11-15 00:18:39,139]\u001b[0m Trial 41 finished with value: 0.6754540633159268 and parameters: {'n_estimators': 915, 'max_depth': 8, 'max_features': 27, 'min_impurity_decrease': 0.05496545497134558}. Best is trial 32 with value: 0.8393412750217579.\u001b[0m\n",
      "\u001b[32m[I 2024-11-15 00:19:09,118]\u001b[0m Trial 42 finished with value: 0.6985922541340294 and parameters: {'n_estimators': 892, 'max_depth': 7, 'max_features': 28, 'min_impurity_decrease': 0.021877248297651298}. Best is trial 32 with value: 0.8393412750217579.\u001b[0m\n",
      "\u001b[32m[I 2024-11-15 00:19:30,396]\u001b[0m Trial 43 finished with value: 0.5127665361183639 and parameters: {'n_estimators': 964, 'max_depth': 6, 'max_features': 29, 'min_impurity_decrease': 0.41108811935450607}. Best is trial 32 with value: 0.8393412750217579.\u001b[0m\n",
      "\u001b[32m[I 2024-11-15 00:19:59,880]\u001b[0m Trial 44 finished with value: 0.7061478731505657 and parameters: {'n_estimators': 838, 'max_depth': 8, 'max_features': 28, 'min_impurity_decrease': 0.019314747660582145}. Best is trial 32 with value: 0.8393412750217579.\u001b[0m\n",
      "\u001b[32m[I 2024-11-15 00:20:18,427]\u001b[0m Trial 45 finished with value: 0.5127665361183639 and parameters: {'n_estimators': 829, 'max_depth': 10, 'max_features': 30, 'min_impurity_decrease': 0.5467395091872262}. Best is trial 32 with value: 0.8393412750217579.\u001b[0m\n",
      "\u001b[32m[I 2024-11-15 00:20:35,451]\u001b[0m Trial 46 finished with value: 0.5127665361183639 and parameters: {'n_estimators': 769, 'max_depth': 9, 'max_features': 26, 'min_impurity_decrease': 0.2835905311154459}. Best is trial 32 with value: 0.8393412750217579.\u001b[0m\n",
      "\u001b[32m[I 2024-11-15 00:20:56,671]\u001b[0m Trial 47 finished with value: 0.5127665361183639 and parameters: {'n_estimators': 966, 'max_depth': 8, 'max_features': 28, 'min_impurity_decrease': 0.8816062203771051}. Best is trial 32 with value: 0.8393412750217579.\u001b[0m\n",
      "\u001b[32m[I 2024-11-15 00:21:11,540]\u001b[0m Trial 48 finished with value: 0.5127665361183639 and parameters: {'n_estimators': 710, 'max_depth': 6, 'max_features': 24, 'min_impurity_decrease': 1.7554372932180642}. Best is trial 32 with value: 0.8393412750217579.\u001b[0m\n",
      "\u001b[32m[I 2024-11-15 00:21:25,052]\u001b[0m Trial 49 finished with value: 0.5127665361183639 and parameters: {'n_estimators': 615, 'max_depth': 12, 'max_features': 29, 'min_impurity_decrease': 0.6574939529531398}. Best is trial 32 with value: 0.8393412750217579.\u001b[0m\n",
      "\u001b[32m[I 2024-11-15 00:21:31,776]\u001b[0m Trial 50 finished with value: 0.8312655026109661 and parameters: {'n_estimators': 131, 'max_depth': 5, 'max_features': 25, 'min_impurity_decrease': 0.0016373580283458693}. Best is trial 32 with value: 0.8393412750217579.\u001b[0m\n",
      "\u001b[32m[I 2024-11-15 00:21:50,281]\u001b[0m Trial 51 finished with value: 0.5127665361183639 and parameters: {'n_estimators': 883, 'max_depth': 5, 'max_features': 25, 'min_impurity_decrease': 0.2655601364891188}. Best is trial 32 with value: 0.8393412750217579.\u001b[0m\n",
      "\u001b[32m[I 2024-11-15 00:21:54,488]\u001b[0m Trial 52 finished with value: 0.5127665361183639 and parameters: {'n_estimators': 221, 'max_depth': 6, 'max_features': 9, 'min_impurity_decrease': 0.3997428026813785}. Best is trial 32 with value: 0.8393412750217579.\u001b[0m\n",
      "\u001b[32m[I 2024-11-15 00:21:59,374]\u001b[0m Trial 53 finished with value: 0.5127665361183639 and parameters: {'n_estimators': 107, 'max_depth': 5, 'max_features': 28, 'min_impurity_decrease': 0.15131285339591388}. Best is trial 32 with value: 0.8393412750217579.\u001b[0m\n",
      "\u001b[32m[I 2024-11-15 00:22:29,352]\u001b[0m Trial 54 finished with value: 0.8631035139251522 and parameters: {'n_estimators': 458, 'max_depth': 7, 'max_features': 26, 'min_impurity_decrease': 0.00020383882985497773}. Best is trial 54 with value: 0.8631035139251522.\u001b[0m\n",
      "\u001b[32m[I 2024-11-15 00:22:38,820]\u001b[0m Trial 55 finished with value: 0.5127665361183639 and parameters: {'n_estimators': 440, 'max_depth': 18, 'max_features': 23, 'min_impurity_decrease': 0.8273269708956272}. Best is trial 54 with value: 0.8631035139251522.\u001b[0m\n",
      "\u001b[32m[I 2024-11-15 00:22:42,660]\u001b[0m Trial 56 finished with value: 0.5127665361183639 and parameters: {'n_estimators': 164, 'max_depth': 8, 'max_features': 26, 'min_impurity_decrease': 1.1862986122343195}. Best is trial 54 with value: 0.8631035139251522.\u001b[0m\n",
      "\u001b[32m[I 2024-11-15 00:22:49,916]\u001b[0m Trial 57 finished with value: 0.5127665361183639 and parameters: {'n_estimators': 356, 'max_depth': 7, 'max_features': 20, 'min_impurity_decrease': 0.5212423242989549}. Best is trial 54 with value: 0.8631035139251522.\u001b[0m\n",
      "\u001b[32m[I 2024-11-15 00:22:55,790]\u001b[0m Trial 58 finished with value: 0.5127665361183639 and parameters: {'n_estimators': 258, 'max_depth': 9, 'max_features': 24, 'min_impurity_decrease': 0.2652651332693122}. Best is trial 54 with value: 0.8631035139251522.\u001b[0m\n",
      "\u001b[32m[I 2024-11-15 00:22:59,493]\u001b[0m Trial 59 finished with value: 0.5127665361183639 and parameters: {'n_estimators': 162, 'max_depth': 5, 'max_features': 25, 'min_impurity_decrease': 0.6123181115353179}. Best is trial 54 with value: 0.8631035139251522.\u001b[0m\n",
      "\u001b[32m[I 2024-11-15 00:23:14,980]\u001b[0m Trial 60 finished with value: 0.5127665361183639 and parameters: {'n_estimators': 830, 'max_depth': 6, 'max_features': 17, 'min_impurity_decrease': 4.395921481641627}. Best is trial 54 with value: 0.8631035139251522.\u001b[0m\n",
      "\u001b[32m[I 2024-11-15 00:24:05,866]\u001b[0m Trial 61 finished with value: 0.8077627284595301 and parameters: {'n_estimators': 953, 'max_depth': 7, 'max_features': 29, 'min_impurity_decrease': 0.00804418475141749}. Best is trial 54 with value: 0.8631035139251522.\u001b[0m\n",
      "\u001b[32m[I 2024-11-15 00:24:38,885]\u001b[0m Trial 62 finished with value: 0.7017700174064403 and parameters: {'n_estimators': 976, 'max_depth': 7, 'max_features': 29, 'min_impurity_decrease': 0.02119988024007733}. Best is trial 54 with value: 0.8631035139251522.\u001b[0m\n",
      "\u001b[32m[I 2024-11-15 00:24:50,806]\u001b[0m Trial 63 finished with value: 0.5127665361183639 and parameters: {'n_estimators': 551, 'max_depth': 8, 'max_features': 26, 'min_impurity_decrease': 0.3484188328834943}. Best is trial 54 with value: 0.8631035139251522.\u001b[0m\n",
      "\u001b[32m[I 2024-11-15 00:24:58,765]\u001b[0m Trial 64 finished with value: 0.5127665361183639 and parameters: {'n_estimators': 336, 'max_depth': 6, 'max_features': 30, 'min_impurity_decrease': 0.17772244701435774}. Best is trial 54 with value: 0.8631035139251522.\u001b[0m\n",
      "\u001b[32m[I 2024-11-15 00:25:19,312]\u001b[0m Trial 65 finished with value: 0.5127665361183639 and parameters: {'n_estimators': 949, 'max_depth': 15, 'max_features': 27, 'min_impurity_decrease': 4.109958450710825}. Best is trial 54 with value: 0.8631035139251522.\u001b[0m\n",
      "\u001b[32m[I 2024-11-15 00:25:34,388]\u001b[0m Trial 66 finished with value: 0.5127665361183639 and parameters: {'n_estimators': 724, 'max_depth': 7, 'max_features': 22, 'min_impurity_decrease': 0.18665505538896485}. Best is trial 54 with value: 0.8631035139251522.\u001b[0m\n",
      "\u001b[32m[I 2024-11-15 00:25:53,611]\u001b[0m Trial 67 finished with value: 0.5127665361183639 and parameters: {'n_estimators': 849, 'max_depth': 5, 'max_features': 28, 'min_impurity_decrease': 0.45873168823000166}. Best is trial 54 with value: 0.8631035139251522.\u001b[0m\n",
      "\u001b[32m[I 2024-11-15 00:26:10,682]\u001b[0m Trial 68 finished with value: 0.5127665361183639 and parameters: {'n_estimators': 774, 'max_depth': 16, 'max_features': 26, 'min_impurity_decrease': 2.844295593565694}. Best is trial 54 with value: 0.8631035139251522.\u001b[0m\n",
      "\u001b[32m[I 2024-11-15 00:26:21,648]\u001b[0m Trial 69 finished with value: 0.5127665361183639 and parameters: {'n_estimators': 471, 'max_depth': 10, 'max_features': 29, 'min_impurity_decrease': 0.7873015423668303}. Best is trial 54 with value: 0.8631035139251522.\u001b[0m\n",
      "\u001b[32m[I 2024-11-15 00:26:38,343]\u001b[0m Trial 70 finished with value: 0.5127665361183639 and parameters: {'n_estimators': 937, 'max_depth': 6, 'max_features': 15, 'min_impurity_decrease': 1.0499883135229977}. Best is trial 54 with value: 0.8631035139251522.\u001b[0m\n",
      "\u001b[32m[I 2024-11-15 00:27:01,158]\u001b[0m Trial 71 finished with value: 0.5360998694516972 and parameters: {'n_estimators': 997, 'max_depth': 7, 'max_features': 30, 'min_impurity_decrease': 0.0881217828658866}. Best is trial 54 with value: 0.8631035139251522.\u001b[0m\n",
      "\u001b[32m[I 2024-11-15 00:27:32,232]\u001b[0m Trial 72 finished with value: 0.6848345028285465 and parameters: {'n_estimators': 971, 'max_depth': 8, 'max_features': 29, 'min_impurity_decrease': 0.030118637469662864}. Best is trial 54 with value: 0.8631035139251522.\u001b[0m\n",
      "\u001b[32m[I 2024-11-15 00:27:51,907]\u001b[0m Trial 73 finished with value: 0.5127665361183639 and parameters: {'n_estimators': 889, 'max_depth': 7, 'max_features': 27, 'min_impurity_decrease': 0.18785776729447537}. Best is trial 54 with value: 0.8631035139251522.\u001b[0m\n",
      "\u001b[32m[I 2024-11-15 00:28:13,250]\u001b[0m Trial 74 finished with value: 0.5127665361183639 and parameters: {'n_estimators': 975, 'max_depth': 9, 'max_features': 29, 'min_impurity_decrease': 0.32121501588074114}. Best is trial 54 with value: 0.8631035139251522.\u001b[0m\n",
      "\u001b[32m[I 2024-11-15 00:29:08,503]\u001b[0m Trial 75 finished with value: 0.8547652850304612 and parameters: {'n_estimators': 908, 'max_depth': 8, 'max_features': 25, 'min_impurity_decrease': 0.003301068443349278}. Best is trial 54 with value: 0.8631035139251522.\u001b[0m\n",
      "\u001b[32m[I 2024-11-15 00:29:27,275]\u001b[0m Trial 76 finished with value: 0.5127665361183639 and parameters: {'n_estimators': 902, 'max_depth': 9, 'max_features': 25, 'min_impurity_decrease': 0.41854186869246945}. Best is trial 54 with value: 0.8631035139251522.\u001b[0m\n",
      "\u001b[32m[I 2024-11-15 00:29:46,209]\u001b[0m Trial 77 finished with value: 0.5127665361183639 and parameters: {'n_estimators': 853, 'max_depth': 5, 'max_features': 24, 'min_impurity_decrease': 0.21014842099686815}. Best is trial 54 with value: 0.8631035139251522.\u001b[0m\n",
      "\u001b[32m[I 2024-11-15 00:30:04,867]\u001b[0m Trial 78 finished with value: 0.5127665361183639 and parameters: {'n_estimators': 932, 'max_depth': 8, 'max_features': 21, 'min_impurity_decrease': 0.5593126777642605}. Best is trial 54 with value: 0.8631035139251522.\u001b[0m\n",
      "\u001b[32m[I 2024-11-15 00:30:22,237]\u001b[0m Trial 79 finished with value: 0.6808739936901652 and parameters: {'n_estimators': 606, 'max_depth': 6, 'max_features': 23, 'min_impurity_decrease': 0.027447372822104427}. Best is trial 54 with value: 0.8631035139251522.\u001b[0m\n",
      "\u001b[32m[I 2024-11-15 00:30:40,534]\u001b[0m Trial 80 finished with value: 0.5127665361183639 and parameters: {'n_estimators': 823, 'max_depth': 8, 'max_features': 26, 'min_impurity_decrease': 0.36171986663833094}. Best is trial 54 with value: 0.8631035139251522.\u001b[0m\n",
      "\u001b[32m[I 2024-11-15 00:31:35,343]\u001b[0m Trial 81 finished with value: 0.8245396812445605 and parameters: {'n_estimators': 961, 'max_depth': 7, 'max_features': 28, 'min_impurity_decrease': 0.006323452295319689}. Best is trial 54 with value: 0.8631035139251522.\u001b[0m\n",
      "\u001b[32m[I 2024-11-15 00:31:55,098]\u001b[0m Trial 82 finished with value: 0.5127665361183639 and parameters: {'n_estimators': 908, 'max_depth': 7, 'max_features': 27, 'min_impurity_decrease': 0.14545468847328025}. Best is trial 54 with value: 0.8631035139251522.\u001b[0m\n",
      "\u001b[32m[I 2024-11-15 00:32:16,876]\u001b[0m Trial 83 finished with value: 0.5127665361183639 and parameters: {'n_estimators': 945, 'max_depth': 6, 'max_features': 28, 'min_impurity_decrease': 0.13721453841024123}. Best is trial 54 with value: 0.8631035139251522.\u001b[0m\n",
      "\u001b[32m[I 2024-11-15 00:33:05,800]\u001b[0m Trial 84 finished with value: 0.8457509247171453 and parameters: {'n_estimators': 869, 'max_depth': 7, 'max_features': 25, 'min_impurity_decrease': 0.0038615852061512136}. Best is trial 54 with value: 0.8631035139251522.\u001b[0m\n",
      "\u001b[32m[I 2024-11-15 00:33:56,423]\u001b[0m Trial 85 finished with value: 0.8511701751523062 and parameters: {'n_estimators': 879, 'max_depth': 11, 'max_features': 24, 'min_impurity_decrease': 0.003865167918489046}. Best is trial 54 with value: 0.8631035139251522.\u001b[0m\n",
      "\u001b[32m[I 2024-11-15 00:34:13,110]\u001b[0m Trial 86 finished with value: 0.5127665361183639 and parameters: {'n_estimators': 802, 'max_depth': 11, 'max_features': 25, 'min_impurity_decrease': 0.3018514555717025}. Best is trial 54 with value: 0.8631035139251522.\u001b[0m\n",
      "\u001b[32m[I 2024-11-15 00:34:31,099]\u001b[0m Trial 87 finished with value: 0.5127665361183639 and parameters: {'n_estimators': 878, 'max_depth': 14, 'max_features': 24, 'min_impurity_decrease': 0.5886408849327645}. Best is trial 54 with value: 0.8631035139251522.\u001b[0m\n",
      "\u001b[32m[I 2024-11-15 00:34:48,644]\u001b[0m Trial 88 finished with value: 0.5127665361183639 and parameters: {'n_estimators': 870, 'max_depth': 11, 'max_features': 23, 'min_impurity_decrease': 0.44897323911385234}. Best is trial 54 with value: 0.8631035139251522.\u001b[0m\n",
      "\u001b[32m[I 2024-11-15 00:35:02,605]\u001b[0m Trial 89 finished with value: 0.5127665361183639 and parameters: {'n_estimators': 642, 'max_depth': 20, 'max_features': 25, 'min_impurity_decrease': 2.3494285961951182}. Best is trial 54 with value: 0.8631035139251522.\u001b[0m\n",
      "\u001b[32m[I 2024-11-15 00:35:22,038]\u001b[0m Trial 90 finished with value: 0.5127665361183639 and parameters: {'n_estimators': 912, 'max_depth': 7, 'max_features': 27, 'min_impurity_decrease': 0.24604220474495173}. Best is trial 54 with value: 0.8631035139251522.\u001b[0m\n",
      "\u001b[32m[I 2024-11-15 00:36:06,658]\u001b[0m Trial 91 finished with value: 0.809951044386423 and parameters: {'n_estimators': 847, 'max_depth': 8, 'max_features': 28, 'min_impurity_decrease': 0.007725253706930437}. Best is trial 54 with value: 0.8631035139251522.\u001b[0m\n",
      "\u001b[32m[I 2024-11-15 00:36:27,077]\u001b[0m Trial 92 finished with value: 0.5127665361183639 and parameters: {'n_estimators': 958, 'max_depth': 9, 'max_features': 27, 'min_impurity_decrease': 3.619334249445366}. Best is trial 54 with value: 0.8631035139251522.\u001b[0m\n",
      "\u001b[32m[I 2024-11-15 00:36:46,800]\u001b[0m Trial 93 finished with value: 0.5127665361183639 and parameters: {'n_estimators': 889, 'max_depth': 8, 'max_features': 26, 'min_impurity_decrease': 0.141040415079931}. Best is trial 54 with value: 0.8631035139251522.\u001b[0m\n",
      "\u001b[32m[I 2024-11-15 00:37:06,766]\u001b[0m Trial 94 finished with value: 0.5127665361183639 and parameters: {'n_estimators': 921, 'max_depth': 10, 'max_features': 28, 'min_impurity_decrease': 0.349709599658014}. Best is trial 54 with value: 0.8631035139251522.\u001b[0m\n",
      "\u001b[32m[I 2024-11-15 00:37:57,698]\u001b[0m Trial 95 finished with value: 0.8311595681026981 and parameters: {'n_estimators': 856, 'max_depth': 12, 'max_features': 27, 'min_impurity_decrease': 0.005748148087947065}. Best is trial 54 with value: 0.8631035139251522.\u001b[0m\n",
      "\u001b[32m[I 2024-11-15 00:38:16,906]\u001b[0m Trial 96 finished with value: 0.5127665361183639 and parameters: {'n_estimators': 857, 'max_depth': 12, 'max_features': 24, 'min_impurity_decrease': 0.7194678415042882}. Best is trial 54 with value: 0.8631035139251522.\u001b[0m\n",
      "\u001b[32m[I 2024-11-15 00:38:34,564]\u001b[0m Trial 97 finished with value: 0.5127665361183639 and parameters: {'n_estimators': 780, 'max_depth': 13, 'max_features': 30, 'min_impurity_decrease': 4.662035109660959}. Best is trial 54 with value: 0.8631035139251522.\u001b[0m\n",
      "\u001b[32m[I 2024-11-15 00:39:32,158]\u001b[0m Trial 98 finished with value: 0.8755598618363795 and parameters: {'n_estimators': 754, 'max_depth': 12, 'max_features': 25, 'min_impurity_decrease': 0.0005874088405539582}. Best is trial 98 with value: 0.8755598618363795.\u001b[0m\n",
      "\u001b[32m[I 2024-11-15 00:39:49,225]\u001b[0m Trial 99 finished with value: 0.5127665361183639 and parameters: {'n_estimators': 815, 'max_depth': 12, 'max_features': 26, 'min_impurity_decrease': 0.15034709399643392}. Best is trial 98 with value: 0.8755598618363795.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "#Tuning hyperparameters\n",
    "#Step 1. Define an objective function to be maximized.\n",
    "def objective(trial):\n",
    "    n_estimators = trial.suggest_int(\"n_estimators\",100,1000,1) \n",
    "    max_depth = trial.suggest_int(\"max_depth\",5,20,1)\n",
    "    max_features = trial.suggest_int(\"max_features\",5,30,1)\n",
    "    min_impurity_decrease = trial.suggest_float(\"min_impurity_decrease\",0,5,log=False) \n",
    "    model = RandomForestClassifier(n_estimators = n_estimators\n",
    "              ,max_depth = max_depth\n",
    "              ,max_features = max_features\n",
    "              ,min_impurity_decrease = min_impurity_decrease\n",
    "              ,random_state=1\n",
    "              ,verbose=False\n",
    "              ,n_jobs=8)\n",
    "\n",
    "# Step 2: Scoring method:\n",
    "    score = model_selection.cross_val_score(model, X, y, n_jobs=8, scoring=\"accuracy\",cv=Cv_optuna)\n",
    "    accuracy = score.mean()\n",
    "    return accuracy\n",
    " \n",
    "# Step 3: Running it\n",
    "study = optuna.create_study(direction=\"maximize\",sampler=optuna.samplers.TPESampler(seed=0))\n",
    "study.optimize(objective, n_trials=100, show_progress_bar=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "3ea7fc26-11ae-497b-ab4a-949cd12a43a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best parameters are : \n",
      "{'n_estimators': 754, 'max_depth': 12, 'max_features': 25, 'min_impurity_decrease': 0.0005874088405539582}\n"
     ]
    }
   ],
   "source": [
    "# Getting the best parameters:\n",
    "print(f\"The best parameters are : \\n{study.best_params}\")\n",
    "# Setting the best model\n",
    "clf=RandomForestClassifier(n_estimators = study.best_params['n_estimators']\n",
    "              ,max_depth = study.best_params['max_depth']\n",
    "              ,max_features = study.best_params['max_features']\n",
    "              ,min_impurity_decrease = study.best_params['min_impurity_decrease']\n",
    "              ,random_state=0\n",
    "              ,verbose=False\n",
    "              ,n_jobs=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "90cca67e-3df8-43ff-8b96-2c9bec87ee43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mean</th>\n",
       "      <th>Se</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Accuracy_test</th>\n",
       "      <td>0.875664</td>\n",
       "      <td>0.002017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Accuracy_train</th>\n",
       "      <td>0.980875</td>\n",
       "      <td>0.000400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1 Score</th>\n",
       "      <td>0.879635</td>\n",
       "      <td>0.002014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Precision</th>\n",
       "      <td>0.873302</td>\n",
       "      <td>0.002478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recall</th>\n",
       "      <td>0.886582</td>\n",
       "      <td>0.003324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Roc_auc</th>\n",
       "      <td>0.938121</td>\n",
       "      <td>0.001341</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Mean        Se\n",
       "Accuracy_test   0.875664  0.002017\n",
       "Accuracy_train  0.980875  0.000400\n",
       "F1 Score        0.879635  0.002014\n",
       "Precision       0.873302  0.002478\n",
       "Recall          0.886582  0.003324\n",
       "Roc_auc         0.938121  0.001341"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Model2\n",
    "Model2=Model_results(clf,X,y,Cv_model)\n",
    "Model2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "346eea08-6a51-48fc-bfcd-1a8d913649a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th>Method</th>\n",
       "      <th colspan=\"4\" halign=\"left\">RF</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model</th>\n",
       "      <th colspan=\"2\" halign=\"left\">Model 1</th>\n",
       "      <th colspan=\"2\" halign=\"left\">Model 2</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Values</th>\n",
       "      <th>Mean</th>\n",
       "      <th>Se</th>\n",
       "      <th>Mean</th>\n",
       "      <th>Se</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Accuracy_test</th>\n",
       "      <td>0.870818</td>\n",
       "      <td>0.002059</td>\n",
       "      <td>0.875664</td>\n",
       "      <td>0.002017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Accuracy_train</th>\n",
       "      <td>0.993682</td>\n",
       "      <td>0.000167</td>\n",
       "      <td>0.980875</td>\n",
       "      <td>0.000400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1 Score</th>\n",
       "      <td>0.873881</td>\n",
       "      <td>0.002078</td>\n",
       "      <td>0.879635</td>\n",
       "      <td>0.002014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Precision</th>\n",
       "      <td>0.874890</td>\n",
       "      <td>0.002495</td>\n",
       "      <td>0.873302</td>\n",
       "      <td>0.002478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recall</th>\n",
       "      <td>0.873369</td>\n",
       "      <td>0.003310</td>\n",
       "      <td>0.886582</td>\n",
       "      <td>0.003324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Roc_auc</th>\n",
       "      <td>0.936350</td>\n",
       "      <td>0.001440</td>\n",
       "      <td>0.938121</td>\n",
       "      <td>0.001341</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Method                RF                              \n",
       "Model            Model 1             Model 2          \n",
       "Values              Mean        Se      Mean        Se\n",
       "Accuracy_test   0.870818  0.002059  0.875664  0.002017\n",
       "Accuracy_train  0.993682  0.000167  0.980875  0.000400\n",
       "F1 Score        0.873881  0.002078  0.879635  0.002014\n",
       "Precision       0.874890  0.002495  0.873302  0.002478\n",
       "Recall          0.873369  0.003310  0.886582  0.003324\n",
       "Roc_auc         0.936350  0.001440  0.938121  0.001341"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Saving the data of model performance\n",
    "Model_data=pd.concat([Model1,Model2],axis=1)\n",
    "Model_data.columns = [['RF']*4,['Model 1','Model 1', 'Model 2','Model 2'], ['Mean', 'Se', 'Mean', 'Se']]  \n",
    "Model_data.columns.names=['Method','Model','Values']\n",
    "Model_data.to_csv(\"./RF_model_lasso_data.csv\",sep=',')\n",
    "Model_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "115be659-b066-4abf-85ac-59fccd101ad4",
   "metadata": {},
   "source": [
    "## 1.4 XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "3ff2324c-d316-43ae-96dc-e58f404273a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf=xgb.XGBClassifier(random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "03979633-d8bb-44e7-a9d7-b7050c4c32c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mean</th>\n",
       "      <th>Se</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Accuracy_test</th>\n",
       "      <td>0.872696</td>\n",
       "      <td>0.002064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Accuracy_train</th>\n",
       "      <td>0.993682</td>\n",
       "      <td>0.000167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1 Score</th>\n",
       "      <td>0.876134</td>\n",
       "      <td>0.002067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Precision</th>\n",
       "      <td>0.874216</td>\n",
       "      <td>0.002496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recall</th>\n",
       "      <td>0.878554</td>\n",
       "      <td>0.003303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Roc_auc</th>\n",
       "      <td>0.943173</td>\n",
       "      <td>0.001266</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Mean        Se\n",
       "Accuracy_test   0.872696  0.002064\n",
       "Accuracy_train  0.993682  0.000167\n",
       "F1 Score        0.876134  0.002067\n",
       "Precision       0.874216  0.002496\n",
       "Recall          0.878554  0.003303\n",
       "Roc_auc         0.943173  0.001266"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Model1 \n",
    "Model1_clf=clf\n",
    "#Model1\n",
    "Model1=Model_results(Model1_clf,X,y,Cv_model)\n",
    "Model1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "c6e5e42b-3688-4c6f-aa87-cf0fe5b1ff05",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2024-11-15 00:44:39,818]\u001b[0m A new study created in memory with name: no-name-fb6c69a8-dc40-42fe-bb25-f29e0a422845\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_81784\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_81784\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-11-15 00:47:15,708]\u001b[0m Trial 0 finished with value: 0.8742581864664924 and parameters: {'lambda': 0.15676677195506075, 'alpha': 0.7257005721594281, 'colsample_bytree': 0.7, 'subsample': 0.7000000000000001, 'learning_rate': 0.0801, 'n_estimators': 664}. Best is trial 0 with value: 0.8742581864664924.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_81784\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_81784\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-11-15 00:49:27,503]\u001b[0m Trial 1 finished with value: 0.8740487652306353 and parameters: {'lambda': 0.0562793204741517, 'alpha': 3.6905577292137624, 'colsample_bytree': 1.0, 'subsample': 0.6000000000000001, 'learning_rate': 0.1551, 'n_estimators': 552}. Best is trial 0 with value: 0.8742581864664924.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_81784\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_81784\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-11-15 00:51:16,304]\u001b[0m Trial 2 finished with value: 0.8182365100087032 and parameters: {'lambda': 0.18714500686240676, 'alpha': 5.039489598671215, 'colsample_bytree': 0.3, 'subsample': 0.4, 'learning_rate': 0.0001, 'n_estimators': 841}. Best is trial 0 with value: 0.8742581864664924.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_81784\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_81784\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-11-15 00:54:23,489]\u001b[0m Trial 3 finished with value: 0.8756107212793732 and parameters: {'lambda': 1.2960656597279736, 'alpha': 3.0202896401586674, 'colsample_bytree': 1.0, 'subsample': 0.9, 'learning_rate': 0.0901, 'n_estimators': 792}. Best is trial 3 with value: 0.8756107212793732.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_81784\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_81784\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-11-15 00:55:21,539]\u001b[0m Trial 4 finished with value: 0.8734773444299391 and parameters: {'lambda': 0.0029723346443356552, 'alpha': 0.3628140404024381, 'colsample_bytree': 0.4, 'subsample': 1.0, 'learning_rate': 0.10010000000000001, 'n_estimators': 444}. Best is trial 3 with value: 0.8756107212793732.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_81784\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_81784\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-11-15 00:58:13,723]\u001b[0m Trial 5 finished with value: 0.8574231668842472 and parameters: {'lambda': 0.011434638743472197, 'alpha': 1.2500712230836255, 'colsample_bytree': 0.6000000000000001, 'subsample': 0.7000000000000001, 'learning_rate': 0.0001, 'n_estimators': 637}. Best is trial 3 with value: 0.8756107212793732.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_81784\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_81784\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-11-15 01:00:58,914]\u001b[0m Trial 6 finished with value: 0.8743616731940819 and parameters: {'lambda': 0.2807908107885728, 'alpha': 0.2935864364395359, 'colsample_bytree': 1.0, 'subsample': 0.8, 'learning_rate': 0.07010000000000001, 'n_estimators': 465}. Best is trial 3 with value: 0.8756107212793732.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_81784\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_81784\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-11-15 01:01:57,066]\u001b[0m Trial 7 finished with value: 0.8737357212793735 and parameters: {'lambda': 0.6173405204074314, 'alpha': 0.0017414134181586202, 'colsample_bytree': 0.8, 'subsample': 0.8, 'learning_rate': 0.040100000000000004, 'n_estimators': 172}. Best is trial 3 with value: 0.8756107212793732.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_81784\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_81784\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-11-15 01:02:35,593]\u001b[0m Trial 8 finished with value: 0.8726954144908615 and parameters: {'lambda': 0.01826894228153233, 'alpha': 0.028499883436971588, 'colsample_bytree': 0.7, 'subsample': 0.7000000000000001, 'learning_rate': 0.1951, 'n_estimators': 147}. Best is trial 3 with value: 0.8756107212793732.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_81784\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_81784\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-11-15 01:03:50,704]\u001b[0m Trial 9 finished with value: 0.8731100413402959 and parameters: {'lambda': 0.006847105576684045, 'alpha': 0.004418125737902547, 'colsample_bytree': 0.8, 'subsample': 0.5, 'learning_rate': 0.0901, 'n_estimators': 282}. Best is trial 3 with value: 0.8756107212793732.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_81784\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_81784\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-11-15 01:06:51,884]\u001b[0m Trial 10 finished with value: 0.8742059671453437 and parameters: {'lambda': 6.8179090749657245, 'alpha': 0.05930570259610594, 'colsample_bytree': 0.5, 'subsample': 1.0, 'learning_rate': 0.1301, 'n_estimators': 987}. Best is trial 3 with value: 0.8756107212793732.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_81784\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_81784\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-11-15 01:09:35,825]\u001b[0m Trial 11 finished with value: 0.8758723618363794 and parameters: {'lambda': 1.9073794982580998, 'alpha': 0.19733730083782078, 'colsample_bytree': 1.0, 'subsample': 0.9, 'learning_rate': 0.0551, 'n_estimators': 410}. Best is trial 11 with value: 0.8758723618363794.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_81784\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_81784\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-11-15 01:14:13,290]\u001b[0m Trial 12 finished with value: 0.8770708224543081 and parameters: {'lambda': 2.5678455391010973, 'alpha': 0.013018672297928333, 'colsample_bytree': 0.9000000000000001, 'subsample': 0.9, 'learning_rate': 0.040100000000000004, 'n_estimators': 822}. Best is trial 12 with value: 0.8770708224543081.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_81784\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_81784\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-11-15 01:16:16,620]\u001b[0m Trial 13 finished with value: 0.8762369451697128 and parameters: {'lambda': 6.1962979052601455, 'alpha': 0.016605414256086717, 'colsample_bytree': 0.9000000000000001, 'subsample': 0.9, 'learning_rate': 0.040100000000000004, 'n_estimators': 320}. Best is trial 12 with value: 0.8770708224543081.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_81784\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_81784\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-11-15 01:18:14,935]\u001b[0m Trial 14 finished with value: 0.8745161553524804 and parameters: {'lambda': 7.40203726233777, 'alpha': 0.011611561568510122, 'colsample_bytree': 0.8, 'subsample': 0.9, 'learning_rate': 0.0301, 'n_estimators': 337}. Best is trial 12 with value: 0.8770708224543081.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_81784\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_81784\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-11-15 01:18:36,381]\u001b[0m Trial 15 finished with value: 0.8627387946040034 and parameters: {'lambda': 2.085029294210006, 'alpha': 0.013951155540245766, 'colsample_bytree': 0.9000000000000001, 'subsample': 0.8, 'learning_rate': 0.0251, 'n_estimators': 53}. Best is trial 12 with value: 0.8770708224543081.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_81784\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_81784\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-11-15 01:23:56,218]\u001b[0m Trial 16 finished with value: 0.8747259845517843 and parameters: {'lambda': 7.885094859929797, 'alpha': 0.001142158786840836, 'colsample_bytree': 0.9000000000000001, 'subsample': 1.0, 'learning_rate': 0.0451, 'n_estimators': 890}. Best is trial 12 with value: 0.8770708224543081.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_81784\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_81784\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-11-15 01:27:14,024]\u001b[0m Trial 17 finished with value: 0.8741544277632726 and parameters: {'lambda': 0.0010007385532741766, 'alpha': 0.005488888137678222, 'colsample_bytree': 0.9000000000000001, 'subsample': 0.9, 'learning_rate': 0.1201, 'n_estimators': 709}. Best is trial 12 with value: 0.8770708224543081.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_81784\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_81784\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-11-15 01:29:04,744]\u001b[0m Trial 18 finished with value: 0.8747779318973019 and parameters: {'lambda': 0.6287742707135822, 'alpha': 0.06766923553845729, 'colsample_bytree': 0.6000000000000001, 'subsample': 0.6000000000000001, 'learning_rate': 0.0201, 'n_estimators': 556}. Best is trial 12 with value: 0.8770708224543081.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_81784\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_81784\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-11-15 01:30:31,400]\u001b[0m Trial 19 finished with value: 0.874985857267189 and parameters: {'lambda': 0.049226036561702456, 'alpha': 0.023723553790922777, 'colsample_bytree': 0.8, 'subsample': 0.8, 'learning_rate': 0.0601, 'n_estimators': 288}. Best is trial 12 with value: 0.8770708224543081.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_81784\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_81784\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-11-15 01:34:45,872]\u001b[0m Trial 20 finished with value: 0.874414572454308 and parameters: {'lambda': 2.5132520362548596, 'alpha': 0.003696664769448613, 'colsample_bytree': 0.9000000000000001, 'subsample': 1.0, 'learning_rate': 0.11510000000000001, 'n_estimators': 965}. Best is trial 12 with value: 0.8770708224543081.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_81784\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_81784\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-11-15 01:37:46,306]\u001b[0m Trial 21 finished with value: 0.8755597258485639 and parameters: {'lambda': 3.035923324203101, 'alpha': 0.23654034400654037, 'colsample_bytree': 1.0, 'subsample': 0.9, 'learning_rate': 0.0551, 'n_estimators': 416}. Best is trial 12 with value: 0.8770708224543081.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_81784\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_81784\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-11-15 01:40:05,372]\u001b[0m Trial 22 finished with value: 0.8742575065274152 and parameters: {'lambda': 0.8269724716778049, 'alpha': 0.0987944650600272, 'colsample_bytree': 0.9000000000000001, 'subsample': 0.9, 'learning_rate': 0.015099999999999999, 'n_estimators': 367}. Best is trial 12 with value: 0.8770708224543081.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_81784\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_81784\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-11-15 01:41:38,878]\u001b[0m Trial 23 finished with value: 0.8749344538729331 and parameters: {'lambda': 4.488995619743988, 'alpha': 0.038129640251230966, 'colsample_bytree': 1.0, 'subsample': 0.9, 'learning_rate': 0.0601, 'n_estimators': 234}. Best is trial 12 with value: 0.8770708224543081.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_81784\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_81784\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-11-15 01:43:53,070]\u001b[0m Trial 24 finished with value: 0.8754034758485639 and parameters: {'lambda': 1.723864128065011, 'alpha': 0.01197486027497178, 'colsample_bytree': 0.7, 'subsample': 0.8, 'learning_rate': 0.040100000000000004, 'n_estimators': 496}. Best is trial 12 with value: 0.8770708224543081.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_81784\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_81784\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-11-15 01:46:52,774]\u001b[0m Trial 25 finished with value: 0.8749888489991298 and parameters: {'lambda': 0.3780314876736387, 'alpha': 0.1901399064122322, 'colsample_bytree': 0.9000000000000001, 'subsample': 1.0, 'learning_rate': 0.0751, 'n_estimators': 604}. Best is trial 12 with value: 0.8770708224543081.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_81784\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_81784\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-11-15 01:48:55,194]\u001b[0m Trial 26 finished with value: 0.8757677872062664 and parameters: {'lambda': 3.6487702596547424, 'alpha': 0.16401231055169369, 'colsample_bytree': 0.8, 'subsample': 0.9, 'learning_rate': 0.0451, 'n_estimators': 375}. Best is trial 12 with value: 0.8770708224543081.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_81784\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_81784\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-11-15 01:53:27,766]\u001b[0m Trial 27 finished with value: 0.8755069625761532 and parameters: {'lambda': 1.0824215390459981, 'alpha': 0.00901709250087776, 'colsample_bytree': 1.0, 'subsample': 0.7000000000000001, 'learning_rate': 0.0101, 'n_estimators': 708}. Best is trial 12 with value: 0.8770708224543081.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_81784\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_81784\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-11-15 01:57:55,245]\u001b[0m Trial 28 finished with value: 0.8751422432550043 and parameters: {'lambda': 5.145103147267329, 'alpha': 0.6642377809865375, 'colsample_bytree': 0.9000000000000001, 'subsample': 0.8, 'learning_rate': 0.035100000000000006, 'n_estimators': 781}. Best is trial 12 with value: 0.8770708224543081.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_81784\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_81784\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-11-15 01:58:43,808]\u001b[0m Trial 29 finished with value: 0.8757696910356831 and parameters: {'lambda': 0.07077562962343581, 'alpha': 0.020858765441844684, 'colsample_bytree': 0.7, 'subsample': 0.6000000000000001, 'learning_rate': 0.07010000000000001, 'n_estimators': 184}. Best is trial 12 with value: 0.8770708224543081.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_81784\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_81784\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-11-15 01:59:53,113]\u001b[0m Trial 30 finished with value: 0.8758215023933856 and parameters: {'lambda': 0.10678482264427308, 'alpha': 0.05096041059915502, 'colsample_bytree': 0.8, 'subsample': 1.0, 'learning_rate': 0.0551, 'n_estimators': 300}. Best is trial 12 with value: 0.8770708224543081.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_81784\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_81784\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-11-15 02:00:27,713]\u001b[0m Trial 31 finished with value: 0.8769663838120104 and parameters: {'lambda': 0.024213509451712495, 'alpha': 0.04475276045325755, 'colsample_bytree': 0.8, 'subsample': 1.0, 'learning_rate': 0.0551, 'n_estimators': 293}. Best is trial 12 with value: 0.8770708224543081.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_81784\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_81784\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-11-15 02:01:19,672]\u001b[0m Trial 32 finished with value: 0.8753008050478678 and parameters: {'lambda': 0.026015772095883117, 'alpha': 0.11766752586483051, 'colsample_bytree': 1.0, 'subsample': 1.0, 'learning_rate': 0.08510000000000001, 'n_estimators': 411}. Best is trial 12 with value: 0.8770708224543081.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_81784\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_81784\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-11-15 02:01:52,293]\u001b[0m Trial 33 finished with value: 0.8735791993037424 and parameters: {'lambda': 9.9320045353999, 'alpha': 0.599263047538916, 'colsample_bytree': 0.9000000000000001, 'subsample': 0.9, 'learning_rate': 0.050100000000000006, 'n_estimators': 222}. Best is trial 12 with value: 0.8770708224543081.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_81784\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_81784\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-11-15 02:02:48,981]\u001b[0m Trial 34 finished with value: 0.8745177872062664 and parameters: {'lambda': 0.005516401582752778, 'alpha': 1.8073070224082781, 'colsample_bytree': 1.0, 'subsample': 0.9, 'learning_rate': 0.1051, 'n_estimators': 538}. Best is trial 12 with value: 0.8770708224543081.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_81784\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_81784\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-11-15 02:03:15,641]\u001b[0m Trial 35 finished with value: 0.8716513000435161 and parameters: {'lambda': 0.22766164434982217, 'alpha': 0.006876545618341649, 'colsample_bytree': 0.8, 'subsample': 0.4, 'learning_rate': 0.14509999999999998, 'n_estimators': 356}. Best is trial 12 with value: 0.8770708224543081.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_81784\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_81784\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-11-15 02:03:21,673]\u001b[0m Trial 36 finished with value: 0.8730060106614448 and parameters: {'lambda': 0.03281553269349776, 'alpha': 0.0025496027912013364, 'colsample_bytree': 0.3, 'subsample': 1.0, 'learning_rate': 0.0651, 'n_estimators': 86}. Best is trial 12 with value: 0.8770708224543081.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_81784\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_81784\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-11-15 02:04:13,117]\u001b[0m Trial 37 finished with value: 0.8264186248912098 and parameters: {'lambda': 1.4398682244563592, 'alpha': 8.861629685772476, 'colsample_bytree': 0.7, 'subsample': 0.8, 'learning_rate': 0.0001, 'n_estimators': 462}. Best is trial 12 with value: 0.8770708224543081.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_81784\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_81784\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-11-15 02:04:29,418]\u001b[0m Trial 38 finished with value: 0.8753507125761532 and parameters: {'lambda': 0.12345593820706345, 'alpha': 0.021177086964089164, 'colsample_bytree': 0.4, 'subsample': 0.9, 'learning_rate': 0.0301, 'n_estimators': 254}. Best is trial 12 with value: 0.8770708224543081.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_81784\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_81784\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-11-15 02:04:49,985]\u001b[0m Trial 39 finished with value: 0.8743626251087904 and parameters: {'lambda': 0.31919002718185835, 'alpha': 0.38248591664414916, 'colsample_bytree': 1.0, 'subsample': 1.0, 'learning_rate': 0.0801, 'n_estimators': 134}. Best is trial 12 with value: 0.8770708224543081.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_81784\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_81784\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-11-15 02:05:35,060]\u001b[0m Trial 40 finished with value: 0.8719644799825934 and parameters: {'lambda': 0.011453859137299289, 'alpha': 0.11785832530228672, 'colsample_bytree': 0.9000000000000001, 'subsample': 0.7000000000000001, 'learning_rate': 0.1851, 'n_estimators': 502}. Best is trial 12 with value: 0.8770708224543081.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_81784\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_81784\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-11-15 02:06:10,385]\u001b[0m Trial 41 finished with value: 0.8762377610966057 and parameters: {'lambda': 0.08009249639391422, 'alpha': 0.044468593090041406, 'colsample_bytree': 0.8, 'subsample': 1.0, 'learning_rate': 0.050100000000000006, 'n_estimators': 313}. Best is trial 12 with value: 0.8770708224543081.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_81784\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_81784\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-11-15 02:06:50,096]\u001b[0m Trial 42 finished with value: 0.8693065981288077 and parameters: {'lambda': 0.049925299428624774, 'alpha': 0.0390594479570684, 'colsample_bytree': 0.8, 'subsample': 1.0, 'learning_rate': 0.0101, 'n_estimators': 312}. Best is trial 12 with value: 0.8770708224543081.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_81784\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_81784\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-11-15 02:07:34,619]\u001b[0m Trial 43 finished with value: 0.8763938751087903 and parameters: {'lambda': 0.07705836930624219, 'alpha': 0.08080450625911936, 'colsample_bytree': 0.8, 'subsample': 1.0, 'learning_rate': 0.035100000000000006, 'n_estimators': 397}. Best is trial 12 with value: 0.8770708224543081.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_81784\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_81784\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-11-15 02:07:54,442]\u001b[0m Trial 44 finished with value: 0.8745179231940818 and parameters: {'lambda': 0.07995097985192368, 'alpha': 0.07609065256090353, 'colsample_bytree': 0.6000000000000001, 'subsample': 1.0, 'learning_rate': 0.040100000000000004, 'n_estimators': 214}. Best is trial 12 with value: 0.8770708224543081.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_81784\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_81784\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-11-15 02:08:29,104]\u001b[0m Trial 45 finished with value: 0.8751965023933856 and parameters: {'lambda': 0.16597080122323282, 'alpha': 0.03370491042186044, 'colsample_bytree': 0.7, 'subsample': 1.0, 'learning_rate': 0.0251, 'n_estimators': 328}. Best is trial 12 with value: 0.8770708224543081.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_81784\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_81784\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-11-15 02:09:00,894]\u001b[0m Trial 46 finished with value: 0.8740493091818974 and parameters: {'lambda': 0.019031525272118283, 'alpha': 0.019027670977019042, 'colsample_bytree': 0.8, 'subsample': 1.0, 'learning_rate': 0.035100000000000006, 'n_estimators': 260}. Best is trial 12 with value: 0.8770708224543081.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_81784\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_81784\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-11-15 02:09:41,684]\u001b[0m Trial 47 finished with value: 0.8750909758485641 and parameters: {'lambda': 0.036210940643025526, 'alpha': 0.015017511918056435, 'colsample_bytree': 0.8, 'subsample': 1.0, 'learning_rate': 0.0951, 'n_estimators': 396}. Best is trial 12 with value: 0.8770708224543081.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_81784\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_81784\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-11-15 02:10:41,635]\u001b[0m Trial 48 finished with value: 0.8756633485639688 and parameters: {'lambda': 0.01248245401356691, 'alpha': 0.008302717772998462, 'colsample_bytree': 0.7, 'subsample': 0.9, 'learning_rate': 0.0201, 'n_estimators': 582}. Best is trial 12 with value: 0.8770708224543081.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_81784\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_81784\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-11-15 02:11:15,974]\u001b[0m Trial 49 finished with value: 0.8755601338120107 and parameters: {'lambda': 0.007957049159639143, 'alpha': 0.05390688092121265, 'colsample_bytree': 0.6000000000000001, 'subsample': 0.9, 'learning_rate': 0.07010000000000001, 'n_estimators': 440}. Best is trial 12 with value: 0.8770708224543081.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_81784\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_81784\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-11-15 02:12:37,874]\u001b[0m Trial 50 finished with value: 0.873319734551784 and parameters: {'lambda': 0.43997911685171226, 'alpha': 0.030088683733497105, 'colsample_bytree': 0.9000000000000001, 'subsample': 0.5, 'learning_rate': 0.050100000000000006, 'n_estimators': 870}. Best is trial 12 with value: 0.8770708224543081.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_81784\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_81784\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-11-15 02:13:24,861]\u001b[0m Trial 51 finished with value: 0.8757162478241949 and parameters: {'lambda': 5.685399693114345, 'alpha': 0.08371190756723752, 'colsample_bytree': 0.9000000000000001, 'subsample': 1.0, 'learning_rate': 0.0451, 'n_estimators': 347}. Best is trial 12 with value: 0.8770708224543081.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_81784\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_81784\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-11-15 02:14:16,967]\u001b[0m Trial 52 finished with value: 0.8752470898607484 and parameters: {'lambda': 0.06682922528222628, 'alpha': 0.36172348328654996, 'colsample_bytree': 0.8, 'subsample': 0.9, 'learning_rate': 0.0601, 'n_estimators': 484}. Best is trial 12 with value: 0.8770708224543081.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_81784\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_81784\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-11-15 02:15:17,404]\u001b[0m Trial 53 finished with value: 0.8750376686248913 and parameters: {'lambda': 2.415699961660441, 'alpha': 0.1325698263800169, 'colsample_bytree': 1.0, 'subsample': 0.8, 'learning_rate': 0.0301, 'n_estimators': 434}. Best is trial 12 with value: 0.8770708224543081.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_81784\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_81784\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-11-15 02:16:09,840]\u001b[0m Trial 54 finished with value: 0.8724329580069627 and parameters: {'lambda': 0.13993224003939408, 'alpha': 0.04863774056266789, 'colsample_bytree': 0.9000000000000001, 'subsample': 0.9, 'learning_rate': 0.0101, 'n_estimators': 389}. Best is trial 12 with value: 0.8770708224543081.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_81784\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_81784\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-11-15 02:16:44,695]\u001b[0m Trial 55 finished with value: 0.8754566470844212 and parameters: {'lambda': 0.9687950111073276, 'alpha': 0.1974732837200702, 'colsample_bytree': 0.8, 'subsample': 1.0, 'learning_rate': 0.050100000000000006, 'n_estimators': 289}. Best is trial 12 with value: 0.8770708224543081.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_81784\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_81784\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-11-15 02:17:08,514]\u001b[0m Trial 56 finished with value: 0.8749355417754568 and parameters: {'lambda': 0.5595342596547543, 'alpha': 0.01475108879915725, 'colsample_bytree': 0.9000000000000001, 'subsample': 0.8, 'learning_rate': 0.0801, 'n_estimators': 190}. Best is trial 12 with value: 0.8770708224543081.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_81784\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_81784\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-11-15 02:18:46,557]\u001b[0m Trial 57 finished with value: 0.8743098618363794 and parameters: {'lambda': 3.5827381711865907, 'alpha': 0.06733924249557648, 'colsample_bytree': 1.0, 'subsample': 0.9, 'learning_rate': 0.0651, 'n_estimators': 806}. Best is trial 12 with value: 0.8770708224543081.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_81784\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_81784\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-11-15 02:20:33,824]\u001b[0m Trial 58 finished with value: 0.8766034323324631 and parameters: {'lambda': 0.23639482688784724, 'alpha': 0.0031465141765635906, 'colsample_bytree': 0.9000000000000001, 'subsample': 1.0, 'learning_rate': 0.035100000000000006, 'n_estimators': 919}. Best is trial 12 with value: 0.8770708224543081.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_81784\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_81784\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-11-15 02:22:22,076]\u001b[0m Trial 59 finished with value: 0.8771766209747605 and parameters: {'lambda': 0.039621891846015396, 'alpha': 0.002705374997517302, 'colsample_bytree': 0.8, 'subsample': 1.0, 'learning_rate': 0.0201, 'n_estimators': 948}. Best is trial 59 with value: 0.8771766209747605.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_81784\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_81784\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-11-15 02:23:54,143]\u001b[0m Trial 60 finished with value: 0.8761874456048738 and parameters: {'lambda': 0.20805124399744432, 'alpha': 0.0011092065082825276, 'colsample_bytree': 0.7, 'subsample': 1.0, 'learning_rate': 0.0201, 'n_estimators': 931}. Best is trial 59 with value: 0.8771766209747605.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_81784\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_81784\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-11-15 02:25:33,595]\u001b[0m Trial 61 finished with value: 0.8759777523933855 and parameters: {'lambda': 0.0204899238984654, 'alpha': 0.0025579796543857268, 'colsample_bytree': 0.8, 'subsample': 1.0, 'learning_rate': 0.035100000000000006, 'n_estimators': 994}. Best is trial 59 with value: 0.8771766209747605.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_81784\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_81784\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-11-15 02:27:35,326]\u001b[0m Trial 62 finished with value: 0.8402304993472586 and parameters: {'lambda': 0.04008185559116487, 'alpha': 0.004438331613558568, 'colsample_bytree': 0.8, 'subsample': 1.0, 'learning_rate': 0.0001, 'n_estimators': 942}. Best is trial 59 with value: 0.8771766209747605.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_81784\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_81784\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-11-15 02:29:21,078]\u001b[0m Trial 63 finished with value: 0.8759778883812013 and parameters: {'lambda': 0.09852330973569692, 'alpha': 0.0017422582132935937, 'colsample_bytree': 0.9000000000000001, 'subsample': 1.0, 'learning_rate': 0.0251, 'n_estimators': 902}. Best is trial 59 with value: 0.8771766209747605.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_81784\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_81784\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-11-15 02:30:58,055]\u001b[0m Trial 64 finished with value: 0.8757173357267188 and parameters: {'lambda': 0.055150216377134666, 'alpha': 0.002646554903299117, 'colsample_bytree': 0.9000000000000001, 'subsample': 1.0, 'learning_rate': 0.040100000000000004, 'n_estimators': 843}. Best is trial 59 with value: 0.8771766209747605.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_81784\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_81784\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-11-15 02:32:29,104]\u001b[0m Trial 65 finished with value: 0.8764985857267189 and parameters: {'lambda': 0.02687669786383044, 'alpha': 0.0016764770089021349, 'colsample_bytree': 0.8, 'subsample': 1.0, 'learning_rate': 0.015099999999999999, 'n_estimators': 756}. Best is trial 59 with value: 0.8771766209747605.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_81784\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_81784\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-11-15 02:34:00,606]\u001b[0m Trial 66 finished with value: 0.8738398879460401 and parameters: {'lambda': 0.02595444267161302, 'alpha': 0.0017625671266645036, 'colsample_bytree': 0.8, 'subsample': 1.0, 'learning_rate': 0.0101, 'n_estimators': 762}. Best is trial 59 with value: 0.8771766209747605.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_81784\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_81784\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-11-15 02:35:17,178]\u001b[0m Trial 67 finished with value: 0.8715982647954743 and parameters: {'lambda': 0.08483399071570272, 'alpha': 0.0036790271367071266, 'colsample_bytree': 0.7, 'subsample': 1.0, 'learning_rate': 0.0051, 'n_estimators': 708}. Best is trial 59 with value: 0.8771766209747605.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_81784\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_81784\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-11-15 02:36:53,577]\u001b[0m Trial 68 finished with value: 0.876133322454308 and parameters: {'lambda': 0.013777921384722227, 'alpha': 0.001311288759645209, 'colsample_bytree': 0.8, 'subsample': 1.0, 'learning_rate': 0.015099999999999999, 'n_estimators': 822}. Best is trial 59 with value: 0.8771766209747605.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_81784\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_81784\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-11-15 02:38:06,292]\u001b[0m Trial 69 finished with value: 0.8767062391209746 and parameters: {'lambda': 0.002360787758663562, 'alpha': 0.005812465228790088, 'colsample_bytree': 0.7, 'subsample': 0.9, 'learning_rate': 0.0251, 'n_estimators': 741}. Best is trial 59 with value: 0.8771766209747605.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_81784\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_81784\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-11-15 02:39:09,640]\u001b[0m Trial 70 finished with value: 0.8762378970844211 and parameters: {'lambda': 0.0014509670571243318, 'alpha': 0.005693831291567184, 'colsample_bytree': 0.7, 'subsample': 0.9, 'learning_rate': 0.0301, 'n_estimators': 657}. Best is trial 59 with value: 0.8771766209747605.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_81784\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_81784\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-11-15 02:40:07,782]\u001b[0m Trial 71 finished with value: 0.8768113577023499 and parameters: {'lambda': 0.002111254033722209, 'alpha': 0.005727231247900287, 'colsample_bytree': 0.6000000000000001, 'subsample': 0.9, 'learning_rate': 0.0251, 'n_estimators': 670}. Best is trial 59 with value: 0.8771766209747605.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_81784\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_81784\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-11-15 02:41:07,178]\u001b[0m Trial 72 finished with value: 0.8778531603568319 and parameters: {'lambda': 0.0030837050510052594, 'alpha': 0.011205459307836951, 'colsample_bytree': 0.5, 'subsample': 0.9, 'learning_rate': 0.0201, 'n_estimators': 769}. Best is trial 72 with value: 0.8778531603568319.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_81784\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_81784\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-11-15 02:42:02,009]\u001b[0m Trial 73 finished with value: 0.8772786118363795 and parameters: {'lambda': 0.002902486875579974, 'alpha': 0.009253684311144466, 'colsample_bytree': 0.5, 'subsample': 0.9, 'learning_rate': 0.0201, 'n_estimators': 745}. Best is trial 72 with value: 0.8778531603568319.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_81784\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_81784\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-11-15 02:42:57,169]\u001b[0m Trial 74 finished with value: 0.8771753970844213 and parameters: {'lambda': 0.0027667033041175915, 'alpha': 0.010012167307929788, 'colsample_bytree': 0.5, 'subsample': 0.9, 'learning_rate': 0.0201, 'n_estimators': 718}. Best is trial 72 with value: 0.8778531603568319.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_81784\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_81784\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-11-15 02:43:50,234]\u001b[0m Trial 75 finished with value: 0.8758216383812011 and parameters: {'lambda': 0.002702010442666205, 'alpha': 0.009744292227273974, 'colsample_bytree': 0.5, 'subsample': 0.8, 'learning_rate': 0.0251, 'n_estimators': 730}. Best is trial 72 with value: 0.8778531603568319.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_81784\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_81784\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-11-15 02:44:40,856]\u001b[0m Trial 76 finished with value: 0.8773309671453439 and parameters: {'lambda': 0.003234494373644734, 'alpha': 0.006358480782162718, 'colsample_bytree': 0.5, 'subsample': 0.9, 'learning_rate': 0.0201, 'n_estimators': 675}. Best is trial 72 with value: 0.8778531603568319.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_81784\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_81784\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-11-15 02:45:28,965]\u001b[0m Trial 77 finished with value: 0.8767067830722368 and parameters: {'lambda': 0.00412066871403912, 'alpha': 0.011629549013349064, 'colsample_bytree': 0.5, 'subsample': 0.8, 'learning_rate': 0.015099999999999999, 'n_estimators': 629}. Best is trial 72 with value: 0.8778531603568319.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_81784\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_81784\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-11-15 02:46:15,709]\u001b[0m Trial 78 finished with value: 0.8748823705395995 and parameters: {'lambda': 0.0016838986551332917, 'alpha': 0.007146766715708949, 'colsample_bytree': 0.4, 'subsample': 0.9, 'learning_rate': 0.0051, 'n_estimators': 662}. Best is trial 72 with value: 0.8778531603568319.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_81784\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_81784\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-11-15 02:47:24,990]\u001b[0m Trial 79 finished with value: 0.8736315546127067 and parameters: {'lambda': 0.003983120557005908, 'alpha': 0.00449356154289989, 'colsample_bytree': 0.5, 'subsample': 0.9, 'learning_rate': 0.0051, 'n_estimators': 858}. Best is trial 72 with value: 0.8778531603568319.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_81784\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_81784\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-11-15 02:48:23,276]\u001b[0m Trial 80 finished with value: 0.8757176077023501 and parameters: {'lambda': 0.00788910854212667, 'alpha': 0.008569245116458795, 'colsample_bytree': 0.5, 'subsample': 0.8, 'learning_rate': 0.0201, 'n_estimators': 794}. Best is trial 72 with value: 0.8778531603568319.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_81784\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_81784\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-11-15 02:49:09,528]\u001b[0m Trial 81 finished with value: 0.8771751251087901 and parameters: {'lambda': 0.00393556736895547, 'alpha': 0.01272698178519547, 'colsample_bytree': 0.5, 'subsample': 0.9, 'learning_rate': 0.015099999999999999, 'n_estimators': 622}. Best is trial 72 with value: 0.8778531603568319.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_81784\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_81784\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-11-15 02:50:02,362]\u001b[0m Trial 82 finished with value: 0.8771226338120104 and parameters: {'lambda': 0.0019883114096240907, 'alpha': 0.02378382560553772, 'colsample_bytree': 0.5, 'subsample': 0.9, 'learning_rate': 0.0201, 'n_estimators': 706}. Best is trial 72 with value: 0.8778531603568319.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_81784\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_81784\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-11-15 02:50:47,087]\u001b[0m Trial 83 finished with value: 0.8760806951697129 and parameters: {'lambda': 0.004086544297177316, 'alpha': 0.018315280983152, 'colsample_bytree': 0.4, 'subsample': 0.9, 'learning_rate': 0.015099999999999999, 'n_estimators': 687}. Best is trial 72 with value: 0.8778531603568319.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_81784\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_81784\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-11-15 02:51:39,333]\u001b[0m Trial 84 finished with value: 0.8635715839860748 and parameters: {'lambda': 0.005359524528675459, 'alpha': 0.0256056470397381, 'colsample_bytree': 0.5, 'subsample': 0.9, 'learning_rate': 0.0001, 'n_estimators': 620}. Best is trial 72 with value: 0.8778531603568319.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_81784\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_81784\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-11-15 02:52:16,411]\u001b[0m Trial 85 finished with value: 0.8762883485639686 and parameters: {'lambda': 0.0011882070003876324, 'alpha': 0.011093227491087336, 'colsample_bytree': 0.4, 'subsample': 0.9, 'learning_rate': 0.0201, 'n_estimators': 578}. Best is trial 72 with value: 0.8778531603568319.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_81784\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_81784\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-11-15 02:53:16,514]\u001b[0m Trial 86 finished with value: 0.8755599978241949 and parameters: {'lambda': 0.0016126414922709895, 'alpha': 0.013882328836967267, 'colsample_bytree': 0.5, 'subsample': 0.9, 'learning_rate': 0.0101, 'n_estimators': 770}. Best is trial 72 with value: 0.8778531603568319.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_81784\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_81784\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-11-15 02:54:10,225]\u001b[0m Trial 87 finished with value: 0.8772281603568319 and parameters: {'lambda': 0.005902798600962376, 'alpha': 0.0229896761645262, 'colsample_bytree': 0.5, 'subsample': 0.8, 'learning_rate': 0.0301, 'n_estimators': 724}. Best is trial 72 with value: 0.8778531603568319.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_81784\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_81784\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-11-15 02:55:01,727]\u001b[0m Trial 88 finished with value: 0.8756114012184508 and parameters: {'lambda': 0.0033906992229335176, 'alpha': 0.024124025403992003, 'colsample_bytree': 0.5, 'subsample': 0.8, 'learning_rate': 0.0301, 'n_estimators': 725}. Best is trial 72 with value: 0.8778531603568319.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_81784\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_81784\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-11-15 02:56:01,720]\u001b[0m Trial 89 finished with value: 0.8767581864664926 and parameters: {'lambda': 0.0055293807169655125, 'alpha': 0.0075322390695671615, 'colsample_bytree': 0.6000000000000001, 'subsample': 0.8, 'learning_rate': 0.0201, 'n_estimators': 689}. Best is trial 72 with value: 0.8778531603568319.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_81784\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_81784\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-11-15 02:57:10,511]\u001b[0m Trial 90 finished with value: 0.8734746246736294 and parameters: {'lambda': 0.0019476678133913156, 'alpha': 0.009995225435278364, 'colsample_bytree': 0.5, 'subsample': 0.9, 'learning_rate': 0.0051, 'n_estimators': 829}. Best is trial 72 with value: 0.8778531603568319.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_81784\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_81784\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-11-15 02:57:52,213]\u001b[0m Trial 91 finished with value: 0.8760815110966058 and parameters: {'lambda': 0.0028215738994097116, 'alpha': 0.032247562245228095, 'colsample_bytree': 0.4, 'subsample': 0.9, 'learning_rate': 0.0301, 'n_estimators': 649}. Best is trial 72 with value: 0.8778531603568319.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_81784\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_81784\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-11-15 02:58:39,857]\u001b[0m Trial 92 finished with value: 0.8757165197998259 and parameters: {'lambda': 0.006635763342885786, 'alpha': 0.016793256713646988, 'colsample_bytree': 0.5, 'subsample': 0.9, 'learning_rate': 0.0451, 'n_estimators': 681}. Best is trial 72 with value: 0.8778531603568319.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_81784\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_81784\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-11-15 02:59:21,910]\u001b[0m Trial 93 finished with value: 0.8737378970844213 and parameters: {'lambda': 0.0013379293659148738, 'alpha': 0.013212094106557555, 'colsample_bytree': 0.5, 'subsample': 0.7000000000000001, 'learning_rate': 0.035100000000000006, 'n_estimators': 596}. Best is trial 72 with value: 0.8778531603568319.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_81784\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_81784\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-11-15 03:00:21,695]\u001b[0m Trial 94 finished with value: 0.8759769364664927 and parameters: {'lambda': 0.0032960392441155765, 'alpha': 0.023431679767069582, 'colsample_bytree': 0.6000000000000001, 'subsample': 0.9, 'learning_rate': 0.040100000000000004, 'n_estimators': 712}. Best is trial 72 with value: 0.8778531603568319.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_81784\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_81784\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-11-15 03:01:22,149]\u001b[0m Trial 95 finished with value: 0.8761855417754569 and parameters: {'lambda': 0.001001091330507245, 'alpha': 0.01873044310236445, 'colsample_bytree': 0.5, 'subsample': 0.8, 'learning_rate': 0.015099999999999999, 'n_estimators': 794}. Best is trial 72 with value: 0.8778531603568319.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_81784\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_81784\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-11-15 03:02:08,699]\u001b[0m Trial 96 finished with value: 0.8763946910356831 and parameters: {'lambda': 0.0024475236065363095, 'alpha': 0.03878866218894483, 'colsample_bytree': 0.4, 'subsample': 0.9, 'learning_rate': 0.0301, 'n_estimators': 747}. Best is trial 72 with value: 0.8778531603568319.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_81784\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_81784\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-11-15 03:03:14,405]\u001b[0m Trial 97 finished with value: 0.8756127610966056 and parameters: {'lambda': 0.009648892188656232, 'alpha': 0.006938685748854457, 'colsample_bytree': 0.6000000000000001, 'subsample': 0.8, 'learning_rate': 0.0201, 'n_estimators': 778}. Best is trial 72 with value: 0.8778531603568319.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_81784\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_81784\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-11-15 03:03:53,991]\u001b[0m Trial 98 finished with value: 0.8731640285030461 and parameters: {'lambda': 0.005196187999973316, 'alpha': 0.026892989877632226, 'colsample_bytree': 0.5, 'subsample': 0.9, 'learning_rate': 0.1701, 'n_estimators': 707}. Best is trial 72 with value: 0.8778531603568319.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_81784\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_81784\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-11-15 03:04:33,612]\u001b[0m Trial 99 finished with value: 0.8766023444299391 and parameters: {'lambda': 0.00451892372921799, 'alpha': 0.012324097924993657, 'colsample_bytree': 0.5, 'subsample': 0.9, 'learning_rate': 0.0451, 'n_estimators': 548}. Best is trial 72 with value: 0.8778531603568319.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "#Tuning hyperparameters\n",
    "#Step 1. Define an objective function to be maximized.\n",
    "def objective(trial):\n",
    "    param = {\n",
    "        'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
    "        'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
    "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.3,1.0,step=0.1),\n",
    "        'subsample': trial.suggest_float('subsample', 0.4, 1.0, step=0.1),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.0001, 0.2, step=0.005),\n",
    "        'n_estimators': trial.suggest_int(\"n_estimators\",50,1000,1)\n",
    "        #'min_child_weight': trial.suggest_int('min_child_weight', 1, 300),\n",
    "    }\n",
    "    model = xgb.XGBClassifier(**param,random_state=1,n_jobs=8)\n",
    "\n",
    " \n",
    "# Step 2: Scoring method:\n",
    "    score = model_selection.cross_val_score(model, X, y, n_jobs=8, scoring=\"accuracy\",cv=Cv_optuna)\n",
    "    accuracy = score.mean()\n",
    "    return accuracy\n",
    "\n",
    "# Step 3: Running it\n",
    "study = optuna.create_study(direction=\"maximize\",sampler=optuna.samplers.TPESampler(seed=0))\n",
    "study.optimize(objective, n_trials=100, show_progress_bar=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "b2be4542-3f0e-438f-8e41-c67d96410fab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best parameters are : \n",
      "{'lambda': 0.0030837050510052594, 'alpha': 0.011205459307836951, 'colsample_bytree': 0.5, 'subsample': 0.9, 'learning_rate': 0.0201, 'n_estimators': 769}\n"
     ]
    }
   ],
   "source": [
    "# Getting the best parameters:\n",
    "print(f\"The best parameters are : \\n{study.best_params}\")\n",
    "# Setting the best model\n",
    "clf=xgb.XGBClassifier(alpha = study.best_params['alpha']\n",
    "              ,colsample_bytree = study.best_params['colsample_bytree']\n",
    "              ,subsample = study.best_params['subsample']\n",
    "              ,n_estimators = study.best_params['n_estimators']\n",
    "              ,learning_rate= study.best_params['learning_rate'], n_jobs=8\n",
    "              ,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "d0687ace-1f1a-44a0-9329-fc50b681ff53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mean</th>\n",
       "      <th>Se</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Accuracy_test</th>\n",
       "      <td>0.876915</td>\n",
       "      <td>0.002066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Accuracy_train</th>\n",
       "      <td>0.993682</td>\n",
       "      <td>0.000167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1 Score</th>\n",
       "      <td>0.879990</td>\n",
       "      <td>0.002123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Precision</th>\n",
       "      <td>0.879541</td>\n",
       "      <td>0.002321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recall</th>\n",
       "      <td>0.880991</td>\n",
       "      <td>0.003643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Roc_auc</th>\n",
       "      <td>0.946797</td>\n",
       "      <td>0.001243</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Mean        Se\n",
       "Accuracy_test   0.876915  0.002066\n",
       "Accuracy_train  0.993682  0.000167\n",
       "F1 Score        0.879990  0.002123\n",
       "Precision       0.879541  0.002321\n",
       "Recall          0.880991  0.003643\n",
       "Roc_auc         0.946797  0.001243"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Model2\n",
    "Model2=Model_results(clf,X,y,Cv_model)\n",
    "Model2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "0bb46026-eb5e-4693-8e81-0a0a2ed16564",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th>Method</th>\n",
       "      <th colspan=\"4\" halign=\"left\">XGB</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model</th>\n",
       "      <th colspan=\"2\" halign=\"left\">Model 1</th>\n",
       "      <th colspan=\"2\" halign=\"left\">Model 2</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Values</th>\n",
       "      <th>Mean</th>\n",
       "      <th>Se</th>\n",
       "      <th>Mean</th>\n",
       "      <th>Se</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Accuracy_test</th>\n",
       "      <td>0.872696</td>\n",
       "      <td>0.002064</td>\n",
       "      <td>0.876915</td>\n",
       "      <td>0.002066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Accuracy_train</th>\n",
       "      <td>0.993682</td>\n",
       "      <td>0.000167</td>\n",
       "      <td>0.993682</td>\n",
       "      <td>0.000167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1 Score</th>\n",
       "      <td>0.876134</td>\n",
       "      <td>0.002067</td>\n",
       "      <td>0.879990</td>\n",
       "      <td>0.002123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Precision</th>\n",
       "      <td>0.874216</td>\n",
       "      <td>0.002496</td>\n",
       "      <td>0.879541</td>\n",
       "      <td>0.002321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recall</th>\n",
       "      <td>0.878554</td>\n",
       "      <td>0.003303</td>\n",
       "      <td>0.880991</td>\n",
       "      <td>0.003643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Roc_auc</th>\n",
       "      <td>0.943173</td>\n",
       "      <td>0.001266</td>\n",
       "      <td>0.946797</td>\n",
       "      <td>0.001243</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Method               XGB                              \n",
       "Model            Model 1             Model 2          \n",
       "Values              Mean        Se      Mean        Se\n",
       "Accuracy_test   0.872696  0.002064  0.876915  0.002066\n",
       "Accuracy_train  0.993682  0.000167  0.993682  0.000167\n",
       "F1 Score        0.876134  0.002067  0.879990  0.002123\n",
       "Precision       0.874216  0.002496  0.879541  0.002321\n",
       "Recall          0.878554  0.003303  0.880991  0.003643\n",
       "Roc_auc         0.943173  0.001266  0.946797  0.001243"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Saving the data of model performance\n",
    "Model_data=pd.concat([Model1,Model2],axis=1)\n",
    "Model_data.columns = [['XGB']*4,['Model 1','Model 1', 'Model 2','Model 2'], ['Mean', 'Se', 'Mean', 'Se']]  \n",
    "Model_data.columns.names=['Method','Model','Values']\n",
    "Model_data.to_csv(\"./XGB_model_lasso_data.csv\",sep=',')\n",
    "Model_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "208fbfd4-b156-43fb-b7b8-5f38ee0e24ef",
   "metadata": {},
   "source": [
    "# 2. MLREM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "45019f5e-5468-4d1b-a4de-8b8c86e33654",
   "metadata": {},
   "outputs": [],
   "source": [
    "col_data= pd.read_csv(\"./Results/MLREM_col.csv\",header=0,index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "f6d91ba6-9049-4060-818a-8cf59d7a47b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MW</th>\n",
       "      <th>D/Dtr09</th>\n",
       "      <th>ZM1MulPer</th>\n",
       "      <th>ECC</th>\n",
       "      <th>CENT</th>\n",
       "      <th>SMTI</th>\n",
       "      <th>SMTIV</th>\n",
       "      <th>GMTIV</th>\n",
       "      <th>Wap</th>\n",
       "      <th>IDMT</th>\n",
       "      <th>...</th>\n",
       "      <th>ATSC5s</th>\n",
       "      <th>P_VSA_MR_3</th>\n",
       "      <th>P_VSA_ppp_ar</th>\n",
       "      <th>P_VSA_ppp_con</th>\n",
       "      <th>P_VSA_charge_2</th>\n",
       "      <th>SM15_EA(ed)</th>\n",
       "      <th>T(O..Br)</th>\n",
       "      <th>TPSA(Tot)</th>\n",
       "      <th>SAdon</th>\n",
       "      <th>Vx</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Ma_2019_A</th>\n",
       "      <td>267.28</td>\n",
       "      <td>66.871159</td>\n",
       "      <td>348.869542</td>\n",
       "      <td>135.0</td>\n",
       "      <td>383.0</td>\n",
       "      <td>2886.0</td>\n",
       "      <td>5576.0</td>\n",
       "      <td>10547.0</td>\n",
       "      <td>5729.0</td>\n",
       "      <td>4739.692713</td>\n",
       "      <td>...</td>\n",
       "      <td>90.763661</td>\n",
       "      <td>139.049917</td>\n",
       "      <td>75.680233</td>\n",
       "      <td>63.202194</td>\n",
       "      <td>1.899093</td>\n",
       "      <td>36.892542</td>\n",
       "      <td>0.0</td>\n",
       "      <td>139.54</td>\n",
       "      <td>160.947217</td>\n",
       "      <td>291.295681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ma_2019_U</th>\n",
       "      <td>244.23</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>340.039426</td>\n",
       "      <td>118.0</td>\n",
       "      <td>295.0</td>\n",
       "      <td>2084.0</td>\n",
       "      <td>4432.0</td>\n",
       "      <td>8734.0</td>\n",
       "      <td>2194.0</td>\n",
       "      <td>3416.557603</td>\n",
       "      <td>...</td>\n",
       "      <td>139.839496</td>\n",
       "      <td>139.049917</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>48.373245</td>\n",
       "      <td>46.279992</td>\n",
       "      <td>36.205320</td>\n",
       "      <td>0.0</td>\n",
       "      <td>124.78</td>\n",
       "      <td>146.060780</td>\n",
       "      <td>262.840532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ma_2019_C</th>\n",
       "      <td>243.25</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>319.988367</td>\n",
       "      <td>118.0</td>\n",
       "      <td>295.0</td>\n",
       "      <td>2084.0</td>\n",
       "      <td>4240.0</td>\n",
       "      <td>7972.0</td>\n",
       "      <td>2194.0</td>\n",
       "      <td>3416.557603</td>\n",
       "      <td>...</td>\n",
       "      <td>137.031903</td>\n",
       "      <td>139.049917</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>67.057867</td>\n",
       "      <td>3.124314</td>\n",
       "      <td>36.205320</td>\n",
       "      <td>0.0</td>\n",
       "      <td>130.83</td>\n",
       "      <td>160.947217</td>\n",
       "      <td>269.667774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ma_2019_G</th>\n",
       "      <td>283.28</td>\n",
       "      <td>71.547747</td>\n",
       "      <td>387.546658</td>\n",
       "      <td>144.0</td>\n",
       "      <td>446.0</td>\n",
       "      <td>3270.0</td>\n",
       "      <td>6542.0</td>\n",
       "      <td>12768.0</td>\n",
       "      <td>6578.0</td>\n",
       "      <td>5547.544286</td>\n",
       "      <td>...</td>\n",
       "      <td>117.471961</td>\n",
       "      <td>139.049917</td>\n",
       "      <td>32.387883</td>\n",
       "      <td>80.922082</td>\n",
       "      <td>45.054770</td>\n",
       "      <td>36.939118</td>\n",
       "      <td>0.0</td>\n",
       "      <td>159.51</td>\n",
       "      <td>178.957968</td>\n",
       "      <td>301.046512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ma_2019_dA</th>\n",
       "      <td>251.28</td>\n",
       "      <td>63.146800</td>\n",
       "      <td>315.599992</td>\n",
       "      <td>128.0</td>\n",
       "      <td>336.0</td>\n",
       "      <td>2584.0</td>\n",
       "      <td>4822.0</td>\n",
       "      <td>8812.0</td>\n",
       "      <td>5068.0</td>\n",
       "      <td>4099.715332</td>\n",
       "      <td>...</td>\n",
       "      <td>52.221046</td>\n",
       "      <td>96.366574</td>\n",
       "      <td>75.680233</td>\n",
       "      <td>63.202194</td>\n",
       "      <td>1.899093</td>\n",
       "      <td>36.335611</td>\n",
       "      <td>0.0</td>\n",
       "      <td>119.31</td>\n",
       "      <td>118.263874</td>\n",
       "      <td>281.544850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tang_2019_ArabinoC</th>\n",
       "      <td>243.25</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>319.988367</td>\n",
       "      <td>118.0</td>\n",
       "      <td>295.0</td>\n",
       "      <td>2084.0</td>\n",
       "      <td>4240.0</td>\n",
       "      <td>7972.0</td>\n",
       "      <td>2194.0</td>\n",
       "      <td>3416.557603</td>\n",
       "      <td>...</td>\n",
       "      <td>137.031903</td>\n",
       "      <td>139.049917</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>67.057867</td>\n",
       "      <td>3.124314</td>\n",
       "      <td>36.205320</td>\n",
       "      <td>0.0</td>\n",
       "      <td>130.83</td>\n",
       "      <td>160.947217</td>\n",
       "      <td>269.667774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tang_2019_DideoxyC</th>\n",
       "      <td>211.25</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>253.494297</td>\n",
       "      <td>103.0</td>\n",
       "      <td>213.0</td>\n",
       "      <td>1585.0</td>\n",
       "      <td>2963.0</td>\n",
       "      <td>5062.0</td>\n",
       "      <td>1633.0</td>\n",
       "      <td>2398.199373</td>\n",
       "      <td>...</td>\n",
       "      <td>59.519699</td>\n",
       "      <td>53.683231</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>67.057867</td>\n",
       "      <td>3.124314</td>\n",
       "      <td>34.619300</td>\n",
       "      <td>0.0</td>\n",
       "      <td>90.37</td>\n",
       "      <td>75.580531</td>\n",
       "      <td>250.166113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Peters_2014_3</th>\n",
       "      <td>268.26</td>\n",
       "      <td>66.871159</td>\n",
       "      <td>369.000658</td>\n",
       "      <td>135.0</td>\n",
       "      <td>383.0</td>\n",
       "      <td>2886.0</td>\n",
       "      <td>5763.0</td>\n",
       "      <td>11275.0</td>\n",
       "      <td>5729.0</td>\n",
       "      <td>4739.692713</td>\n",
       "      <td>...</td>\n",
       "      <td>100.945467</td>\n",
       "      <td>139.049917</td>\n",
       "      <td>32.387883</td>\n",
       "      <td>87.641582</td>\n",
       "      <td>27.044020</td>\n",
       "      <td>36.892542</td>\n",
       "      <td>0.0</td>\n",
       "      <td>133.49</td>\n",
       "      <td>146.060780</td>\n",
       "      <td>284.468439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Plank_2016_2</th>\n",
       "      <td>393.17</td>\n",
       "      <td>71.547747</td>\n",
       "      <td>412.608258</td>\n",
       "      <td>144.0</td>\n",
       "      <td>446.0</td>\n",
       "      <td>3270.0</td>\n",
       "      <td>6760.0</td>\n",
       "      <td>13668.0</td>\n",
       "      <td>6578.0</td>\n",
       "      <td>5547.544286</td>\n",
       "      <td>...</td>\n",
       "      <td>73.852917</td>\n",
       "      <td>96.366574</td>\n",
       "      <td>32.387883</td>\n",
       "      <td>80.922082</td>\n",
       "      <td>45.054770</td>\n",
       "      <td>36.939118</td>\n",
       "      <td>0.0</td>\n",
       "      <td>139.28</td>\n",
       "      <td>136.274624</td>\n",
       "      <td>334.202658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Du2021_L_G</th>\n",
       "      <td>283.28</td>\n",
       "      <td>71.547747</td>\n",
       "      <td>387.546658</td>\n",
       "      <td>144.0</td>\n",
       "      <td>446.0</td>\n",
       "      <td>3270.0</td>\n",
       "      <td>6542.0</td>\n",
       "      <td>12768.0</td>\n",
       "      <td>6578.0</td>\n",
       "      <td>5547.544286</td>\n",
       "      <td>...</td>\n",
       "      <td>117.471961</td>\n",
       "      <td>139.049917</td>\n",
       "      <td>32.387883</td>\n",
       "      <td>80.922082</td>\n",
       "      <td>45.054770</td>\n",
       "      <td>36.939118</td>\n",
       "      <td>0.0</td>\n",
       "      <td>159.51</td>\n",
       "      <td>178.957968</td>\n",
       "      <td>301.046512</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>71 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        MW    D/Dtr09   ZM1MulPer    ECC   CENT    SMTI  \\\n",
       "ID                                                                        \n",
       "Ma_2019_A           267.28  66.871159  348.869542  135.0  383.0  2886.0   \n",
       "Ma_2019_U           244.23   0.000000  340.039426  118.0  295.0  2084.0   \n",
       "Ma_2019_C           243.25   0.000000  319.988367  118.0  295.0  2084.0   \n",
       "Ma_2019_G           283.28  71.547747  387.546658  144.0  446.0  3270.0   \n",
       "Ma_2019_dA          251.28  63.146800  315.599992  128.0  336.0  2584.0   \n",
       "...                    ...        ...         ...    ...    ...     ...   \n",
       "Tang_2019_ArabinoC  243.25   0.000000  319.988367  118.0  295.0  2084.0   \n",
       "Tang_2019_DideoxyC  211.25   0.000000  253.494297  103.0  213.0  1585.0   \n",
       "Peters_2014_3       268.26  66.871159  369.000658  135.0  383.0  2886.0   \n",
       "Plank_2016_2        393.17  71.547747  412.608258  144.0  446.0  3270.0   \n",
       "Du2021_L_G          283.28  71.547747  387.546658  144.0  446.0  3270.0   \n",
       "\n",
       "                     SMTIV    GMTIV     Wap         IDMT  ...      ATSC5s  \\\n",
       "ID                                                        ...               \n",
       "Ma_2019_A           5576.0  10547.0  5729.0  4739.692713  ...   90.763661   \n",
       "Ma_2019_U           4432.0   8734.0  2194.0  3416.557603  ...  139.839496   \n",
       "Ma_2019_C           4240.0   7972.0  2194.0  3416.557603  ...  137.031903   \n",
       "Ma_2019_G           6542.0  12768.0  6578.0  5547.544286  ...  117.471961   \n",
       "Ma_2019_dA          4822.0   8812.0  5068.0  4099.715332  ...   52.221046   \n",
       "...                    ...      ...     ...          ...  ...         ...   \n",
       "Tang_2019_ArabinoC  4240.0   7972.0  2194.0  3416.557603  ...  137.031903   \n",
       "Tang_2019_DideoxyC  2963.0   5062.0  1633.0  2398.199373  ...   59.519699   \n",
       "Peters_2014_3       5763.0  11275.0  5729.0  4739.692713  ...  100.945467   \n",
       "Plank_2016_2        6760.0  13668.0  6578.0  5547.544286  ...   73.852917   \n",
       "Du2021_L_G          6542.0  12768.0  6578.0  5547.544286  ...  117.471961   \n",
       "\n",
       "                    P_VSA_MR_3  P_VSA_ppp_ar  P_VSA_ppp_con  P_VSA_charge_2  \\\n",
       "ID                                                                            \n",
       "Ma_2019_A           139.049917     75.680233      63.202194        1.899093   \n",
       "Ma_2019_U           139.049917      0.000000      48.373245       46.279992   \n",
       "Ma_2019_C           139.049917      0.000000      67.057867        3.124314   \n",
       "Ma_2019_G           139.049917     32.387883      80.922082       45.054770   \n",
       "Ma_2019_dA           96.366574     75.680233      63.202194        1.899093   \n",
       "...                        ...           ...            ...             ...   \n",
       "Tang_2019_ArabinoC  139.049917      0.000000      67.057867        3.124314   \n",
       "Tang_2019_DideoxyC   53.683231      0.000000      67.057867        3.124314   \n",
       "Peters_2014_3       139.049917     32.387883      87.641582       27.044020   \n",
       "Plank_2016_2         96.366574     32.387883      80.922082       45.054770   \n",
       "Du2021_L_G          139.049917     32.387883      80.922082       45.054770   \n",
       "\n",
       "                    SM15_EA(ed)  T(O..Br)  TPSA(Tot)       SAdon          Vx  \n",
       "ID                                                                            \n",
       "Ma_2019_A             36.892542       0.0     139.54  160.947217  291.295681  \n",
       "Ma_2019_U             36.205320       0.0     124.78  146.060780  262.840532  \n",
       "Ma_2019_C             36.205320       0.0     130.83  160.947217  269.667774  \n",
       "Ma_2019_G             36.939118       0.0     159.51  178.957968  301.046512  \n",
       "Ma_2019_dA            36.335611       0.0     119.31  118.263874  281.544850  \n",
       "...                         ...       ...        ...         ...         ...  \n",
       "Tang_2019_ArabinoC    36.205320       0.0     130.83  160.947217  269.667774  \n",
       "Tang_2019_DideoxyC    34.619300       0.0      90.37   75.580531  250.166113  \n",
       "Peters_2014_3         36.892542       0.0     133.49  146.060780  284.468439  \n",
       "Plank_2016_2          36.939118       0.0     139.28  136.274624  334.202658  \n",
       "Du2021_L_G            36.939118       0.0     159.51  178.957968  301.046512  \n",
       "\n",
       "[71 rows x 28 columns]"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MRLEM_data=X_NAomit_data[col_data.index]\n",
    "MRLEM_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "6d8bf42e-2223-4c7b-9bd2-7c2787032802",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MW</th>\n",
       "      <th>D/Dtr09</th>\n",
       "      <th>ZM1MulPer</th>\n",
       "      <th>ECC</th>\n",
       "      <th>CENT</th>\n",
       "      <th>SMTI</th>\n",
       "      <th>SMTIV</th>\n",
       "      <th>GMTIV</th>\n",
       "      <th>Wap</th>\n",
       "      <th>IDMT</th>\n",
       "      <th>...</th>\n",
       "      <th>ATSC5s</th>\n",
       "      <th>P_VSA_MR_3</th>\n",
       "      <th>P_VSA_ppp_ar</th>\n",
       "      <th>P_VSA_ppp_con</th>\n",
       "      <th>P_VSA_charge_2</th>\n",
       "      <th>SM15_EA(ed)</th>\n",
       "      <th>T(O..Br)</th>\n",
       "      <th>TPSA(Tot)</th>\n",
       "      <th>SAdon</th>\n",
       "      <th>Vx</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Ma_2019_A</th>\n",
       "      <td>0.128645</td>\n",
       "      <td>0.181294</td>\n",
       "      <td>0.193207</td>\n",
       "      <td>0.036281</td>\n",
       "      <td>0.026667</td>\n",
       "      <td>0.030815</td>\n",
       "      <td>0.037803</td>\n",
       "      <td>0.044265</td>\n",
       "      <td>0.024087</td>\n",
       "      <td>0.024617</td>\n",
       "      <td>...</td>\n",
       "      <td>0.176802</td>\n",
       "      <td>0.999046</td>\n",
       "      <td>0.285905</td>\n",
       "      <td>0.104723</td>\n",
       "      <td>0.015761</td>\n",
       "      <td>0.446054</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.472652</td>\n",
       "      <td>0.769847</td>\n",
       "      <td>0.069993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ma_2019_U</th>\n",
       "      <td>0.075722</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.175319</td>\n",
       "      <td>0.017007</td>\n",
       "      <td>0.012863</td>\n",
       "      <td>0.011819</td>\n",
       "      <td>0.021252</td>\n",
       "      <td>0.029633</td>\n",
       "      <td>0.003299</td>\n",
       "      <td>0.010706</td>\n",
       "      <td>...</td>\n",
       "      <td>0.401921</td>\n",
       "      <td>0.999046</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.031193</td>\n",
       "      <td>0.384100</td>\n",
       "      <td>0.311208</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.330770</td>\n",
       "      <td>0.665700</td>\n",
       "      <td>0.021569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ma_2019_C</th>\n",
       "      <td>0.073472</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.134701</td>\n",
       "      <td>0.017007</td>\n",
       "      <td>0.012863</td>\n",
       "      <td>0.011819</td>\n",
       "      <td>0.018475</td>\n",
       "      <td>0.023484</td>\n",
       "      <td>0.003299</td>\n",
       "      <td>0.010706</td>\n",
       "      <td>...</td>\n",
       "      <td>0.389042</td>\n",
       "      <td>0.999046</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.123842</td>\n",
       "      <td>0.025930</td>\n",
       "      <td>0.311208</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.388926</td>\n",
       "      <td>0.769847</td>\n",
       "      <td>0.033187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ma_2019_G</th>\n",
       "      <td>0.165381</td>\n",
       "      <td>0.193972</td>\n",
       "      <td>0.271557</td>\n",
       "      <td>0.046485</td>\n",
       "      <td>0.036549</td>\n",
       "      <td>0.039910</td>\n",
       "      <td>0.051778</td>\n",
       "      <td>0.062188</td>\n",
       "      <td>0.029080</td>\n",
       "      <td>0.033111</td>\n",
       "      <td>...</td>\n",
       "      <td>0.299317</td>\n",
       "      <td>0.999046</td>\n",
       "      <td>0.122355</td>\n",
       "      <td>0.192589</td>\n",
       "      <td>0.373931</td>\n",
       "      <td>0.455193</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.664616</td>\n",
       "      <td>0.895853</td>\n",
       "      <td>0.086587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ma_2019_dA</th>\n",
       "      <td>0.091909</td>\n",
       "      <td>0.171197</td>\n",
       "      <td>0.125811</td>\n",
       "      <td>0.028345</td>\n",
       "      <td>0.019294</td>\n",
       "      <td>0.023662</td>\n",
       "      <td>0.026894</td>\n",
       "      <td>0.030263</td>\n",
       "      <td>0.020200</td>\n",
       "      <td>0.017889</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.666030</td>\n",
       "      <td>0.285905</td>\n",
       "      <td>0.104723</td>\n",
       "      <td>0.015761</td>\n",
       "      <td>0.336774</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.278189</td>\n",
       "      <td>0.471230</td>\n",
       "      <td>0.053399</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  MW   D/Dtr09  ZM1MulPer       ECC      CENT      SMTI  \\\n",
       "ID                                                                        \n",
       "Ma_2019_A   0.128645  0.181294   0.193207  0.036281  0.026667  0.030815   \n",
       "Ma_2019_U   0.075722  0.000000   0.175319  0.017007  0.012863  0.011819   \n",
       "Ma_2019_C   0.073472  0.000000   0.134701  0.017007  0.012863  0.011819   \n",
       "Ma_2019_G   0.165381  0.193972   0.271557  0.046485  0.036549  0.039910   \n",
       "Ma_2019_dA  0.091909  0.171197   0.125811  0.028345  0.019294  0.023662   \n",
       "\n",
       "               SMTIV     GMTIV       Wap      IDMT  ...    ATSC5s  P_VSA_MR_3  \\\n",
       "ID                                                  ...                         \n",
       "Ma_2019_A   0.037803  0.044265  0.024087  0.024617  ...  0.176802    0.999046   \n",
       "Ma_2019_U   0.021252  0.029633  0.003299  0.010706  ...  0.401921    0.999046   \n",
       "Ma_2019_C   0.018475  0.023484  0.003299  0.010706  ...  0.389042    0.999046   \n",
       "Ma_2019_G   0.051778  0.062188  0.029080  0.033111  ...  0.299317    0.999046   \n",
       "Ma_2019_dA  0.026894  0.030263  0.020200  0.017889  ...  0.000000    0.666030   \n",
       "\n",
       "            P_VSA_ppp_ar  P_VSA_ppp_con  P_VSA_charge_2  SM15_EA(ed)  \\\n",
       "ID                                                                     \n",
       "Ma_2019_A       0.285905       0.104723        0.015761     0.446054   \n",
       "Ma_2019_U       0.000000       0.031193        0.384100     0.311208   \n",
       "Ma_2019_C       0.000000       0.123842        0.025930     0.311208   \n",
       "Ma_2019_G       0.122355       0.192589        0.373931     0.455193   \n",
       "Ma_2019_dA      0.285905       0.104723        0.015761     0.336774   \n",
       "\n",
       "            T(O..Br)  TPSA(Tot)     SAdon        Vx  \n",
       "ID                                                   \n",
       "Ma_2019_A        0.0   0.472652  0.769847  0.069993  \n",
       "Ma_2019_U        0.0   0.330770  0.665700  0.021569  \n",
       "Ma_2019_C        0.0   0.388926  0.769847  0.033187  \n",
       "Ma_2019_G        0.0   0.664616  0.895853  0.086587  \n",
       "Ma_2019_dA       0.0   0.278189  0.471230  0.053399  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Scale data\n",
    "Scaler = preprocessing.MinMaxScaler() #StandardScaler\n",
    "Transformer =Scaler.fit(MRLEM_data)\n",
    "X_scaled_data=Transformer.transform(MRLEM_data)\n",
    "X_scaled_data =pd.DataFrame(X_scaled_data)\n",
    "X_scaled_data.columns=MRLEM_data.columns\n",
    "X_scaled_data.index=Raw_data.index\n",
    "X_scaled_data.to_csv(\"./Original data/MRLEM_data_X_scaled_data.csv\",sep=',',header=1,index=1)\n",
    "joblib.dump(Transformer, './Models/MRLEM_data_Scaler_transformer.pkl')\n",
    "\n",
    "X_scaled_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "c5eb8b75-76bc-4fcb-aad5-6762048df1c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Model_results(Model_clf,X_test,y,Cv_model):\n",
    "    Model_scores= cross_validate(estimator=Model_clf, X=X_test, y=y, cv=Cv_model,scoring=( 'accuracy','f1','precision','recall','roc_auc'), return_train_score=True)\n",
    "    Model_score= cross_validate(estimator=Model_clf, X=X_test, y=y, cv=Cv_model,scoring=( 'accuracy','f1','precision','recall','roc_auc'), return_train_score=False)\n",
    "#Accuracy\n",
    "    Model_Accuracy_test_mean=Model_scores['test_accuracy'].mean()\n",
    "    Model_Accuracy_test_se=(Model_scores['test_accuracy'].std()/math.sqrt(len(Model_scores['test_accuracy']))) \n",
    "    Model_Accuracy_train_mean=Model_scores['train_accuracy'].mean()\n",
    "    Model_Accuracy_train_se=(Model_scores['train_accuracy'].std()/math.sqrt(len(Model_scores['train_accuracy']))) \n",
    "#f1\n",
    "    Model_f1_mean=Model_score['test_f1'].mean()\n",
    "    Model_f1_se=(Model_score['test_f1'].std()/math.sqrt(len(Model_score['test_f1']))) \n",
    "#precision\n",
    "    Model_precision_mean=Model_score['test_precision'].mean()\n",
    "    Model_precision_se=(Model_score['test_precision'].std()/math.sqrt(len(Model_score['test_precision']))) \n",
    "#recall\n",
    "    Model_recall_mean=Model_score['test_recall'].mean()\n",
    "    Model_recall_se=(Model_score['test_recall'].std()/math.sqrt(len(Model_score['test_recall']))) \n",
    "#roc_auc\n",
    "    Model_roc_auc_mean=Model_score['test_roc_auc'].mean()\n",
    "    Model_roc_auc_se=(Model_score['test_roc_auc'].std()/math.sqrt(len(Model_score['test_roc_auc']))) \n",
    "    Model = {'Mean':[Model_Accuracy_test_mean,Model_Accuracy_train_mean,Model_f1_mean,Model_precision_mean,Model_recall_mean,Model_roc_auc_mean],\n",
    "        'Se':[Model_Accuracy_test_se,Model_Accuracy_train_se,Model_f1_se,Model_precision_se,Model_recall_se,Model_roc_auc_se]}\n",
    "    Model = pd.DataFrame(Model, index=['Accuracy_test','Accuracy_train','F1 Score','Precision','Recall','Roc_auc'])\n",
    "    return Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "43024221-dcb1-4c20-a862-8ba15cc4978a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setting the KFold \n",
    "Cv_optuna= RepeatedStratifiedKFold(n_splits=5, n_repeats=10, random_state=0)\n",
    "Cv_model= RepeatedStratifiedKFold(n_splits=5, n_repeats=10, random_state=0)\n",
    "Cv_RFECV= RepeatedStratifiedKFold(n_splits=5, n_repeats=10, random_state=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "ef2d9106-5c7e-4daa-89d3-1c228a5ac78a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data pre-processing of models\n",
    "X=np.array(X_scaled_data)\n",
    "y=Raw_data['Hydrogel-forming ability'].values\n",
    "clf=LogisticRegression(solver='liblinear',random_state=0,dual=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48b68d6d-1a1e-439b-aee8-42486486d23e",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 2.1 DT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "74f1bf04-5bde-4d51-bc10-aee4e7d2c583",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf=DecisionTreeClassifier(random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "7c30897c-633f-4a53-96c3-a415fd50308c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mean</th>\n",
       "      <th>Se</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Accuracy_test</th>\n",
       "      <td>0.629333</td>\n",
       "      <td>0.015032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Accuracy_train</th>\n",
       "      <td>0.729981</td>\n",
       "      <td>0.004700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1 Score</th>\n",
       "      <td>0.697627</td>\n",
       "      <td>0.013235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Precision</th>\n",
       "      <td>0.620752</td>\n",
       "      <td>0.011961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recall</th>\n",
       "      <td>0.811071</td>\n",
       "      <td>0.020893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Roc_auc</th>\n",
       "      <td>0.664796</td>\n",
       "      <td>0.020543</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Mean        Se\n",
       "Accuracy_test   0.629333  0.015032\n",
       "Accuracy_train  0.729981  0.004700\n",
       "F1 Score        0.697627  0.013235\n",
       "Precision       0.620752  0.011961\n",
       "Recall          0.811071  0.020893\n",
       "Roc_auc         0.664796  0.020543"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Model1 \n",
    "Model1_clf=clf\n",
    "#Model1\n",
    "Model1=Model_results(Model1_clf,X,y,Cv_model)\n",
    "Model1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "f86a6975-0d73-46e6-9ba4-c3c488b2a565",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2024-01-12 01:29:56,212]\u001b[0m A new study created in memory with name: no-name-6a0b1671-0ec2-4905-98f9-69d2f7e33654\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:29:57,476]\u001b[0m Trial 0 finished with value: 0.6312380952380953 and parameters: {'max_depth': 4, 'max_features': 17, 'min_samples_split': 16}. Best is trial 0 with value: 0.6312380952380953.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:29:57,505]\u001b[0m Trial 1 finished with value: 0.5926666666666667 and parameters: {'max_depth': 4, 'max_features': 14, 'min_samples_split': 17}. Best is trial 0 with value: 0.6312380952380953.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:29:57,530]\u001b[0m Trial 2 finished with value: 0.6375238095238095 and parameters: {'max_depth': 4, 'max_features': 19, 'min_samples_split': 25}. Best is trial 2 with value: 0.6375238095238095.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:29:57,554]\u001b[0m Trial 3 finished with value: 0.6208571428571428 and parameters: {'max_depth': 4, 'max_features': 18, 'min_samples_split': 14}. Best is trial 2 with value: 0.6375238095238095.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:29:57,579]\u001b[0m Trial 4 finished with value: 0.6296190476190476 and parameters: {'max_depth': 4, 'max_features': 20, 'min_samples_split': 3}. Best is trial 2 with value: 0.6375238095238095.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:29:57,600]\u001b[0m Trial 5 finished with value: 0.6120952380952381 and parameters: {'max_depth': 3, 'max_features': 10, 'min_samples_split': 21}. Best is trial 2 with value: 0.6375238095238095.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:29:57,624]\u001b[0m Trial 6 finished with value: 0.6318095238095238 and parameters: {'max_depth': 5, 'max_features': 19, 'min_samples_split': 25}. Best is trial 2 with value: 0.6375238095238095.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:29:57,646]\u001b[0m Trial 7 finished with value: 0.5998095238095238 and parameters: {'max_depth': 5, 'max_features': 15, 'min_samples_split': 20}. Best is trial 2 with value: 0.6375238095238095.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:29:57,666]\u001b[0m Trial 8 finished with value: 0.6439999999999999 and parameters: {'max_depth': 3, 'max_features': 17, 'min_samples_split': 5}. Best is trial 8 with value: 0.6439999999999999.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:29:57,689]\u001b[0m Trial 9 finished with value: 0.6057142857142856 and parameters: {'max_depth': 5, 'max_features': 15, 'min_samples_split': 11}. Best is trial 8 with value: 0.6439999999999999.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:29:57,714]\u001b[0m Trial 10 finished with value: 0.601047619047619 and parameters: {'max_depth': 3, 'max_features': 12, 'min_samples_split': 2}. Best is trial 8 with value: 0.6439999999999999.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:29:57,739]\u001b[0m Trial 11 finished with value: 0.6411428571428571 and parameters: {'max_depth': 3, 'max_features': 17, 'min_samples_split': 8}. Best is trial 8 with value: 0.6439999999999999.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:29:57,765]\u001b[0m Trial 12 finished with value: 0.6411428571428571 and parameters: {'max_depth': 3, 'max_features': 17, 'min_samples_split': 9}. Best is trial 8 with value: 0.6439999999999999.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:29:57,789]\u001b[0m Trial 13 finished with value: 0.6411428571428571 and parameters: {'max_depth': 3, 'max_features': 17, 'min_samples_split': 7}. Best is trial 8 with value: 0.6439999999999999.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:29:57,813]\u001b[0m Trial 14 finished with value: 0.6280952380952382 and parameters: {'max_depth': 3, 'max_features': 13, 'min_samples_split': 6}. Best is trial 8 with value: 0.6439999999999999.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:29:57,838]\u001b[0m Trial 15 finished with value: 0.64 and parameters: {'max_depth': 3, 'max_features': 16, 'min_samples_split': 5}. Best is trial 8 with value: 0.6439999999999999.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:29:57,862]\u001b[0m Trial 16 finished with value: 0.64 and parameters: {'max_depth': 3, 'max_features': 16, 'min_samples_split': 10}. Best is trial 8 with value: 0.6439999999999999.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:29:57,887]\u001b[0m Trial 17 finished with value: 0.6042857142857144 and parameters: {'max_depth': 3, 'max_features': 20, 'min_samples_split': 6}. Best is trial 8 with value: 0.6439999999999999.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:29:57,914]\u001b[0m Trial 18 finished with value: 0.6207619047619047 and parameters: {'max_depth': 4, 'max_features': 18, 'min_samples_split': 12}. Best is trial 8 with value: 0.6439999999999999.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:29:57,939]\u001b[0m Trial 19 finished with value: 0.6295238095238096 and parameters: {'max_depth': 3, 'max_features': 13, 'min_samples_split': 4}. Best is trial 8 with value: 0.6439999999999999.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:29:57,964]\u001b[0m Trial 20 finished with value: 0.6385714285714286 and parameters: {'max_depth': 3, 'max_features': 16, 'min_samples_split': 7}. Best is trial 8 with value: 0.6439999999999999.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:29:57,989]\u001b[0m Trial 21 finished with value: 0.6411428571428571 and parameters: {'max_depth': 3, 'max_features': 17, 'min_samples_split': 9}. Best is trial 8 with value: 0.6439999999999999.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:29:58,013]\u001b[0m Trial 22 finished with value: 0.6111428571428571 and parameters: {'max_depth': 3, 'max_features': 18, 'min_samples_split': 13}. Best is trial 8 with value: 0.6439999999999999.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:29:58,038]\u001b[0m Trial 23 finished with value: 0.6411428571428571 and parameters: {'max_depth': 3, 'max_features': 17, 'min_samples_split': 8}. Best is trial 8 with value: 0.6439999999999999.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:29:58,063]\u001b[0m Trial 24 finished with value: 0.6253333333333333 and parameters: {'max_depth': 3, 'max_features': 19, 'min_samples_split': 9}. Best is trial 8 with value: 0.6439999999999999.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:29:58,088]\u001b[0m Trial 25 finished with value: 0.6405714285714285 and parameters: {'max_depth': 4, 'max_features': 16, 'min_samples_split': 10}. Best is trial 8 with value: 0.6439999999999999.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:29:58,114]\u001b[0m Trial 26 finished with value: 0.6097142857142858 and parameters: {'max_depth': 3, 'max_features': 14, 'min_samples_split': 4}. Best is trial 8 with value: 0.6439999999999999.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:29:58,137]\u001b[0m Trial 27 finished with value: 0.6129523809523809 and parameters: {'max_depth': 3, 'max_features': 15, 'min_samples_split': 6}. Best is trial 8 with value: 0.6439999999999999.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:29:58,163]\u001b[0m Trial 28 finished with value: 0.6222857142857143 and parameters: {'max_depth': 4, 'max_features': 18, 'min_samples_split': 7}. Best is trial 8 with value: 0.6439999999999999.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:29:58,187]\u001b[0m Trial 29 finished with value: 0.6396190476190476 and parameters: {'max_depth': 4, 'max_features': 17, 'min_samples_split': 14}. Best is trial 8 with value: 0.6439999999999999.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:29:58,212]\u001b[0m Trial 30 finished with value: 0.6363809523809524 and parameters: {'max_depth': 3, 'max_features': 19, 'min_samples_split': 16}. Best is trial 8 with value: 0.6439999999999999.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:29:58,237]\u001b[0m Trial 31 finished with value: 0.6411428571428571 and parameters: {'max_depth': 3, 'max_features': 17, 'min_samples_split': 8}. Best is trial 8 with value: 0.6439999999999999.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:29:58,260]\u001b[0m Trial 32 finished with value: 0.6385714285714286 and parameters: {'max_depth': 3, 'max_features': 16, 'min_samples_split': 9}. Best is trial 8 with value: 0.6439999999999999.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:29:58,285]\u001b[0m Trial 33 finished with value: 0.624 and parameters: {'max_depth': 3, 'max_features': 18, 'min_samples_split': 2}. Best is trial 8 with value: 0.6439999999999999.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:29:58,312]\u001b[0m Trial 34 finished with value: 0.6411428571428571 and parameters: {'max_depth': 3, 'max_features': 17, 'min_samples_split': 11}. Best is trial 8 with value: 0.6439999999999999.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:29:58,335]\u001b[0m Trial 35 finished with value: 0.614 and parameters: {'max_depth': 4, 'max_features': 15, 'min_samples_split': 4}. Best is trial 8 with value: 0.6439999999999999.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:29:58,360]\u001b[0m Trial 36 finished with value: 0.6111428571428571 and parameters: {'max_depth': 3, 'max_features': 18, 'min_samples_split': 12}. Best is trial 8 with value: 0.6439999999999999.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:29:58,386]\u001b[0m Trial 37 finished with value: 0.6011428571428571 and parameters: {'max_depth': 4, 'max_features': 14, 'min_samples_split': 7}. Best is trial 8 with value: 0.6439999999999999.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:29:58,413]\u001b[0m Trial 38 finished with value: 0.6281904761904762 and parameters: {'max_depth': 3, 'max_features': 19, 'min_samples_split': 5}. Best is trial 8 with value: 0.6439999999999999.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:29:58,439]\u001b[0m Trial 39 finished with value: 0.6067619047619047 and parameters: {'max_depth': 4, 'max_features': 10, 'min_samples_split': 16}. Best is trial 8 with value: 0.6439999999999999.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:29:58,466]\u001b[0m Trial 40 finished with value: 0.6393333333333333 and parameters: {'max_depth': 5, 'max_features': 16, 'min_samples_split': 11}. Best is trial 8 with value: 0.6439999999999999.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:29:58,491]\u001b[0m Trial 41 finished with value: 0.6411428571428571 and parameters: {'max_depth': 3, 'max_features': 17, 'min_samples_split': 9}. Best is trial 8 with value: 0.6439999999999999.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:29:58,519]\u001b[0m Trial 42 finished with value: 0.6368571428571428 and parameters: {'max_depth': 3, 'max_features': 17, 'min_samples_split': 14}. Best is trial 8 with value: 0.6439999999999999.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:29:58,545]\u001b[0m Trial 43 finished with value: 0.6411428571428571 and parameters: {'max_depth': 3, 'max_features': 17, 'min_samples_split': 8}. Best is trial 8 with value: 0.6439999999999999.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:29:58,570]\u001b[0m Trial 44 finished with value: 0.614 and parameters: {'max_depth': 3, 'max_features': 18, 'min_samples_split': 10}. Best is trial 8 with value: 0.6439999999999999.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:29:58,597]\u001b[0m Trial 45 finished with value: 0.6411428571428571 and parameters: {'max_depth': 3, 'max_features': 17, 'min_samples_split': 8}. Best is trial 8 with value: 0.6439999999999999.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:29:58,624]\u001b[0m Trial 46 finished with value: 0.6056190476190477 and parameters: {'max_depth': 3, 'max_features': 20, 'min_samples_split': 5}. Best is trial 8 with value: 0.6439999999999999.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:29:58,651]\u001b[0m Trial 47 finished with value: 0.64 and parameters: {'max_depth': 3, 'max_features': 16, 'min_samples_split': 3}. Best is trial 8 with value: 0.6439999999999999.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:29:58,678]\u001b[0m Trial 48 finished with value: 0.6143809523809524 and parameters: {'max_depth': 3, 'max_features': 15, 'min_samples_split': 8}. Best is trial 8 with value: 0.6439999999999999.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:29:58,704]\u001b[0m Trial 49 finished with value: 0.6180952380952381 and parameters: {'max_depth': 3, 'max_features': 18, 'min_samples_split': 21}. Best is trial 8 with value: 0.6439999999999999.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:29:58,729]\u001b[0m Trial 50 finished with value: 0.6406666666666666 and parameters: {'max_depth': 3, 'max_features': 11, 'min_samples_split': 3}. Best is trial 8 with value: 0.6439999999999999.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:29:58,758]\u001b[0m Trial 51 finished with value: 0.6411428571428571 and parameters: {'max_depth': 3, 'max_features': 17, 'min_samples_split': 11}. Best is trial 8 with value: 0.6439999999999999.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:29:58,785]\u001b[0m Trial 52 finished with value: 0.6411428571428571 and parameters: {'max_depth': 3, 'max_features': 17, 'min_samples_split': 11}. Best is trial 8 with value: 0.6439999999999999.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:29:58,811]\u001b[0m Trial 53 finished with value: 0.6371428571428572 and parameters: {'max_depth': 3, 'max_features': 16, 'min_samples_split': 12}. Best is trial 8 with value: 0.6439999999999999.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:29:58,838]\u001b[0m Trial 54 finished with value: 0.6425714285714286 and parameters: {'max_depth': 3, 'max_features': 17, 'min_samples_split': 6}. Best is trial 8 with value: 0.6439999999999999.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:29:58,863]\u001b[0m Trial 55 finished with value: 0.6211428571428571 and parameters: {'max_depth': 3, 'max_features': 18, 'min_samples_split': 6}. Best is trial 8 with value: 0.6439999999999999.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:29:58,888]\u001b[0m Trial 56 finished with value: 0.6375238095238095 and parameters: {'max_depth': 3, 'max_features': 19, 'min_samples_split': 24}. Best is trial 8 with value: 0.6439999999999999.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:29:58,915]\u001b[0m Trial 57 finished with value: 0.6422857142857145 and parameters: {'max_depth': 5, 'max_features': 16, 'min_samples_split': 7}. Best is trial 8 with value: 0.6439999999999999.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:29:58,941]\u001b[0m Trial 58 finished with value: 0.6604761904761905 and parameters: {'max_depth': 5, 'max_features': 16, 'min_samples_split': 5}. Best is trial 58 with value: 0.6604761904761905.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:29:58,966]\u001b[0m Trial 59 finished with value: 0.6406666666666666 and parameters: {'max_depth': 5, 'max_features': 15, 'min_samples_split': 6}. Best is trial 58 with value: 0.6604761904761905.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:29:58,992]\u001b[0m Trial 60 finished with value: 0.6604761904761905 and parameters: {'max_depth': 5, 'max_features': 16, 'min_samples_split': 5}. Best is trial 58 with value: 0.6604761904761905.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:29:59,017]\u001b[0m Trial 61 finished with value: 0.6604761904761905 and parameters: {'max_depth': 5, 'max_features': 16, 'min_samples_split': 5}. Best is trial 58 with value: 0.6604761904761905.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:29:59,044]\u001b[0m Trial 62 finished with value: 0.647904761904762 and parameters: {'max_depth': 5, 'max_features': 14, 'min_samples_split': 3}. Best is trial 58 with value: 0.6604761904761905.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:29:59,073]\u001b[0m Trial 63 finished with value: 0.6742857142857143 and parameters: {'max_depth': 5, 'max_features': 13, 'min_samples_split': 2}. Best is trial 63 with value: 0.6742857142857143.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:29:59,099]\u001b[0m Trial 64 finished with value: 0.6520952380952381 and parameters: {'max_depth': 5, 'max_features': 14, 'min_samples_split': 2}. Best is trial 63 with value: 0.6742857142857143.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:29:59,125]\u001b[0m Trial 65 finished with value: 0.6742857142857143 and parameters: {'max_depth': 5, 'max_features': 13, 'min_samples_split': 2}. Best is trial 63 with value: 0.6742857142857143.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:29:59,151]\u001b[0m Trial 66 finished with value: 0.68 and parameters: {'max_depth': 5, 'max_features': 13, 'min_samples_split': 3}. Best is trial 66 with value: 0.68.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:29:59,176]\u001b[0m Trial 67 finished with value: 0.6742857142857143 and parameters: {'max_depth': 5, 'max_features': 13, 'min_samples_split': 2}. Best is trial 66 with value: 0.68.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:29:59,201]\u001b[0m Trial 68 finished with value: 0.6742857142857143 and parameters: {'max_depth': 5, 'max_features': 13, 'min_samples_split': 2}. Best is trial 66 with value: 0.68.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:29:59,226]\u001b[0m Trial 69 finished with value: 0.6742857142857143 and parameters: {'max_depth': 5, 'max_features': 13, 'min_samples_split': 2}. Best is trial 66 with value: 0.68.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:29:59,252]\u001b[0m Trial 70 finished with value: 0.6742857142857143 and parameters: {'max_depth': 5, 'max_features': 13, 'min_samples_split': 2}. Best is trial 66 with value: 0.68.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:29:59,278]\u001b[0m Trial 71 finished with value: 0.6742857142857143 and parameters: {'max_depth': 5, 'max_features': 13, 'min_samples_split': 2}. Best is trial 66 with value: 0.68.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:29:59,302]\u001b[0m Trial 72 finished with value: 0.6742857142857143 and parameters: {'max_depth': 5, 'max_features': 13, 'min_samples_split': 2}. Best is trial 66 with value: 0.68.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:29:59,328]\u001b[0m Trial 73 finished with value: 0.6690476190476191 and parameters: {'max_depth': 5, 'max_features': 12, 'min_samples_split': 3}. Best is trial 66 with value: 0.68.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:29:59,355]\u001b[0m Trial 74 finished with value: 0.6761904761904762 and parameters: {'max_depth': 5, 'max_features': 12, 'min_samples_split': 2}. Best is trial 66 with value: 0.68.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:29:59,380]\u001b[0m Trial 75 finished with value: 0.6676190476190478 and parameters: {'max_depth': 5, 'max_features': 12, 'min_samples_split': 4}. Best is trial 66 with value: 0.68.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:29:59,416]\u001b[0m Trial 76 finished with value: 0.6742857142857143 and parameters: {'max_depth': 5, 'max_features': 13, 'min_samples_split': 2}. Best is trial 66 with value: 0.68.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:29:59,444]\u001b[0m Trial 77 finished with value: 0.6690476190476191 and parameters: {'max_depth': 5, 'max_features': 12, 'min_samples_split': 3}. Best is trial 66 with value: 0.68.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:29:59,471]\u001b[0m Trial 78 finished with value: 0.6451428571428572 and parameters: {'max_depth': 5, 'max_features': 11, 'min_samples_split': 4}. Best is trial 66 with value: 0.68.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:29:59,496]\u001b[0m Trial 79 finished with value: 0.6742857142857143 and parameters: {'max_depth': 5, 'max_features': 13, 'min_samples_split': 2}. Best is trial 66 with value: 0.68.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:29:59,522]\u001b[0m Trial 80 finished with value: 0.6676190476190478 and parameters: {'max_depth': 5, 'max_features': 12, 'min_samples_split': 4}. Best is trial 66 with value: 0.68.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:29:59,548]\u001b[0m Trial 81 finished with value: 0.6742857142857143 and parameters: {'max_depth': 5, 'max_features': 13, 'min_samples_split': 2}. Best is trial 66 with value: 0.68.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:29:59,573]\u001b[0m Trial 82 finished with value: 0.68 and parameters: {'max_depth': 5, 'max_features': 13, 'min_samples_split': 3}. Best is trial 66 with value: 0.68.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:29:59,599]\u001b[0m Trial 83 finished with value: 0.647904761904762 and parameters: {'max_depth': 5, 'max_features': 14, 'min_samples_split': 3}. Best is trial 66 with value: 0.68.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:29:59,624]\u001b[0m Trial 84 finished with value: 0.6478095238095238 and parameters: {'max_depth': 5, 'max_features': 11, 'min_samples_split': 3}. Best is trial 66 with value: 0.68.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:29:59,649]\u001b[0m Trial 85 finished with value: 0.6759999999999999 and parameters: {'max_depth': 5, 'max_features': 13, 'min_samples_split': 4}. Best is trial 66 with value: 0.68.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:29:59,675]\u001b[0m Trial 86 finished with value: 0.6676190476190478 and parameters: {'max_depth': 5, 'max_features': 12, 'min_samples_split': 4}. Best is trial 66 with value: 0.68.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:29:59,701]\u001b[0m Trial 87 finished with value: 0.6337142857142858 and parameters: {'max_depth': 5, 'max_features': 12, 'min_samples_split': 18}. Best is trial 66 with value: 0.68.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:29:59,729]\u001b[0m Trial 88 finished with value: 0.68 and parameters: {'max_depth': 5, 'max_features': 13, 'min_samples_split': 3}. Best is trial 66 with value: 0.68.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:29:59,758]\u001b[0m Trial 89 finished with value: 0.647904761904762 and parameters: {'max_depth': 5, 'max_features': 14, 'min_samples_split': 3}. Best is trial 66 with value: 0.68.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:29:59,784]\u001b[0m Trial 90 finished with value: 0.68 and parameters: {'max_depth': 5, 'max_features': 13, 'min_samples_split': 3}. Best is trial 66 with value: 0.68.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:29:59,809]\u001b[0m Trial 91 finished with value: 0.6759999999999999 and parameters: {'max_depth': 5, 'max_features': 13, 'min_samples_split': 4}. Best is trial 66 with value: 0.68.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:29:59,836]\u001b[0m Trial 92 finished with value: 0.6759999999999999 and parameters: {'max_depth': 5, 'max_features': 13, 'min_samples_split': 4}. Best is trial 66 with value: 0.68.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:29:59,862]\u001b[0m Trial 93 finished with value: 0.6759999999999999 and parameters: {'max_depth': 5, 'max_features': 13, 'min_samples_split': 4}. Best is trial 66 with value: 0.68.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:29:59,889]\u001b[0m Trial 94 finished with value: 0.6379047619047619 and parameters: {'max_depth': 5, 'max_features': 14, 'min_samples_split': 4}. Best is trial 66 with value: 0.68.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:29:59,915]\u001b[0m Trial 95 finished with value: 0.6676190476190478 and parameters: {'max_depth': 5, 'max_features': 12, 'min_samples_split': 4}. Best is trial 66 with value: 0.68.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:29:59,942]\u001b[0m Trial 96 finished with value: 0.68 and parameters: {'max_depth': 5, 'max_features': 13, 'min_samples_split': 3}. Best is trial 66 with value: 0.68.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:29:59,968]\u001b[0m Trial 97 finished with value: 0.6421904761904762 and parameters: {'max_depth': 5, 'max_features': 14, 'min_samples_split': 5}. Best is trial 66 with value: 0.68.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:29:59,993]\u001b[0m Trial 98 finished with value: 0.6634285714285714 and parameters: {'max_depth': 5, 'max_features': 12, 'min_samples_split': 5}. Best is trial 66 with value: 0.68.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:30:00,019]\u001b[0m Trial 99 finished with value: 0.6478095238095238 and parameters: {'max_depth': 5, 'max_features': 11, 'min_samples_split': 3}. Best is trial 66 with value: 0.68.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "#Tuning hyperparameters\n",
    "#Step 1. Define an objective function to be maximized.\n",
    "def objective(trial):\n",
    "    param = {\n",
    "        'max_depth': trial.suggest_int('max_depth',3,5,1),\n",
    "        'max_features' : trial.suggest_int(\"max_features\",10,20,1),\n",
    "        'min_samples_split':trial.suggest_int('min_samples_split',2,25,1)\n",
    "    }\n",
    "    model = DecisionTreeClassifier(**param,random_state=1)\n",
    "\n",
    " \n",
    "# Step 2: Scoring method:\n",
    "    score = model_selection.cross_val_score(model, X, y, n_jobs=8, scoring=\"accuracy\",cv=Cv_optuna)\n",
    "    accuracy = score.mean()\n",
    "    return accuracy\n",
    " \n",
    "# Step 3: Running it\n",
    "study = optuna.create_study(direction=\"maximize\",sampler=optuna.samplers.TPESampler(seed=0))\n",
    "study.optimize(objective, n_trials=100, show_progress_bar=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "6ec0811a-1713-4b39-b21f-cb09e9594c4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best parameters are : \n",
      "{'max_depth': 5, 'max_features': 13, 'min_samples_split': 3}\n"
     ]
    }
   ],
   "source": [
    "# Getting the best parameters:\n",
    "print(f\"The best parameters are : \\n{study.best_params}\")\n",
    "# Setting the best model\n",
    "clf =DecisionTreeClassifier(max_depth = study.best_params['max_depth']\n",
    "              ,max_features = study.best_params['max_features']\n",
    "              #,n_estimators = study.best_params['n_estimators']\n",
    "              #,learning_rate = study.best_params['learning_rate']\n",
    "              ,min_samples_split= study.best_params['min_samples_split']\n",
    "              ,random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "9d1899f3-a5c0-4f3d-8fb2-176c72ea4a4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mean</th>\n",
       "      <th>Se</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Accuracy_test</th>\n",
       "      <td>0.680000</td>\n",
       "      <td>0.012329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Accuracy_train</th>\n",
       "      <td>0.925345</td>\n",
       "      <td>0.005584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1 Score</th>\n",
       "      <td>0.706865</td>\n",
       "      <td>0.012092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Precision</th>\n",
       "      <td>0.698240</td>\n",
       "      <td>0.013460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recall</th>\n",
       "      <td>0.735714</td>\n",
       "      <td>0.020076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Roc_auc</th>\n",
       "      <td>0.690561</td>\n",
       "      <td>0.015281</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Mean        Se\n",
       "Accuracy_test   0.680000  0.012329\n",
       "Accuracy_train  0.925345  0.005584\n",
       "F1 Score        0.706865  0.012092\n",
       "Precision       0.698240  0.013460\n",
       "Recall          0.735714  0.020076\n",
       "Roc_auc         0.690561  0.015281"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Model2\n",
    "Model2=Model_results(clf,X,y,Cv_model)\n",
    "Model2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "390c5554-ccf3-490e-9e3e-7d53299bb3bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th>Method</th>\n",
       "      <th colspan=\"4\" halign=\"left\">DT</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model</th>\n",
       "      <th colspan=\"2\" halign=\"left\">Model 1</th>\n",
       "      <th colspan=\"2\" halign=\"left\">Model 2</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Values</th>\n",
       "      <th>Mean</th>\n",
       "      <th>Se</th>\n",
       "      <th>Mean</th>\n",
       "      <th>Se</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Accuracy_test</th>\n",
       "      <td>0.629333</td>\n",
       "      <td>0.015032</td>\n",
       "      <td>0.680000</td>\n",
       "      <td>0.012329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Accuracy_train</th>\n",
       "      <td>0.729981</td>\n",
       "      <td>0.004700</td>\n",
       "      <td>0.925345</td>\n",
       "      <td>0.005584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1 Score</th>\n",
       "      <td>0.697627</td>\n",
       "      <td>0.013235</td>\n",
       "      <td>0.706865</td>\n",
       "      <td>0.012092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Precision</th>\n",
       "      <td>0.620752</td>\n",
       "      <td>0.011961</td>\n",
       "      <td>0.698240</td>\n",
       "      <td>0.013460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recall</th>\n",
       "      <td>0.811071</td>\n",
       "      <td>0.020893</td>\n",
       "      <td>0.735714</td>\n",
       "      <td>0.020076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Roc_auc</th>\n",
       "      <td>0.664796</td>\n",
       "      <td>0.020543</td>\n",
       "      <td>0.690561</td>\n",
       "      <td>0.015281</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Method                DT                              \n",
       "Model            Model 1             Model 2          \n",
       "Values              Mean        Se      Mean        Se\n",
       "Accuracy_test   0.629333  0.015032  0.680000  0.012329\n",
       "Accuracy_train  0.729981  0.004700  0.925345  0.005584\n",
       "F1 Score        0.697627  0.013235  0.706865  0.012092\n",
       "Precision       0.620752  0.011961  0.698240  0.013460\n",
       "Recall          0.811071  0.020893  0.735714  0.020076\n",
       "Roc_auc         0.664796  0.020543  0.690561  0.015281"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Saving the data of model performance\n",
    "Model_data=pd.concat([Model1,Model2],axis=1)\n",
    "Model_data.columns = [['DT']*4,['Model 1','Model 1', 'Model 2','Model 2'], ['Mean', 'Se', 'Mean', 'Se']]  \n",
    "Model_data.columns.names=['Method','Model','Values']\n",
    "Model_data.to_csv(\"./Results/DT_model_mlrem_data.csv\",sep=',')\n",
    "Model_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff716df6-f48a-4890-819b-cca04c92e57c",
   "metadata": {},
   "source": [
    "## 2.2 LR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "96eeb954-8032-43c2-afb2-e47f675b2d15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mean</th>\n",
       "      <th>Se</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Accuracy_test</th>\n",
       "      <td>0.680000</td>\n",
       "      <td>0.012329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Accuracy_train</th>\n",
       "      <td>0.925345</td>\n",
       "      <td>0.005584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1 Score</th>\n",
       "      <td>0.706865</td>\n",
       "      <td>0.012092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Precision</th>\n",
       "      <td>0.698240</td>\n",
       "      <td>0.013460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recall</th>\n",
       "      <td>0.735714</td>\n",
       "      <td>0.020076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Roc_auc</th>\n",
       "      <td>0.690561</td>\n",
       "      <td>0.015281</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Mean        Se\n",
       "Accuracy_test   0.680000  0.012329\n",
       "Accuracy_train  0.925345  0.005584\n",
       "F1 Score        0.706865  0.012092\n",
       "Precision       0.698240  0.013460\n",
       "Recall          0.735714  0.020076\n",
       "Roc_auc         0.690561  0.015281"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Model1\n",
    "Model1_clf=clf\n",
    "#Model1\n",
    "Model1=Model_results(Model1_clf,X,y,Cv_model)\n",
    "Model1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "662dc3e0-7ca9-41f6-ad45-99db640a18b8",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2024-01-12 01:33:46,194]\u001b[0m A new study created in memory with name: no-name-e4ba7b5b-b8fd-4929-82c3-50137ca4832b\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:33:46,218]\u001b[0m Trial 0 finished with value: 0.6096190476190476 and parameters: {'logreg_c': 0.3177840006884068, 'l1_ratio': 0.7482920440979423, 'max_iter': 100}. Best is trial 0 with value: 0.6096190476190476.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:33:46,239]\u001b[0m Trial 1 finished with value: 0.6195238095238095 and parameters: {'logreg_c': 0.0651621545821569, 'l1_ratio': 0.23208030173540176, 'max_iter': 275}. Best is trial 1 with value: 0.6195238095238095.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:33:46,262]\u001b[0m Trial 2 finished with value: 0.570095238095238 and parameters: {'logreg_c': 0.013108749615263334, 'l1_ratio': 0.411004654338743, 'max_iter': 854}. Best is trial 1 with value: 0.6195238095238095.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:33:46,284]\u001b[0m Trial 3 finished with value: 0.6294285714285714 and parameters: {'logreg_c': 1.7096232052870346, 'l1_ratio': 0.4772750629629653, 'max_iter': 1402}. Best is trial 3 with value: 0.6294285714285714.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:33:46,305]\u001b[0m Trial 4 finished with value: 0.574095238095238 and parameters: {'logreg_c': 0.016854407828169382, 'l1_ratio': 0.8903056927518509, 'max_iter': 152}. Best is trial 3 with value: 0.6294285714285714.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:33:46,328]\u001b[0m Trial 5 finished with value: 0.6167619047619047 and parameters: {'logreg_c': 10.539137268289434, 'l1_ratio': 0.4755743221304143, 'max_iter': 1162}. Best is trial 3 with value: 0.6294285714285714.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:33:46,351]\u001b[0m Trial 6 finished with value: 0.5672380952380952 and parameters: {'logreg_c': 0.006955392321661603, 'l1_ratio': 0.2782913401763909, 'max_iter': 1622}. Best is trial 3 with value: 0.6294285714285714.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:33:46,373]\u001b[0m Trial 7 finished with value: 0.6282857142857143 and parameters: {'logreg_c': 645.0144652189372, 'l1_ratio': 0.38208176034331853, 'max_iter': 1416}. Best is trial 3 with value: 0.6294285714285714.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:33:46,397]\u001b[0m Trial 8 finished with value: 0.6093333333333334 and parameters: {'logreg_c': 181.27374779133626, 'l1_ratio': 0.9051459971534626, 'max_iter': 261}. Best is trial 3 with value: 0.6294285714285714.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:33:46,418]\u001b[0m Trial 9 finished with value: 0.5601904761904761 and parameters: {'logreg_c': 0.001715255021408637, 'l1_ratio': 0.25284737760811204, 'max_iter': 1769}. Best is trial 3 with value: 0.6294285714285714.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:33:46,444]\u001b[0m Trial 10 finished with value: 0.6153333333333333 and parameters: {'logreg_c': 9.589685409552947, 'l1_ratio': 0.6553689413187243, 'max_iter': 845}. Best is trial 3 with value: 0.6294285714285714.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:33:46,469]\u001b[0m Trial 11 finished with value: 0.6268571428571428 and parameters: {'logreg_c': 843.2126062012233, 'l1_ratio': 0.5380831473609496, 'max_iter': 1376}. Best is trial 3 with value: 0.6294285714285714.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:33:46,493]\u001b[0m Trial 12 finished with value: 0.6167619047619047 and parameters: {'logreg_c': 7.624466107886496, 'l1_ratio': 0.378272352651409, 'max_iter': 1494}. Best is trial 3 with value: 0.6294285714285714.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:33:46,518]\u001b[0m Trial 13 finished with value: 0.6162857142857143 and parameters: {'logreg_c': 51.786339691986214, 'l1_ratio': 0.6316370562712422, 'max_iter': 1128}. Best is trial 3 with value: 0.6294285714285714.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:33:46,543]\u001b[0m Trial 14 finished with value: 0.627904761904762 and parameters: {'logreg_c': 0.8529452363532304, 'l1_ratio': 0.13738672304214128, 'max_iter': 1780}. Best is trial 3 with value: 0.6294285714285714.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:33:46,570]\u001b[0m Trial 15 finished with value: 0.6281904761904762 and parameters: {'logreg_c': 763.5588094994378, 'l1_ratio': 0.3689322680983461, 'max_iter': 1971}. Best is trial 3 with value: 0.6294285714285714.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:33:46,596]\u001b[0m Trial 16 finished with value: 0.6195238095238096 and parameters: {'logreg_c': 0.13707192890174966, 'l1_ratio': 0.5845266407991517, 'max_iter': 1309}. Best is trial 3 with value: 0.6294285714285714.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:33:46,623]\u001b[0m Trial 17 finished with value: 0.6120000000000001 and parameters: {'logreg_c': 76.37303329769077, 'l1_ratio': 0.7683639981317943, 'max_iter': 716}. Best is trial 3 with value: 0.6294285714285714.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:33:46,649]\u001b[0m Trial 18 finished with value: 0.6252380952380953 and parameters: {'logreg_c': 2.932001936719566, 'l1_ratio': 0.10084185856253824, 'max_iter': 553}. Best is trial 3 with value: 0.6294285714285714.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:33:46,674]\u001b[0m Trial 19 finished with value: 0.6307619047619046 and parameters: {'logreg_c': 1.3160447446956969, 'l1_ratio': 0.4671561613242705, 'max_iter': 1312}. Best is trial 19 with value: 0.6307619047619046.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:33:46,701]\u001b[0m Trial 20 finished with value: 0.6293333333333333 and parameters: {'logreg_c': 1.4651691779773963, 'l1_ratio': 0.4935134748265029, 'max_iter': 983}. Best is trial 19 with value: 0.6307619047619046.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:33:46,725]\u001b[0m Trial 21 finished with value: 0.6237142857142858 and parameters: {'logreg_c': 0.8287025892084571, 'l1_ratio': 0.5199862466969595, 'max_iter': 1054}. Best is trial 19 with value: 0.6307619047619046.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:33:46,751]\u001b[0m Trial 22 finished with value: 0.6238095238095238 and parameters: {'logreg_c': 3.1654611271505058, 'l1_ratio': 0.4597028916076701, 'max_iter': 1266}. Best is trial 19 with value: 0.6307619047619046.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:33:46,777]\u001b[0m Trial 23 finished with value: 0.6166666666666667 and parameters: {'logreg_c': 0.1535200845989714, 'l1_ratio': 0.6782814588832947, 'max_iter': 981}. Best is trial 19 with value: 0.6307619047619046.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:33:46,803]\u001b[0m Trial 24 finished with value: 0.6294285714285714 and parameters: {'logreg_c': 1.8873063599506599, 'l1_ratio': 0.326102166138698, 'max_iter': 1522}. Best is trial 19 with value: 0.6307619047619046.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:33:46,827]\u001b[0m Trial 25 finished with value: 0.6180952380952381 and parameters: {'logreg_c': 0.41516225975438653, 'l1_ratio': 0.2979284535359352, 'max_iter': 1547}. Best is trial 19 with value: 0.6307619047619046.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:33:46,853]\u001b[0m Trial 26 finished with value: 0.6191428571428571 and parameters: {'logreg_c': 17.953162228525414, 'l1_ratio': 0.31727555023219167, 'max_iter': 1687}. Best is trial 19 with value: 0.6307619047619046.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:33:46,878]\u001b[0m Trial 27 finished with value: 0.6266666666666666 and parameters: {'logreg_c': 2.602409837373429, 'l1_ratio': 0.19868034857393024, 'max_iter': 1919}. Best is trial 19 with value: 0.6307619047619046.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:33:46,905]\u001b[0m Trial 28 finished with value: 0.6195238095238095 and parameters: {'logreg_c': 0.07229078967635784, 'l1_ratio': 0.42868388614084174, 'max_iter': 1511}. Best is trial 19 with value: 0.6307619047619046.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:33:46,931]\u001b[0m Trial 29 finished with value: 0.6194285714285716 and parameters: {'logreg_c': 0.3860177138367054, 'l1_ratio': 0.8158505713189557, 'max_iter': 1211}. Best is trial 19 with value: 0.6307619047619046.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:33:46,956]\u001b[0m Trial 30 finished with value: 0.6168571428571429 and parameters: {'logreg_c': 4.8505444157280655, 'l1_ratio': 0.989090737470458, 'max_iter': 1389}. Best is trial 19 with value: 0.6307619047619046.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:33:46,984]\u001b[0m Trial 31 finished with value: 0.6293333333333334 and parameters: {'logreg_c': 1.2065391735314397, 'l1_ratio': 0.4963584342131737, 'max_iter': 1011}. Best is trial 19 with value: 0.6307619047619046.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:33:47,011]\u001b[0m Trial 32 finished with value: 0.6162857142857143 and parameters: {'logreg_c': 28.72272514710678, 'l1_ratio': 0.581199409657952, 'max_iter': 582}. Best is trial 19 with value: 0.6307619047619046.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:33:47,038]\u001b[0m Trial 33 finished with value: 0.6293333333333333 and parameters: {'logreg_c': 1.3696220900607625, 'l1_ratio': 0.42558482659301816, 'max_iter': 1297}. Best is trial 19 with value: 0.6307619047619046.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:33:47,063]\u001b[0m Trial 34 finished with value: 0.6067619047619047 and parameters: {'logreg_c': 0.2875637249472787, 'l1_ratio': 0.3482207466346646, 'max_iter': 1109}. Best is trial 19 with value: 0.6307619047619046.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:33:47,088]\u001b[0m Trial 35 finished with value: 0.6009523809523809 and parameters: {'logreg_c': 0.03576221722627603, 'l1_ratio': 0.5765441371212959, 'max_iter': 870}. Best is trial 19 with value: 0.6307619047619046.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:33:47,116]\u001b[0m Trial 36 finished with value: 0.6209523809523809 and parameters: {'logreg_c': 0.6626791637945557, 'l1_ratio': 0.20185400717777569, 'max_iter': 1676}. Best is trial 19 with value: 0.6307619047619046.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:33:47,140]\u001b[0m Trial 37 finished with value: 0.6294285714285714 and parameters: {'logreg_c': 1.9120072183363928, 'l1_ratio': 0.4733809188346099, 'max_iter': 1467}. Best is trial 19 with value: 0.6307619047619046.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:33:47,165]\u001b[0m Trial 38 finished with value: 0.6177142857142858 and parameters: {'logreg_c': 19.34210830669201, 'l1_ratio': 0.44990617999528343, 'max_iter': 1557}. Best is trial 19 with value: 0.6307619047619046.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:33:47,192]\u001b[0m Trial 39 finished with value: 0.6139047619047618 and parameters: {'logreg_c': 0.22059945415572177, 'l1_ratio': 0.3267785933880323, 'max_iter': 1424}. Best is trial 19 with value: 0.6307619047619046.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:33:47,219]\u001b[0m Trial 40 finished with value: 0.6139047619047618 and parameters: {'logreg_c': 5.702688279032213, 'l1_ratio': 0.706870700092175, 'max_iter': 1216}. Best is trial 19 with value: 0.6307619047619046.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:33:47,247]\u001b[0m Trial 41 finished with value: 0.6307619047619047 and parameters: {'logreg_c': 2.1083445203193767, 'l1_ratio': 0.5013573618384977, 'max_iter': 1814}. Best is trial 41 with value: 0.6307619047619047.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:33:47,273]\u001b[0m Trial 42 finished with value: 0.6294285714285714 and parameters: {'logreg_c': 1.8778046360697456, 'l1_ratio': 0.39812276354777576, 'max_iter': 1899}. Best is trial 41 with value: 0.6307619047619047.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:33:47,308]\u001b[0m Trial 43 finished with value: 0.6196190476190475 and parameters: {'logreg_c': 4.005595097886426, 'l1_ratio': 0.40683807642605113, 'max_iter': 1851}. Best is trial 41 with value: 0.6307619047619047.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:33:47,335]\u001b[0m Trial 44 finished with value: 0.6153333333333333 and parameters: {'logreg_c': 10.51995398501394, 'l1_ratio': 0.5242462748652383, 'max_iter': 1635}. Best is trial 41 with value: 0.6307619047619047.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:33:47,361]\u001b[0m Trial 45 finished with value: 0.6166666666666667 and parameters: {'logreg_c': 0.43649305773415953, 'l1_ratio': 0.62669435281089, 'max_iter': 1803}. Best is trial 41 with value: 0.6307619047619047.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:33:47,387]\u001b[0m Trial 46 finished with value: 0.6195238095238095 and parameters: {'logreg_c': 0.07187646725784044, 'l1_ratio': 0.281967448657918, 'max_iter': 1917}. Best is trial 41 with value: 0.6307619047619047.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:33:47,414]\u001b[0m Trial 47 finished with value: 0.627904761904762 and parameters: {'logreg_c': 2.0310237754182316, 'l1_ratio': 0.39414395429506727, 'max_iter': 1726}. Best is trial 41 with value: 0.6307619047619047.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:33:47,441]\u001b[0m Trial 48 finished with value: 0.620952380952381 and parameters: {'logreg_c': 0.6082079556285477, 'l1_ratio': 0.5660058818783812, 'max_iter': 1618}. Best is trial 41 with value: 0.6307619047619047.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:33:47,466]\u001b[0m Trial 49 finished with value: 0.6108571428571429 and parameters: {'logreg_c': 240.59569344033093, 'l1_ratio': 0.24451803344912826, 'max_iter': 1985}. Best is trial 41 with value: 0.6307619047619047.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:33:47,492]\u001b[0m Trial 50 finished with value: 0.5643809523809523 and parameters: {'logreg_c': 0.003166482546125131, 'l1_ratio': 0.4598078240788601, 'max_iter': 1365}. Best is trial 41 with value: 0.6307619047619047.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:33:47,518]\u001b[0m Trial 51 finished with value: 0.6167619047619047 and parameters: {'logreg_c': 7.943065063340901, 'l1_ratio': 0.3551537545361903, 'max_iter': 1474}. Best is trial 41 with value: 0.6307619047619047.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:33:47,545]\u001b[0m Trial 52 finished with value: 0.6294285714285714 and parameters: {'logreg_c': 1.8518389019522237, 'l1_ratio': 0.49224974644280434, 'max_iter': 1844}. Best is trial 41 with value: 0.6307619047619047.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:33:47,571]\u001b[0m Trial 53 finished with value: 0.627904761904762 and parameters: {'logreg_c': 1.3572714107165977, 'l1_ratio': 0.49277895678099476, 'max_iter': 1458}. Best is trial 41 with value: 0.6307619047619047.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:33:47,598]\u001b[0m Trial 54 finished with value: 0.6210476190476191 and parameters: {'logreg_c': 3.7115076962149858, 'l1_ratio': 0.6102000361609092, 'max_iter': 1590}. Best is trial 41 with value: 0.6307619047619047.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:33:47,625]\u001b[0m Trial 55 finished with value: 0.6264761904761904 and parameters: {'logreg_c': 0.8911994905571492, 'l1_ratio': 0.3993140649769618, 'max_iter': 1883}. Best is trial 41 with value: 0.6307619047619047.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:33:47,651]\u001b[0m Trial 56 finished with value: 0.6294285714285714 and parameters: {'logreg_c': 2.2506604255090674, 'l1_ratio': 0.5420213510321465, 'max_iter': 1719}. Best is trial 41 with value: 0.6307619047619047.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:33:47,678]\u001b[0m Trial 57 finished with value: 0.6191428571428571 and parameters: {'logreg_c': 19.197800367683012, 'l1_ratio': 0.4652438210429772, 'max_iter': 1762}. Best is trial 41 with value: 0.6307619047619047.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:33:47,705]\u001b[0m Trial 58 finished with value: 0.6195238095238096 and parameters: {'logreg_c': 0.17391612699617703, 'l1_ratio': 0.5464710550797393, 'max_iter': 1365}. Best is trial 41 with value: 0.6307619047619047.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:33:47,730]\u001b[0m Trial 59 finished with value: 0.613904761904762 and parameters: {'logreg_c': 6.575270743844423, 'l1_ratio': 0.5466415698694522, 'max_iter': 1686}. Best is trial 41 with value: 0.6307619047619047.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:33:47,758]\u001b[0m Trial 60 finished with value: 0.6163809523809525 and parameters: {'logreg_c': 54.54049186437329, 'l1_ratio': 0.4325278919043865, 'max_iter': 1996}. Best is trial 41 with value: 0.6307619047619047.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:33:47,784]\u001b[0m Trial 61 finished with value: 0.6307619047619047 and parameters: {'logreg_c': 2.096362271932597, 'l1_ratio': 0.5160078527964562, 'max_iter': 1556}. Best is trial 41 with value: 0.6307619047619047.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:33:47,811]\u001b[0m Trial 62 finished with value: 0.6266666666666666 and parameters: {'logreg_c': 2.538893199184801, 'l1_ratio': 0.504806699044337, 'max_iter': 1744}. Best is trial 41 with value: 0.6307619047619047.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:33:47,838]\u001b[0m Trial 63 finished with value: 0.6308571428571428 and parameters: {'logreg_c': 1.6491171164828378, 'l1_ratio': 0.37983614680640526, 'max_iter': 1831}. Best is trial 63 with value: 0.6308571428571428.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:33:47,865]\u001b[0m Trial 64 finished with value: 0.6207619047619048 and parameters: {'logreg_c': 0.5680946103743453, 'l1_ratio': 0.6124516385720995, 'max_iter': 1804}. Best is trial 63 with value: 0.6308571428571428.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:33:47,891]\u001b[0m Trial 65 finished with value: 0.6194285714285714 and parameters: {'logreg_c': 12.835933863876129, 'l1_ratio': 0.3307896654069705, 'max_iter': 1545}. Best is trial 63 with value: 0.6308571428571428.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:33:47,916]\u001b[0m Trial 66 finished with value: 0.6167619047619047 and parameters: {'logreg_c': 4.284809135627299, 'l1_ratio': 0.49198373373937326, 'max_iter': 1318}. Best is trial 63 with value: 0.6308571428571428.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:33:47,944]\u001b[0m Trial 67 finished with value: 0.6307619047619047 and parameters: {'logreg_c': 0.9489377554918126, 'l1_ratio': 0.37627684812340034, 'max_iter': 1225}. Best is trial 63 with value: 0.6308571428571428.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:33:47,968]\u001b[0m Trial 68 finished with value: 0.6292380952380953 and parameters: {'logreg_c': 1.0538708885678392, 'l1_ratio': 0.6781276320502876, 'max_iter': 1209}. Best is trial 63 with value: 0.6308571428571428.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:33:47,993]\u001b[0m Trial 69 finished with value: 0.6067619047619047 and parameters: {'logreg_c': 0.29155306833483985, 'l1_ratio': 0.36263117743566936, 'max_iter': 1660}. Best is trial 63 with value: 0.6308571428571428.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:33:48,018]\u001b[0m Trial 70 finished with value: 0.6251428571428571 and parameters: {'logreg_c': 0.8333203040302765, 'l1_ratio': 0.43197726798313846, 'max_iter': 1169}. Best is trial 63 with value: 0.6308571428571428.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:33:48,045]\u001b[0m Trial 71 finished with value: 0.6224761904761905 and parameters: {'logreg_c': 3.2825957984619203, 'l1_ratio': 0.52930545567372, 'max_iter': 1902}. Best is trial 63 with value: 0.6308571428571428.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:33:48,071]\u001b[0m Trial 72 finished with value: 0.6294285714285714 and parameters: {'logreg_c': 1.707563442346071, 'l1_ratio': 0.2692265008939825, 'max_iter': 1804}. Best is trial 63 with value: 0.6308571428571428.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:33:48,098]\u001b[0m Trial 73 finished with value: 0.627904761904762 and parameters: {'logreg_c': 1.244565542128993, 'l1_ratio': 0.22628313375302067, 'max_iter': 1283}. Best is trial 63 with value: 0.6308571428571428.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:33:48,124]\u001b[0m Trial 74 finished with value: 0.617904761904762 and parameters: {'logreg_c': 0.5423233219501331, 'l1_ratio': 0.37441966805804505, 'max_iter': 1429}. Best is trial 63 with value: 0.6308571428571428.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:33:48,150]\u001b[0m Trial 75 finished with value: 0.6238095238095238 and parameters: {'logreg_c': 2.6428530082211377, 'l1_ratio': 0.2853040906189891, 'max_iter': 1736}. Best is trial 63 with value: 0.6308571428571428.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:33:48,175]\u001b[0m Trial 76 finished with value: 0.6209523809523809 and parameters: {'logreg_c': 0.10939627711828923, 'l1_ratio': 0.4735312789321377, 'max_iter': 1846}. Best is trial 63 with value: 0.6308571428571428.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:33:48,201]\u001b[0m Trial 77 finished with value: 0.6264761904761904 and parameters: {'logreg_c': 0.8745518604877525, 'l1_ratio': 0.442590140651025, 'max_iter': 1078}. Best is trial 63 with value: 0.6308571428571428.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:33:48,227]\u001b[0m Trial 78 finished with value: 0.6154285714285713 and parameters: {'logreg_c': 5.330321809025692, 'l1_ratio': 0.4137370416803211, 'max_iter': 1943}. Best is trial 63 with value: 0.6308571428571428.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:33:48,254]\u001b[0m Trial 79 finished with value: 0.6321904761904762 and parameters: {'logreg_c': 1.5684558195868687, 'l1_ratio': 0.51063148634346, 'max_iter': 1863}. Best is trial 79 with value: 0.6321904761904762.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:33:48,280]\u001b[0m Trial 80 finished with value: 0.6194285714285716 and parameters: {'logreg_c': 0.37976816840820854, 'l1_ratio': 0.34025799616210806, 'max_iter': 1579}. Best is trial 79 with value: 0.6321904761904762.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:33:48,304]\u001b[0m Trial 81 finished with value: 0.6308571428571428 and parameters: {'logreg_c': 1.5835184104709785, 'l1_ratio': 0.5016015552438089, 'max_iter': 1871}. Best is trial 79 with value: 0.6321904761904762.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:33:48,327]\u001b[0m Trial 82 finished with value: 0.6308571428571428 and parameters: {'logreg_c': 1.6594874201724938, 'l1_ratio': 0.3063290111973975, 'max_iter': 1960}. Best is trial 79 with value: 0.6321904761904762.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:33:48,352]\u001b[0m Trial 83 finished with value: 0.6307619047619046 and parameters: {'logreg_c': 1.343979148614231, 'l1_ratio': 0.5176219420701993, 'max_iter': 1967}. Best is trial 79 with value: 0.6321904761904762.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:33:48,376]\u001b[0m Trial 84 finished with value: 0.6223809523809524 and parameters: {'logreg_c': 0.7187697779331849, 'l1_ratio': 0.5672396458148798, 'max_iter': 1939}. Best is trial 79 with value: 0.6321904761904762.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:33:48,402]\u001b[0m Trial 85 finished with value: 0.6293333333333334 and parameters: {'logreg_c': 1.2029830464414577, 'l1_ratio': 0.5185295899090988, 'max_iter': 1859}. Best is trial 79 with value: 0.6321904761904762.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:33:48,427]\u001b[0m Trial 86 finished with value: 0.6266666666666666 and parameters: {'logreg_c': 2.9061910777908393, 'l1_ratio': 0.3132992841051993, 'max_iter': 1949}. Best is trial 79 with value: 0.6321904761904762.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:33:48,450]\u001b[0m Trial 87 finished with value: 0.6096190476190476 and parameters: {'logreg_c': 0.2725593715364528, 'l1_ratio': 0.3860887328318272, 'max_iter': 1796}. Best is trial 79 with value: 0.6321904761904762.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:33:48,475]\u001b[0m Trial 88 finished with value: 0.6165714285714287 and parameters: {'logreg_c': 0.4912865251268892, 'l1_ratio': 0.5945013797755109, 'max_iter': 2000}. Best is trial 79 with value: 0.6321904761904762.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:33:48,499]\u001b[0m Trial 89 finished with value: 0.6153333333333333 and parameters: {'logreg_c': 8.240833064906228, 'l1_ratio': 0.5139563256443173, 'max_iter': 162}. Best is trial 79 with value: 0.6321904761904762.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:33:48,523]\u001b[0m Trial 90 finished with value: 0.6307619047619047 and parameters: {'logreg_c': 1.4731369609639198, 'l1_ratio': 0.4554672724433561, 'max_iter': 1883}. Best is trial 79 with value: 0.6321904761904762.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:33:48,546]\u001b[0m Trial 91 finished with value: 0.627904761904762 and parameters: {'logreg_c': 1.2362306827283187, 'l1_ratio': 0.45224194854848165, 'max_iter': 1869}. Best is trial 79 with value: 0.6321904761904762.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:33:48,572]\u001b[0m Trial 92 finished with value: 0.628 and parameters: {'logreg_c': 1.8218108234980488, 'l1_ratio': 0.47339867982647943, 'max_iter': 1823}. Best is trial 79 with value: 0.6321904761904762.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:33:48,595]\u001b[0m Trial 93 finished with value: 0.6167619047619047 and parameters: {'logreg_c': 4.271962308570505, 'l1_ratio': 0.5609556013046808, 'max_iter': 1914}. Best is trial 79 with value: 0.6321904761904762.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:33:48,618]\u001b[0m Trial 94 finished with value: 0.6307619047619047 and parameters: {'logreg_c': 0.9774627856036887, 'l1_ratio': 0.42302130014987804, 'max_iter': 1700}. Best is trial 79 with value: 0.6321904761904762.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:33:48,643]\u001b[0m Trial 95 finished with value: 0.6222857142857143 and parameters: {'logreg_c': 0.8082919920657609, 'l1_ratio': 0.41564559443826843, 'max_iter': 1765}. Best is trial 79 with value: 0.6321904761904762.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:33:48,667]\u001b[0m Trial 96 finished with value: 0.6308571428571428 and parameters: {'logreg_c': 1.576347619069216, 'l1_ratio': 0.37665937232889934, 'max_iter': 1705}. Best is trial 79 with value: 0.6321904761904762.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:33:48,691]\u001b[0m Trial 97 finished with value: 0.6252380952380953 and parameters: {'logreg_c': 3.119735317205072, 'l1_ratio': 0.3724348739191003, 'max_iter': 1701}. Best is trial 79 with value: 0.6321904761904762.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:33:48,715]\u001b[0m Trial 98 finished with value: 0.613904761904762 and parameters: {'logreg_c': 6.204154164274675, 'l1_ratio': 0.3480031298152046, 'max_iter': 1631}. Best is trial 79 with value: 0.6321904761904762.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:33:48,739]\u001b[0m Trial 99 finished with value: 0.6195238095238096 and parameters: {'logreg_c': 0.6240590821298014, 'l1_ratio': 0.39483273607916664, 'max_iter': 1765}. Best is trial 79 with value: 0.6321904761904762.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "#Tuning hyperparameters\n",
    "#Step 1. Define an objective function to be maximized.\n",
    "def objective(trial):\n",
    "    logreg_c = trial.suggest_float(\"logreg_c\", 1e-3,  1e3, log=True)\n",
    "    l1_ratio = trial.suggest_float(\"l1_ratio\",0.1,1,log=False) \n",
    "    #penalty = trial.suggest_categorical(\"penalty\",['l1','l2'])\n",
    "    max_iter = trial.suggest_int(\"max_iter\", 100,2000)\n",
    "    model =LogisticRegression(C=logreg_c,\n",
    "                              max_iter=max_iter,\n",
    "                              l1_ratio=l1_ratio,\n",
    "                              solver='liblinear',random_state=1)\n",
    "    \n",
    "# Step 2: Scoring method:\n",
    "    score = model_selection.cross_val_score(model, X, y, n_jobs=8, scoring=\"accuracy\",cv=Cv_optuna)\n",
    "    accuracy = score.mean()\n",
    "    return accuracy\n",
    "\n",
    "# Step 3: Running it\n",
    "study = optuna.create_study(direction=\"maximize\",sampler=optuna.samplers.TPESampler(seed=1))\n",
    "study.optimize(objective, n_trials=100, show_progress_bar=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "36a76651-b007-4715-a58f-8776deab4b8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best parameters are : \n",
      "{'logreg_c': 1.5684558195868687, 'l1_ratio': 0.51063148634346, 'max_iter': 1863}\n"
     ]
    }
   ],
   "source": [
    "# Getting the best parameters:\n",
    "print(f\"The best parameters are : \\n{study.best_params}\")\n",
    "# Setting the best model\n",
    "clf=LogisticRegression(C=study.best_params['logreg_c'],\n",
    "                              max_iter=study.best_params['max_iter'],\n",
    "                              l1_ratio=study.best_params['l1_ratio'],\n",
    "                              solver='liblinear',\n",
    "                              random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "b3ae0d1b-badc-4865-802b-396e3ee1b6cf",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mean</th>\n",
       "      <th>Se</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Accuracy_test</th>\n",
       "      <td>0.632190</td>\n",
       "      <td>0.014648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Accuracy_train</th>\n",
       "      <td>0.735909</td>\n",
       "      <td>0.004541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1 Score</th>\n",
       "      <td>0.694496</td>\n",
       "      <td>0.013341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Precision</th>\n",
       "      <td>0.627650</td>\n",
       "      <td>0.012121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recall</th>\n",
       "      <td>0.794643</td>\n",
       "      <td>0.021058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Roc_auc</th>\n",
       "      <td>0.673325</td>\n",
       "      <td>0.020325</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Mean        Se\n",
       "Accuracy_test   0.632190  0.014648\n",
       "Accuracy_train  0.735909  0.004541\n",
       "F1 Score        0.694496  0.013341\n",
       "Precision       0.627650  0.012121\n",
       "Recall          0.794643  0.021058\n",
       "Roc_auc         0.673325  0.020325"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Model2\n",
    "Model2=Model_results(clf,X,y,Cv_model)\n",
    "Model2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "a5007e9c-21fb-4007-bc2e-d5875dabe240",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th>Method</th>\n",
       "      <th colspan=\"4\" halign=\"left\">LR</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model</th>\n",
       "      <th colspan=\"2\" halign=\"left\">Model 1</th>\n",
       "      <th colspan=\"2\" halign=\"left\">Model 2</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Values</th>\n",
       "      <th>Mean</th>\n",
       "      <th>Se</th>\n",
       "      <th>Mean</th>\n",
       "      <th>Se</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Accuracy_test</th>\n",
       "      <td>0.680000</td>\n",
       "      <td>0.012329</td>\n",
       "      <td>0.632190</td>\n",
       "      <td>0.014648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Accuracy_train</th>\n",
       "      <td>0.925345</td>\n",
       "      <td>0.005584</td>\n",
       "      <td>0.735909</td>\n",
       "      <td>0.004541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1 Score</th>\n",
       "      <td>0.706865</td>\n",
       "      <td>0.012092</td>\n",
       "      <td>0.694496</td>\n",
       "      <td>0.013341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Precision</th>\n",
       "      <td>0.698240</td>\n",
       "      <td>0.013460</td>\n",
       "      <td>0.627650</td>\n",
       "      <td>0.012121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recall</th>\n",
       "      <td>0.735714</td>\n",
       "      <td>0.020076</td>\n",
       "      <td>0.794643</td>\n",
       "      <td>0.021058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Roc_auc</th>\n",
       "      <td>0.690561</td>\n",
       "      <td>0.015281</td>\n",
       "      <td>0.673325</td>\n",
       "      <td>0.020325</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Method                LR                              \n",
       "Model            Model 1             Model 2          \n",
       "Values              Mean        Se      Mean        Se\n",
       "Accuracy_test   0.680000  0.012329  0.632190  0.014648\n",
       "Accuracy_train  0.925345  0.005584  0.735909  0.004541\n",
       "F1 Score        0.706865  0.012092  0.694496  0.013341\n",
       "Precision       0.698240  0.013460  0.627650  0.012121\n",
       "Recall          0.735714  0.020076  0.794643  0.021058\n",
       "Roc_auc         0.690561  0.015281  0.673325  0.020325"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Saving the data of model performance\n",
    "Model_data=pd.concat([Model1,Model2],axis=1)\n",
    "Model_data.columns = [['LR']*4,['Model 1','Model 1', 'Model 2','Model 2'], ['Mean', 'Se', 'Mean', 'Se']]  \n",
    "Model_data.columns.names=['Method','Model','Values']\n",
    "Model_data.to_csv(\"./Results/LR_model_mlrem_data.csv\",sep=',')\n",
    "Model_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "892cd0c1-3914-4d08-a63a-550ffd5f60fb",
   "metadata": {},
   "source": [
    "## 2.3 RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "570a3fc5-5ce1-4bd8-a18a-b9209126a44e",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf=RandomForestClassifier(random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "4448a0ec-3f59-45ad-be0b-3713b3c0072b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mean</th>\n",
       "      <th>Se</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Accuracy_test</th>\n",
       "      <td>0.676381</td>\n",
       "      <td>0.014691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Accuracy_train</th>\n",
       "      <td>0.978164</td>\n",
       "      <td>0.001539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1 Score</th>\n",
       "      <td>0.711877</td>\n",
       "      <td>0.013423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Precision</th>\n",
       "      <td>0.688878</td>\n",
       "      <td>0.014746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recall</th>\n",
       "      <td>0.757857</td>\n",
       "      <td>0.020561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Roc_auc</th>\n",
       "      <td>0.756424</td>\n",
       "      <td>0.017012</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Mean        Se\n",
       "Accuracy_test   0.676381  0.014691\n",
       "Accuracy_train  0.978164  0.001539\n",
       "F1 Score        0.711877  0.013423\n",
       "Precision       0.688878  0.014746\n",
       "Recall          0.757857  0.020561\n",
       "Roc_auc         0.756424  0.017012"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Model1\n",
    "Model1_clf=clf\n",
    "#Model1\n",
    "Model1=Model_results(Model1_clf,X,y,Cv_model)\n",
    "Model1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "d0f9ce84-3537-484b-9862-bf7cefca94b8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2024-01-12 01:35:16,075]\u001b[0m A new study created in memory with name: no-name-0e368382-34a5-42fd-91ba-b1b1a0a8e3bf\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:35:19,314]\u001b[0m Trial 0 finished with value: 0.5352380952380952 and parameters: {'n_estimators': 594, 'max_depth': 16, 'max_features': 20, 'min_impurity_decrease': 2.724415914984484}. Best is trial 0 with value: 0.5352380952380952.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:35:21,908]\u001b[0m Trial 1 finished with value: 0.5352380952380952 and parameters: {'n_estimators': 481, 'max_depth': 15, 'max_features': 16, 'min_impurity_decrease': 4.4588650039103985}. Best is trial 0 with value: 0.5352380952380952.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:35:27,120]\u001b[0m Trial 2 finished with value: 0.5352380952380952 and parameters: {'n_estimators': 968, 'max_depth': 11, 'max_features': 25, 'min_impurity_decrease': 2.644474598764522}. Best is trial 0 with value: 0.5352380952380952.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:35:30,335]\u001b[0m Trial 3 finished with value: 0.5352380952380952 and parameters: {'n_estimators': 611, 'max_depth': 19, 'max_features': 6, 'min_impurity_decrease': 0.43564649850770354}. Best is trial 0 with value: 0.5352380952380952.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:35:31,006]\u001b[0m Trial 4 finished with value: 0.5352380952380952 and parameters: {'n_estimators': 118, 'max_depth': 18, 'max_features': 25, 'min_impurity_decrease': 4.3500607412340955}. Best is trial 0 with value: 0.5352380952380952.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:35:36,134]\u001b[0m Trial 5 finished with value: 0.5352380952380952 and parameters: {'n_estimators': 981, 'max_depth': 17, 'max_features': 16, 'min_impurity_decrease': 3.902645881432277}. Best is trial 0 with value: 0.5352380952380952.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:35:37,261]\u001b[0m Trial 6 finished with value: 0.5352380952380952 and parameters: {'n_estimators': 206, 'max_depth': 15, 'max_features': 8, 'min_impurity_decrease': 4.7233445852479194}. Best is trial 0 with value: 0.5352380952380952.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:35:40,255]\u001b[0m Trial 7 finished with value: 0.5352380952380952 and parameters: {'n_estimators': 570, 'max_depth': 11, 'max_features': 11, 'min_impurity_decrease': 3.871168447171083}. Best is trial 0 with value: 0.5352380952380952.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:35:42,854]\u001b[0m Trial 8 finished with value: 0.5352380952380952 and parameters: {'n_estimators': 510, 'max_depth': 14, 'max_features': 5, 'min_impurity_decrease': 3.0881774853793855}. Best is trial 0 with value: 0.5352380952380952.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:35:46,294]\u001b[0m Trial 9 finished with value: 0.5352380952380952 and parameters: {'n_estimators': 651, 'max_depth': 14, 'max_features': 29, 'min_impurity_decrease': 3.409101495517417}. Best is trial 0 with value: 0.5352380952380952.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:35:50,414]\u001b[0m Trial 10 finished with value: 0.5352380952380952 and parameters: {'n_estimators': 790, 'max_depth': 7, 'max_features': 21, 'min_impurity_decrease': 1.5046577569438309}. Best is trial 0 with value: 0.5352380952380952.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:35:52,562]\u001b[0m Trial 11 finished with value: 0.5352380952380952 and parameters: {'n_estimators': 397, 'max_depth': 20, 'max_features': 16, 'min_impurity_decrease': 1.9887909510549393}. Best is trial 0 with value: 0.5352380952380952.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:35:54,439]\u001b[0m Trial 12 finished with value: 0.5352380952380952 and parameters: {'n_estimators': 353, 'max_depth': 16, 'max_features': 20, 'min_impurity_decrease': 0.7029374955194359}. Best is trial 0 with value: 0.5352380952380952.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:35:56,713]\u001b[0m Trial 13 finished with value: 0.5352380952380952 and parameters: {'n_estimators': 411, 'max_depth': 12, 'max_features': 12, 'min_impurity_decrease': 4.931175650908394}. Best is trial 0 with value: 0.5352380952380952.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:36:00,636]\u001b[0m Trial 14 finished with value: 0.5352380952380952 and parameters: {'n_estimators': 743, 'max_depth': 7, 'max_features': 19, 'min_impurity_decrease': 1.5253121430442067}. Best is trial 0 with value: 0.5352380952380952.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:36:04,681]\u001b[0m Trial 15 finished with value: 0.5352380952380952 and parameters: {'n_estimators': 757, 'max_depth': 13, 'max_features': 12, 'min_impurity_decrease': 2.668111844473928}. Best is trial 0 with value: 0.5352380952380952.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:36:06,269]\u001b[0m Trial 16 finished with value: 0.5352380952380952 and parameters: {'n_estimators': 286, 'max_depth': 9, 'max_features': 24, 'min_impurity_decrease': 3.4814210246729473}. Best is trial 0 with value: 0.5352380952380952.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:36:10,648]\u001b[0m Trial 17 finished with value: 0.5352380952380952 and parameters: {'n_estimators': 807, 'max_depth': 5, 'max_features': 19, 'min_impurity_decrease': 1.4307627258174422}. Best is trial 0 with value: 0.5352380952380952.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:36:14,484]\u001b[0m Trial 18 finished with value: 0.5352380952380952 and parameters: {'n_estimators': 714, 'max_depth': 13, 'max_features': 12, 'min_impurity_decrease': 2.574069984147719}. Best is trial 0 with value: 0.5352380952380952.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:36:16,040]\u001b[0m Trial 19 finished with value: 0.5352380952380952 and parameters: {'n_estimators': 291, 'max_depth': 8, 'max_features': 24, 'min_impurity_decrease': 3.3144569973486893}. Best is trial 0 with value: 0.5352380952380952.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:36:20,679]\u001b[0m Trial 20 finished with value: 0.5352380952380952 and parameters: {'n_estimators': 871, 'max_depth': 5, 'max_features': 29, 'min_impurity_decrease': 1.0528796896599464}. Best is trial 0 with value: 0.5352380952380952.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:36:24,313]\u001b[0m Trial 21 finished with value: 0.5352380952380952 and parameters: {'n_estimators': 670, 'max_depth': 10, 'max_features': 14, 'min_impurity_decrease': 2.1272690676619246}. Best is trial 0 with value: 0.5352380952380952.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:36:27,036]\u001b[0m Trial 22 finished with value: 0.5352380952380952 and parameters: {'n_estimators': 502, 'max_depth': 9, 'max_features': 23, 'min_impurity_decrease': 3.0212243946132653}. Best is trial 0 with value: 0.5352380952380952.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:36:31,734]\u001b[0m Trial 23 finished with value: 0.5352380952380952 and parameters: {'n_estimators': 871, 'max_depth': 6, 'max_features': 30, 'min_impurity_decrease': 0.8924229302747374}. Best is trial 0 with value: 0.5352380952380952.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:36:35,612]\u001b[0m Trial 24 finished with value: 0.5352380952380952 and parameters: {'n_estimators': 673, 'max_depth': 11, 'max_features': 28, 'min_impurity_decrease': 2.183958261339378}. Best is trial 0 with value: 0.5352380952380952.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:36:41,146]\u001b[0m Trial 25 finished with value: 0.5352380952380952 and parameters: {'n_estimators': 548, 'max_depth': 9, 'max_features': 22, 'min_impurity_decrease': 2.0762642939740097}. Best is trial 0 with value: 0.5352380952380952.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:36:51,062]\u001b[0m Trial 26 finished with value: 0.6323809523809524 and parameters: {'n_estimators': 859, 'max_depth': 7, 'max_features': 27, 'min_impurity_decrease': 0.05016303754931206}. Best is trial 26 with value: 0.6323809523809524.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:37:01,691]\u001b[0m Trial 27 finished with value: 0.672 and parameters: {'n_estimators': 889, 'max_depth': 6, 'max_features': 27, 'min_impurity_decrease': 0.008573433661244079}. Best is trial 27 with value: 0.672.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:37:11,727]\u001b[0m Trial 28 finished with value: 0.6322857142857143 and parameters: {'n_estimators': 901, 'max_depth': 7, 'max_features': 27, 'min_impurity_decrease': 0.04449057244021093}. Best is trial 27 with value: 0.672.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:37:22,093]\u001b[0m Trial 29 finished with value: 0.6254285714285714 and parameters: {'n_estimators': 918, 'max_depth': 7, 'max_features': 27, 'min_impurity_decrease': 0.06568686852538762}. Best is trial 27 with value: 0.672.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:37:30,555]\u001b[0m Trial 30 finished with value: 0.5352380952380952 and parameters: {'n_estimators': 855, 'max_depth': 6, 'max_features': 26, 'min_impurity_decrease': 0.3179551086113602}. Best is trial 27 with value: 0.672.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:37:38,485]\u001b[0m Trial 31 finished with value: 0.597047619047619 and parameters: {'n_estimators': 937, 'max_depth': 7, 'max_features': 27, 'min_impurity_decrease': 0.18490386200494244}. Best is trial 27 with value: 0.672.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:37:46,299]\u001b[0m Trial 32 finished with value: 0.6747619047619048 and parameters: {'n_estimators': 913, 'max_depth': 8, 'max_features': 27, 'min_impurity_decrease': 0.004905793398417582}. Best is trial 32 with value: 0.6747619047619048.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:37:56,619]\u001b[0m Trial 33 finished with value: 0.6761904761904762 and parameters: {'n_estimators': 917, 'max_depth': 6, 'max_features': 30, 'min_impurity_decrease': 0.0020653183224317627}. Best is trial 33 with value: 0.6761904761904762.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:38:05,942]\u001b[0m Trial 34 finished with value: 0.5352380952380952 and parameters: {'n_estimators': 989, 'max_depth': 5, 'max_features': 29, 'min_impurity_decrease': 0.6299600959488392}. Best is trial 33 with value: 0.6761904761904762.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:38:13,475]\u001b[0m Trial 35 finished with value: 0.5352380952380952 and parameters: {'n_estimators': 815, 'max_depth': 8, 'max_features': 30, 'min_impurity_decrease': 0.4674586648441808}. Best is trial 33 with value: 0.6761904761904762.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:38:23,053]\u001b[0m Trial 36 finished with value: 0.5352380952380952 and parameters: {'n_estimators': 961, 'max_depth': 6, 'max_features': 25, 'min_impurity_decrease': 1.1357603095945366}. Best is trial 33 with value: 0.6761904761904762.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:38:31,082]\u001b[0m Trial 37 finished with value: 0.5352380952380952 and parameters: {'n_estimators': 840, 'max_depth': 8, 'max_features': 26, 'min_impurity_decrease': 0.4114799952729883}. Best is trial 33 with value: 0.6761904761904762.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:38:40,979]\u001b[0m Trial 38 finished with value: 0.5352380952380952 and parameters: {'n_estimators': 998, 'max_depth': 10, 'max_features': 23, 'min_impurity_decrease': 0.7115028745023322}. Best is trial 33 with value: 0.6761904761904762.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:38:51,024]\u001b[0m Trial 39 finished with value: 0.6297142857142857 and parameters: {'n_estimators': 903, 'max_depth': 6, 'max_features': 28, 'min_impurity_decrease': 0.06208220513260173}. Best is trial 33 with value: 0.6761904761904762.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:38:58,675]\u001b[0m Trial 40 finished with value: 0.5352380952380952 and parameters: {'n_estimators': 758, 'max_depth': 5, 'max_features': 25, 'min_impurity_decrease': 1.2530333907876288}. Best is trial 33 with value: 0.6761904761904762.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:39:08,515]\u001b[0m Trial 41 finished with value: 0.6322857142857143 and parameters: {'n_estimators': 907, 'max_depth': 8, 'max_features': 27, 'min_impurity_decrease': 0.05286677087361633}. Best is trial 33 with value: 0.6761904761904762.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:39:17,698]\u001b[0m Trial 42 finished with value: 0.5352380952380952 and parameters: {'n_estimators': 942, 'max_depth': 8, 'max_features': 30, 'min_impurity_decrease': 0.5113387488083093}. Best is trial 33 with value: 0.6761904761904762.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:39:26,348]\u001b[0m Trial 43 finished with value: 0.5421904761904762 and parameters: {'n_estimators': 888, 'max_depth': 10, 'max_features': 28, 'min_impurity_decrease': 0.22488874368369016}. Best is trial 33 with value: 0.6761904761904762.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:39:34,856]\u001b[0m Trial 44 finished with value: 0.5352380952380952 and parameters: {'n_estimators': 829, 'max_depth': 6, 'max_features': 26, 'min_impurity_decrease': 0.9284394996974525}. Best is trial 33 with value: 0.6761904761904762.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:39:45,663]\u001b[0m Trial 45 finished with value: 0.6718095238095237 and parameters: {'n_estimators': 948, 'max_depth': 9, 'max_features': 28, 'min_impurity_decrease': 0.0222031983719142}. Best is trial 33 with value: 0.6761904761904762.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:39:55,567]\u001b[0m Trial 46 finished with value: 0.5352380952380952 and parameters: {'n_estimators': 949, 'max_depth': 9, 'max_features': 29, 'min_impurity_decrease': 0.3420653743587697}. Best is trial 33 with value: 0.6761904761904762.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:40:02,772]\u001b[0m Trial 47 finished with value: 0.5352380952380952 and parameters: {'n_estimators': 785, 'max_depth': 7, 'max_features': 9, 'min_impurity_decrease': 0.6816047837540026}. Best is trial 33 with value: 0.6761904761904762.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:40:08,909]\u001b[0m Trial 48 finished with value: 0.5352380952380952 and parameters: {'n_estimators': 622, 'max_depth': 6, 'max_features': 24, 'min_impurity_decrease': 0.8511767213202808}. Best is trial 33 with value: 0.6761904761904762.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:40:09,968]\u001b[0m Trial 49 finished with value: 0.5309523809523808 and parameters: {'n_estimators': 107, 'max_depth': 10, 'max_features': 21, 'min_impurity_decrease': 0.26320721389361473}. Best is trial 33 with value: 0.6761904761904762.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:40:17,265]\u001b[0m Trial 50 finished with value: 0.5352380952380952 and parameters: {'n_estimators': 708, 'max_depth': 12, 'max_features': 28, 'min_impurity_decrease': 1.8082382735708258}. Best is trial 33 with value: 0.6761904761904762.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:40:28,042]\u001b[0m Trial 51 finished with value: 0.676095238095238 and parameters: {'n_estimators': 962, 'max_depth': 7, 'max_features': 27, 'min_impurity_decrease': 0.02106459317315383}. Best is trial 33 with value: 0.6761904761904762.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:40:37,749]\u001b[0m Trial 52 finished with value: 0.5352380952380952 and parameters: {'n_estimators': 955, 'max_depth': 7, 'max_features': 26, 'min_impurity_decrease': 0.49937746742507}. Best is trial 33 with value: 0.6761904761904762.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:40:47,221]\u001b[0m Trial 53 finished with value: 0.5323809523809523 and parameters: {'n_estimators': 989, 'max_depth': 5, 'max_features': 30, 'min_impurity_decrease': 0.24933984959020736}. Best is trial 33 with value: 0.6761904761904762.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:40:57,354]\u001b[0m Trial 54 finished with value: 0.671904761904762 and parameters: {'n_estimators': 850, 'max_depth': 8, 'max_features': 29, 'min_impurity_decrease': 0.00020460322913867096}. Best is trial 33 with value: 0.6761904761904762.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:41:06,231]\u001b[0m Trial 55 finished with value: 0.5352380952380952 and parameters: {'n_estimators': 926, 'max_depth': 8, 'max_features': 29, 'min_impurity_decrease': 0.5829495913183985}. Best is trial 33 with value: 0.6761904761904762.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:41:13,996]\u001b[0m Trial 56 finished with value: 0.5352380952380952 and parameters: {'n_estimators': 807, 'max_depth': 9, 'max_features': 25, 'min_impurity_decrease': 4.063447563238093}. Best is trial 33 with value: 0.6761904761904762.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:41:24,402]\u001b[0m Trial 57 finished with value: 0.6761904761904762 and parameters: {'n_estimators': 880, 'max_depth': 11, 'max_features': 28, 'min_impurity_decrease': 0.007051219363487071}. Best is trial 33 with value: 0.6761904761904762.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:41:26,100]\u001b[0m Trial 58 finished with value: 0.5352380952380952 and parameters: {'n_estimators': 167, 'max_depth': 11, 'max_features': 29, 'min_impurity_decrease': 0.798147610103549}. Best is trial 33 with value: 0.6761904761904762.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:41:33,758]\u001b[0m Trial 59 finished with value: 0.5352380952380952 and parameters: {'n_estimators': 770, 'max_depth': 18, 'max_features': 30, 'min_impurity_decrease': 0.382341636539112}. Best is trial 33 with value: 0.6761904761904762.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:41:41,537]\u001b[0m Trial 60 finished with value: 0.5309523809523808 and parameters: {'n_estimators': 843, 'max_depth': 16, 'max_features': 17, 'min_impurity_decrease': 0.2654469511283595}. Best is trial 33 with value: 0.6761904761904762.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:41:52,032]\u001b[0m Trial 61 finished with value: 0.6776190476190476 and parameters: {'n_estimators': 879, 'max_depth': 9, 'max_features': 28, 'min_impurity_decrease': 0.008123194334826785}. Best is trial 61 with value: 0.6776190476190476.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:42:01,231]\u001b[0m Trial 62 finished with value: 0.5956190476190477 and parameters: {'n_estimators': 876, 'max_depth': 12, 'max_features': 28, 'min_impurity_decrease': 0.18049512848250882}. Best is trial 61 with value: 0.6776190476190476.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:42:09,726]\u001b[0m Trial 63 finished with value: 0.5352380952380952 and parameters: {'n_estimators': 889, 'max_depth': 8, 'max_features': 26, 'min_impurity_decrease': 0.5086713670369812}. Best is trial 61 with value: 0.6776190476190476.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:42:16,982]\u001b[0m Trial 64 finished with value: 0.5983809523809525 and parameters: {'n_estimators': 736, 'max_depth': 14, 'max_features': 23, 'min_impurity_decrease': 0.17773926474715257}. Best is trial 61 with value: 0.6776190476190476.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:42:26,203]\u001b[0m Trial 65 finished with value: 0.5352380952380952 and parameters: {'n_estimators': 969, 'max_depth': 10, 'max_features': 29, 'min_impurity_decrease': 0.33631758132430556}. Best is trial 61 with value: 0.6776190476190476.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:42:35,065]\u001b[0m Trial 66 finished with value: 0.6165714285714285 and parameters: {'n_estimators': 925, 'max_depth': 11, 'max_features': 27, 'min_impurity_decrease': 0.1425798717417805}. Best is trial 61 with value: 0.6776190476190476.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:42:44,003]\u001b[0m Trial 67 finished with value: 0.5352380952380952 and parameters: {'n_estimators': 862, 'max_depth': 6, 'max_features': 24, 'min_impurity_decrease': 2.868193262665083}. Best is trial 61 with value: 0.6776190476190476.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:42:51,348]\u001b[0m Trial 68 finished with value: 0.5352380952380952 and parameters: {'n_estimators': 797, 'max_depth': 9, 'max_features': 25, 'min_impurity_decrease': 0.994325851568861}. Best is trial 61 with value: 0.6776190476190476.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:43:00,977]\u001b[0m Trial 69 finished with value: 0.6535238095238095 and parameters: {'n_estimators': 828, 'max_depth': 7, 'max_features': 30, 'min_impurity_decrease': 0.031484934359399815}. Best is trial 61 with value: 0.6776190476190476.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:43:09,542]\u001b[0m Trial 70 finished with value: 0.5352380952380952 and parameters: {'n_estimators': 974, 'max_depth': 8, 'max_features': 15, 'min_impurity_decrease': 0.634550934357082}. Best is trial 61 with value: 0.6776190476190476.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:43:19,004]\u001b[0m Trial 71 finished with value: 0.5352380952380952 and parameters: {'n_estimators': 931, 'max_depth': 9, 'max_features': 28, 'min_impurity_decrease': 0.38649297888281287}. Best is trial 61 with value: 0.6776190476190476.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:43:29,212]\u001b[0m Trial 72 finished with value: 0.6577142857142857 and parameters: {'n_estimators': 899, 'max_depth': 9, 'max_features': 28, 'min_impurity_decrease': 0.030118637469662382}. Best is trial 61 with value: 0.6776190476190476.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:43:40,472]\u001b[0m Trial 73 finished with value: 0.6464761904761906 and parameters: {'n_estimators': 997, 'max_depth': 8, 'max_features': 27, 'min_impurity_decrease': 0.03301911564319314}. Best is trial 61 with value: 0.6776190476190476.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:43:49,058]\u001b[0m Trial 74 finished with value: 0.5832380952380952 and parameters: {'n_estimators': 869, 'max_depth': 7, 'max_features': 29, 'min_impurity_decrease': 0.19804900719497173}. Best is trial 61 with value: 0.6776190476190476.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:44:00,411]\u001b[0m Trial 75 finished with value: 0.6733333333333333 and parameters: {'n_estimators': 960, 'max_depth': 11, 'max_features': 27, 'min_impurity_decrease': 0.0033010724541531968}. Best is trial 61 with value: 0.6776190476190476.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:44:09,453]\u001b[0m Trial 76 finished with value: 0.5352380952380952 and parameters: {'n_estimators': 913, 'max_depth': 11, 'max_features': 26, 'min_impurity_decrease': 0.42939915296424785}. Best is trial 61 with value: 0.6776190476190476.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:44:18,106]\u001b[0m Trial 77 finished with value: 0.5941904761904763 and parameters: {'n_estimators': 841, 'max_depth': 13, 'max_features': 27, 'min_impurity_decrease': 0.16676348958431253}. Best is trial 61 with value: 0.6776190476190476.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:44:22,894]\u001b[0m Trial 78 finished with value: 0.5352380952380952 and parameters: {'n_estimators': 457, 'max_depth': 6, 'max_features': 29, 'min_impurity_decrease': 0.7933694921818996}. Best is trial 61 with value: 0.6776190476190476.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:44:31,918]\u001b[0m Trial 79 finished with value: 0.5352380952380952 and parameters: {'n_estimators': 965, 'max_depth': 12, 'max_features': 26, 'min_impurity_decrease': 0.5862286818332793}. Best is trial 61 with value: 0.6776190476190476.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:44:40,745]\u001b[0m Trial 80 finished with value: 0.5352380952380952 and parameters: {'n_estimators': 894, 'max_depth': 10, 'max_features': 30, 'min_impurity_decrease': 0.3144294030115981}. Best is trial 61 with value: 0.6776190476190476.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:44:51,308]\u001b[0m Trial 81 finished with value: 0.6733333333333335 and parameters: {'n_estimators': 934, 'max_depth': 10, 'max_features': 28, 'min_impurity_decrease': 0.006323452295319941}. Best is trial 61 with value: 0.6776190476190476.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:45:00,829]\u001b[0m Trial 82 finished with value: 0.6165714285714285 and parameters: {'n_estimators': 927, 'max_depth': 10, 'max_features': 28, 'min_impurity_decrease': 0.14545468932474404}. Best is trial 61 with value: 0.6776190476190476.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:45:10,329]\u001b[0m Trial 83 finished with value: 0.5352380952380952 and parameters: {'n_estimators': 975, 'max_depth': 5, 'max_features': 27, 'min_impurity_decrease': 0.33087900745123566}. Best is trial 61 with value: 0.6776190476190476.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:45:19,087]\u001b[0m Trial 84 finished with value: 0.5352380952380952 and parameters: {'n_estimators': 874, 'max_depth': 10, 'max_features': 28, 'min_impurity_decrease': 2.387601930957447}. Best is trial 61 with value: 0.6776190476190476.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:45:29,929]\u001b[0m Trial 85 finished with value: 0.6748571428571429 and parameters: {'n_estimators': 952, 'max_depth': 11, 'max_features': 25, 'min_impurity_decrease': 0.0007392099609671288}. Best is trial 61 with value: 0.6776190476190476.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:45:39,247]\u001b[0m Trial 86 finished with value: 0.5352380952380952 and parameters: {'n_estimators': 947, 'max_depth': 11, 'max_features': 26, 'min_impurity_decrease': 0.48146683809049023}. Best is trial 61 with value: 0.6776190476190476.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:45:47,789]\u001b[0m Trial 87 finished with value: 0.6207619047619047 and parameters: {'n_estimators': 915, 'max_depth': 13, 'max_features': 24, 'min_impurity_decrease': 0.13757031221334323}. Best is trial 61 with value: 0.6776190476190476.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:45:58,181]\u001b[0m Trial 88 finished with value: 0.5352380952380952 and parameters: {'n_estimators': 998, 'max_depth': 12, 'max_features': 25, 'min_impurity_decrease': 0.30676748165353357}. Best is trial 61 with value: 0.6776190476190476.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:46:07,313]\u001b[0m Trial 89 finished with value: 0.5352380952380952 and parameters: {'n_estimators': 956, 'max_depth': 11, 'max_features': 27, 'min_impurity_decrease': 4.576798205075603}. Best is trial 61 with value: 0.6776190476190476.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:46:10,360]\u001b[0m Trial 90 finished with value: 0.620952380952381 and parameters: {'n_estimators': 289, 'max_depth': 12, 'max_features': 7, 'min_impurity_decrease': 0.1288307028354426}. Best is trial 61 with value: 0.6776190476190476.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:46:20,365]\u001b[0m Trial 91 finished with value: 0.6761904761904762 and parameters: {'n_estimators': 852, 'max_depth': 7, 'max_features': 29, 'min_impurity_decrease': 0.007725264887275658}. Best is trial 61 with value: 0.6776190476190476.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:46:29,221]\u001b[0m Trial 92 finished with value: 0.5295238095238095 and parameters: {'n_estimators': 889, 'max_depth': 11, 'max_features': 30, 'min_impurity_decrease': 0.2520599220602134}. Best is trial 61 with value: 0.6776190476190476.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:46:38,312]\u001b[0m Trial 93 finished with value: 0.6732380952380952 and parameters: {'n_estimators': 822, 'max_depth': 7, 'max_features': 29, 'min_impurity_decrease': 0.02259369678524981}. Best is trial 61 with value: 0.6776190476190476.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:46:42,912]\u001b[0m Trial 94 finished with value: 0.617904761904762 and parameters: {'n_estimators': 812, 'max_depth': 7, 'max_features': 29, 'min_impurity_decrease': 0.14831488771027054}. Best is trial 61 with value: 0.6776190476190476.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:46:48,995]\u001b[0m Trial 95 finished with value: 0.6761904761904762 and parameters: {'n_estimators': 940, 'max_depth': 7, 'max_features': 28, 'min_impurity_decrease': 0.005823654890190223}. Best is trial 61 with value: 0.6776190476190476.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:46:54,400]\u001b[0m Trial 96 finished with value: 0.5352380952380952 and parameters: {'n_estimators': 938, 'max_depth': 9, 'max_features': 28, 'min_impurity_decrease': 0.4235083475944678}. Best is trial 61 with value: 0.6776190476190476.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:46:59,625]\u001b[0m Trial 97 finished with value: 0.5352380952380952 and parameters: {'n_estimators': 978, 'max_depth': 10, 'max_features': 27, 'min_impurity_decrease': 0.5367328068166792}. Best is trial 61 with value: 0.6776190476190476.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:47:05,409]\u001b[0m Trial 98 finished with value: 0.6733333333333335 and parameters: {'n_estimators': 919, 'max_depth': 8, 'max_features': 30, 'min_impurity_decrease': 0.0005874942435908203}. Best is trial 61 with value: 0.6776190476190476.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:47:10,306]\u001b[0m Trial 99 finished with value: 0.5352380952380952 and parameters: {'n_estimators': 909, 'max_depth': 8, 'max_features': 30, 'min_impurity_decrease': 0.719689906318086}. Best is trial 61 with value: 0.6776190476190476.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "#Tuning hyperparameters\n",
    "#Step 1. Define an objective function to be maximized.\n",
    "def objective(trial):\n",
    "    n_estimators = trial.suggest_int(\"n_estimators\",100,1000,1) \n",
    "    max_depth = trial.suggest_int(\"max_depth\",5,20,1)\n",
    "    max_features = trial.suggest_int(\"max_features\",5,30,1)\n",
    "    min_impurity_decrease = trial.suggest_float(\"min_impurity_decrease\",0,5,log=False) \n",
    "    model = RandomForestClassifier(n_estimators = n_estimators\n",
    "              ,max_depth = max_depth\n",
    "              ,max_features = max_features\n",
    "              ,min_impurity_decrease = min_impurity_decrease\n",
    "              ,random_state=1\n",
    "              ,verbose=False\n",
    "              ,n_jobs=8)\n",
    "\n",
    "# Step 2: Scoring method:\n",
    "    score = model_selection.cross_val_score(model, X, y, n_jobs=8, scoring=\"accuracy\",cv=Cv_optuna)\n",
    "    accuracy = score.mean()\n",
    "    return accuracy\n",
    " \n",
    "# Step 3: Running it\n",
    "study = optuna.create_study(direction=\"maximize\",sampler=optuna.samplers.TPESampler(seed=0))\n",
    "study.optimize(objective, n_trials=100, show_progress_bar=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "9b88d250-7567-4062-b7d5-0a9638d732c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best parameters are : \n",
      "{'n_estimators': 879, 'max_depth': 9, 'max_features': 28, 'min_impurity_decrease': 0.008123194334826785}\n"
     ]
    }
   ],
   "source": [
    "# Getting the best parameters:\n",
    "print(f\"The best parameters are : \\n{study.best_params}\")\n",
    "# Setting the best model\n",
    "clf=RandomForestClassifier(n_estimators = study.best_params['n_estimators']\n",
    "              ,max_depth = study.best_params['max_depth']\n",
    "              ,max_features = study.best_params['max_features']\n",
    "              ,min_impurity_decrease = study.best_params['min_impurity_decrease']\n",
    "              ,random_state=0\n",
    "              ,verbose=False\n",
    "              ,n_jobs=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "a4281260-9ed3-4ed2-93c1-ed1888b7625f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mean</th>\n",
       "      <th>Se</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Accuracy_test</th>\n",
       "      <td>0.670571</td>\n",
       "      <td>0.013460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Accuracy_train</th>\n",
       "      <td>0.974643</td>\n",
       "      <td>0.001874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1 Score</th>\n",
       "      <td>0.703054</td>\n",
       "      <td>0.013994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Precision</th>\n",
       "      <td>0.681364</td>\n",
       "      <td>0.014131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recall</th>\n",
       "      <td>0.749643</td>\n",
       "      <td>0.022551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Roc_auc</th>\n",
       "      <td>0.752985</td>\n",
       "      <td>0.015938</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Mean        Se\n",
       "Accuracy_test   0.670571  0.013460\n",
       "Accuracy_train  0.974643  0.001874\n",
       "F1 Score        0.703054  0.013994\n",
       "Precision       0.681364  0.014131\n",
       "Recall          0.749643  0.022551\n",
       "Roc_auc         0.752985  0.015938"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Model2\n",
    "Model2=Model_results(clf,X,y,Cv_model)\n",
    "Model2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "c06b82a5-a8ce-4b80-b011-d93c0ab3a6cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th>Method</th>\n",
       "      <th colspan=\"4\" halign=\"left\">RF</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model</th>\n",
       "      <th colspan=\"2\" halign=\"left\">Model 1</th>\n",
       "      <th colspan=\"2\" halign=\"left\">Model 2</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Values</th>\n",
       "      <th>Mean</th>\n",
       "      <th>Se</th>\n",
       "      <th>Mean</th>\n",
       "      <th>Se</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Accuracy_test</th>\n",
       "      <td>0.676381</td>\n",
       "      <td>0.014691</td>\n",
       "      <td>0.670571</td>\n",
       "      <td>0.013460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Accuracy_train</th>\n",
       "      <td>0.978164</td>\n",
       "      <td>0.001539</td>\n",
       "      <td>0.974643</td>\n",
       "      <td>0.001874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1 Score</th>\n",
       "      <td>0.711877</td>\n",
       "      <td>0.013423</td>\n",
       "      <td>0.703054</td>\n",
       "      <td>0.013994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Precision</th>\n",
       "      <td>0.688878</td>\n",
       "      <td>0.014746</td>\n",
       "      <td>0.681364</td>\n",
       "      <td>0.014131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recall</th>\n",
       "      <td>0.757857</td>\n",
       "      <td>0.020561</td>\n",
       "      <td>0.749643</td>\n",
       "      <td>0.022551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Roc_auc</th>\n",
       "      <td>0.756424</td>\n",
       "      <td>0.017012</td>\n",
       "      <td>0.752985</td>\n",
       "      <td>0.015938</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Method                RF                              \n",
       "Model            Model 1             Model 2          \n",
       "Values              Mean        Se      Mean        Se\n",
       "Accuracy_test   0.676381  0.014691  0.670571  0.013460\n",
       "Accuracy_train  0.978164  0.001539  0.974643  0.001874\n",
       "F1 Score        0.711877  0.013423  0.703054  0.013994\n",
       "Precision       0.688878  0.014746  0.681364  0.014131\n",
       "Recall          0.757857  0.020561  0.749643  0.022551\n",
       "Roc_auc         0.756424  0.017012  0.752985  0.015938"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Saving the data of model performance\n",
    "Model_data=pd.concat([Model1,Model2],axis=1)\n",
    "Model_data.columns = [['RF']*4,['Model 1','Model 1', 'Model 2','Model 2'], ['Mean', 'Se', 'Mean', 'Se']]  \n",
    "Model_data.columns.names=['Method','Model','Values']\n",
    "Model_data.to_csv(\"./Results/RF_model_mlrem_data.csv\",sep=',')\n",
    "Model_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de27d5ec-8039-4cfd-8629-ad30d87ca90f",
   "metadata": {},
   "source": [
    "## 2.4 XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "19aa8297-4182-4dac-8857-008a9ad45f1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf=xgb.XGBClassifier(random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "66336653-640b-407f-8c25-80c9e29b3651",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mean</th>\n",
       "      <th>Se</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Accuracy_test</th>\n",
       "      <td>0.662476</td>\n",
       "      <td>0.016918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Accuracy_train</th>\n",
       "      <td>0.978164</td>\n",
       "      <td>0.001539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1 Score</th>\n",
       "      <td>0.693483</td>\n",
       "      <td>0.017356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Precision</th>\n",
       "      <td>0.671509</td>\n",
       "      <td>0.015551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recall</th>\n",
       "      <td>0.737143</td>\n",
       "      <td>0.025112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Roc_auc</th>\n",
       "      <td>0.749660</td>\n",
       "      <td>0.017686</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Mean        Se\n",
       "Accuracy_test   0.662476  0.016918\n",
       "Accuracy_train  0.978164  0.001539\n",
       "F1 Score        0.693483  0.017356\n",
       "Precision       0.671509  0.015551\n",
       "Recall          0.737143  0.025112\n",
       "Roc_auc         0.749660  0.017686"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Model1 \n",
    "Model1_clf=clf\n",
    "#Model1\n",
    "Model1=Model_results(Model1_clf,X,y,Cv_model)\n",
    "Model1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "2184b863-0c03-4641-8e98-2b00c0fd5878",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2024-01-12 01:49:39,219]\u001b[0m A new study created in memory with name: no-name-9bfd5a88-8b2a-4996-844c-9f159bf96100\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-01-12 01:49:44,945]\u001b[0m Trial 0 finished with value: 0.6608571428571429 and parameters: {'lambda': 0.15676677195506075, 'alpha': 0.7257005721594281, 'colsample_bytree': 0.7, 'subsample': 0.7000000000000001, 'learning_rate': 0.0801, 'n_estimators': 664}. Best is trial 0 with value: 0.6608571428571429.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-01-12 01:49:47,925]\u001b[0m Trial 1 finished with value: 0.6323809523809524 and parameters: {'lambda': 0.0562793204741517, 'alpha': 3.6905577292137624, 'colsample_bytree': 1.0, 'subsample': 0.6000000000000001, 'learning_rate': 0.1551, 'n_estimators': 552}. Best is trial 0 with value: 0.6608571428571429.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-01-12 01:49:51,796]\u001b[0m Trial 2 finished with value: 0.5408571428571428 and parameters: {'lambda': 0.18714500686240676, 'alpha': 5.039489598671215, 'colsample_bytree': 0.3, 'subsample': 0.4, 'learning_rate': 0.0001, 'n_estimators': 841}. Best is trial 0 with value: 0.6608571428571429.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-01-12 01:49:56,159]\u001b[0m Trial 3 finished with value: 0.6392380952380953 and parameters: {'lambda': 1.2960656597279736, 'alpha': 3.0202896401586674, 'colsample_bytree': 1.0, 'subsample': 0.9, 'learning_rate': 0.0901, 'n_estimators': 792}. Best is trial 0 with value: 0.6608571428571429.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-01-12 01:49:59,349]\u001b[0m Trial 4 finished with value: 0.6553333333333334 and parameters: {'lambda': 0.0029723346443356552, 'alpha': 0.3628140404024381, 'colsample_bytree': 0.4, 'subsample': 1.0, 'learning_rate': 0.10010000000000001, 'n_estimators': 444}. Best is trial 0 with value: 0.6608571428571429.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-01-12 01:50:06,638]\u001b[0m Trial 5 finished with value: 0.638 and parameters: {'lambda': 0.011434638743472197, 'alpha': 1.2500712230836255, 'colsample_bytree': 0.6000000000000001, 'subsample': 0.7000000000000001, 'learning_rate': 0.0001, 'n_estimators': 637}. Best is trial 0 with value: 0.6608571428571429.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-01-12 01:50:10,699]\u001b[0m Trial 6 finished with value: 0.6510476190476191 and parameters: {'lambda': 0.2807908107885728, 'alpha': 0.2935864364395359, 'colsample_bytree': 1.0, 'subsample': 0.8, 'learning_rate': 0.07010000000000001, 'n_estimators': 465}. Best is trial 0 with value: 0.6608571428571429.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-01-12 01:50:12,762]\u001b[0m Trial 7 finished with value: 0.6508571428571429 and parameters: {'lambda': 0.6173405204074314, 'alpha': 0.0017414134181586202, 'colsample_bytree': 0.8, 'subsample': 0.8, 'learning_rate': 0.040100000000000004, 'n_estimators': 172}. Best is trial 0 with value: 0.6608571428571429.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-01-12 01:50:13,989]\u001b[0m Trial 8 finished with value: 0.6779047619047618 and parameters: {'lambda': 0.01826894228153233, 'alpha': 0.028499883436971588, 'colsample_bytree': 0.7, 'subsample': 0.7000000000000001, 'learning_rate': 0.1951, 'n_estimators': 147}. Best is trial 8 with value: 0.6779047619047618.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-01-12 01:50:16,120]\u001b[0m Trial 9 finished with value: 0.667904761904762 and parameters: {'lambda': 0.006847105576684045, 'alpha': 0.004418125737902547, 'colsample_bytree': 0.8, 'subsample': 0.5, 'learning_rate': 0.0901, 'n_estimators': 282}. Best is trial 8 with value: 0.6779047619047618.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-01-12 01:50:16,755]\u001b[0m Trial 10 finished with value: 0.6451428571428572 and parameters: {'lambda': 5.790132527437195, 'alpha': 0.025043968115100592, 'colsample_bytree': 0.5, 'subsample': 0.5, 'learning_rate': 0.1901, 'n_estimators': 57}. Best is trial 8 with value: 0.6779047619047618.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-01-12 01:50:18,686]\u001b[0m Trial 11 finished with value: 0.6690476190476192 and parameters: {'lambda': 0.017123553109627314, 'alpha': 0.013676263870483537, 'colsample_bytree': 0.8, 'subsample': 0.5, 'learning_rate': 0.14509999999999998, 'n_estimators': 277}. Best is trial 8 with value: 0.6779047619047618.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-01-12 01:50:20,734]\u001b[0m Trial 12 finished with value: 0.6763809523809523 and parameters: {'lambda': 0.02491353701899208, 'alpha': 0.023063141329483616, 'colsample_bytree': 0.8, 'subsample': 0.4, 'learning_rate': 0.15009999999999998, 'n_estimators': 319}. Best is trial 8 with value: 0.6779047619047618.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-01-12 01:50:22,688]\u001b[0m Trial 13 finished with value: 0.662 and parameters: {'lambda': 0.04474111800996658, 'alpha': 0.038990832725213885, 'colsample_bytree': 0.6000000000000001, 'subsample': 0.4, 'learning_rate': 0.1951, 'n_estimators': 316}. Best is trial 8 with value: 0.6779047619047618.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-01-12 01:50:23,622]\u001b[0m Trial 14 finished with value: 0.6509523809523808 and parameters: {'lambda': 0.0012140452982167488, 'alpha': 0.06910620324453418, 'colsample_bytree': 0.7, 'subsample': 0.6000000000000001, 'learning_rate': 0.1551, 'n_estimators': 94}. Best is trial 8 with value: 0.6779047619047618.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-01-12 01:50:25,465]\u001b[0m Trial 15 finished with value: 0.6680000000000001 and parameters: {'lambda': 0.027126643489253296, 'alpha': 0.0045017087887461935, 'colsample_bytree': 0.9000000000000001, 'subsample': 1.0, 'learning_rate': 0.1301, 'n_estimators': 204}. Best is trial 8 with value: 0.6779047619047618.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-01-12 01:50:27,896]\u001b[0m Trial 16 finished with value: 0.6703809523809525 and parameters: {'lambda': 0.004818440651909064, 'alpha': 0.16888877355169551, 'colsample_bytree': 0.5, 'subsample': 0.6000000000000001, 'learning_rate': 0.1751, 'n_estimators': 358}. Best is trial 8 with value: 0.6779047619047618.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-01-12 01:50:29,534]\u001b[0m Trial 17 finished with value: 0.6649523809523811 and parameters: {'lambda': 0.0010007385532741818, 'alpha': 0.009646273191219181, 'colsample_bytree': 0.9000000000000001, 'subsample': 0.8, 'learning_rate': 0.1201, 'n_estimators': 181}. Best is trial 8 with value: 0.6779047619047618.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-01-12 01:50:31,793]\u001b[0m Trial 18 finished with value: 0.6763809523809524 and parameters: {'lambda': 0.061634227943790754, 'alpha': 0.07305295568841107, 'colsample_bytree': 0.7, 'subsample': 0.4, 'learning_rate': 0.1701, 'n_estimators': 367}. Best is trial 8 with value: 0.6779047619047618.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-01-12 01:50:36,908]\u001b[0m Trial 19 finished with value: 0.6748571428571429 and parameters: {'lambda': 0.08189216606299816, 'alpha': 0.09137793328553549, 'colsample_bytree': 0.5, 'subsample': 0.6000000000000001, 'learning_rate': 0.1751, 'n_estimators': 930}. Best is trial 8 with value: 0.6779047619047618.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-01-12 01:50:40,298]\u001b[0m Trial 20 finished with value: 0.6764761904761906 and parameters: {'lambda': 1.6767154928982846, 'alpha': 0.0016483661900255071, 'colsample_bytree': 0.7, 'subsample': 0.9, 'learning_rate': 0.1751, 'n_estimators': 429}. Best is trial 8 with value: 0.6779047619047618.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-01-12 01:50:44,316]\u001b[0m Trial 21 finished with value: 0.6525714285714286 and parameters: {'lambda': 7.401604059812908, 'alpha': 0.0010968075467978052, 'colsample_bytree': 0.7, 'subsample': 0.9, 'learning_rate': 0.18009999999999998, 'n_estimators': 421}. Best is trial 8 with value: 0.6779047619047618.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-01-12 01:50:48,618]\u001b[0m Trial 22 finished with value: 0.6694285714285715 and parameters: {'lambda': 2.0928422583512405, 'alpha': 0.0036652235601470915, 'colsample_bytree': 0.6000000000000001, 'subsample': 0.9, 'learning_rate': 0.1701, 'n_estimators': 558}. Best is trial 8 with value: 0.6779047619047618.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-01-12 01:50:51,373]\u001b[0m Trial 23 finished with value: 0.6751428571428572 and parameters: {'lambda': 0.6439279076937869, 'alpha': 0.04386602055339343, 'colsample_bytree': 0.7, 'subsample': 0.7000000000000001, 'learning_rate': 0.1951, 'n_estimators': 391}. Best is trial 8 with value: 0.6779047619047618.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-01-12 01:50:54,900]\u001b[0m Trial 24 finished with value: 0.6764761904761905 and parameters: {'lambda': 0.3883136303907193, 'alpha': 0.010049953917114773, 'colsample_bytree': 0.6000000000000001, 'subsample': 0.8, 'learning_rate': 0.1301, 'n_estimators': 496}. Best is trial 8 with value: 0.6779047619047618.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-01-12 01:50:59,980]\u001b[0m Trial 25 finished with value: 0.6653333333333333 and parameters: {'lambda': 2.7802503139996473, 'alpha': 0.008337657822509066, 'colsample_bytree': 0.6000000000000001, 'subsample': 0.8, 'learning_rate': 0.1301, 'n_estimators': 656}. Best is trial 8 with value: 0.6779047619047618.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-01-12 01:51:05,250]\u001b[0m Trial 26 finished with value: 0.6790476190476192 and parameters: {'lambda': 0.5989769734564016, 'alpha': 0.001754204354028918, 'colsample_bytree': 0.4, 'subsample': 0.9, 'learning_rate': 0.11510000000000001, 'n_estimators': 725}. Best is trial 26 with value: 0.6790476190476192.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-01-12 01:51:12,244]\u001b[0m Trial 27 finished with value: 0.6693333333333336 and parameters: {'lambda': 1.2518838419016274, 'alpha': 0.002084110757581769, 'colsample_bytree': 0.4, 'subsample': 0.9, 'learning_rate': 0.0451, 'n_estimators': 779}. Best is trial 26 with value: 0.6790476190476192.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-01-12 01:51:21,465]\u001b[0m Trial 28 finished with value: 0.6609523809523811 and parameters: {'lambda': 4.723187635059192, 'alpha': 0.002467585771750723, 'colsample_bytree': 0.3, 'subsample': 1.0, 'learning_rate': 0.050100000000000006, 'n_estimators': 916}. Best is trial 26 with value: 0.6790476190476192.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-01-12 01:51:26,158]\u001b[0m Trial 29 finished with value: 0.6861904761904764 and parameters: {'lambda': 0.1357530766063751, 'alpha': 0.00604912334356112, 'colsample_bytree': 0.4, 'subsample': 0.7000000000000001, 'learning_rate': 0.11510000000000001, 'n_estimators': 740}. Best is trial 29 with value: 0.6861904761904764.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-01-12 01:51:30,752]\u001b[0m Trial 30 finished with value: 0.6750476190476192 and parameters: {'lambda': 0.18092199214591256, 'alpha': 0.0010057216538091605, 'colsample_bytree': 0.4, 'subsample': 0.7000000000000001, 'learning_rate': 0.1101, 'n_estimators': 709}. Best is trial 29 with value: 0.6861904761904764.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-01-12 01:51:35,311]\u001b[0m Trial 31 finished with value: 0.6751428571428572 and parameters: {'lambda': 0.11119277519798368, 'alpha': 0.006118149756823851, 'colsample_bytree': 0.5, 'subsample': 0.7000000000000001, 'learning_rate': 0.11510000000000001, 'n_estimators': 723}. Best is trial 29 with value: 0.6861904761904764.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-01-12 01:51:40,257]\u001b[0m Trial 32 finished with value: 0.6821904761904765 and parameters: {'lambda': 0.6301118583785598, 'alpha': 0.01900920382279658, 'colsample_bytree': 0.4, 'subsample': 0.9, 'learning_rate': 0.0651, 'n_estimators': 591}. Best is trial 29 with value: 0.6861904761904764.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-01-12 01:51:45,058]\u001b[0m Trial 33 finished with value: 0.6763809523809524 and parameters: {'lambda': 0.6999320996994477, 'alpha': 0.016156842125445648, 'colsample_bytree': 0.3, 'subsample': 0.7000000000000001, 'learning_rate': 0.0601, 'n_estimators': 588}. Best is trial 29 with value: 0.6861904761904764.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-01-12 01:51:52,041]\u001b[0m Trial 34 finished with value: 0.674952380952381 and parameters: {'lambda': 0.3527627967271589, 'alpha': 0.030241715405447074, 'colsample_bytree': 0.4, 'subsample': 0.8, 'learning_rate': 0.0751, 'n_estimators': 991}. Best is trial 29 with value: 0.6861904761904764.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-01-12 01:51:59,408]\u001b[0m Trial 35 finished with value: 0.6609523809523811 and parameters: {'lambda': 0.14364941444825624, 'alpha': 0.017627889213148507, 'colsample_bytree': 0.3, 'subsample': 0.6000000000000001, 'learning_rate': 0.0201, 'n_estimators': 836}. Best is trial 29 with value: 0.6861904761904764.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-01-12 01:52:04,321]\u001b[0m Trial 36 finished with value: 0.6680000000000001 and parameters: {'lambda': 1.0360787933743876, 'alpha': 0.006610100039382611, 'colsample_bytree': 0.4, 'subsample': 1.0, 'learning_rate': 0.10010000000000001, 'n_estimators': 590}. Best is trial 29 with value: 0.6861904761904764.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-01-12 01:52:07,614]\u001b[0m Trial 37 finished with value: 0.5927619047619048 and parameters: {'lambda': 0.24008342239429287, 'alpha': 8.861629685772453, 'colsample_bytree': 0.5, 'subsample': 0.7000000000000001, 'learning_rate': 0.08510000000000001, 'n_estimators': 730}. Best is trial 29 with value: 0.6861904761904764.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-01-12 01:52:14,227]\u001b[0m Trial 38 finished with value: 0.6707619047619049 and parameters: {'lambda': 0.037769804089962805, 'alpha': 0.17532934883981124, 'colsample_bytree': 0.4, 'subsample': 0.9, 'learning_rate': 0.0201, 'n_estimators': 622}. Best is trial 29 with value: 0.6861904761904764.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-01-12 01:52:17,939]\u001b[0m Trial 39 finished with value: 0.677904761904762 and parameters: {'lambda': 0.08654988469845346, 'alpha': 0.0033305961239733462, 'colsample_bytree': 0.3, 'subsample': 0.8, 'learning_rate': 0.1401, 'n_estimators': 535}. Best is trial 29 with value: 0.6861904761904764.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-01-12 01:52:22,157]\u001b[0m Trial 40 finished with value: 0.667904761904762 and parameters: {'lambda': 0.4364559577785702, 'alpha': 0.002986127875870649, 'colsample_bytree': 0.3, 'subsample': 0.8, 'learning_rate': 0.1051, 'n_estimators': 529}. Best is trial 29 with value: 0.6861904761904764.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-01-12 01:52:26,780]\u001b[0m Trial 41 finished with value: 0.6820952380952382 and parameters: {'lambda': 0.012041246302698917, 'alpha': 0.005755556753698326, 'colsample_bytree': 0.3, 'subsample': 0.9, 'learning_rate': 0.1401, 'n_estimators': 679}. Best is trial 29 with value: 0.6861904761904764.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-01-12 01:52:30,094]\u001b[0m Trial 42 finished with value: 0.6821904761904761 and parameters: {'lambda': 0.00976530253589791, 'alpha': 0.004521658633426094, 'colsample_bytree': 0.3, 'subsample': 0.9, 'learning_rate': 0.1401, 'n_estimators': 692}. Best is trial 29 with value: 0.6861904761904764.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-01-12 01:52:31,968]\u001b[0m Trial 43 finished with value: 0.6820952380952382 and parameters: {'lambda': 0.009533938648370993, 'alpha': 0.005142380479852608, 'colsample_bytree': 0.4, 'subsample': 0.9, 'learning_rate': 0.1201, 'n_estimators': 779}. Best is trial 29 with value: 0.6861904761904764.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-01-12 01:52:34,015]\u001b[0m Trial 44 finished with value: 0.701714285714286 and parameters: {'lambda': 0.008556178294461857, 'alpha': 0.00559859295117001, 'colsample_bytree': 0.3, 'subsample': 1.0, 'learning_rate': 0.1601, 'n_estimators': 792}. Best is trial 44 with value: 0.701714285714286.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-01-12 01:52:35,874]\u001b[0m Trial 45 finished with value: 0.7003809523809525 and parameters: {'lambda': 0.002736395942107596, 'alpha': 0.010967284413723879, 'colsample_bytree': 0.3, 'subsample': 1.0, 'learning_rate': 0.1601, 'n_estimators': 687}. Best is trial 44 with value: 0.701714285714286.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-01-12 01:52:38,163]\u001b[0m Trial 46 finished with value: 0.6960952380952382 and parameters: {'lambda': 0.0028166231869091456, 'alpha': 0.009994188044722196, 'colsample_bytree': 0.3, 'subsample': 1.0, 'learning_rate': 0.1651, 'n_estimators': 830}. Best is trial 44 with value: 0.701714285714286.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-01-12 01:52:40,457]\u001b[0m Trial 47 finished with value: 0.6947619047619049 and parameters: {'lambda': 0.0019027548784550043, 'alpha': 0.012393652417147363, 'colsample_bytree': 0.3, 'subsample': 1.0, 'learning_rate': 0.0651, 'n_estimators': 836}. Best is trial 44 with value: 0.701714285714286.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-01-12 01:52:42,704]\u001b[0m Trial 48 finished with value: 0.6960952380952381 and parameters: {'lambda': 0.0024183815673537484, 'alpha': 0.011729643522042612, 'colsample_bytree': 0.3, 'subsample': 1.0, 'learning_rate': 0.1851, 'n_estimators': 846}. Best is trial 44 with value: 0.701714285714286.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-01-12 01:52:44,291]\u001b[0m Trial 49 finished with value: 0.6551428571428572 and parameters: {'lambda': 0.0019408046467350051, 'alpha': 1.0433113847404174, 'colsample_bytree': 0.3, 'subsample': 1.0, 'learning_rate': 0.1851, 'n_estimators': 854}. Best is trial 44 with value: 0.701714285714286.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-01-12 01:52:46,542]\u001b[0m Trial 50 finished with value: 0.7002857142857144 and parameters: {'lambda': 0.0033591891295767654, 'alpha': 0.01382541664678391, 'colsample_bytree': 0.3, 'subsample': 1.0, 'learning_rate': 0.1601, 'n_estimators': 874}. Best is trial 44 with value: 0.701714285714286.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-01-12 01:52:48,705]\u001b[0m Trial 51 finished with value: 0.7017142857142857 and parameters: {'lambda': 0.0034229051056133657, 'alpha': 0.012871271791450633, 'colsample_bytree': 0.3, 'subsample': 1.0, 'learning_rate': 0.1601, 'n_estimators': 866}. Best is trial 44 with value: 0.701714285714286.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-01-12 01:52:51,053]\u001b[0m Trial 52 finished with value: 0.7001904761904763 and parameters: {'lambda': 0.004225220871455537, 'alpha': 0.011370294688030805, 'colsample_bytree': 0.3, 'subsample': 1.0, 'learning_rate': 0.1601, 'n_estimators': 890}. Best is trial 44 with value: 0.701714285714286.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-01-12 01:52:53,527]\u001b[0m Trial 53 finished with value: 0.6960000000000002 and parameters: {'lambda': 0.004103597114144333, 'alpha': 0.04967022533268807, 'colsample_bytree': 0.3, 'subsample': 1.0, 'learning_rate': 0.1601, 'n_estimators': 920}. Best is trial 44 with value: 0.701714285714286.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-01-12 01:52:55,907]\u001b[0m Trial 54 finished with value: 0.7031428571428572 and parameters: {'lambda': 0.004043834319918063, 'alpha': 0.029633425764158693, 'colsample_bytree': 0.3, 'subsample': 1.0, 'learning_rate': 0.1601, 'n_estimators': 894}. Best is trial 54 with value: 0.7031428571428572.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-01-12 01:52:58,610]\u001b[0m Trial 55 finished with value: 0.6975238095238098 and parameters: {'lambda': 0.004980224075064425, 'alpha': 0.03510787695470061, 'colsample_bytree': 0.3, 'subsample': 1.0, 'learning_rate': 0.1551, 'n_estimators': 995}. Best is trial 54 with value: 0.7031428571428572.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-01-12 01:53:00,935]\u001b[0m Trial 56 finished with value: 0.7102857142857144 and parameters: {'lambda': 0.0013221304985698086, 'alpha': 0.02305461805888264, 'colsample_bytree': 0.3, 'subsample': 1.0, 'learning_rate': 0.15009999999999998, 'n_estimators': 884}. Best is trial 56 with value: 0.7102857142857144.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-01-12 01:53:03,490]\u001b[0m Trial 57 finished with value: 0.6793333333333333 and parameters: {'lambda': 0.0012446922418356734, 'alpha': 0.022077479688830965, 'colsample_bytree': 0.4, 'subsample': 1.0, 'learning_rate': 0.15009999999999998, 'n_estimators': 962}. Best is trial 56 with value: 0.7102857142857144.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-01-12 01:53:05,883]\u001b[0m Trial 58 finished with value: 0.6791428571428573 and parameters: {'lambda': 0.006622004577595627, 'alpha': 0.1431496104944084, 'colsample_bytree': 0.3, 'subsample': 1.0, 'learning_rate': 0.1651, 'n_estimators': 885}. Best is trial 56 with value: 0.7102857142857144.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-01-12 01:53:08,000]\u001b[0m Trial 59 finished with value: 0.6751428571428572 and parameters: {'lambda': 0.0014168536815106854, 'alpha': 0.02621704841078774, 'colsample_bytree': 0.5, 'subsample': 1.0, 'learning_rate': 0.15009999999999998, 'n_estimators': 803}. Best is trial 56 with value: 0.7102857142857144.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-01-12 01:53:10,527]\u001b[0m Trial 60 finished with value: 0.677904761904762 and parameters: {'lambda': 0.003453061915516729, 'alpha': 0.06591221885128822, 'colsample_bytree': 0.4, 'subsample': 1.0, 'learning_rate': 0.1701, 'n_estimators': 955}. Best is trial 56 with value: 0.7102857142857144.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-01-12 01:53:12,750]\u001b[0m Trial 61 finished with value: 0.6932380952380953 and parameters: {'lambda': 0.006241233717411143, 'alpha': 0.008377211507259008, 'colsample_bytree': 0.3, 'subsample': 1.0, 'learning_rate': 0.1601, 'n_estimators': 885}. Best is trial 56 with value: 0.7102857142857144.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-01-12 01:53:15,123]\u001b[0m Trial 62 finished with value: 0.7001904761904763 and parameters: {'lambda': 0.00199673319822298, 'alpha': 0.01284143905578283, 'colsample_bytree': 0.3, 'subsample': 1.0, 'learning_rate': 0.1601, 'n_estimators': 875}. Best is trial 56 with value: 0.7102857142857144.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-01-12 01:53:17,298]\u001b[0m Trial 63 finished with value: 0.6935238095238097 and parameters: {'lambda': 0.0018104838952691495, 'alpha': 0.014581416070468362, 'colsample_bytree': 0.3, 'subsample': 1.0, 'learning_rate': 0.18009999999999998, 'n_estimators': 804}. Best is trial 56 with value: 0.7102857142857144.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-01-12 01:53:19,428]\u001b[0m Trial 64 finished with value: 0.7004761904761907 and parameters: {'lambda': 0.0024756254478756406, 'alpha': 0.052568127938742146, 'colsample_bytree': 0.3, 'subsample': 1.0, 'learning_rate': 0.14509999999999998, 'n_estimators': 764}. Best is trial 56 with value: 0.7102857142857144.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-01-12 01:53:21,329]\u001b[0m Trial 65 finished with value: 0.6792380952380952 and parameters: {'lambda': 0.0028689485895962183, 'alpha': 0.04629073394230276, 'colsample_bytree': 0.9000000000000001, 'subsample': 0.9, 'learning_rate': 0.1351, 'n_estimators': 765}. Best is trial 56 with value: 0.7102857142857144.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-01-12 01:53:22,970]\u001b[0m Trial 66 finished with value: 0.6595238095238096 and parameters: {'lambda': 0.001014578900194637, 'alpha': 0.36043897298369987, 'colsample_bytree': 0.4, 'subsample': 1.0, 'learning_rate': 0.14509999999999998, 'n_estimators': 761}. Best is trial 56 with value: 0.7102857142857144.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-01-12 01:53:25,064]\u001b[0m Trial 67 finished with value: 0.6751428571428572 and parameters: {'lambda': 0.01737522874540943, 'alpha': 0.05780931059819181, 'colsample_bytree': 1.0, 'subsample': 0.9, 'learning_rate': 0.15009999999999998, 'n_estimators': 815}. Best is trial 56 with value: 0.7102857142857144.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-01-12 01:53:27,445]\u001b[0m Trial 68 finished with value: 0.6863809523809524 and parameters: {'lambda': 0.0015222664201042758, 'alpha': 0.11020953113272494, 'colsample_bytree': 0.3, 'subsample': 1.0, 'learning_rate': 0.1301, 'n_estimators': 936}. Best is trial 56 with value: 0.7102857142857144.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-01-12 01:53:29,694]\u001b[0m Trial 69 finished with value: 0.6778095238095238 and parameters: {'lambda': 0.003426341240967464, 'alpha': 0.03256146187092011, 'colsample_bytree': 0.4, 'subsample': 1.0, 'learning_rate': 0.1751, 'n_estimators': 866}. Best is trial 56 with value: 0.7102857142857144.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-01-12 01:53:31,832]\u001b[0m Trial 70 finished with value: 0.6820952380952382 and parameters: {'lambda': 0.005384501751833538, 'alpha': 0.022922639033061288, 'colsample_bytree': 0.4, 'subsample': 0.9, 'learning_rate': 0.14509999999999998, 'n_estimators': 905}. Best is trial 56 with value: 0.7102857142857144.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-01-12 01:53:34,361]\u001b[0m Trial 71 finished with value: 0.6932380952380954 and parameters: {'lambda': 0.0038325905699101567, 'alpha': 0.02051598231771764, 'colsample_bytree': 0.3, 'subsample': 1.0, 'learning_rate': 0.1651, 'n_estimators': 965}. Best is trial 56 with value: 0.7102857142857144.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-01-12 01:53:36,703]\u001b[0m Trial 72 finished with value: 0.7002857142857144 and parameters: {'lambda': 0.0024577069483295065, 'alpha': 0.007109582478627625, 'colsample_bytree': 0.3, 'subsample': 1.0, 'learning_rate': 0.1551, 'n_estimators': 896}. Best is trial 56 with value: 0.7102857142857144.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-01-12 01:53:38,713]\u001b[0m Trial 73 finished with value: 0.6973333333333335 and parameters: {'lambda': 0.0024282570038449054, 'alpha': 0.08294927790166803, 'colsample_bytree': 0.3, 'subsample': 1.0, 'learning_rate': 0.1551, 'n_estimators': 752}. Best is trial 56 with value: 0.7102857142857144.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-01-12 01:53:40,765]\u001b[0m Trial 74 finished with value: 0.6973333333333335 and parameters: {'lambda': 0.008296731719590096, 'alpha': 0.0073542298983549645, 'colsample_bytree': 0.3, 'subsample': 1.0, 'learning_rate': 0.1701, 'n_estimators': 787}. Best is trial 56 with value: 0.7102857142857144.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-01-12 01:53:42,888]\u001b[0m Trial 75 finished with value: 0.678952380952381 and parameters: {'lambda': 0.013459544298683093, 'alpha': 0.01606555197132388, 'colsample_bytree': 0.3, 'subsample': 0.5, 'learning_rate': 0.1251, 'n_estimators': 938}. Best is trial 56 with value: 0.7102857142857144.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-01-12 01:53:45,243]\u001b[0m Trial 76 finished with value: 0.6835238095238096 and parameters: {'lambda': 0.002432929541319386, 'alpha': 0.03867844669314933, 'colsample_bytree': 0.4, 'subsample': 1.0, 'learning_rate': 0.1551, 'n_estimators': 905}. Best is trial 56 with value: 0.7102857142857144.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-01-12 01:53:46,786]\u001b[0m Trial 77 finished with value: 0.6908571428571428 and parameters: {'lambda': 0.0014775448337385007, 'alpha': 0.008379965030471833, 'colsample_bytree': 0.3, 'subsample': 0.9, 'learning_rate': 0.1901, 'n_estimators': 647}. Best is trial 56 with value: 0.7102857142857144.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-01-12 01:53:48,713]\u001b[0m Trial 78 finished with value: 0.6807619047619049 and parameters: {'lambda': 0.006701372418938602, 'alpha': 0.004045620666985065, 'colsample_bytree': 0.4, 'subsample': 0.9, 'learning_rate': 0.14509999999999998, 'n_estimators': 820}. Best is trial 56 with value: 0.7102857142857144.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-01-12 01:53:50,849]\u001b[0m Trial 79 finished with value: 0.6876190476190479 and parameters: {'lambda': 0.003127746609011728, 'alpha': 0.025715495289677936, 'colsample_bytree': 0.3, 'subsample': 1.0, 'learning_rate': 0.18009999999999998, 'n_estimators': 858}. Best is trial 56 with value: 0.7102857142857144.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-01-12 01:53:52,896]\u001b[0m Trial 80 finished with value: 0.6960952380952383 and parameters: {'lambda': 0.0011720575701298413, 'alpha': 0.016807260672059614, 'colsample_bytree': 0.3, 'subsample': 1.0, 'learning_rate': 0.1651, 'n_estimators': 797}. Best is trial 56 with value: 0.7102857142857144.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-01-12 01:53:55,044]\u001b[0m Trial 81 finished with value: 0.7044761904761907 and parameters: {'lambda': 0.0020203854446397642, 'alpha': 0.013357193776383159, 'colsample_bytree': 0.3, 'subsample': 1.0, 'learning_rate': 0.1601, 'n_estimators': 877}. Best is trial 56 with value: 0.7102857142857144.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-01-12 01:53:57,400]\u001b[0m Trial 82 finished with value: 0.698857142857143 and parameters: {'lambda': 0.005019268124724571, 'alpha': 0.009246692653937827, 'colsample_bytree': 0.3, 'subsample': 1.0, 'learning_rate': 0.1701, 'n_estimators': 903}. Best is trial 56 with value: 0.7102857142857144.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-01-12 01:53:59,710]\u001b[0m Trial 83 finished with value: 0.6962857142857143 and parameters: {'lambda': 0.002471192899337615, 'alpha': 0.014195787739054177, 'colsample_bytree': 0.3, 'subsample': 1.0, 'learning_rate': 0.1351, 'n_estimators': 863}. Best is trial 56 with value: 0.7102857142857144.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-01-12 01:54:01,031]\u001b[0m Trial 84 finished with value: 0.6265714285714286 and parameters: {'lambda': 0.0020518609785551635, 'alpha': 2.3474089145676693, 'colsample_bytree': 0.3, 'subsample': 1.0, 'learning_rate': 0.1551, 'n_estimators': 709}. Best is trial 56 with value: 0.7102857142857144.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-01-12 01:54:03,502]\u001b[0m Trial 85 finished with value: 0.6877142857142857 and parameters: {'lambda': 0.0016715687766010845, 'alpha': 0.007252154293450322, 'colsample_bytree': 0.4, 'subsample': 1.0, 'learning_rate': 0.1401, 'n_estimators': 973}. Best is trial 56 with value: 0.7102857142857144.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-01-12 01:54:05,680]\u001b[0m Trial 86 finished with value: 0.6807619047619048 and parameters: {'lambda': 0.004042017054172613, 'alpha': 0.019549267963618795, 'colsample_bytree': 0.3, 'subsample': 0.9, 'learning_rate': 0.15009999999999998, 'n_estimators': 938}. Best is trial 56 with value: 0.7102857142857144.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-01-12 01:54:07,852]\u001b[0m Trial 87 finished with value: 0.7031428571428572 and parameters: {'lambda': 0.023473634497896897, 'alpha': 0.005636601005747783, 'colsample_bytree': 0.3, 'subsample': 1.0, 'learning_rate': 0.1601, 'n_estimators': 848}. Best is trial 56 with value: 0.7102857142857144.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-01-12 01:54:10,073]\u001b[0m Trial 88 finished with value: 0.6862857142857144 and parameters: {'lambda': 0.03357853084274716, 'alpha': 0.004764047018815245, 'colsample_bytree': 0.4, 'subsample': 1.0, 'learning_rate': 0.1751, 'n_estimators': 843}. Best is trial 56 with value: 0.7102857142857144.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-01-12 01:54:12,340]\u001b[0m Trial 89 finished with value: 0.7031428571428572 and parameters: {'lambda': 0.00851847070190272, 'alpha': 0.010913691529586302, 'colsample_bytree': 0.3, 'subsample': 1.0, 'learning_rate': 0.1651, 'n_estimators': 816}. Best is trial 56 with value: 0.7102857142857144.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-01-12 01:54:14,158]\u001b[0m Trial 90 finished with value: 0.6907619047619049 and parameters: {'lambda': 0.026298523095546197, 'alpha': 0.002337637077580732, 'colsample_bytree': 0.3, 'subsample': 0.9, 'learning_rate': 0.18009999999999998, 'n_estimators': 767}. Best is trial 56 with value: 0.7102857142857144.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-01-12 01:54:16,189]\u001b[0m Trial 91 finished with value: 0.6889523809523811 and parameters: {'lambda': 0.007679646889123362, 'alpha': 0.003095610150491639, 'colsample_bytree': 0.3, 'subsample': 1.0, 'learning_rate': 0.1651, 'n_estimators': 817}. Best is trial 56 with value: 0.7102857142857144.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-01-12 01:54:18,346]\u001b[0m Trial 92 finished with value: 0.698857142857143 and parameters: {'lambda': 0.019627147648464925, 'alpha': 0.010308846754474606, 'colsample_bytree': 0.3, 'subsample': 1.0, 'learning_rate': 0.14509999999999998, 'n_estimators': 789}. Best is trial 56 with value: 0.7102857142857144.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-01-12 01:54:20,399]\u001b[0m Trial 93 finished with value: 0.6989523809523811 and parameters: {'lambda': 0.012104952676441646, 'alpha': 0.03039331547668624, 'colsample_bytree': 0.3, 'subsample': 1.0, 'learning_rate': 0.1601, 'n_estimators': 742}. Best is trial 56 with value: 0.7102857142857144.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-01-12 01:54:21,764]\u001b[0m Trial 94 finished with value: 0.7060000000000001 and parameters: {'lambda': 0.005758744911796952, 'alpha': 0.00592458636159379, 'colsample_bytree': 0.3, 'subsample': 1.0, 'learning_rate': 0.1551, 'n_estimators': 489}. Best is trial 56 with value: 0.7102857142857144.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-01-12 01:54:23,361]\u001b[0m Trial 95 finished with value: 0.7003809523809525 and parameters: {'lambda': 0.05944768953566761, 'alpha': 0.00537721962184014, 'colsample_bytree': 0.3, 'subsample': 1.0, 'learning_rate': 0.15009999999999998, 'n_estimators': 559}. Best is trial 56 with value: 0.7102857142857144.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-01-12 01:54:24,709]\u001b[0m Trial 96 finished with value: 0.6947619047619048 and parameters: {'lambda': 0.04615810486191638, 'alpha': 0.005041871944751029, 'colsample_bytree': 0.3, 'subsample': 1.0, 'learning_rate': 0.15009999999999998, 'n_estimators': 482}. Best is trial 56 with value: 0.7102857142857144.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-01-12 01:54:25,993]\u001b[0m Trial 97 finished with value: 0.6821904761904762 and parameters: {'lambda': 0.009891164357898056, 'alpha': 0.0036417886687594215, 'colsample_bytree': 0.4, 'subsample': 1.0, 'learning_rate': 0.1701, 'n_estimators': 462}. Best is trial 56 with value: 0.7102857142857144.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-01-12 01:54:28,093]\u001b[0m Trial 98 finished with value: 0.6793333333333336 and parameters: {'lambda': 0.07346609827384647, 'alpha': 0.0017648041937854684, 'colsample_bytree': 0.3, 'subsample': 0.9, 'learning_rate': 0.1351, 'n_estimators': 557}. Best is trial 56 with value: 0.7102857142857144.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-01-12 01:54:32,881]\u001b[0m Trial 99 finished with value: 0.6862857142857142 and parameters: {'lambda': 0.005843712147701568, 'alpha': 0.010227730927162207, 'colsample_bytree': 0.4, 'subsample': 1.0, 'learning_rate': 0.1651, 'n_estimators': 681}. Best is trial 56 with value: 0.7102857142857144.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "#Tuning hyperparameters\n",
    "#Step 1. Define an objective function to be maximized.\n",
    "def objective(trial):\n",
    "    param = {\n",
    "        'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
    "        'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
    "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.3,1.0,step=0.1),\n",
    "        'subsample': trial.suggest_float('subsample', 0.4, 1.0, step=0.1),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.0001, 0.2, step=0.005),\n",
    "        'n_estimators': trial.suggest_int(\"n_estimators\",50,1000,1)\n",
    "        #'min_child_weight': trial.suggest_int('min_child_weight', 1, 300),\n",
    "    }\n",
    "    model = xgb.XGBClassifier(**param,random_state=1,n_jobs=8)\n",
    "\n",
    " \n",
    "# Step 2: Scoring method:\n",
    "    score = model_selection.cross_val_score(model, X, y, n_jobs=8, scoring=\"accuracy\",cv=Cv_optuna)\n",
    "    accuracy = score.mean()\n",
    "    return accuracy\n",
    "\n",
    "# Step 3: Running it\n",
    "study = optuna.create_study(direction=\"maximize\",sampler=optuna.samplers.TPESampler(seed=0))\n",
    "study.optimize(objective, n_trials=100, show_progress_bar=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "61fd4c6f-d6af-4f71-8f40-73e5cb7f1a34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best parameters are : \n",
      "{'lambda': 0.0013221304985698086, 'alpha': 0.02305461805888264, 'colsample_bytree': 0.3, 'subsample': 1.0, 'learning_rate': 0.15009999999999998, 'n_estimators': 884}\n"
     ]
    }
   ],
   "source": [
    "# Getting the best parameters:\n",
    "print(f\"The best parameters are : \\n{study.best_params}\")\n",
    "# Setting the best model\n",
    "clf=xgb.XGBClassifier(alpha = study.best_params['alpha']\n",
    "              ,colsample_bytree = study.best_params['colsample_bytree']\n",
    "              ,subsample = study.best_params['subsample']\n",
    "              ,n_estimators = study.best_params['n_estimators']\n",
    "              ,learning_rate= study.best_params['learning_rate'], n_jobs=8\n",
    "              ,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "4b5d7bd3-660b-42d3-9546-2633863cc8ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mean</th>\n",
       "      <th>Se</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Accuracy_test</th>\n",
       "      <td>0.682000</td>\n",
       "      <td>0.015467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Accuracy_train</th>\n",
       "      <td>0.978164</td>\n",
       "      <td>0.001539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1 Score</th>\n",
       "      <td>0.710276</td>\n",
       "      <td>0.015000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Precision</th>\n",
       "      <td>0.693874</td>\n",
       "      <td>0.013624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recall</th>\n",
       "      <td>0.748214</td>\n",
       "      <td>0.023279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Roc_auc</th>\n",
       "      <td>0.752117</td>\n",
       "      <td>0.018448</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Mean        Se\n",
       "Accuracy_test   0.682000  0.015467\n",
       "Accuracy_train  0.978164  0.001539\n",
       "F1 Score        0.710276  0.015000\n",
       "Precision       0.693874  0.013624\n",
       "Recall          0.748214  0.023279\n",
       "Roc_auc         0.752117  0.018448"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Model2=Model_results(clf,X,y,Cv_model)\n",
    "Model2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "a8261ab4-67a6-445c-8d21-feddad6b3796",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th>Method</th>\n",
       "      <th colspan=\"4\" halign=\"left\">XGB</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model</th>\n",
       "      <th colspan=\"2\" halign=\"left\">Model 1</th>\n",
       "      <th colspan=\"2\" halign=\"left\">Model 2</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Values</th>\n",
       "      <th>Mean</th>\n",
       "      <th>Se</th>\n",
       "      <th>Mean</th>\n",
       "      <th>Se</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Accuracy_test</th>\n",
       "      <td>0.662476</td>\n",
       "      <td>0.016918</td>\n",
       "      <td>0.682000</td>\n",
       "      <td>0.015467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Accuracy_train</th>\n",
       "      <td>0.978164</td>\n",
       "      <td>0.001539</td>\n",
       "      <td>0.978164</td>\n",
       "      <td>0.001539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1 Score</th>\n",
       "      <td>0.693483</td>\n",
       "      <td>0.017356</td>\n",
       "      <td>0.710276</td>\n",
       "      <td>0.015000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Precision</th>\n",
       "      <td>0.671509</td>\n",
       "      <td>0.015551</td>\n",
       "      <td>0.693874</td>\n",
       "      <td>0.013624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recall</th>\n",
       "      <td>0.737143</td>\n",
       "      <td>0.025112</td>\n",
       "      <td>0.748214</td>\n",
       "      <td>0.023279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Roc_auc</th>\n",
       "      <td>0.749660</td>\n",
       "      <td>0.017686</td>\n",
       "      <td>0.752117</td>\n",
       "      <td>0.018448</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Method               XGB                              \n",
       "Model            Model 1             Model 2          \n",
       "Values              Mean        Se      Mean        Se\n",
       "Accuracy_test   0.662476  0.016918  0.682000  0.015467\n",
       "Accuracy_train  0.978164  0.001539  0.978164  0.001539\n",
       "F1 Score        0.693483  0.017356  0.710276  0.015000\n",
       "Precision       0.671509  0.015551  0.693874  0.013624\n",
       "Recall          0.737143  0.025112  0.748214  0.023279\n",
       "Roc_auc         0.749660  0.017686  0.752117  0.018448"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Saving the data of model performance\n",
    "Model_data=pd.concat([Model1,Model2],axis=1)\n",
    "Model_data.columns = [['XGB']*4,['Model 1','Model 1', 'Model 2','Model 2'], ['Mean', 'Se', 'Mean', 'Se']]  \n",
    "Model_data.columns.names=['Method','Model','Values']\n",
    "Model_data.to_csv(\"./Results/XGB_model_mlrem_data.csv\",sep=',')\n",
    "Model_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec50adff-12d7-4284-a740-a33a46351d03",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hydrogel",
   "language": "python",
   "name": "hydrogel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
