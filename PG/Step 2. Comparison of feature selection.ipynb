{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "50559d19-ab40-4880-bae7-44a3dbe180a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Others\n",
    "import random\n",
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "from pandas import Series\n",
    "import numpy as np\n",
    "import math\n",
    "import os\n",
    "import warnings\n",
    "import optuna\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "70ff5d38-60c9-476d-a509-9e1419bea2b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing packages\n",
    "#Sklearn\n",
    "from sklearn import model_selection, linear_model\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.feature_selection import RFECV,SelectFromModel\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV,RandomizedSearchCV,RepeatedStratifiedKFold,cross_validate\n",
    "from sklearn.metrics import accuracy_score,precision_score,recall_score,f1_score,auc,roc_auc_score,roc_curve,classification_report\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.linear_model import Ridge, LinearRegression, Lasso\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "a6baca9e-4a5b-4e5f-9cd3-2db48c543dc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LassoCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "bc75945b-ce4f-4650-8380-f7bfb5ff1b51",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"C:/Users/A/Desktop/Bioactive/PG\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "12865361-291e-449c-8ca4-53ed95b92f16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(152, 4143)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MW</th>\n",
       "      <th>AMW</th>\n",
       "      <th>Sv</th>\n",
       "      <th>Se</th>\n",
       "      <th>Sp</th>\n",
       "      <th>Si</th>\n",
       "      <th>Mv</th>\n",
       "      <th>Me</th>\n",
       "      <th>Mp</th>\n",
       "      <th>Mi</th>\n",
       "      <th>...</th>\n",
       "      <th>s1_numAroBonds</th>\n",
       "      <th>s2_numAroBonds</th>\n",
       "      <th>s3_numAroBonds</th>\n",
       "      <th>s4_numAroBonds</th>\n",
       "      <th>s34_size</th>\n",
       "      <th>s34_relSize</th>\n",
       "      <th>s34_phSize</th>\n",
       "      <th>s34_phRelSize</th>\n",
       "      <th>chiralMoment</th>\n",
       "      <th>chiralPhMoment</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5904</th>\n",
       "      <td>334.43</td>\n",
       "      <td>8.156829</td>\n",
       "      <td>26.3035</td>\n",
       "      <td>41.6580</td>\n",
       "      <td>27.5683</td>\n",
       "      <td>46.0758</td>\n",
       "      <td>0.641549</td>\n",
       "      <td>1.016049</td>\n",
       "      <td>0.672398</td>\n",
       "      <td>1.123800</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>18.166667</td>\n",
       "      <td>0.789855</td>\n",
       "      <td>4.5</td>\n",
       "      <td>0.195652</td>\n",
       "      <td>18.311935</td>\n",
       "      <td>5.513107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155543311</th>\n",
       "      <td>697.70</td>\n",
       "      <td>9.302667</td>\n",
       "      <td>54.1818</td>\n",
       "      <td>77.2467</td>\n",
       "      <td>54.1084</td>\n",
       "      <td>84.7897</td>\n",
       "      <td>0.722424</td>\n",
       "      <td>1.029956</td>\n",
       "      <td>0.721445</td>\n",
       "      <td>1.130529</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155511868</th>\n",
       "      <td>641.64</td>\n",
       "      <td>9.299130</td>\n",
       "      <td>49.7912</td>\n",
       "      <td>71.1087</td>\n",
       "      <td>49.6196</td>\n",
       "      <td>77.6987</td>\n",
       "      <td>0.721612</td>\n",
       "      <td>1.030561</td>\n",
       "      <td>0.719125</td>\n",
       "      <td>1.126068</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155547676</th>\n",
       "      <td>654.66</td>\n",
       "      <td>8.286835</td>\n",
       "      <td>52.4108</td>\n",
       "      <td>79.3777</td>\n",
       "      <td>55.1198</td>\n",
       "      <td>88.9797</td>\n",
       "      <td>0.663428</td>\n",
       "      <td>1.004781</td>\n",
       "      <td>0.697719</td>\n",
       "      <td>1.126325</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155510814</th>\n",
       "      <td>661.72</td>\n",
       "      <td>8.822933</td>\n",
       "      <td>53.4152</td>\n",
       "      <td>76.2213</td>\n",
       "      <td>54.2334</td>\n",
       "      <td>84.1103</td>\n",
       "      <td>0.712203</td>\n",
       "      <td>1.016284</td>\n",
       "      <td>0.723112</td>\n",
       "      <td>1.121471</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 4143 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               MW       AMW       Sv       Se       Sp       Si        Mv  \\\n",
       "CID                                                                         \n",
       "5904       334.43  8.156829  26.3035  41.6580  27.5683  46.0758  0.641549   \n",
       "155543311  697.70  9.302667  54.1818  77.2467  54.1084  84.7897  0.722424   \n",
       "155511868  641.64  9.299130  49.7912  71.1087  49.6196  77.6987  0.721612   \n",
       "155547676  654.66  8.286835  52.4108  79.3777  55.1198  88.9797  0.663428   \n",
       "155510814  661.72  8.822933  53.4152  76.2213  54.2334  84.1103  0.712203   \n",
       "\n",
       "                 Me        Mp        Mi  ...  s1_numAroBonds  s2_numAroBonds  \\\n",
       "CID                                      ...                                   \n",
       "5904       1.016049  0.672398  1.123800  ...             0.0             0.0   \n",
       "155543311  1.029956  0.721445  1.130529  ...             0.0             0.0   \n",
       "155511868  1.030561  0.719125  1.126068  ...             0.0             0.0   \n",
       "155547676  1.004781  0.697719  1.126325  ...             0.0             0.0   \n",
       "155510814  1.016284  0.723112  1.121471  ...             0.0             0.0   \n",
       "\n",
       "           s3_numAroBonds  s4_numAroBonds   s34_size  s34_relSize  s34_phSize  \\\n",
       "CID                                                                             \n",
       "5904                  0.0             6.0  18.166667     0.789855         4.5   \n",
       "155543311             0.0             0.0   0.000000     0.000000         0.0   \n",
       "155511868             0.0             0.0   0.000000     0.000000         0.0   \n",
       "155547676             0.0             0.0   0.000000     0.000000         0.0   \n",
       "155510814             0.0             0.0   0.000000     0.000000         0.0   \n",
       "\n",
       "           s34_phRelSize  chiralMoment  chiralPhMoment  \n",
       "CID                                                     \n",
       "5904            0.195652     18.311935        5.513107  \n",
       "155543311       0.000000      0.000000        0.000000  \n",
       "155511868       0.000000      0.000000        0.000000  \n",
       "155547676       0.000000      0.000000        0.000000  \n",
       "155510814       0.000000      0.000000        0.000000  \n",
       "\n",
       "[5 rows x 4143 columns]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Reading the data\n",
    "ML_data= pd.read_csv(\"./ML_data.csv\",header=0,index_col=0)\n",
    "X_NAomit_data= pd.read_csv(\"./X_NAomit_data.csv\",header=0,index_col=0)\n",
    "Raw_data = pd.read_csv('./Raw_data.csv',index_col=0)\n",
    "\n",
    "#original data(descriptors= 4175）\n",
    "print(X_NAomit_data.shape)\n",
    "X_NAomit_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "a68cc910-dca6-4b63-ae90-8fac100e1ac6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MW</th>\n",
       "      <th>AMW</th>\n",
       "      <th>Sv</th>\n",
       "      <th>Se</th>\n",
       "      <th>Sp</th>\n",
       "      <th>Si</th>\n",
       "      <th>Mv</th>\n",
       "      <th>Me</th>\n",
       "      <th>Mp</th>\n",
       "      <th>Mi</th>\n",
       "      <th>...</th>\n",
       "      <th>s1_numAroBonds</th>\n",
       "      <th>s2_numAroBonds</th>\n",
       "      <th>s3_numAroBonds</th>\n",
       "      <th>s4_numAroBonds</th>\n",
       "      <th>s34_size</th>\n",
       "      <th>s34_relSize</th>\n",
       "      <th>s34_phSize</th>\n",
       "      <th>s34_phRelSize</th>\n",
       "      <th>chiralMoment</th>\n",
       "      <th>chiralPhMoment</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5904</th>\n",
       "      <td>334.43</td>\n",
       "      <td>8.156829</td>\n",
       "      <td>26.3035</td>\n",
       "      <td>41.6580</td>\n",
       "      <td>27.5683</td>\n",
       "      <td>46.0758</td>\n",
       "      <td>0.641549</td>\n",
       "      <td>1.016049</td>\n",
       "      <td>0.672398</td>\n",
       "      <td>1.123800</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>18.166667</td>\n",
       "      <td>0.789855</td>\n",
       "      <td>4.5</td>\n",
       "      <td>0.195652</td>\n",
       "      <td>18.311935</td>\n",
       "      <td>5.513107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155543311</th>\n",
       "      <td>697.70</td>\n",
       "      <td>9.302667</td>\n",
       "      <td>54.1818</td>\n",
       "      <td>77.2467</td>\n",
       "      <td>54.1084</td>\n",
       "      <td>84.7897</td>\n",
       "      <td>0.722424</td>\n",
       "      <td>1.029956</td>\n",
       "      <td>0.721445</td>\n",
       "      <td>1.130529</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155511868</th>\n",
       "      <td>641.64</td>\n",
       "      <td>9.299130</td>\n",
       "      <td>49.7912</td>\n",
       "      <td>71.1087</td>\n",
       "      <td>49.6196</td>\n",
       "      <td>77.6987</td>\n",
       "      <td>0.721612</td>\n",
       "      <td>1.030561</td>\n",
       "      <td>0.719125</td>\n",
       "      <td>1.126068</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155547676</th>\n",
       "      <td>654.66</td>\n",
       "      <td>8.286835</td>\n",
       "      <td>52.4108</td>\n",
       "      <td>79.3777</td>\n",
       "      <td>55.1198</td>\n",
       "      <td>88.9797</td>\n",
       "      <td>0.663428</td>\n",
       "      <td>1.004781</td>\n",
       "      <td>0.697719</td>\n",
       "      <td>1.126325</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155510814</th>\n",
       "      <td>661.72</td>\n",
       "      <td>8.822933</td>\n",
       "      <td>53.4152</td>\n",
       "      <td>76.2213</td>\n",
       "      <td>54.2334</td>\n",
       "      <td>84.1103</td>\n",
       "      <td>0.712203</td>\n",
       "      <td>1.016284</td>\n",
       "      <td>0.723112</td>\n",
       "      <td>1.121471</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162658036</th>\n",
       "      <td>524.55</td>\n",
       "      <td>9.202632</td>\n",
       "      <td>39.2055</td>\n",
       "      <td>59.1708</td>\n",
       "      <td>39.3977</td>\n",
       "      <td>63.9100</td>\n",
       "      <td>0.687816</td>\n",
       "      <td>1.038084</td>\n",
       "      <td>0.691188</td>\n",
       "      <td>1.121228</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162647428</th>\n",
       "      <td>452.54</td>\n",
       "      <td>8.538491</td>\n",
       "      <td>35.7404</td>\n",
       "      <td>53.9379</td>\n",
       "      <td>37.0286</td>\n",
       "      <td>59.2459</td>\n",
       "      <td>0.674347</td>\n",
       "      <td>1.017696</td>\n",
       "      <td>0.698653</td>\n",
       "      <td>1.117847</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162663043</th>\n",
       "      <td>452.54</td>\n",
       "      <td>8.538491</td>\n",
       "      <td>35.7404</td>\n",
       "      <td>53.9379</td>\n",
       "      <td>37.0286</td>\n",
       "      <td>59.2459</td>\n",
       "      <td>0.674347</td>\n",
       "      <td>1.017696</td>\n",
       "      <td>0.698653</td>\n",
       "      <td>1.117847</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168292812</th>\n",
       "      <td>558.44</td>\n",
       "      <td>10.153455</td>\n",
       "      <td>38.3065</td>\n",
       "      <td>56.5271</td>\n",
       "      <td>39.5967</td>\n",
       "      <td>61.2497</td>\n",
       "      <td>0.696482</td>\n",
       "      <td>1.027765</td>\n",
       "      <td>0.719940</td>\n",
       "      <td>1.113631</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168275423</th>\n",
       "      <td>513.99</td>\n",
       "      <td>9.345273</td>\n",
       "      <td>38.1088</td>\n",
       "      <td>56.6217</td>\n",
       "      <td>39.1023</td>\n",
       "      <td>61.3521</td>\n",
       "      <td>0.692887</td>\n",
       "      <td>1.029485</td>\n",
       "      <td>0.710951</td>\n",
       "      <td>1.115493</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>152 rows × 4143 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               MW        AMW       Sv       Se       Sp       Si        Mv  \\\n",
       "CID                                                                          \n",
       "5904       334.43   8.156829  26.3035  41.6580  27.5683  46.0758  0.641549   \n",
       "155543311  697.70   9.302667  54.1818  77.2467  54.1084  84.7897  0.722424   \n",
       "155511868  641.64   9.299130  49.7912  71.1087  49.6196  77.6987  0.721612   \n",
       "155547676  654.66   8.286835  52.4108  79.3777  55.1198  88.9797  0.663428   \n",
       "155510814  661.72   8.822933  53.4152  76.2213  54.2334  84.1103  0.712203   \n",
       "...           ...        ...      ...      ...      ...      ...       ...   \n",
       "162658036  524.55   9.202632  39.2055  59.1708  39.3977  63.9100  0.687816   \n",
       "162647428  452.54   8.538491  35.7404  53.9379  37.0286  59.2459  0.674347   \n",
       "162663043  452.54   8.538491  35.7404  53.9379  37.0286  59.2459  0.674347   \n",
       "168292812  558.44  10.153455  38.3065  56.5271  39.5967  61.2497  0.696482   \n",
       "168275423  513.99   9.345273  38.1088  56.6217  39.1023  61.3521  0.692887   \n",
       "\n",
       "                 Me        Mp        Mi  ...  s1_numAroBonds  s2_numAroBonds  \\\n",
       "CID                                      ...                                   \n",
       "5904       1.016049  0.672398  1.123800  ...             0.0             0.0   \n",
       "155543311  1.029956  0.721445  1.130529  ...             0.0             0.0   \n",
       "155511868  1.030561  0.719125  1.126068  ...             0.0             0.0   \n",
       "155547676  1.004781  0.697719  1.126325  ...             0.0             0.0   \n",
       "155510814  1.016284  0.723112  1.121471  ...             0.0             0.0   \n",
       "...             ...       ...       ...  ...             ...             ...   \n",
       "162658036  1.038084  0.691188  1.121228  ...             0.0             0.0   \n",
       "162647428  1.017696  0.698653  1.117847  ...             0.0             0.0   \n",
       "162663043  1.017696  0.698653  1.117847  ...             0.0             0.0   \n",
       "168292812  1.027765  0.719940  1.113631  ...             0.0             0.0   \n",
       "168275423  1.029485  0.710951  1.115493  ...             0.0             0.0   \n",
       "\n",
       "           s3_numAroBonds  s4_numAroBonds   s34_size  s34_relSize  s34_phSize  \\\n",
       "CID                                                                             \n",
       "5904                  0.0             6.0  18.166667     0.789855         4.5   \n",
       "155543311             0.0             0.0   0.000000     0.000000         0.0   \n",
       "155511868             0.0             0.0   0.000000     0.000000         0.0   \n",
       "155547676             0.0             0.0   0.000000     0.000000         0.0   \n",
       "155510814             0.0             0.0   0.000000     0.000000         0.0   \n",
       "...                   ...             ...        ...          ...         ...   \n",
       "162658036             0.0             0.0   0.000000     0.000000         0.0   \n",
       "162647428             0.0             0.0   0.000000     0.000000         0.0   \n",
       "162663043             0.0             0.0   0.000000     0.000000         0.0   \n",
       "168292812             0.0             0.0   0.000000     0.000000         0.0   \n",
       "168275423             0.0             0.0   0.000000     0.000000         0.0   \n",
       "\n",
       "           s34_phRelSize  chiralMoment  chiralPhMoment  \n",
       "CID                                                     \n",
       "5904            0.195652     18.311935        5.513107  \n",
       "155543311       0.000000      0.000000        0.000000  \n",
       "155511868       0.000000      0.000000        0.000000  \n",
       "155547676       0.000000      0.000000        0.000000  \n",
       "155510814       0.000000      0.000000        0.000000  \n",
       "...                  ...           ...             ...  \n",
       "162658036       0.000000      0.000000        0.000000  \n",
       "162647428       0.000000      0.000000        0.000000  \n",
       "162663043       0.000000      0.000000        0.000000  \n",
       "168292812       0.000000      0.000000        0.000000  \n",
       "168275423       0.000000      0.000000        0.000000  \n",
       "\n",
       "[152 rows x 4143 columns]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_NAomit_data= pd.read_csv(\"./X_NAomit_data.csv\",header=0,index_col=0)\n",
    "X_NAomit_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "e1c89e32-9d35-4229-a7fd-6dc4bc6e3b4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "col_data= pd.read_csv(\"./X_NAomit_data.csv\",header=0,index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "c075c2f5-c839-4ab6-8f1d-ee4e808c3238",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MW</th>\n",
       "      <th>AMW</th>\n",
       "      <th>Sv</th>\n",
       "      <th>Se</th>\n",
       "      <th>Sp</th>\n",
       "      <th>Si</th>\n",
       "      <th>Mv</th>\n",
       "      <th>Me</th>\n",
       "      <th>Mp</th>\n",
       "      <th>Mi</th>\n",
       "      <th>...</th>\n",
       "      <th>s1_numAroBonds</th>\n",
       "      <th>s2_numAroBonds</th>\n",
       "      <th>s3_numAroBonds</th>\n",
       "      <th>s4_numAroBonds</th>\n",
       "      <th>s34_size</th>\n",
       "      <th>s34_relSize</th>\n",
       "      <th>s34_phSize</th>\n",
       "      <th>s34_phRelSize</th>\n",
       "      <th>chiralMoment</th>\n",
       "      <th>chiralPhMoment</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5904</th>\n",
       "      <td>334.43</td>\n",
       "      <td>8.156829</td>\n",
       "      <td>26.3035</td>\n",
       "      <td>41.6580</td>\n",
       "      <td>27.5683</td>\n",
       "      <td>46.0758</td>\n",
       "      <td>0.641549</td>\n",
       "      <td>1.016049</td>\n",
       "      <td>0.672398</td>\n",
       "      <td>1.123800</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>18.166667</td>\n",
       "      <td>0.789855</td>\n",
       "      <td>4.5</td>\n",
       "      <td>0.195652</td>\n",
       "      <td>18.311935</td>\n",
       "      <td>5.513107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155543311</th>\n",
       "      <td>697.70</td>\n",
       "      <td>9.302667</td>\n",
       "      <td>54.1818</td>\n",
       "      <td>77.2467</td>\n",
       "      <td>54.1084</td>\n",
       "      <td>84.7897</td>\n",
       "      <td>0.722424</td>\n",
       "      <td>1.029956</td>\n",
       "      <td>0.721445</td>\n",
       "      <td>1.130529</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155511868</th>\n",
       "      <td>641.64</td>\n",
       "      <td>9.299130</td>\n",
       "      <td>49.7912</td>\n",
       "      <td>71.1087</td>\n",
       "      <td>49.6196</td>\n",
       "      <td>77.6987</td>\n",
       "      <td>0.721612</td>\n",
       "      <td>1.030561</td>\n",
       "      <td>0.719125</td>\n",
       "      <td>1.126068</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155547676</th>\n",
       "      <td>654.66</td>\n",
       "      <td>8.286835</td>\n",
       "      <td>52.4108</td>\n",
       "      <td>79.3777</td>\n",
       "      <td>55.1198</td>\n",
       "      <td>88.9797</td>\n",
       "      <td>0.663428</td>\n",
       "      <td>1.004781</td>\n",
       "      <td>0.697719</td>\n",
       "      <td>1.126325</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155510814</th>\n",
       "      <td>661.72</td>\n",
       "      <td>8.822933</td>\n",
       "      <td>53.4152</td>\n",
       "      <td>76.2213</td>\n",
       "      <td>54.2334</td>\n",
       "      <td>84.1103</td>\n",
       "      <td>0.712203</td>\n",
       "      <td>1.016284</td>\n",
       "      <td>0.723112</td>\n",
       "      <td>1.121471</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162658036</th>\n",
       "      <td>524.55</td>\n",
       "      <td>9.202632</td>\n",
       "      <td>39.2055</td>\n",
       "      <td>59.1708</td>\n",
       "      <td>39.3977</td>\n",
       "      <td>63.9100</td>\n",
       "      <td>0.687816</td>\n",
       "      <td>1.038084</td>\n",
       "      <td>0.691188</td>\n",
       "      <td>1.121228</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162647428</th>\n",
       "      <td>452.54</td>\n",
       "      <td>8.538491</td>\n",
       "      <td>35.7404</td>\n",
       "      <td>53.9379</td>\n",
       "      <td>37.0286</td>\n",
       "      <td>59.2459</td>\n",
       "      <td>0.674347</td>\n",
       "      <td>1.017696</td>\n",
       "      <td>0.698653</td>\n",
       "      <td>1.117847</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162663043</th>\n",
       "      <td>452.54</td>\n",
       "      <td>8.538491</td>\n",
       "      <td>35.7404</td>\n",
       "      <td>53.9379</td>\n",
       "      <td>37.0286</td>\n",
       "      <td>59.2459</td>\n",
       "      <td>0.674347</td>\n",
       "      <td>1.017696</td>\n",
       "      <td>0.698653</td>\n",
       "      <td>1.117847</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168292812</th>\n",
       "      <td>558.44</td>\n",
       "      <td>10.153455</td>\n",
       "      <td>38.3065</td>\n",
       "      <td>56.5271</td>\n",
       "      <td>39.5967</td>\n",
       "      <td>61.2497</td>\n",
       "      <td>0.696482</td>\n",
       "      <td>1.027765</td>\n",
       "      <td>0.719940</td>\n",
       "      <td>1.113631</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168275423</th>\n",
       "      <td>513.99</td>\n",
       "      <td>9.345273</td>\n",
       "      <td>38.1088</td>\n",
       "      <td>56.6217</td>\n",
       "      <td>39.1023</td>\n",
       "      <td>61.3521</td>\n",
       "      <td>0.692887</td>\n",
       "      <td>1.029485</td>\n",
       "      <td>0.710951</td>\n",
       "      <td>1.115493</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>152 rows × 4143 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               MW        AMW       Sv       Se       Sp       Si        Mv  \\\n",
       "CID                                                                          \n",
       "5904       334.43   8.156829  26.3035  41.6580  27.5683  46.0758  0.641549   \n",
       "155543311  697.70   9.302667  54.1818  77.2467  54.1084  84.7897  0.722424   \n",
       "155511868  641.64   9.299130  49.7912  71.1087  49.6196  77.6987  0.721612   \n",
       "155547676  654.66   8.286835  52.4108  79.3777  55.1198  88.9797  0.663428   \n",
       "155510814  661.72   8.822933  53.4152  76.2213  54.2334  84.1103  0.712203   \n",
       "...           ...        ...      ...      ...      ...      ...       ...   \n",
       "162658036  524.55   9.202632  39.2055  59.1708  39.3977  63.9100  0.687816   \n",
       "162647428  452.54   8.538491  35.7404  53.9379  37.0286  59.2459  0.674347   \n",
       "162663043  452.54   8.538491  35.7404  53.9379  37.0286  59.2459  0.674347   \n",
       "168292812  558.44  10.153455  38.3065  56.5271  39.5967  61.2497  0.696482   \n",
       "168275423  513.99   9.345273  38.1088  56.6217  39.1023  61.3521  0.692887   \n",
       "\n",
       "                 Me        Mp        Mi  ...  s1_numAroBonds  s2_numAroBonds  \\\n",
       "CID                                      ...                                   \n",
       "5904       1.016049  0.672398  1.123800  ...             0.0             0.0   \n",
       "155543311  1.029956  0.721445  1.130529  ...             0.0             0.0   \n",
       "155511868  1.030561  0.719125  1.126068  ...             0.0             0.0   \n",
       "155547676  1.004781  0.697719  1.126325  ...             0.0             0.0   \n",
       "155510814  1.016284  0.723112  1.121471  ...             0.0             0.0   \n",
       "...             ...       ...       ...  ...             ...             ...   \n",
       "162658036  1.038084  0.691188  1.121228  ...             0.0             0.0   \n",
       "162647428  1.017696  0.698653  1.117847  ...             0.0             0.0   \n",
       "162663043  1.017696  0.698653  1.117847  ...             0.0             0.0   \n",
       "168292812  1.027765  0.719940  1.113631  ...             0.0             0.0   \n",
       "168275423  1.029485  0.710951  1.115493  ...             0.0             0.0   \n",
       "\n",
       "           s3_numAroBonds  s4_numAroBonds   s34_size  s34_relSize  s34_phSize  \\\n",
       "CID                                                                             \n",
       "5904                  0.0             6.0  18.166667     0.789855         4.5   \n",
       "155543311             0.0             0.0   0.000000     0.000000         0.0   \n",
       "155511868             0.0             0.0   0.000000     0.000000         0.0   \n",
       "155547676             0.0             0.0   0.000000     0.000000         0.0   \n",
       "155510814             0.0             0.0   0.000000     0.000000         0.0   \n",
       "...                   ...             ...        ...          ...         ...   \n",
       "162658036             0.0             0.0   0.000000     0.000000         0.0   \n",
       "162647428             0.0             0.0   0.000000     0.000000         0.0   \n",
       "162663043             0.0             0.0   0.000000     0.000000         0.0   \n",
       "168292812             0.0             0.0   0.000000     0.000000         0.0   \n",
       "168275423             0.0             0.0   0.000000     0.000000         0.0   \n",
       "\n",
       "           s34_phRelSize  chiralMoment  chiralPhMoment  \n",
       "CID                                                     \n",
       "5904            0.195652     18.311935        5.513107  \n",
       "155543311       0.000000      0.000000        0.000000  \n",
       "155511868       0.000000      0.000000        0.000000  \n",
       "155547676       0.000000      0.000000        0.000000  \n",
       "155510814       0.000000      0.000000        0.000000  \n",
       "...                  ...           ...             ...  \n",
       "162658036       0.000000      0.000000        0.000000  \n",
       "162647428       0.000000      0.000000        0.000000  \n",
       "162663043       0.000000      0.000000        0.000000  \n",
       "168292812       0.000000      0.000000        0.000000  \n",
       "168275423       0.000000      0.000000        0.000000  \n",
       "\n",
       "[152 rows x 4143 columns]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_NAomit_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "8129de55-e5e1-44df-bea5-1de439f32345",
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 0.99  # 如果列中 0 的比例超过 90%，则移除该列\n",
    "non_zero_threshold = X_NAomit_data.shape[0] * (1 - threshold)\n",
    "X_NAomit_data =X_NAomit_data.loc[:, (X_NAomit_data != 0).sum(axis=0) > non_zero_threshold]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "25db298a-25a8-4f41-ba0a-23d279862cce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MW</th>\n",
       "      <th>AMW</th>\n",
       "      <th>Sv</th>\n",
       "      <th>Se</th>\n",
       "      <th>Sp</th>\n",
       "      <th>Si</th>\n",
       "      <th>Mv</th>\n",
       "      <th>Me</th>\n",
       "      <th>Mp</th>\n",
       "      <th>Mi</th>\n",
       "      <th>...</th>\n",
       "      <th>s4_numRotBonds</th>\n",
       "      <th>s2_numAroBonds</th>\n",
       "      <th>s3_numAroBonds</th>\n",
       "      <th>s4_numAroBonds</th>\n",
       "      <th>s34_size</th>\n",
       "      <th>s34_relSize</th>\n",
       "      <th>s34_phSize</th>\n",
       "      <th>s34_phRelSize</th>\n",
       "      <th>chiralMoment</th>\n",
       "      <th>chiralPhMoment</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5904</th>\n",
       "      <td>334.43</td>\n",
       "      <td>8.156829</td>\n",
       "      <td>26.3035</td>\n",
       "      <td>41.6580</td>\n",
       "      <td>27.5683</td>\n",
       "      <td>46.0758</td>\n",
       "      <td>0.641549</td>\n",
       "      <td>1.016049</td>\n",
       "      <td>0.672398</td>\n",
       "      <td>1.123800</td>\n",
       "      <td>...</td>\n",
       "      <td>2.666667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>18.166667</td>\n",
       "      <td>0.789855</td>\n",
       "      <td>4.5</td>\n",
       "      <td>0.195652</td>\n",
       "      <td>18.311935</td>\n",
       "      <td>5.513107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155543311</th>\n",
       "      <td>697.70</td>\n",
       "      <td>9.302667</td>\n",
       "      <td>54.1818</td>\n",
       "      <td>77.2467</td>\n",
       "      <td>54.1084</td>\n",
       "      <td>84.7897</td>\n",
       "      <td>0.722424</td>\n",
       "      <td>1.029956</td>\n",
       "      <td>0.721445</td>\n",
       "      <td>1.130529</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155511868</th>\n",
       "      <td>641.64</td>\n",
       "      <td>9.299130</td>\n",
       "      <td>49.7912</td>\n",
       "      <td>71.1087</td>\n",
       "      <td>49.6196</td>\n",
       "      <td>77.6987</td>\n",
       "      <td>0.721612</td>\n",
       "      <td>1.030561</td>\n",
       "      <td>0.719125</td>\n",
       "      <td>1.126068</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155547676</th>\n",
       "      <td>654.66</td>\n",
       "      <td>8.286835</td>\n",
       "      <td>52.4108</td>\n",
       "      <td>79.3777</td>\n",
       "      <td>55.1198</td>\n",
       "      <td>88.9797</td>\n",
       "      <td>0.663428</td>\n",
       "      <td>1.004781</td>\n",
       "      <td>0.697719</td>\n",
       "      <td>1.126325</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155510814</th>\n",
       "      <td>661.72</td>\n",
       "      <td>8.822933</td>\n",
       "      <td>53.4152</td>\n",
       "      <td>76.2213</td>\n",
       "      <td>54.2334</td>\n",
       "      <td>84.1103</td>\n",
       "      <td>0.712203</td>\n",
       "      <td>1.016284</td>\n",
       "      <td>0.723112</td>\n",
       "      <td>1.121471</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162658036</th>\n",
       "      <td>524.55</td>\n",
       "      <td>9.202632</td>\n",
       "      <td>39.2055</td>\n",
       "      <td>59.1708</td>\n",
       "      <td>39.3977</td>\n",
       "      <td>63.9100</td>\n",
       "      <td>0.687816</td>\n",
       "      <td>1.038084</td>\n",
       "      <td>0.691188</td>\n",
       "      <td>1.121228</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162647428</th>\n",
       "      <td>452.54</td>\n",
       "      <td>8.538491</td>\n",
       "      <td>35.7404</td>\n",
       "      <td>53.9379</td>\n",
       "      <td>37.0286</td>\n",
       "      <td>59.2459</td>\n",
       "      <td>0.674347</td>\n",
       "      <td>1.017696</td>\n",
       "      <td>0.698653</td>\n",
       "      <td>1.117847</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162663043</th>\n",
       "      <td>452.54</td>\n",
       "      <td>8.538491</td>\n",
       "      <td>35.7404</td>\n",
       "      <td>53.9379</td>\n",
       "      <td>37.0286</td>\n",
       "      <td>59.2459</td>\n",
       "      <td>0.674347</td>\n",
       "      <td>1.017696</td>\n",
       "      <td>0.698653</td>\n",
       "      <td>1.117847</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168292812</th>\n",
       "      <td>558.44</td>\n",
       "      <td>10.153455</td>\n",
       "      <td>38.3065</td>\n",
       "      <td>56.5271</td>\n",
       "      <td>39.5967</td>\n",
       "      <td>61.2497</td>\n",
       "      <td>0.696482</td>\n",
       "      <td>1.027765</td>\n",
       "      <td>0.719940</td>\n",
       "      <td>1.113631</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168275423</th>\n",
       "      <td>513.99</td>\n",
       "      <td>9.345273</td>\n",
       "      <td>38.1088</td>\n",
       "      <td>56.6217</td>\n",
       "      <td>39.1023</td>\n",
       "      <td>61.3521</td>\n",
       "      <td>0.692887</td>\n",
       "      <td>1.029485</td>\n",
       "      <td>0.710951</td>\n",
       "      <td>1.115493</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>152 rows × 2338 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               MW        AMW       Sv       Se       Sp       Si        Mv  \\\n",
       "CID                                                                          \n",
       "5904       334.43   8.156829  26.3035  41.6580  27.5683  46.0758  0.641549   \n",
       "155543311  697.70   9.302667  54.1818  77.2467  54.1084  84.7897  0.722424   \n",
       "155511868  641.64   9.299130  49.7912  71.1087  49.6196  77.6987  0.721612   \n",
       "155547676  654.66   8.286835  52.4108  79.3777  55.1198  88.9797  0.663428   \n",
       "155510814  661.72   8.822933  53.4152  76.2213  54.2334  84.1103  0.712203   \n",
       "...           ...        ...      ...      ...      ...      ...       ...   \n",
       "162658036  524.55   9.202632  39.2055  59.1708  39.3977  63.9100  0.687816   \n",
       "162647428  452.54   8.538491  35.7404  53.9379  37.0286  59.2459  0.674347   \n",
       "162663043  452.54   8.538491  35.7404  53.9379  37.0286  59.2459  0.674347   \n",
       "168292812  558.44  10.153455  38.3065  56.5271  39.5967  61.2497  0.696482   \n",
       "168275423  513.99   9.345273  38.1088  56.6217  39.1023  61.3521  0.692887   \n",
       "\n",
       "                 Me        Mp        Mi  ...  s4_numRotBonds  s2_numAroBonds  \\\n",
       "CID                                      ...                                   \n",
       "5904       1.016049  0.672398  1.123800  ...        2.666667             0.0   \n",
       "155543311  1.029956  0.721445  1.130529  ...        0.000000             0.0   \n",
       "155511868  1.030561  0.719125  1.126068  ...        0.000000             0.0   \n",
       "155547676  1.004781  0.697719  1.126325  ...        0.000000             0.0   \n",
       "155510814  1.016284  0.723112  1.121471  ...        0.000000             0.0   \n",
       "...             ...       ...       ...  ...             ...             ...   \n",
       "162658036  1.038084  0.691188  1.121228  ...        0.000000             0.0   \n",
       "162647428  1.017696  0.698653  1.117847  ...        0.000000             0.0   \n",
       "162663043  1.017696  0.698653  1.117847  ...        0.000000             0.0   \n",
       "168292812  1.027765  0.719940  1.113631  ...        0.000000             0.0   \n",
       "168275423  1.029485  0.710951  1.115493  ...        0.000000             0.0   \n",
       "\n",
       "           s3_numAroBonds  s4_numAroBonds   s34_size  s34_relSize  s34_phSize  \\\n",
       "CID                                                                             \n",
       "5904                  0.0             6.0  18.166667     0.789855         4.5   \n",
       "155543311             0.0             0.0   0.000000     0.000000         0.0   \n",
       "155511868             0.0             0.0   0.000000     0.000000         0.0   \n",
       "155547676             0.0             0.0   0.000000     0.000000         0.0   \n",
       "155510814             0.0             0.0   0.000000     0.000000         0.0   \n",
       "...                   ...             ...        ...          ...         ...   \n",
       "162658036             0.0             0.0   0.000000     0.000000         0.0   \n",
       "162647428             0.0             0.0   0.000000     0.000000         0.0   \n",
       "162663043             0.0             0.0   0.000000     0.000000         0.0   \n",
       "168292812             0.0             0.0   0.000000     0.000000         0.0   \n",
       "168275423             0.0             0.0   0.000000     0.000000         0.0   \n",
       "\n",
       "           s34_phRelSize  chiralMoment  chiralPhMoment  \n",
       "CID                                                     \n",
       "5904            0.195652     18.311935        5.513107  \n",
       "155543311       0.000000      0.000000        0.000000  \n",
       "155511868       0.000000      0.000000        0.000000  \n",
       "155547676       0.000000      0.000000        0.000000  \n",
       "155510814       0.000000      0.000000        0.000000  \n",
       "...                  ...           ...             ...  \n",
       "162658036       0.000000      0.000000        0.000000  \n",
       "162647428       0.000000      0.000000        0.000000  \n",
       "162663043       0.000000      0.000000        0.000000  \n",
       "168292812       0.000000      0.000000        0.000000  \n",
       "168275423       0.000000      0.000000        0.000000  \n",
       "\n",
       "[152 rows x 2338 columns]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_NAomit_data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "1cf34dcf-3f11-4e44-83ca-67542efeea48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3.34430000e+02, 8.15682927e+00, 2.63035000e+01, ...,\n",
       "        1.95652174e-01, 1.83119353e+01, 5.51310699e+00],\n",
       "       [6.97700000e+02, 9.30266667e+00, 5.41818000e+01, ...,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "       [6.41640000e+02, 9.29913043e+00, 4.97912000e+01, ...,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "       ...,\n",
       "       [4.52540000e+02, 8.53849057e+00, 3.57404000e+01, ...,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "       [5.58440000e+02, 1.01534545e+01, 3.83065000e+01, ...,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "       [5.13990000e+02, 9.34527273e+00, 3.81088000e+01, ...,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00]])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X=np.array(X_NAomit_data)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "fd096547-56ce-48a2-9a6f-210d1e31be3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MW</th>\n",
       "      <th>AMW</th>\n",
       "      <th>Sv</th>\n",
       "      <th>Se</th>\n",
       "      <th>Sp</th>\n",
       "      <th>Si</th>\n",
       "      <th>Mv</th>\n",
       "      <th>Me</th>\n",
       "      <th>Mp</th>\n",
       "      <th>Mi</th>\n",
       "      <th>...</th>\n",
       "      <th>s4_numRotBonds</th>\n",
       "      <th>s2_numAroBonds</th>\n",
       "      <th>s3_numAroBonds</th>\n",
       "      <th>s4_numAroBonds</th>\n",
       "      <th>s34_size</th>\n",
       "      <th>s34_relSize</th>\n",
       "      <th>s34_phSize</th>\n",
       "      <th>s34_phRelSize</th>\n",
       "      <th>chiralMoment</th>\n",
       "      <th>chiralPhMoment</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5904</th>\n",
       "      <td>334.43</td>\n",
       "      <td>8.156829</td>\n",
       "      <td>26.3035</td>\n",
       "      <td>41.6580</td>\n",
       "      <td>27.5683</td>\n",
       "      <td>46.0758</td>\n",
       "      <td>0.641549</td>\n",
       "      <td>1.016049</td>\n",
       "      <td>0.672398</td>\n",
       "      <td>1.123800</td>\n",
       "      <td>...</td>\n",
       "      <td>2.666667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>18.166667</td>\n",
       "      <td>0.789855</td>\n",
       "      <td>4.5</td>\n",
       "      <td>0.195652</td>\n",
       "      <td>18.311935</td>\n",
       "      <td>5.513107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155543311</th>\n",
       "      <td>697.70</td>\n",
       "      <td>9.302667</td>\n",
       "      <td>54.1818</td>\n",
       "      <td>77.2467</td>\n",
       "      <td>54.1084</td>\n",
       "      <td>84.7897</td>\n",
       "      <td>0.722424</td>\n",
       "      <td>1.029956</td>\n",
       "      <td>0.721445</td>\n",
       "      <td>1.130529</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155511868</th>\n",
       "      <td>641.64</td>\n",
       "      <td>9.299130</td>\n",
       "      <td>49.7912</td>\n",
       "      <td>71.1087</td>\n",
       "      <td>49.6196</td>\n",
       "      <td>77.6987</td>\n",
       "      <td>0.721612</td>\n",
       "      <td>1.030561</td>\n",
       "      <td>0.719125</td>\n",
       "      <td>1.126068</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155547676</th>\n",
       "      <td>654.66</td>\n",
       "      <td>8.286835</td>\n",
       "      <td>52.4108</td>\n",
       "      <td>79.3777</td>\n",
       "      <td>55.1198</td>\n",
       "      <td>88.9797</td>\n",
       "      <td>0.663428</td>\n",
       "      <td>1.004781</td>\n",
       "      <td>0.697719</td>\n",
       "      <td>1.126325</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155510814</th>\n",
       "      <td>661.72</td>\n",
       "      <td>8.822933</td>\n",
       "      <td>53.4152</td>\n",
       "      <td>76.2213</td>\n",
       "      <td>54.2334</td>\n",
       "      <td>84.1103</td>\n",
       "      <td>0.712203</td>\n",
       "      <td>1.016284</td>\n",
       "      <td>0.723112</td>\n",
       "      <td>1.121471</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162658036</th>\n",
       "      <td>524.55</td>\n",
       "      <td>9.202632</td>\n",
       "      <td>39.2055</td>\n",
       "      <td>59.1708</td>\n",
       "      <td>39.3977</td>\n",
       "      <td>63.9100</td>\n",
       "      <td>0.687816</td>\n",
       "      <td>1.038084</td>\n",
       "      <td>0.691188</td>\n",
       "      <td>1.121228</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162647428</th>\n",
       "      <td>452.54</td>\n",
       "      <td>8.538491</td>\n",
       "      <td>35.7404</td>\n",
       "      <td>53.9379</td>\n",
       "      <td>37.0286</td>\n",
       "      <td>59.2459</td>\n",
       "      <td>0.674347</td>\n",
       "      <td>1.017696</td>\n",
       "      <td>0.698653</td>\n",
       "      <td>1.117847</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162663043</th>\n",
       "      <td>452.54</td>\n",
       "      <td>8.538491</td>\n",
       "      <td>35.7404</td>\n",
       "      <td>53.9379</td>\n",
       "      <td>37.0286</td>\n",
       "      <td>59.2459</td>\n",
       "      <td>0.674347</td>\n",
       "      <td>1.017696</td>\n",
       "      <td>0.698653</td>\n",
       "      <td>1.117847</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168292812</th>\n",
       "      <td>558.44</td>\n",
       "      <td>10.153455</td>\n",
       "      <td>38.3065</td>\n",
       "      <td>56.5271</td>\n",
       "      <td>39.5967</td>\n",
       "      <td>61.2497</td>\n",
       "      <td>0.696482</td>\n",
       "      <td>1.027765</td>\n",
       "      <td>0.719940</td>\n",
       "      <td>1.113631</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168275423</th>\n",
       "      <td>513.99</td>\n",
       "      <td>9.345273</td>\n",
       "      <td>38.1088</td>\n",
       "      <td>56.6217</td>\n",
       "      <td>39.1023</td>\n",
       "      <td>61.3521</td>\n",
       "      <td>0.692887</td>\n",
       "      <td>1.029485</td>\n",
       "      <td>0.710951</td>\n",
       "      <td>1.115493</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>152 rows × 2338 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               MW        AMW       Sv       Se       Sp       Si        Mv  \\\n",
       "CID                                                                          \n",
       "5904       334.43   8.156829  26.3035  41.6580  27.5683  46.0758  0.641549   \n",
       "155543311  697.70   9.302667  54.1818  77.2467  54.1084  84.7897  0.722424   \n",
       "155511868  641.64   9.299130  49.7912  71.1087  49.6196  77.6987  0.721612   \n",
       "155547676  654.66   8.286835  52.4108  79.3777  55.1198  88.9797  0.663428   \n",
       "155510814  661.72   8.822933  53.4152  76.2213  54.2334  84.1103  0.712203   \n",
       "...           ...        ...      ...      ...      ...      ...       ...   \n",
       "162658036  524.55   9.202632  39.2055  59.1708  39.3977  63.9100  0.687816   \n",
       "162647428  452.54   8.538491  35.7404  53.9379  37.0286  59.2459  0.674347   \n",
       "162663043  452.54   8.538491  35.7404  53.9379  37.0286  59.2459  0.674347   \n",
       "168292812  558.44  10.153455  38.3065  56.5271  39.5967  61.2497  0.696482   \n",
       "168275423  513.99   9.345273  38.1088  56.6217  39.1023  61.3521  0.692887   \n",
       "\n",
       "                 Me        Mp        Mi  ...  s4_numRotBonds  s2_numAroBonds  \\\n",
       "CID                                      ...                                   \n",
       "5904       1.016049  0.672398  1.123800  ...        2.666667             0.0   \n",
       "155543311  1.029956  0.721445  1.130529  ...        0.000000             0.0   \n",
       "155511868  1.030561  0.719125  1.126068  ...        0.000000             0.0   \n",
       "155547676  1.004781  0.697719  1.126325  ...        0.000000             0.0   \n",
       "155510814  1.016284  0.723112  1.121471  ...        0.000000             0.0   \n",
       "...             ...       ...       ...  ...             ...             ...   \n",
       "162658036  1.038084  0.691188  1.121228  ...        0.000000             0.0   \n",
       "162647428  1.017696  0.698653  1.117847  ...        0.000000             0.0   \n",
       "162663043  1.017696  0.698653  1.117847  ...        0.000000             0.0   \n",
       "168292812  1.027765  0.719940  1.113631  ...        0.000000             0.0   \n",
       "168275423  1.029485  0.710951  1.115493  ...        0.000000             0.0   \n",
       "\n",
       "           s3_numAroBonds  s4_numAroBonds   s34_size  s34_relSize  s34_phSize  \\\n",
       "CID                                                                             \n",
       "5904                  0.0             6.0  18.166667     0.789855         4.5   \n",
       "155543311             0.0             0.0   0.000000     0.000000         0.0   \n",
       "155511868             0.0             0.0   0.000000     0.000000         0.0   \n",
       "155547676             0.0             0.0   0.000000     0.000000         0.0   \n",
       "155510814             0.0             0.0   0.000000     0.000000         0.0   \n",
       "...                   ...             ...        ...          ...         ...   \n",
       "162658036             0.0             0.0   0.000000     0.000000         0.0   \n",
       "162647428             0.0             0.0   0.000000     0.000000         0.0   \n",
       "162663043             0.0             0.0   0.000000     0.000000         0.0   \n",
       "168292812             0.0             0.0   0.000000     0.000000         0.0   \n",
       "168275423             0.0             0.0   0.000000     0.000000         0.0   \n",
       "\n",
       "           s34_phRelSize  chiralMoment  chiralPhMoment  \n",
       "CID                                                     \n",
       "5904            0.195652     18.311935        5.513107  \n",
       "155543311       0.000000      0.000000        0.000000  \n",
       "155511868       0.000000      0.000000        0.000000  \n",
       "155547676       0.000000      0.000000        0.000000  \n",
       "155510814       0.000000      0.000000        0.000000  \n",
       "...                  ...           ...             ...  \n",
       "162658036       0.000000      0.000000        0.000000  \n",
       "162647428       0.000000      0.000000        0.000000  \n",
       "162663043       0.000000      0.000000        0.000000  \n",
       "168292812       0.000000      0.000000        0.000000  \n",
       "168275423       0.000000      0.000000        0.000000  \n",
       "\n",
       "[152 rows x 2338 columns]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_NAomit_data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "f561878b-84e9-41a4-aecf-49bd8626f377",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acvalue</th>\n",
       "      <th>aid</th>\n",
       "      <th>sid</th>\n",
       "      <th>cid.1</th>\n",
       "      <th>geneid</th>\n",
       "      <th>pmid</th>\n",
       "      <th>aidtype</th>\n",
       "      <th>aidmdate</th>\n",
       "      <th>hasdrc</th>\n",
       "      <th>rnai</th>\n",
       "      <th>...</th>\n",
       "      <th>targeturl</th>\n",
       "      <th>ecs</th>\n",
       "      <th>repacxn</th>\n",
       "      <th>taxid</th>\n",
       "      <th>cellids</th>\n",
       "      <th>targettaxid</th>\n",
       "      <th>tissueid</th>\n",
       "      <th>tissuename</th>\n",
       "      <th>Antimicrobial</th>\n",
       "      <th>SMILES</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cid</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5904</th>\n",
       "      <td>0.29</td>\n",
       "      <td>1437928</td>\n",
       "      <td>103165163</td>\n",
       "      <td>5904</td>\n",
       "      <td>NaN</td>\n",
       "      <td>28079378.0</td>\n",
       "      <td>Confirmatory</td>\n",
       "      <td>20220830</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>/taxonomy/837</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>837</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>CC1(C(N2C(S1)C(C2=O)NC(=O)CC3=CC=CC=C3)C(=O)O)C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155543311</th>\n",
       "      <td>2.30</td>\n",
       "      <td>1571234</td>\n",
       "      <td>440163866</td>\n",
       "      <td>155543311</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30881614.0</td>\n",
       "      <td>Confirmatory</td>\n",
       "      <td>20220830</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>/taxonomy/837</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>837</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>C1=CC(=CC=C1C2=NC(=C(O2)C3=CC=C(C=C3)F)C4=CC=C...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155511868</th>\n",
       "      <td>2.40</td>\n",
       "      <td>1571234</td>\n",
       "      <td>440111790</td>\n",
       "      <td>155511868</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30881614.0</td>\n",
       "      <td>Confirmatory</td>\n",
       "      <td>20220830</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>/taxonomy/837</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>837</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>C1=CC=C(C(=C1)C2=NC(=C(O2)C3=CC=CO3)C4=CC=CO4)...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155547676</th>\n",
       "      <td>3.70</td>\n",
       "      <td>1571234</td>\n",
       "      <td>440174844</td>\n",
       "      <td>155547676</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30881614.0</td>\n",
       "      <td>Confirmatory</td>\n",
       "      <td>20220830</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>/taxonomy/837</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>837</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>CCN(CC)C1=NC(=NC(=N1)C2=CN(N=N2)C3=CC=C(C=C3)C...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155510814</th>\n",
       "      <td>4.30</td>\n",
       "      <td>1571234</td>\n",
       "      <td>440110233</td>\n",
       "      <td>155510814</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30881614.0</td>\n",
       "      <td>Confirmatory</td>\n",
       "      <td>20220830</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>/taxonomy/837</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>837</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>C1=CC=C(C=C1)C2=C(OC(=N2)C3=CC(=CC=C3)N4C=C(N=...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162658036</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1725206</td>\n",
       "      <td>461535923</td>\n",
       "      <td>162658036</td>\n",
       "      <td>NaN</td>\n",
       "      <td>33062172.0</td>\n",
       "      <td>Literature-derived</td>\n",
       "      <td>20220318</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>/taxonomy/837</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>837</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>CN1C=C(C2=C1C=CC(=C2)[N+](=O)[O-])CC3=CC(=C(C=...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162647428</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1725205</td>\n",
       "      <td>461520763</td>\n",
       "      <td>162647428</td>\n",
       "      <td>NaN</td>\n",
       "      <td>33062172.0</td>\n",
       "      <td>Literature-derived</td>\n",
       "      <td>20220318</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>/taxonomy/837</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>837</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>CN1C=C(C2=CC=CC=C21)CC3=CC(=C(C=C3)OC)C(=O)NS(...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162663043</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1725205</td>\n",
       "      <td>461543092</td>\n",
       "      <td>162663043</td>\n",
       "      <td>NaN</td>\n",
       "      <td>33062172.0</td>\n",
       "      <td>Literature-derived</td>\n",
       "      <td>20220318</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>/taxonomy/837</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>837</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>CN1C=C(C2=CC=CC=C21)CC3=CC(=C(C=C3)OC)C(=O)NS(...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168292812</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1848340</td>\n",
       "      <td>482079746</td>\n",
       "      <td>168292812</td>\n",
       "      <td>NaN</td>\n",
       "      <td>36273428.0</td>\n",
       "      <td>Literature-derived</td>\n",
       "      <td>20230629</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>/taxonomy/837</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>837</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>CN1C=C(C2=C1C=CC(=C2)[N+](=O)[O-])CC3=CC(=C(C=...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168275423</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1848361</td>\n",
       "      <td>482055793</td>\n",
       "      <td>168275423</td>\n",
       "      <td>NaN</td>\n",
       "      <td>36273428.0</td>\n",
       "      <td>Literature-derived</td>\n",
       "      <td>20230629</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>/taxonomy/837</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>837</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>CN1C=C(C2=C1C=CC(=C2)[N+](=O)[O-])CC3=CC(=C(C=...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>152 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           acvalue      aid        sid      cid.1  geneid        pmid  \\\n",
       "cid                                                                     \n",
       "5904          0.29  1437928  103165163       5904     NaN  28079378.0   \n",
       "155543311     2.30  1571234  440163866  155543311     NaN  30881614.0   \n",
       "155511868     2.40  1571234  440111790  155511868     NaN  30881614.0   \n",
       "155547676     3.70  1571234  440174844  155547676     NaN  30881614.0   \n",
       "155510814     4.30  1571234  440110233  155510814     NaN  30881614.0   \n",
       "...            ...      ...        ...        ...     ...         ...   \n",
       "162658036      NaN  1725206  461535923  162658036     NaN  33062172.0   \n",
       "162647428      NaN  1725205  461520763  162647428     NaN  33062172.0   \n",
       "162663043      NaN  1725205  461543092  162663043     NaN  33062172.0   \n",
       "168292812      NaN  1848340  482079746  168292812     NaN  36273428.0   \n",
       "168275423      NaN  1848361  482055793  168275423     NaN  36273428.0   \n",
       "\n",
       "                      aidtype  aidmdate  hasdrc  rnai  ...      targeturl  \\\n",
       "cid                                                    ...                  \n",
       "5904             Confirmatory  20220830       0     0  ...  /taxonomy/837   \n",
       "155543311        Confirmatory  20220830       0     0  ...  /taxonomy/837   \n",
       "155511868        Confirmatory  20220830       0     0  ...  /taxonomy/837   \n",
       "155547676        Confirmatory  20220830       0     0  ...  /taxonomy/837   \n",
       "155510814        Confirmatory  20220830       0     0  ...  /taxonomy/837   \n",
       "...                       ...       ...     ...   ...  ...            ...   \n",
       "162658036  Literature-derived  20220318       0     0  ...  /taxonomy/837   \n",
       "162647428  Literature-derived  20220318       0     0  ...  /taxonomy/837   \n",
       "162663043  Literature-derived  20220318       0     0  ...  /taxonomy/837   \n",
       "168292812  Literature-derived  20230629       0     0  ...  /taxonomy/837   \n",
       "168275423  Literature-derived  20230629       0     0  ...  /taxonomy/837   \n",
       "\n",
       "           ecs repacxn taxid cellids targettaxid tissueid tissuename  \\\n",
       "cid                                                                    \n",
       "5904       NaN     NaN   NaN     NaN         837      NaN        NaN   \n",
       "155543311  NaN     NaN   NaN     NaN         837      NaN        NaN   \n",
       "155511868  NaN     NaN   NaN     NaN         837      NaN        NaN   \n",
       "155547676  NaN     NaN   NaN     NaN         837      NaN        NaN   \n",
       "155510814  NaN     NaN   NaN     NaN         837      NaN        NaN   \n",
       "...        ...     ...   ...     ...         ...      ...        ...   \n",
       "162658036  NaN     NaN   NaN     NaN         837      NaN        NaN   \n",
       "162647428  NaN     NaN   NaN     NaN         837      NaN        NaN   \n",
       "162663043  NaN     NaN   NaN     NaN         837      NaN        NaN   \n",
       "168292812  NaN     NaN   NaN     NaN         837      NaN        NaN   \n",
       "168275423  NaN     NaN   NaN     NaN         837      NaN        NaN   \n",
       "\n",
       "          Antimicrobial                                             SMILES  \n",
       "cid                                                                         \n",
       "5904                  1    CC1(C(N2C(S1)C(C2=O)NC(=O)CC3=CC=CC=C3)C(=O)O)C  \n",
       "155543311             1  C1=CC(=CC=C1C2=NC(=C(O2)C3=CC=C(C=C3)F)C4=CC=C...  \n",
       "155511868             1  C1=CC=C(C(=C1)C2=NC(=C(O2)C3=CC=CO3)C4=CC=CO4)...  \n",
       "155547676             1  CCN(CC)C1=NC(=NC(=N1)C2=CN(N=N2)C3=CC=C(C=C3)C...  \n",
       "155510814             1  C1=CC=C(C=C1)C2=C(OC(=N2)C3=CC(=CC=C3)N4C=C(N=...  \n",
       "...                 ...                                                ...  \n",
       "162658036             1  CN1C=C(C2=C1C=CC(=C2)[N+](=O)[O-])CC3=CC(=C(C=...  \n",
       "162647428             0  CN1C=C(C2=CC=CC=C21)CC3=CC(=C(C=C3)OC)C(=O)NS(...  \n",
       "162663043             0  CN1C=C(C2=CC=CC=C21)CC3=CC(=C(C=C3)OC)C(=O)NS(...  \n",
       "168292812             1  CN1C=C(C2=C1C=CC(=C2)[N+](=O)[O-])CC3=CC(=C(C=...  \n",
       "168275423             1  CN1C=C(C2=C1C=CC(=C2)[N+](=O)[O-])CC3=CC(=C(C=...  \n",
       "\n",
       "[152 rows x 28 columns]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Raw_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "066559ff-aefe-4de1-98aa-04e6e2d7d8de",
   "metadata": {},
   "outputs": [],
   "source": [
    "y=Raw_data['Antimicrobial']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "8f04d536-af36-4f80-8c82-b43e30cbf6d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "Cv_model= RepeatedStratifiedKFold(n_splits=5, n_repeats=10, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdf835fc-df29-4f95-ac06-6cc88fa619f2",
   "metadata": {},
   "source": [
    "# 1. LASSO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "07038cde-c52d-4ba2-b851-445a650f8dc7",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.047e-03, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.409e-03, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.652e-03, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.462e-03, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.955e-03, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.698e-03, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.926e-03, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.010e-03, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.829e-03, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.850e-03, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.126e-02, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.046e-02, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.768e-03, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.866e-03, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.862e-03, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.915e-03, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.713e-03, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.051e-03, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.052e-02, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.646e-03, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.692e-03, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.344e-03, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.904e-03, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.568e-03, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.548e-03, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.906e-03, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.532e-03, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.391e-03, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.465e-03, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.949e-03, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.381e-02, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.458e-02, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.877e-02, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.132e-03, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.003e-02, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.268e-03, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.148e-02, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.608e-02, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.005e-02, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.619e-02, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.027e-02, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.929e-02, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.184e-02, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.478e-02, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.105e-02, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.924e-02, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.890e-02, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.082e-02, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.840e-02, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.607e-02, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.848e-02, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.525e-02, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.029e-03, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.079e-03, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.954e-03, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.448e-03, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.379e-03, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.520e-03, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.714e-03, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.300e-03, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.424e-03, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.762e-03, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.625e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.124e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.761e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.950e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.340e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.537e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.719e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.446e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.091e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.941e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.267e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.736e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.400e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.086e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.316e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.602e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.967e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.158e-03, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.750e-03, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.638e-03, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.293e-03, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.444e-03, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.614e-03, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.629e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.272e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.363e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.440e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.091e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.611e-03, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.022e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.290e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.015e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.054e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.231e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.433e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.116e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.494e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.714e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.460e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.196e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.814e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.050e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.992e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.567e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.364e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.189e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.597e-03, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.412e-03, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.847e-03, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.451e-03, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.583e-03, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.721e-03, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.024e-03, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.024e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.132e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.017e-03, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.295e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.372e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.678e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.238e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.873e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.800e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.678e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.612e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.072e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.353e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.233e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.558e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.292e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.632e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.948e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.630e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.792e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.322e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.408e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.145e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.740e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.957e-03, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.322e-03, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.824e-03, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.031e-02, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.862e-03, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.226e-03, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.201e-02, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.877e-02, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.411e-02, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.155e-02, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.027e-02, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.466e-03, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.323e-03, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.396e-02, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.188e-02, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.460e-02, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.805e-02, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.613e-02, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.549e-02, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.475e-02, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.647e-02, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.752e-02, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.783e-03, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.519e-03, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.171e-03, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.248e-03, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.260e-03, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.869e-03, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.823e-03, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.168e-03, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.268e-03, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.009e-03, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.805e-03, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.835e-03, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.751e-03, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.519e-03, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.859e-03, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.156e-03, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.725e-03, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.714e-03, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.842e-03, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.483e-03, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.880e-03, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.525e-03, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.629e-03, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.640e-03, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.854e-03, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.388e-03, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.237e-03, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.300e-03, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.658e-03, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.207e-03, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.164e-03, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.232e-03, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.049e-03, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.561e-03, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.311e-03, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.095e-03, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.371e-03, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.332e-03, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.052e-03, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.803e-03, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.045e-03, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.926e-03, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.018e-03, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.145e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.095e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.095e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.437e-03, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.943e-03, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.047e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.633e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.413e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.396e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.567e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.756e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.687e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.841e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.490e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.640e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.665e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.664e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.866e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.571e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.790e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.651e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.796e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.517e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.464e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.556e-03, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.226e-03, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.297e-03, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.798e-03, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.999e-03, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.504e-03, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.458e-03, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.301e-03, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.203e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.286e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.082e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.988e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.102e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.921e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.162e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.008e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.224e-03, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.368e-03, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.739e-03, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.862e-03, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.259e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.518e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.513e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.460e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.482e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.651e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.595e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.281e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.958e-03, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.958e-03, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.165e-03, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.052e-03, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.114e-03, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.752e-03, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.431e-03, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.267e-03, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.266e-03, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.388e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.160e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.531e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.486e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.285e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.994e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.126e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.403e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.791e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.696e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.600e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.773e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.999e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.232e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.563e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.625e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.862e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.874e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.109e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.084e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.619e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.385e-03, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.903e-03, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.859e-03, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.187e-03, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.842e-03, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.315e-03, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.372e-03, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.139e-03, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.633e-03, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.656e-03, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.594e-03, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.581e-03, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.330e-03, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.109e-03, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.598e-03, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.051e-03, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.684e-03, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.782e-03, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.725e-03, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.413e-03, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.483e-02, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.742e-02, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.932e-02, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.873e-02, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.667e-02, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.641e-02, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.423e-02, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.441e-02, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.020e-02, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.037e-03, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.156e-03, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.524e-03, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.926e-03, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.549e-03, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.620e-03, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.313e-03, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.334e-03, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.264e-03, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.103e-02, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.258e-02, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.540e-03, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.391e-02, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.295e-02, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.292e-02, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.177e-02, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.428e-02, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.544e-02, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.682e-02, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.456e-02, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.429e-02, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.560e-02, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.817e-02, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.184e-02, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.116e-02, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.043e-02, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.633e-02, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.089e-03, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.609e-03, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.957e-03, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.896e-03, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.976e-03, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.142e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.688e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.911e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.617e-03, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.481e-03, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.159e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.786e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.395e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.707e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.950e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.168e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.309e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.127e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.944e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.970e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.850e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.337e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.427e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.857e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.228e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.987e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.925e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.262e-03, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.637e-03, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.406e-03, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.870e-03, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.738e-03, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.185e-03, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.879e-03, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.426e-03, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.784e-03, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.234e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.149e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.535e-03, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.676e-03, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.727e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.071e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.003e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.347e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.530e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.185e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.500e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.637e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.667e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.519e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.061e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.477e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.344e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.465e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.181e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.400e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.334e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.420e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.775e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.805e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.402e-03, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.305e-03, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.492e-03, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.201e-03, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.351e-03, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.257e-03, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.177e-03, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.967e-03, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.925e-03, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.157e-03, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.234e-03, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.477e-03, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.341e-03, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.326e-03, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.152e-03, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.835e-03, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.007e-03, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.968e-03, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.903e-03, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.527e-03, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.542e-03, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.440e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.061e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.976e-03, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.490e-03, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.711e-03, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.283e-03, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.981e-03, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.833e-03, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.225e-03, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.284e-03, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.153e-02, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.138e-02, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.265e-02, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.531e-02, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.970e-02, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.863e-02, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.335e-02, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.231e-02, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.283e-02, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.493e-02, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.212e-02, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.453e-02, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.372e-02, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.377e-02, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.144e-02, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.047e-02, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.694e-02, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.330e-02, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.905e-02, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.873e-02, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.999e-02, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.754e-02, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.252e-03, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.522e-03, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.981e-03, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.566e-03, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.669e-03, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.396e-03, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.181e-02, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.654e-02, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.004e-03, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.134e-02, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.596e-02, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.376e-02, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.334e-02, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.705e-02, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.942e-02, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.835e-02, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.451e-02, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.654e-02, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.343e-02, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.009e-02, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.777e-02, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.149e-02, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.133e-02, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.373e-02, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.163e-02, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.186e-02, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.900e-02, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.571e-02, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.171e-02, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.216e-02, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.889e-02, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.193e-03, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.422e-03, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.992e-03, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.958e-03, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.795e-03, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.024e-03, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.602e-03, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.898e-03, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.701e-03, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.207e-03, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.530e-03, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.684e-03, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.935e-03, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.494e-03, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.846e-03, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.306e-03, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.286e-03, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.314e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.137e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.591e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.494e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.013e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.175e-03, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.329e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.094e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.980e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.828e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.413e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.925e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.164e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.229e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.098e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.069e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.254e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.045e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.289e-03, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.331e-03, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.943e-03, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.196e-03, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.006e-03, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.329e-03, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.980e-03, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.000e-03, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.012e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.057e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.442e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.134e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.384e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.091e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.259e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.672e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.324e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.267e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.531e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.483e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.189e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.174e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.428e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.051e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.088e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.738e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.979e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.409e-03, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.608e-03, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.041e-03, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.212e-03, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.741e-03, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.764e-03, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.455e-03, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.474e-03, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.047e-03, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.651e-03, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.484e-03, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.090e-03, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.672e-03, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.724e-03, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.013e-03, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.781e-03, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.339e-03, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.144e-03, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.963e-03, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.166e-02, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.208e-03, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.557e-03, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.071e-02, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.039e-02, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.802e-02, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.045e-02, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.961e-03, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.283e-02, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.722e-03, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.348e-02, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.876e-02, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.263e-02, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.206e-02, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.070e-02, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.256e-02, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.482e-02, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.668e-02, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.726e-02, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.437e-02, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.248e-02, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.780e-02, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.291e-02, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.818e-02, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.718e-02, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.586e-02, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.511e-02, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.622e-03, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.749e-03, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.953e-03, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.154e-03, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.751e-03, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.497e-03, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.961e-03, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.169e-02, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.019e-02, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.586e-03, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.774e-03, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.019e-02, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.127e-02, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.375e-02, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.144e-02, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.560e-02, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.489e-02, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.172e-02, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.933e-02, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.351e-02, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.358e-02, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.335e-02, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.769e-02, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.396e-02, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.604e-02, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.341e-02, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.417e-02, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.866e-02, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.209e-02, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.202e-02, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.853e-03, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.189e-03, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.850e-03, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.998e-03, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.445e-03, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.484e-03, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.104e-03, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.170e-03, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.451e-03, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.018e-03, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.566e-03, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.224e-03, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.615e-03, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.528e-03, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.977e-03, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.992e-03, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.532e-03, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.883e-03, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.064e-03, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.398e-03, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.851e-03, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.633e-03, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.806e-03, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.004e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.463e-03, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.065e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.576e-03, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.120e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.356e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.480e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.028e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.127e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.925e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.854e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.239e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.249e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.388e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.536e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.342e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.317e-03, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.968e-03, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.028e-03, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.391e-03, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.598e-03, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.525e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.384e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.210e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.240e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.057e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.419e-03, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.584e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.003e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.323e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.852e-03, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.651e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.214e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.024e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.970e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.958e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.828e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.051e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.376e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.192e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.883e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.532e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.039e-03, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.557e-03, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.160e-03, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.043e-03, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.686e-03, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.076e-02, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.567e-03, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.141e-03, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.257e-03, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.927e-03, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.525e-03, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.155e-02, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.266e-02, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.169e-02, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.115e-02, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.443e-02, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.517e-02, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.337e-02, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.574e-02, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.599e-02, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.039e-02, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.942e-02, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.996e-03, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.313e-03, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.760e-03, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.544e-03, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.102e-02, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.976e-03, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.193e-03, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.529e-03, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.590e-03, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.216e-02, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.748e-03, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.606e-02, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.307e-02, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.292e-02, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.323e-03, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.828e-03, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.148e-02, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.582e-02, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.287e-02, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.207e-02, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.563e-02, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.363e-02, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.716e-02, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.090e-02, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.612e-02, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.214e-02, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.518e-02, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.495e-02, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.561e-02, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.320e-02, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.597e-02, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.052e-02, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.547e-02, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.104e-03, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.086e-03, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.521e-03, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.477e-03, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.521e-03, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.967e-03, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.656e-03, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.804e-03, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.610e-03, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.935e-03, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.002e-03, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.839e-03, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.562e-03, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.877e-03, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.818e-03, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.493e-03, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.951e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.034e-03, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.112e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.366e-03, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.233e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.285e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.687e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.262e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.194e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.672e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.470e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.352e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.209e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.861e-03, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.851e-03, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.402e-03, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.110e-03, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.052e-03, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.526e-03, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.396e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.168e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.156e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.514e-03, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.675e-03, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.041e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.449e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.313e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.786e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.029e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.247e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.799e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.475e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.766e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.014e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.105e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.801e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.368e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.631e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.409e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.409e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.239e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.582e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.144e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.641e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.482e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.620e-03, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.396e-03, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.095e-03, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.525e-03, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.107e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.347e-03, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.006e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.658e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.937e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.572e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.698e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.666e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.241e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.482e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.584e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.232e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.558e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.567e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.151e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.014e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.875e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.274e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.587e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.680e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.713e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.753e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.954e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.065e-03, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.223e-03, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.878e-03, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.121e-03, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.616e-03, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.393e-03, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.300e-03, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.120e-02, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.207e-03, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.057e-02, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.634e-02, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.946e-03, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.010e-02, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.395e-03, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.204e-03, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.980e-03, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.605e-02, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.486e-02, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.428e-02, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.220e-02, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.308e-02, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.463e-02, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.732e-02, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.164e-02, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.707e-02, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.753e-02, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.664e-02, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.495e-02, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.220e-02, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.511e-02, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.681e-02, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.014e-03, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.841e-03, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.921e-03, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.690e-03, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.074e-03, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.593e-03, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.925e-03, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.564e-02, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.465e-02, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.312e-02, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.668e-03, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.405e-03, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.049e-02, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.638e-02, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.869e-02, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.101e-02, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.641e-02, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.688e-02, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.741e-02, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.398e-02, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.312e-02, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.252e-02, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.083e-02, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.147e-02, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.276e-02, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.455e-02, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.735e-02, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.796e-02, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.571e-02, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.361e-02, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.582e-03, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.115e-03, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.169e-03, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.174e-03, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.069e-03, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.487e-03, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.944e-03, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.304e-03, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.342e-03, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.761e-03, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.584e-03, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.683e-03, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.153e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.144e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.408e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.584e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.892e-03, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.239e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.009e-03, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.299e-03, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.590e-03, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.112e-03, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.497e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.062e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.248e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.661e-03, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.157e-03, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.690e-03, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.710e-03, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.037e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.827e-03, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.445e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.872e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.176e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.836e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.369e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.218e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.597e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.093e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.414e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.080e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.356e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.828e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.746e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.191e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.074e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.808e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.074e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.930e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.687e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.402e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.428e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.520e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.640e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.857e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.958e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.595e-03, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.168e-03, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.190e-03, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.632e-03, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.681e-03, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.257e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.263e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.320e-03, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.014e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.126e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.321e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.202e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.068e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.936e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.952e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.647e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.306e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.416e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.798e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.886e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.223e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.619e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.995e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.632e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.413e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.847e-03, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.558e-03, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.517e-03, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.709e-03, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.918e-03, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.831e-03, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.272e-03, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.547e-03, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.814e-03, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.506e-03, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.201e-03, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.307e-03, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.398e-03, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.151e-03, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.156e-03, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.127e-02, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.009e-02, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.053e-02, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.003e-02, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.012e-02, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.485e-02, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.282e-02, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.390e-02, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.294e-02, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.204e-02, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.079e-03, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.704e-03, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.360e-03, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.965e-03, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.955e-03, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.236e-02, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.874e-03, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.465e-02, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.665e-03, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.185e-02, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.877e-02, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.095e-02, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.759e-02, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.864e-02, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.905e-02, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.489e-02, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.427e-02, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.591e-02, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.132e-02, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.418e-02, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.181e-02, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.006e-02, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.510e-02, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.671e-02, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.668e-02, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.727e-02, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.276e-02, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.579e-02, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.827e-02, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.190e-02, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.493e-02, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.380e-02, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.715e-03, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.694e-03, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.475e-03, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.608e-03, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.239e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.923e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.009e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.288e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.724e-03, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.475e-03, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.303e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.156e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.945e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.034e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.317e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.812e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.357e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.971e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.426e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.719e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.152e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.634e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.735e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.747e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.365e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.963e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.470e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.729e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.790e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.981e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.417e-03, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.364e-03, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.593e-03, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.961e-03, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.432e-03, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.350e-03, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.389e-03, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.732e-03, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.645e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.215e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.316e-03, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.087e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.073e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.076e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.271e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.529e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.374e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.556e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.523e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.470e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.623e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.713e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.374e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.918e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.967e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.612e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.190e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.227e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.461e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.373e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.945e-03, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.536e-03, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.100e-03, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.203e-03, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.097e-03, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.531e-03, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.236e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.033e-03, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.840e-03, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.668e-03, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.013e-03, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.776e-03, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.843e-03, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.538e-03, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.111e-03, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.419e-03, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.053e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.034e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.940e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.791e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.972e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.727e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.698e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.111e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.276e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.977e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.062e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.668e-03, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.301e-03, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.041e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.017e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.304e-03, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.011e-03, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.930e-03, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.523e-03, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.095e-03, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.959e-03, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.255e-02, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.792e-03, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.866e-03, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.526e-03, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.128e-02, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.712e-02, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.984e-02, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.013e-03, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.389e-03, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.149e-02, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.534e-02, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.333e-02, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.659e-02, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.035e-02, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.879e-02, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.737e-02, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.354e-02, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.857e-02, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.050e-02, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.921e-02, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.931e-02, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.299e-02, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.933e-02, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.343e-02, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.805e-02, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.371e-02, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.041e-03, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.434e-03, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.995e-03, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.102e-03, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.344e-03, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.207e-03, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.414e-03, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.259e-03, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.144e-03, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.289e-02, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.435e-02, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.902e-02, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.438e-02, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.480e-02, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.718e-02, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.454e-02, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.973e-02, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.571e-02, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.619e-02, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.954e-02, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.656e-02, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.735e-02, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.139e-02, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.835e-02, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.377e-02, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.372e-02, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.082e-02, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.029e-02, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.740e-02, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.123e-03, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.781e-03, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.279e-03, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.119e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.759e-03, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.834e-03, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.860e-03, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.552e-03, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.673e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.965e-03, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.255e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.477e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.937e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.747e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.238e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.428e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.704e-03, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.915e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.400e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.984e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.659e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.793e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.546e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.534e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.097e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.698e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.251e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.743e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.749e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.806e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.732e-03, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.964e-03, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.136e-03, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.406e-03, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.589e-03, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.170e-03, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.267e-03, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.047e-03, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.323e-03, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.650e-03, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.079e-03, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.560e-03, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.045e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.444e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.798e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.201e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.754e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.925e-03, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.343e-03, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.987e-03, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.878e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.296e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.404e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.459e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.941e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.291e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.000e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.503e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.202e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.297e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.877e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.256e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.625e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.515e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.492e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.680e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.466e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.427e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.103e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.490e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.421e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.454e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.906e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.068e-03, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.198e-03, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.794e-03, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.770e-03, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.004e-03, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.989e-03, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.213e-03, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.567e-03, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.558e-03, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.374e-03, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.283e-03, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.041e-02, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.677e-02, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.366e-02, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.564e-02, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.787e-02, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.410e-02, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.371e-02, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.450e-02, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.538e-02, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.356e-02, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.912e-02, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.730e-02, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.155e-02, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.257e-02, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.343e-02, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.060e-02, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.964e-03, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.483e-03, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.131e-03, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.277e-03, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.380e-03, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.823e-03, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.071e-03, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.137e-03, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.068e-03, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.324e-02, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.073e-03, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.208e-02, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.090e-02, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.183e-03, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.578e-03, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.414e-02, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.224e-02, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.632e-02, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.216e-02, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.624e-02, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.706e-02, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.897e-02, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.544e-02, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.751e-02, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.787e-02, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.621e-02, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.242e-02, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.168e-02, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.390e-02, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.385e-02, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.444e-02, tolerance: 1.924e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.633e-03, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.868e-03, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.110e-03, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.685e-03, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.457e-03, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.831e-03, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.079e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.988e-03, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.307e-03, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.114e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.261e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.261e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.017e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.121e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.206e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.819e-03, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.151e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.085e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.397e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.271e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.300e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.842e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.514e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.459e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.624e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.868e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.930e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.030e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.645e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.231e-03, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.283e-03, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.954e-03, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.787e-03, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.787e-03, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.002e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.230e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.592e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.438e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.156e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.791e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.732e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.931e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.852e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.596e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.410e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.197e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.336e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.504e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.781e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.121e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.316e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.597e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.910e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.808e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.439e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.864e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.722e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.779e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.941e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.021e-03, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.271e-03, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.581e-03, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.219e-03, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.251e-03, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.959e-03, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.391e-03, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.052e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.840e-03, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.070e-03, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.110e-03, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.240e-03, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.571e-03, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.484e-03, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.067e-03, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.573e-03, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.612e-03, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.930e-03, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.936e-03, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.027e-03, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.102e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.568e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.811e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.866e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.988e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.551e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.510e-02, tolerance: 1.928e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    }
   ],
   "source": [
    "model = make_pipeline(StandardScaler(), LassoCV(cv=Cv_model)).fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "402b4353-a400-45cc-ba23-bddd8b9e5d4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x2b4b955c4c0>"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ymin, ymax =0, 1\n",
    "lasso = model[-1]\n",
    "plt.semilogx(lasso.alphas_, lasso.mse_path_, linestyle=\":\")\n",
    "plt.plot(\n",
    "    lasso.alphas_,\n",
    "    lasso.mse_path_.mean(axis=-1),\n",
    "    color=\"black\",\n",
    "    label=\"Average across the folds\",\n",
    "    linewidth=2,\n",
    ")\n",
    "plt.axvline(lasso.alpha_, linestyle=\"--\", color=\"black\", label=\"alpha: CV estimate\")\n",
    "\n",
    "plt.ylim(ymin, ymax)\n",
    "plt.xlabel(r\"$\\alpha$\")\n",
    "plt.ylabel(\"Mean square error\")\n",
    "plt.legend()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "5d8e3935-01a9-4adb-8939-18d9e9c2c150",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.03681162311584207"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lasso.alpha_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "0be9143b-967c-41fc-8e33-04f34afa9a5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "Cv_model= RepeatedStratifiedKFold(n_splits=5, n_repeats=10, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "d10f1531-da2b-4bb6-b83b-3558bdac2339",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.981e+00, tolerance: 2.408e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(152, 106)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lsvc =  Lasso(alpha=lasso.alpha_).fit(X, y)\n",
    "model = SelectFromModel(lsvc, prefit=True)\n",
    "X_new = model.transform(X)\n",
    "X_new.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "f7b74110-bf78-4a20-973b-7f81bf68a4a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>coef</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>MW</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AMW</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sv</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Se</th>\n",
       "      <td>-0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sp</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>s34_relSize</th>\n",
       "      <td>-0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>s34_phSize</th>\n",
       "      <td>-0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>s34_phRelSize</th>\n",
       "      <td>-0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chiralMoment</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chiralPhMoment</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2338 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                coef\n",
       "MW               0.0\n",
       "AMW              0.0\n",
       "Sv               0.0\n",
       "Se              -0.0\n",
       "Sp               0.0\n",
       "...              ...\n",
       "s34_relSize     -0.0\n",
       "s34_phSize      -0.0\n",
       "s34_phRelSize   -0.0\n",
       "chiralMoment     0.0\n",
       "chiralPhMoment   0.0\n",
       "\n",
       "[2338 rows x 1 columns]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lasso_coef=pd.DataFrame(lsvc.coef_)\n",
    "lasso_coef.index=X_NAomit_data.columns\n",
    "lasso_coef.columns=[\"coef\"]\n",
    "lasso_coef\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "013bbde3-8f0e-4b0f-9f7f-8ba774658777",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>coef</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>C%</th>\n",
       "      <td>0.011404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>D/Dtr05</th>\n",
       "      <td>0.000619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>D/Dtr06</th>\n",
       "      <td>-0.000364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>D/Dtr09</th>\n",
       "      <td>-0.002402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>D/Dtr10</th>\n",
       "      <td>-0.000844</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             coef\n",
       "C%       0.011404\n",
       "D/Dtr05  0.000619\n",
       "D/Dtr06 -0.000364\n",
       "D/Dtr09 -0.002402\n",
       "D/Dtr10 -0.000844"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lasso_coef_last=lasso_coef[(lasso_coef[\"coef\"]>0)|(lasso_coef[\"coef\"]<0)]\n",
    "lasso_coef_last.to_csv(\"./Supplementary Data S6.csv\",sep=',')\n",
    "lasso_coef_last.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "c39feec4-a989-406f-b6a2-1c3428dc3b3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>C%</th>\n",
       "      <th>D/Dtr05</th>\n",
       "      <th>D/Dtr06</th>\n",
       "      <th>D/Dtr09</th>\n",
       "      <th>D/Dtr10</th>\n",
       "      <th>D/Dtr12</th>\n",
       "      <th>ZM1</th>\n",
       "      <th>ZM2</th>\n",
       "      <th>ZM2V</th>\n",
       "      <th>ZM2Per</th>\n",
       "      <th>...</th>\n",
       "      <th>T(N..N)</th>\n",
       "      <th>T(N..O)</th>\n",
       "      <th>T(N..Cl)</th>\n",
       "      <th>T(O..O)</th>\n",
       "      <th>T(O..S)</th>\n",
       "      <th>T(O..F)</th>\n",
       "      <th>T(O..Cl)</th>\n",
       "      <th>T(F..F)</th>\n",
       "      <th>T(F..Cl)</th>\n",
       "      <th>SAtot</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5904</th>\n",
       "      <td>39.024390</td>\n",
       "      <td>56.454579</td>\n",
       "      <td>80.864924</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>126.0</td>\n",
       "      <td>152.0</td>\n",
       "      <td>341.0</td>\n",
       "      <td>539.21</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>440.881289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155543311</th>\n",
       "      <td>50.666667</td>\n",
       "      <td>322.395240</td>\n",
       "      <td>1148.925796</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>286.0</td>\n",
       "      <td>338.0</td>\n",
       "      <td>911.0</td>\n",
       "      <td>1414.98</td>\n",
       "      <td>...</td>\n",
       "      <td>178.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>117.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>729.676449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155511868</th>\n",
       "      <td>49.275362</td>\n",
       "      <td>509.581174</td>\n",
       "      <td>656.729638</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>266.0</td>\n",
       "      <td>317.0</td>\n",
       "      <td>868.0</td>\n",
       "      <td>1353.05</td>\n",
       "      <td>...</td>\n",
       "      <td>162.0</td>\n",
       "      <td>240.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>667.087164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155547676</th>\n",
       "      <td>43.037975</td>\n",
       "      <td>286.294025</td>\n",
       "      <td>674.312576</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>246.0</td>\n",
       "      <td>294.0</td>\n",
       "      <td>747.0</td>\n",
       "      <td>1168.42</td>\n",
       "      <td>...</td>\n",
       "      <td>178.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>263.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>792.530935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155510814</th>\n",
       "      <td>50.666667</td>\n",
       "      <td>281.886688</td>\n",
       "      <td>1047.929055</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>274.0</td>\n",
       "      <td>324.0</td>\n",
       "      <td>843.0</td>\n",
       "      <td>1308.73</td>\n",
       "      <td>...</td>\n",
       "      <td>170.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>724.008885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162658036</th>\n",
       "      <td>42.105263</td>\n",
       "      <td>91.143397</td>\n",
       "      <td>377.011690</td>\n",
       "      <td>168.764086</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>198.0</td>\n",
       "      <td>235.0</td>\n",
       "      <td>662.0</td>\n",
       "      <td>1029.20</td>\n",
       "      <td>...</td>\n",
       "      <td>59.0</td>\n",
       "      <td>266.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>266.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>597.964156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162647428</th>\n",
       "      <td>45.283019</td>\n",
       "      <td>74.684849</td>\n",
       "      <td>316.158038</td>\n",
       "      <td>140.260700</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>172.0</td>\n",
       "      <td>204.0</td>\n",
       "      <td>524.0</td>\n",
       "      <td>818.44</td>\n",
       "      <td>...</td>\n",
       "      <td>8.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>524.945211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162663043</th>\n",
       "      <td>45.283019</td>\n",
       "      <td>75.103709</td>\n",
       "      <td>317.533159</td>\n",
       "      <td>140.991859</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>172.0</td>\n",
       "      <td>204.0</td>\n",
       "      <td>524.0</td>\n",
       "      <td>818.13</td>\n",
       "      <td>...</td>\n",
       "      <td>8.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>524.945211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168292812</th>\n",
       "      <td>43.636364</td>\n",
       "      <td>83.386306</td>\n",
       "      <td>347.351528</td>\n",
       "      <td>154.585411</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>188.0</td>\n",
       "      <td>224.0</td>\n",
       "      <td>611.0</td>\n",
       "      <td>954.71</td>\n",
       "      <td>...</td>\n",
       "      <td>23.0</td>\n",
       "      <td>124.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>124.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>587.799641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168275423</th>\n",
       "      <td>43.636364</td>\n",
       "      <td>83.386306</td>\n",
       "      <td>347.351528</td>\n",
       "      <td>154.585411</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>188.0</td>\n",
       "      <td>224.0</td>\n",
       "      <td>611.0</td>\n",
       "      <td>954.71</td>\n",
       "      <td>...</td>\n",
       "      <td>23.0</td>\n",
       "      <td>124.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>124.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>581.439694</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>152 rows × 106 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  C%     D/Dtr05      D/Dtr06     D/Dtr09  D/Dtr10  D/Dtr12  \\\n",
       "CID                                                                           \n",
       "5904       39.024390   56.454579    80.864924    0.000000      0.0      0.0   \n",
       "155543311  50.666667  322.395240  1148.925796    0.000000      0.0      0.0   \n",
       "155511868  49.275362  509.581174   656.729638    0.000000      0.0      0.0   \n",
       "155547676  43.037975  286.294025   674.312576    0.000000      0.0      0.0   \n",
       "155510814  50.666667  281.886688  1047.929055    0.000000      0.0      0.0   \n",
       "...              ...         ...          ...         ...      ...      ...   \n",
       "162658036  42.105263   91.143397   377.011690  168.764086      0.0      0.0   \n",
       "162647428  45.283019   74.684849   316.158038  140.260700      0.0      0.0   \n",
       "162663043  45.283019   75.103709   317.533159  140.991859      0.0      0.0   \n",
       "168292812  43.636364   83.386306   347.351528  154.585411      0.0      0.0   \n",
       "168275423  43.636364   83.386306   347.351528  154.585411      0.0      0.0   \n",
       "\n",
       "             ZM1    ZM2   ZM2V   ZM2Per  ...  T(N..N)  T(N..O)  T(N..Cl)  \\\n",
       "CID                                      ...                               \n",
       "5904       126.0  152.0  341.0   539.21  ...      3.0     30.0       0.0   \n",
       "155543311  286.0  338.0  911.0  1414.98  ...    178.0     79.0       0.0   \n",
       "155511868  266.0  317.0  868.0  1353.05  ...    162.0    240.0       0.0   \n",
       "155547676  246.0  294.0  747.0  1168.42  ...    178.0     79.0     263.0   \n",
       "155510814  274.0  324.0  843.0  1308.73  ...    170.0     71.0       0.0   \n",
       "...          ...    ...    ...      ...  ...      ...      ...       ...   \n",
       "162658036  198.0  235.0  662.0  1029.20  ...     59.0    266.0       0.0   \n",
       "162647428  172.0  204.0  524.0   818.44  ...      8.0     46.0       0.0   \n",
       "162663043  172.0  204.0  524.0   818.13  ...      8.0     46.0       0.0   \n",
       "168292812  188.0  224.0  611.0   954.71  ...     23.0    124.0       0.0   \n",
       "168275423  188.0  224.0  611.0   954.71  ...     23.0    124.0      30.0   \n",
       "\n",
       "           T(O..O)  T(O..S)  T(O..F)  T(O..Cl)  T(F..F)  T(F..Cl)       SAtot  \n",
       "CID                                                                            \n",
       "5904          33.0     17.0      0.0       0.0      0.0       0.0  440.881289  \n",
       "155543311      0.0      0.0     47.0       0.0    117.0       0.0  729.676449  \n",
       "155511868     12.0      0.0    102.0       0.0     14.0       0.0  667.087164  \n",
       "155547676      0.0      0.0      0.0      13.0      0.0       0.0  792.530935  \n",
       "155510814      0.0      0.0     32.0       0.0     14.0       0.0  724.008885  \n",
       "...            ...      ...      ...       ...      ...       ...         ...  \n",
       "162658036    266.0     44.0      0.0       0.0      0.0       0.0  597.964156  \n",
       "162647428     26.0      8.0     26.0       0.0      0.0       0.0  524.945211  \n",
       "162663043     26.0      8.0     30.0       0.0      0.0       0.0  524.945211  \n",
       "168292812    124.0     32.0      0.0       0.0      0.0       0.0  587.799641  \n",
       "168275423    124.0     32.0      0.0      52.0      0.0       0.0  581.439694  \n",
       "\n",
       "[152 rows x 106 columns]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Lasso_data=X_NAomit_data[X_NAomit_data.columns[model.get_support()]]\n",
    "Lasso_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "afcca2a8-9ce0-4c49-88db-c3265e6374fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "Lasso_data.to_csv('./Lasso_data.csv',encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "c9c9a6da-b735-4689-897c-972cd30e5f64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>C%</th>\n",
       "      <th>D/Dtr05</th>\n",
       "      <th>D/Dtr06</th>\n",
       "      <th>D/Dtr09</th>\n",
       "      <th>D/Dtr10</th>\n",
       "      <th>D/Dtr12</th>\n",
       "      <th>ZM1</th>\n",
       "      <th>ZM2</th>\n",
       "      <th>ZM2V</th>\n",
       "      <th>ZM2Per</th>\n",
       "      <th>...</th>\n",
       "      <th>T(N..N)</th>\n",
       "      <th>T(N..O)</th>\n",
       "      <th>T(N..Cl)</th>\n",
       "      <th>T(O..O)</th>\n",
       "      <th>T(O..S)</th>\n",
       "      <th>T(O..F)</th>\n",
       "      <th>T(O..Cl)</th>\n",
       "      <th>T(F..F)</th>\n",
       "      <th>T(F..Cl)</th>\n",
       "      <th>SAtot</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cid</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5904</th>\n",
       "      <td>0.486494</td>\n",
       "      <td>0.056855</td>\n",
       "      <td>0.054438</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.154762</td>\n",
       "      <td>0.173759</td>\n",
       "      <td>0.175722</td>\n",
       "      <td>0.183841</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000790</td>\n",
       "      <td>0.005207</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.009011</td>\n",
       "      <td>0.386364</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.100661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155543311</th>\n",
       "      <td>0.968459</td>\n",
       "      <td>0.324682</td>\n",
       "      <td>0.773458</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.472222</td>\n",
       "      <td>0.503546</td>\n",
       "      <td>0.659593</td>\n",
       "      <td>0.666737</td>\n",
       "      <td>...</td>\n",
       "      <td>0.046891</td>\n",
       "      <td>0.013713</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.279762</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.225245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155511868</th>\n",
       "      <td>0.910862</td>\n",
       "      <td>0.513195</td>\n",
       "      <td>0.442111</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.432540</td>\n",
       "      <td>0.466312</td>\n",
       "      <td>0.623090</td>\n",
       "      <td>0.632589</td>\n",
       "      <td>...</td>\n",
       "      <td>0.042677</td>\n",
       "      <td>0.041659</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003277</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.607143</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.119658</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.198244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155547676</th>\n",
       "      <td>0.652647</td>\n",
       "      <td>0.288324</td>\n",
       "      <td>0.453948</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.392857</td>\n",
       "      <td>0.425532</td>\n",
       "      <td>0.520374</td>\n",
       "      <td>0.530784</td>\n",
       "      <td>...</td>\n",
       "      <td>0.046891</td>\n",
       "      <td>0.013713</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.245283</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.252360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155510814</th>\n",
       "      <td>0.968459</td>\n",
       "      <td>0.283886</td>\n",
       "      <td>0.705467</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.448413</td>\n",
       "      <td>0.478723</td>\n",
       "      <td>0.601868</td>\n",
       "      <td>0.608151</td>\n",
       "      <td>...</td>\n",
       "      <td>0.044784</td>\n",
       "      <td>0.012324</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.190476</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.119658</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.222800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162658036</th>\n",
       "      <td>0.614035</td>\n",
       "      <td>0.091790</td>\n",
       "      <td>0.253805</td>\n",
       "      <td>0.210738</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.297619</td>\n",
       "      <td>0.320922</td>\n",
       "      <td>0.448217</td>\n",
       "      <td>0.454019</td>\n",
       "      <td>...</td>\n",
       "      <td>0.015543</td>\n",
       "      <td>0.046173</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.072638</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.168425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162647428</th>\n",
       "      <td>0.745587</td>\n",
       "      <td>0.075215</td>\n",
       "      <td>0.212838</td>\n",
       "      <td>0.175146</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.246032</td>\n",
       "      <td>0.265957</td>\n",
       "      <td>0.331070</td>\n",
       "      <td>0.337807</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002107</td>\n",
       "      <td>0.007985</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.007100</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.154762</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.136926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162663043</th>\n",
       "      <td>0.745587</td>\n",
       "      <td>0.075636</td>\n",
       "      <td>0.213764</td>\n",
       "      <td>0.176059</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.246032</td>\n",
       "      <td>0.265957</td>\n",
       "      <td>0.331070</td>\n",
       "      <td>0.337636</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002107</td>\n",
       "      <td>0.007985</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.007100</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.178571</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.136926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168292812</th>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.083978</td>\n",
       "      <td>0.233837</td>\n",
       "      <td>0.193033</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.277778</td>\n",
       "      <td>0.301418</td>\n",
       "      <td>0.404924</td>\n",
       "      <td>0.412946</td>\n",
       "      <td>...</td>\n",
       "      <td>0.006059</td>\n",
       "      <td>0.021524</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.033861</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.164041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168275423</th>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.083978</td>\n",
       "      <td>0.233837</td>\n",
       "      <td>0.193033</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.277778</td>\n",
       "      <td>0.301418</td>\n",
       "      <td>0.404924</td>\n",
       "      <td>0.412946</td>\n",
       "      <td>...</td>\n",
       "      <td>0.006059</td>\n",
       "      <td>0.021524</td>\n",
       "      <td>0.114068</td>\n",
       "      <td>0.033861</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.981132</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.161297</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>152 rows × 106 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 C%   D/Dtr05   D/Dtr06   D/Dtr09  D/Dtr10  D/Dtr12       ZM1  \\\n",
       "cid                                                                             \n",
       "5904       0.486494  0.056855  0.054438  0.000000      0.0      0.0  0.154762   \n",
       "155543311  0.968459  0.324682  0.773458  0.000000      0.0      0.0  0.472222   \n",
       "155511868  0.910862  0.513195  0.442111  0.000000      0.0      0.0  0.432540   \n",
       "155547676  0.652647  0.288324  0.453948  0.000000      0.0      0.0  0.392857   \n",
       "155510814  0.968459  0.283886  0.705467  0.000000      0.0      0.0  0.448413   \n",
       "...             ...       ...       ...       ...      ...      ...       ...   \n",
       "162658036  0.614035  0.091790  0.253805  0.210738      0.0      0.0  0.297619   \n",
       "162647428  0.745587  0.075215  0.212838  0.175146      0.0      0.0  0.246032   \n",
       "162663043  0.745587  0.075636  0.213764  0.176059      0.0      0.0  0.246032   \n",
       "168292812  0.677419  0.083978  0.233837  0.193033      0.0      0.0  0.277778   \n",
       "168275423  0.677419  0.083978  0.233837  0.193033      0.0      0.0  0.277778   \n",
       "\n",
       "                ZM2      ZM2V    ZM2Per  ...   T(N..N)   T(N..O)  T(N..Cl)  \\\n",
       "cid                                      ...                                 \n",
       "5904       0.173759  0.175722  0.183841  ...  0.000790  0.005207  0.000000   \n",
       "155543311  0.503546  0.659593  0.666737  ...  0.046891  0.013713  0.000000   \n",
       "155511868  0.466312  0.623090  0.632589  ...  0.042677  0.041659  0.000000   \n",
       "155547676  0.425532  0.520374  0.530784  ...  0.046891  0.013713  1.000000   \n",
       "155510814  0.478723  0.601868  0.608151  ...  0.044784  0.012324  0.000000   \n",
       "...             ...       ...       ...  ...       ...       ...       ...   \n",
       "162658036  0.320922  0.448217  0.454019  ...  0.015543  0.046173  0.000000   \n",
       "162647428  0.265957  0.331070  0.337807  ...  0.002107  0.007985  0.000000   \n",
       "162663043  0.265957  0.331070  0.337636  ...  0.002107  0.007985  0.000000   \n",
       "168292812  0.301418  0.404924  0.412946  ...  0.006059  0.021524  0.000000   \n",
       "168275423  0.301418  0.404924  0.412946  ...  0.006059  0.021524  0.114068   \n",
       "\n",
       "            T(O..O)   T(O..S)   T(O..F)  T(O..Cl)   T(F..F)  T(F..Cl)  \\\n",
       "cid                                                                     \n",
       "5904       0.009011  0.386364  0.000000  0.000000  0.000000       0.0   \n",
       "155543311  0.000000  0.000000  0.279762  0.000000  1.000000       0.0   \n",
       "155511868  0.003277  0.000000  0.607143  0.000000  0.119658       0.0   \n",
       "155547676  0.000000  0.000000  0.000000  0.245283  0.000000       0.0   \n",
       "155510814  0.000000  0.000000  0.190476  0.000000  0.119658       0.0   \n",
       "...             ...       ...       ...       ...       ...       ...   \n",
       "162658036  0.072638  1.000000  0.000000  0.000000  0.000000       0.0   \n",
       "162647428  0.007100  0.181818  0.154762  0.000000  0.000000       0.0   \n",
       "162663043  0.007100  0.181818  0.178571  0.000000  0.000000       0.0   \n",
       "168292812  0.033861  0.727273  0.000000  0.000000  0.000000       0.0   \n",
       "168275423  0.033861  0.727273  0.000000  0.981132  0.000000       0.0   \n",
       "\n",
       "              SAtot  \n",
       "cid                  \n",
       "5904       0.100661  \n",
       "155543311  0.225245  \n",
       "155511868  0.198244  \n",
       "155547676  0.252360  \n",
       "155510814  0.222800  \n",
       "...             ...  \n",
       "162658036  0.168425  \n",
       "162647428  0.136926  \n",
       "162663043  0.136926  \n",
       "168292812  0.164041  \n",
       "168275423  0.161297  \n",
       "\n",
       "[152 rows x 106 columns]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Scale data\n",
    "Scaler = preprocessing.MinMaxScaler() #StandardScaler\n",
    "Transformer =Scaler.fit(Lasso_data)\n",
    "X_scaled_data=Transformer.transform(Lasso_data)\n",
    "X_scaled_data =pd.DataFrame(X_scaled_data)\n",
    "X_scaled_data.columns=Lasso_data.columns\n",
    "X_scaled_data.index=Raw_data.index\n",
    "\n",
    "joblib.dump(Transformer, './Lasso_Scaler_transformer.pkl')\n",
    "\n",
    "X_scaled_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "2c0643c9-e6ee-441f-a6e6-f8951935a04a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Model_results(Model_clf,X_test,y,Cv_model):\n",
    "    Model_scores= cross_validate(estimator=Model_clf, X=X_test, y=y, cv=Cv_model,scoring=( 'accuracy','f1','precision','recall','roc_auc'), return_train_score=True)\n",
    "    Model_score= cross_validate(estimator=Model_clf, X=X_test, y=y, cv=Cv_model,scoring=( 'accuracy','f1','precision','recall','roc_auc'), return_train_score=False)\n",
    "#Accuracy\n",
    "    Model_Accuracy_test_mean=Model_scores['test_accuracy'].mean()\n",
    "    Model_Accuracy_test_se=(Model_scores['test_accuracy'].std()/math.sqrt(len(Model_scores['test_accuracy']))) \n",
    "    Model_Accuracy_train_mean=Model_scores['train_accuracy'].mean()\n",
    "    Model_Accuracy_train_se=(Model_scores['train_accuracy'].std()/math.sqrt(len(Model_scores['train_accuracy']))) \n",
    "#f1\n",
    "    Model_f1_mean=Model_score['test_f1'].mean()\n",
    "    Model_f1_se=(Model_score['test_f1'].std()/math.sqrt(len(Model_score['test_f1']))) \n",
    "#precision\n",
    "    Model_precision_mean=Model_score['test_precision'].mean()\n",
    "    Model_precision_se=(Model_score['test_precision'].std()/math.sqrt(len(Model_score['test_precision']))) \n",
    "#recall\n",
    "    Model_recall_mean=Model_score['test_recall'].mean()\n",
    "    Model_recall_se=(Model_score['test_recall'].std()/math.sqrt(len(Model_score['test_recall']))) \n",
    "#roc_auc\n",
    "    Model_roc_auc_mean=Model_score['test_roc_auc'].mean()\n",
    "    Model_roc_auc_se=(Model_score['test_roc_auc'].std()/math.sqrt(len(Model_score['test_roc_auc']))) \n",
    "    Model = {'Mean':[Model_Accuracy_test_mean,Model_Accuracy_train_mean,Model_f1_mean,Model_precision_mean,Model_recall_mean,Model_roc_auc_mean],\n",
    "        'Se':[Model_Accuracy_test_se,Model_Accuracy_train_se,Model_f1_se,Model_precision_se,Model_recall_se,Model_roc_auc_se]}\n",
    "    Model = pd.DataFrame(Model, index=['Accuracy_test','Accuracy_train','F1 Score','Precision','Recall','Roc_auc']) # 这里设定了 index 个数要和列表长度一致\n",
    "    return Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "0e49d1bb-d5f4-4e7f-a620-a943c578fba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setting the KFold \n",
    "Cv_optuna= RepeatedStratifiedKFold(n_splits=5, n_repeats=10, random_state=0)\n",
    "Cv_model= RepeatedStratifiedKFold(n_splits=5, n_repeats=10, random_state=0)\n",
    "Cv_RFECV= RepeatedStratifiedKFold(n_splits=5, n_repeats=10, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "8b74394b-d874-4115-b66e-0bac0d514965",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data pre-processing of models\n",
    "X=np.array(X_scaled_data)\n",
    "y=Raw_data['Antimicrobial'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d026e47-e8b2-467a-a5a0-866a1888a801",
   "metadata": {},
   "source": [
    "## 1.1 DT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "e5dd9da6-318e-4a8f-8b6e-46380439376d",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf=DecisionTreeClassifier(random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "9d7e67d4-b288-4270-be5d-1598f117e05d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mean</th>\n",
       "      <th>Se</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Accuracy_test</th>\n",
       "      <td>0.815828</td>\n",
       "      <td>0.008490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Accuracy_train</th>\n",
       "      <td>0.994904</td>\n",
       "      <td>0.000564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1 Score</th>\n",
       "      <td>0.493578</td>\n",
       "      <td>0.026905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Precision</th>\n",
       "      <td>0.541437</td>\n",
       "      <td>0.030501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recall</th>\n",
       "      <td>0.483333</td>\n",
       "      <td>0.029907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Roc_auc</th>\n",
       "      <td>0.692214</td>\n",
       "      <td>0.015877</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Mean        Se\n",
       "Accuracy_test   0.815828  0.008490\n",
       "Accuracy_train  0.994904  0.000564\n",
       "F1 Score        0.493578  0.026905\n",
       "Precision       0.541437  0.030501\n",
       "Recall          0.483333  0.029907\n",
       "Roc_auc         0.692214  0.015877"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Model1 （4175 descriptors）\n",
    "Model1_clf=clf\n",
    "#Model1\n",
    "Model1=Model_results(Model1_clf,X,y,Cv_model)\n",
    "Model1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "7bb0633b-59c6-4ad7-afb1-e241f713f990",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2024-11-14 02:23:20,205]\u001b[0m A new study created in memory with name: no-name-e621ba15-ded6-42b9-b513-205e4f62a77f\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 02:23:23,393]\u001b[0m Trial 0 finished with value: 0.7875268817204301 and parameters: {'max_depth': 4, 'max_features': 17, 'min_samples_split': 16}. Best is trial 0 with value: 0.7875268817204301.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 02:23:23,438]\u001b[0m Trial 1 finished with value: 0.8065806451612905 and parameters: {'max_depth': 4, 'max_features': 14, 'min_samples_split': 17}. Best is trial 1 with value: 0.8065806451612905.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 02:23:23,477]\u001b[0m Trial 2 finished with value: 0.770989247311828 and parameters: {'max_depth': 4, 'max_features': 19, 'min_samples_split': 25}. Best is trial 1 with value: 0.8065806451612905.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 02:23:23,512]\u001b[0m Trial 3 finished with value: 0.7895483870967743 and parameters: {'max_depth': 4, 'max_features': 18, 'min_samples_split': 14}. Best is trial 1 with value: 0.8065806451612905.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 02:23:23,549]\u001b[0m Trial 4 finished with value: 0.8047096774193548 and parameters: {'max_depth': 4, 'max_features': 20, 'min_samples_split': 3}. Best is trial 1 with value: 0.8065806451612905.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 02:23:23,587]\u001b[0m Trial 5 finished with value: 0.8202580645161289 and parameters: {'max_depth': 3, 'max_features': 10, 'min_samples_split': 21}. Best is trial 5 with value: 0.8202580645161289.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 02:23:23,622]\u001b[0m Trial 6 finished with value: 0.7670107526881721 and parameters: {'max_depth': 5, 'max_features': 19, 'min_samples_split': 25}. Best is trial 5 with value: 0.8202580645161289.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 02:23:23,654]\u001b[0m Trial 7 finished with value: 0.7815483870967742 and parameters: {'max_depth': 5, 'max_features': 15, 'min_samples_split': 20}. Best is trial 5 with value: 0.8202580645161289.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 02:23:23,693]\u001b[0m Trial 8 finished with value: 0.7801720430107528 and parameters: {'max_depth': 3, 'max_features': 17, 'min_samples_split': 5}. Best is trial 5 with value: 0.8202580645161289.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 02:23:23,731]\u001b[0m Trial 9 finished with value: 0.7960215053763442 and parameters: {'max_depth': 5, 'max_features': 15, 'min_samples_split': 11}. Best is trial 5 with value: 0.8202580645161289.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 02:23:23,768]\u001b[0m Trial 10 finished with value: 0.8156344086021505 and parameters: {'max_depth': 3, 'max_features': 10, 'min_samples_split': 9}. Best is trial 5 with value: 0.8202580645161289.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 02:23:23,812]\u001b[0m Trial 11 finished with value: 0.8169247311827958 and parameters: {'max_depth': 3, 'max_features': 10, 'min_samples_split': 10}. Best is trial 5 with value: 0.8202580645161289.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 02:23:23,845]\u001b[0m Trial 12 finished with value: 0.8156344086021505 and parameters: {'max_depth': 3, 'max_features': 10, 'min_samples_split': 8}. Best is trial 5 with value: 0.8202580645161289.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 02:23:23,883]\u001b[0m Trial 13 finished with value: 0.7723010752688172 and parameters: {'max_depth': 3, 'max_features': 12, 'min_samples_split': 20}. Best is trial 5 with value: 0.8202580645161289.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 02:23:23,917]\u001b[0m Trial 14 finished with value: 0.7723010752688172 and parameters: {'max_depth': 3, 'max_features': 12, 'min_samples_split': 20}. Best is trial 5 with value: 0.8202580645161289.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 02:23:23,949]\u001b[0m Trial 15 finished with value: 0.7953333333333333 and parameters: {'max_depth': 3, 'max_features': 12, 'min_samples_split': 10}. Best is trial 5 with value: 0.8202580645161289.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 02:23:23,986]\u001b[0m Trial 16 finished with value: 0.8033548387096774 and parameters: {'max_depth': 3, 'max_features': 11, 'min_samples_split': 12}. Best is trial 5 with value: 0.8202580645161289.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 02:23:24,024]\u001b[0m Trial 17 finished with value: 0.8293333333333334 and parameters: {'max_depth': 3, 'max_features': 13, 'min_samples_split': 7}. Best is trial 17 with value: 0.8293333333333334.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 02:23:24,060]\u001b[0m Trial 18 finished with value: 0.817010752688172 and parameters: {'max_depth': 4, 'max_features': 14, 'min_samples_split': 6}. Best is trial 17 with value: 0.8293333333333334.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 02:23:24,097]\u001b[0m Trial 19 finished with value: 0.821462365591398 and parameters: {'max_depth': 3, 'max_features': 13, 'min_samples_split': 2}. Best is trial 17 with value: 0.8293333333333334.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 02:23:24,133]\u001b[0m Trial 20 finished with value: 0.8320000000000001 and parameters: {'max_depth': 4, 'max_features': 13, 'min_samples_split': 2}. Best is trial 20 with value: 0.8320000000000001.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 02:23:24,166]\u001b[0m Trial 21 finished with value: 0.8320000000000001 and parameters: {'max_depth': 4, 'max_features': 13, 'min_samples_split': 2}. Best is trial 20 with value: 0.8320000000000001.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 02:23:24,211]\u001b[0m Trial 22 finished with value: 0.8163870967741935 and parameters: {'max_depth': 4, 'max_features': 14, 'min_samples_split': 5}. Best is trial 20 with value: 0.8320000000000001.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 02:23:24,248]\u001b[0m Trial 23 finished with value: 0.8293763440860217 and parameters: {'max_depth': 5, 'max_features': 13, 'min_samples_split': 2}. Best is trial 20 with value: 0.8320000000000001.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 02:23:24,284]\u001b[0m Trial 24 finished with value: 0.8353548387096775 and parameters: {'max_depth': 5, 'max_features': 13, 'min_samples_split': 3}. Best is trial 24 with value: 0.8353548387096775.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 02:23:24,326]\u001b[0m Trial 25 finished with value: 0.8071397849462365 and parameters: {'max_depth': 5, 'max_features': 16, 'min_samples_split': 4}. Best is trial 24 with value: 0.8353548387096775.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 02:23:24,365]\u001b[0m Trial 26 finished with value: 0.8256344086021506 and parameters: {'max_depth': 4, 'max_features': 11, 'min_samples_split': 4}. Best is trial 24 with value: 0.8353548387096775.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 02:23:24,403]\u001b[0m Trial 27 finished with value: 0.8293763440860217 and parameters: {'max_depth': 5, 'max_features': 13, 'min_samples_split': 2}. Best is trial 24 with value: 0.8353548387096775.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 02:23:24,442]\u001b[0m Trial 28 finished with value: 0.7993333333333332 and parameters: {'max_depth': 4, 'max_features': 16, 'min_samples_split': 7}. Best is trial 24 with value: 0.8353548387096775.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 02:23:24,479]\u001b[0m Trial 29 finished with value: 0.8124516129032259 and parameters: {'max_depth': 4, 'max_features': 14, 'min_samples_split': 4}. Best is trial 24 with value: 0.8353548387096775.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 02:23:24,514]\u001b[0m Trial 30 finished with value: 0.8354838709677418 and parameters: {'max_depth': 5, 'max_features': 11, 'min_samples_split': 6}. Best is trial 30 with value: 0.8354838709677418.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 02:23:24,550]\u001b[0m Trial 31 finished with value: 0.8354838709677418 and parameters: {'max_depth': 5, 'max_features': 11, 'min_samples_split': 6}. Best is trial 30 with value: 0.8354838709677418.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 02:23:24,584]\u001b[0m Trial 32 finished with value: 0.8354838709677418 and parameters: {'max_depth': 5, 'max_features': 11, 'min_samples_split': 6}. Best is trial 30 with value: 0.8354838709677418.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 02:23:24,617]\u001b[0m Trial 33 finished with value: 0.8394193548387097 and parameters: {'max_depth': 5, 'max_features': 11, 'min_samples_split': 7}. Best is trial 33 with value: 0.8394193548387097.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 02:23:24,652]\u001b[0m Trial 34 finished with value: 0.8225376344086022 and parameters: {'max_depth': 5, 'max_features': 11, 'min_samples_split': 14}. Best is trial 33 with value: 0.8394193548387097.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 02:23:24,688]\u001b[0m Trial 35 finished with value: 0.8367956989247312 and parameters: {'max_depth': 5, 'max_features': 11, 'min_samples_split': 8}. Best is trial 33 with value: 0.8394193548387097.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 02:23:24,724]\u001b[0m Trial 36 finished with value: 0.8118494623655915 and parameters: {'max_depth': 5, 'max_features': 12, 'min_samples_split': 8}. Best is trial 33 with value: 0.8394193548387097.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 02:23:24,765]\u001b[0m Trial 37 finished with value: 0.8244301075268816 and parameters: {'max_depth': 5, 'max_features': 11, 'min_samples_split': 13}. Best is trial 33 with value: 0.8394193548387097.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 02:23:24,801]\u001b[0m Trial 38 finished with value: 0.8053118279569894 and parameters: {'max_depth': 5, 'max_features': 10, 'min_samples_split': 16}. Best is trial 33 with value: 0.8394193548387097.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 02:23:24,838]\u001b[0m Trial 39 finished with value: 0.8053333333333333 and parameters: {'max_depth': 5, 'max_features': 12, 'min_samples_split': 9}. Best is trial 33 with value: 0.8394193548387097.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 02:23:24,876]\u001b[0m Trial 40 finished with value: 0.8354838709677418 and parameters: {'max_depth': 5, 'max_features': 11, 'min_samples_split': 6}. Best is trial 33 with value: 0.8394193548387097.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 02:23:24,911]\u001b[0m Trial 41 finished with value: 0.8354838709677418 and parameters: {'max_depth': 5, 'max_features': 11, 'min_samples_split': 6}. Best is trial 33 with value: 0.8394193548387097.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 02:23:24,945]\u001b[0m Trial 42 finished with value: 0.8131397849462365 and parameters: {'max_depth': 5, 'max_features': 10, 'min_samples_split': 8}. Best is trial 33 with value: 0.8394193548387097.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 02:23:24,979]\u001b[0m Trial 43 finished with value: 0.83352688172043 and parameters: {'max_depth': 5, 'max_features': 11, 'min_samples_split': 5}. Best is trial 33 with value: 0.8394193548387097.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 02:23:25,013]\u001b[0m Trial 44 finished with value: 0.8170752688172043 and parameters: {'max_depth': 5, 'max_features': 12, 'min_samples_split': 7}. Best is trial 33 with value: 0.8394193548387097.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 02:23:25,048]\u001b[0m Trial 45 finished with value: 0.8144516129032259 and parameters: {'max_depth': 5, 'max_features': 10, 'min_samples_split': 11}. Best is trial 33 with value: 0.8394193548387097.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 02:23:25,083]\u001b[0m Trial 46 finished with value: 0.8329462365591397 and parameters: {'max_depth': 5, 'max_features': 11, 'min_samples_split': 9}. Best is trial 33 with value: 0.8394193548387097.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 02:23:25,115]\u001b[0m Trial 47 finished with value: 0.7994408602150537 and parameters: {'max_depth': 5, 'max_features': 12, 'min_samples_split': 10}. Best is trial 33 with value: 0.8394193548387097.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 02:23:25,150]\u001b[0m Trial 48 finished with value: 0.8019569892473118 and parameters: {'max_depth': 5, 'max_features': 19, 'min_samples_split': 5}. Best is trial 33 with value: 0.8394193548387097.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 02:23:25,186]\u001b[0m Trial 49 finished with value: 0.8131397849462365 and parameters: {'max_depth': 5, 'max_features': 10, 'min_samples_split': 8}. Best is trial 33 with value: 0.8394193548387097.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 02:23:25,221]\u001b[0m Trial 50 finished with value: 0.8159139784946237 and parameters: {'max_depth': 5, 'max_features': 11, 'min_samples_split': 16}. Best is trial 33 with value: 0.8394193548387097.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 02:23:25,257]\u001b[0m Trial 51 finished with value: 0.8354838709677418 and parameters: {'max_depth': 5, 'max_features': 11, 'min_samples_split': 6}. Best is trial 33 with value: 0.8394193548387097.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 02:23:25,292]\u001b[0m Trial 52 finished with value: 0.8164086021505377 and parameters: {'max_depth': 5, 'max_features': 12, 'min_samples_split': 6}. Best is trial 33 with value: 0.8394193548387097.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 02:23:25,331]\u001b[0m Trial 53 finished with value: 0.8249462365591398 and parameters: {'max_depth': 5, 'max_features': 10, 'min_samples_split': 7}. Best is trial 33 with value: 0.8394193548387097.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 02:23:25,367]\u001b[0m Trial 54 finished with value: 0.802494623655914 and parameters: {'max_depth': 5, 'max_features': 18, 'min_samples_split': 4}. Best is trial 33 with value: 0.8394193548387097.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 02:23:25,406]\u001b[0m Trial 55 finished with value: 0.8243225806451613 and parameters: {'max_depth': 5, 'max_features': 11, 'min_samples_split': 11}. Best is trial 33 with value: 0.8394193548387097.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 02:23:25,440]\u001b[0m Trial 56 finished with value: 0.7960430107526882 and parameters: {'max_depth': 5, 'max_features': 10, 'min_samples_split': 23}. Best is trial 33 with value: 0.8394193548387097.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 02:23:25,474]\u001b[0m Trial 57 finished with value: 0.8170752688172043 and parameters: {'max_depth': 5, 'max_features': 12, 'min_samples_split': 7}. Best is trial 33 with value: 0.8394193548387097.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 02:23:25,505]\u001b[0m Trial 58 finished with value: 0.833505376344086 and parameters: {'max_depth': 5, 'max_features': 11, 'min_samples_split': 3}. Best is trial 33 with value: 0.8394193548387097.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 02:23:25,536]\u001b[0m Trial 59 finished with value: 0.8209677419354839 and parameters: {'max_depth': 5, 'max_features': 12, 'min_samples_split': 5}. Best is trial 33 with value: 0.8394193548387097.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 02:23:25,568]\u001b[0m Trial 60 finished with value: 0.8144731182795698 and parameters: {'max_depth': 5, 'max_features': 10, 'min_samples_split': 9}. Best is trial 33 with value: 0.8394193548387097.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 02:23:25,602]\u001b[0m Trial 61 finished with value: 0.8354838709677418 and parameters: {'max_depth': 5, 'max_features': 11, 'min_samples_split': 6}. Best is trial 33 with value: 0.8394193548387097.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 02:23:25,632]\u001b[0m Trial 62 finished with value: 0.8354838709677418 and parameters: {'max_depth': 5, 'max_features': 11, 'min_samples_split': 6}. Best is trial 33 with value: 0.8394193548387097.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 02:23:25,668]\u001b[0m Trial 63 finished with value: 0.8367956989247312 and parameters: {'max_depth': 5, 'max_features': 11, 'min_samples_split': 8}. Best is trial 33 with value: 0.8394193548387097.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 02:23:25,699]\u001b[0m Trial 64 finished with value: 0.7994408602150537 and parameters: {'max_depth': 5, 'max_features': 12, 'min_samples_split': 10}. Best is trial 33 with value: 0.8394193548387097.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 02:23:25,731]\u001b[0m Trial 65 finished with value: 0.8131397849462365 and parameters: {'max_depth': 5, 'max_features': 10, 'min_samples_split': 8}. Best is trial 33 with value: 0.8394193548387097.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 02:23:25,763]\u001b[0m Trial 66 finished with value: 0.8236989247311829 and parameters: {'max_depth': 5, 'max_features': 11, 'min_samples_split': 12}. Best is trial 33 with value: 0.8394193548387097.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 02:23:25,798]\u001b[0m Trial 67 finished with value: 0.8209677419354839 and parameters: {'max_depth': 5, 'max_features': 12, 'min_samples_split': 5}. Best is trial 33 with value: 0.8394193548387097.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 02:23:25,833]\u001b[0m Trial 68 finished with value: 0.8216129032258066 and parameters: {'max_depth': 4, 'max_features': 10, 'min_samples_split': 4}. Best is trial 33 with value: 0.8394193548387097.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 02:23:25,872]\u001b[0m Trial 69 finished with value: 0.8189677419354838 and parameters: {'max_depth': 5, 'max_features': 13, 'min_samples_split': 18}. Best is trial 33 with value: 0.8394193548387097.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 02:23:25,910]\u001b[0m Trial 70 finished with value: 0.8289247311827956 and parameters: {'max_depth': 4, 'max_features': 11, 'min_samples_split': 7}. Best is trial 33 with value: 0.8394193548387097.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 02:23:25,955]\u001b[0m Trial 71 finished with value: 0.833505376344086 and parameters: {'max_depth': 5, 'max_features': 11, 'min_samples_split': 3}. Best is trial 33 with value: 0.8394193548387097.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 02:23:25,995]\u001b[0m Trial 72 finished with value: 0.8354838709677418 and parameters: {'max_depth': 5, 'max_features': 11, 'min_samples_split': 6}. Best is trial 33 with value: 0.8394193548387097.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 02:23:26,033]\u001b[0m Trial 73 finished with value: 0.8053333333333333 and parameters: {'max_depth': 5, 'max_features': 12, 'min_samples_split': 9}. Best is trial 33 with value: 0.8394193548387097.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 02:23:26,073]\u001b[0m Trial 74 finished with value: 0.8355483870967743 and parameters: {'max_depth': 5, 'max_features': 10, 'min_samples_split': 6}. Best is trial 33 with value: 0.8394193548387097.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 02:23:26,107]\u001b[0m Trial 75 finished with value: 0.8131397849462365 and parameters: {'max_depth': 5, 'max_features': 10, 'min_samples_split': 8}. Best is trial 33 with value: 0.8394193548387097.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 02:23:26,141]\u001b[0m Trial 76 finished with value: 0.8322365591397849 and parameters: {'max_depth': 5, 'max_features': 10, 'min_samples_split': 4}. Best is trial 33 with value: 0.8394193548387097.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 02:23:26,173]\u001b[0m Trial 77 finished with value: 0.7953548387096775 and parameters: {'max_depth': 5, 'max_features': 15, 'min_samples_split': 7}. Best is trial 33 with value: 0.8394193548387097.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 02:23:26,207]\u001b[0m Trial 78 finished with value: 0.8355053763440862 and parameters: {'max_depth': 5, 'max_features': 10, 'min_samples_split': 5}. Best is trial 33 with value: 0.8394193548387097.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 02:23:26,237]\u001b[0m Trial 79 finished with value: 0.8355053763440862 and parameters: {'max_depth': 5, 'max_features': 10, 'min_samples_split': 5}. Best is trial 33 with value: 0.8394193548387097.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 02:23:26,271]\u001b[0m Trial 80 finished with value: 0.8355053763440862 and parameters: {'max_depth': 5, 'max_features': 10, 'min_samples_split': 5}. Best is trial 33 with value: 0.8394193548387097.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 02:23:26,300]\u001b[0m Trial 81 finished with value: 0.8355053763440862 and parameters: {'max_depth': 5, 'max_features': 10, 'min_samples_split': 5}. Best is trial 33 with value: 0.8394193548387097.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 02:23:26,335]\u001b[0m Trial 82 finished with value: 0.834215053763441 and parameters: {'max_depth': 5, 'max_features': 10, 'min_samples_split': 3}. Best is trial 33 with value: 0.8394193548387097.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 02:23:26,368]\u001b[0m Trial 83 finished with value: 0.8355053763440862 and parameters: {'max_depth': 5, 'max_features': 10, 'min_samples_split': 5}. Best is trial 33 with value: 0.8394193548387097.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 02:23:26,405]\u001b[0m Trial 84 finished with value: 0.8355053763440862 and parameters: {'max_depth': 5, 'max_features': 10, 'min_samples_split': 5}. Best is trial 33 with value: 0.8394193548387097.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 02:23:26,438]\u001b[0m Trial 85 finished with value: 0.8322365591397849 and parameters: {'max_depth': 5, 'max_features': 10, 'min_samples_split': 4}. Best is trial 33 with value: 0.8394193548387097.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 02:23:26,475]\u001b[0m Trial 86 finished with value: 0.8355053763440862 and parameters: {'max_depth': 5, 'max_features': 10, 'min_samples_split': 5}. Best is trial 33 with value: 0.8394193548387097.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 02:23:26,511]\u001b[0m Trial 87 finished with value: 0.834215053763441 and parameters: {'max_depth': 5, 'max_features': 10, 'min_samples_split': 3}. Best is trial 33 with value: 0.8394193548387097.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 02:23:26,543]\u001b[0m Trial 88 finished with value: 0.8355053763440862 and parameters: {'max_depth': 5, 'max_features': 10, 'min_samples_split': 5}. Best is trial 33 with value: 0.8394193548387097.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 02:23:26,578]\u001b[0m Trial 89 finished with value: 0.8249462365591398 and parameters: {'max_depth': 5, 'max_features': 10, 'min_samples_split': 7}. Best is trial 33 with value: 0.8394193548387097.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 02:23:26,610]\u001b[0m Trial 90 finished with value: 0.8322365591397849 and parameters: {'max_depth': 5, 'max_features': 10, 'min_samples_split': 4}. Best is trial 33 with value: 0.8394193548387097.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 02:23:26,644]\u001b[0m Trial 91 finished with value: 0.8355053763440862 and parameters: {'max_depth': 5, 'max_features': 10, 'min_samples_split': 5}. Best is trial 33 with value: 0.8394193548387097.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 02:23:26,675]\u001b[0m Trial 92 finished with value: 0.834215053763441 and parameters: {'max_depth': 5, 'max_features': 10, 'min_samples_split': 3}. Best is trial 33 with value: 0.8394193548387097.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 02:23:26,707]\u001b[0m Trial 93 finished with value: 0.8355053763440862 and parameters: {'max_depth': 5, 'max_features': 10, 'min_samples_split': 5}. Best is trial 33 with value: 0.8394193548387097.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 02:23:26,740]\u001b[0m Trial 94 finished with value: 0.8052688172043011 and parameters: {'max_depth': 5, 'max_features': 20, 'min_samples_split': 7}. Best is trial 33 with value: 0.8394193548387097.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 02:23:26,775]\u001b[0m Trial 95 finished with value: 0.8131397849462365 and parameters: {'max_depth': 5, 'max_features': 10, 'min_samples_split': 8}. Best is trial 33 with value: 0.8394193548387097.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 02:23:26,812]\u001b[0m Trial 96 finished with value: 0.8322365591397849 and parameters: {'max_depth': 5, 'max_features': 10, 'min_samples_split': 4}. Best is trial 33 with value: 0.8394193548387097.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 02:23:26,845]\u001b[0m Trial 97 finished with value: 0.8354838709677418 and parameters: {'max_depth': 5, 'max_features': 11, 'min_samples_split': 6}. Best is trial 33 with value: 0.8394193548387097.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 02:23:26,880]\u001b[0m Trial 98 finished with value: 0.8328387096774195 and parameters: {'max_depth': 5, 'max_features': 10, 'min_samples_split': 2}. Best is trial 33 with value: 0.8394193548387097.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 02:23:26,913]\u001b[0m Trial 99 finished with value: 0.83352688172043 and parameters: {'max_depth': 5, 'max_features': 11, 'min_samples_split': 5}. Best is trial 33 with value: 0.8394193548387097.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "#Tuning hyperparameters\n",
    "#Step 1. Define an objective function to be maximized.\n",
    "def objective(trial):\n",
    "    param = {\n",
    "        'max_depth': trial.suggest_int('max_depth',3,5,1),\n",
    "        'max_features' : trial.suggest_int(\"max_features\",10,20,1),\n",
    "        'min_samples_split':trial.suggest_int('min_samples_split',2,25,1)\n",
    "    }\n",
    "    model = DecisionTreeClassifier(**param,random_state=1)\n",
    "\n",
    " \n",
    "# Step 2: Scoring method:\n",
    "    score = model_selection.cross_val_score(model, X, y, n_jobs=12, scoring=\"accuracy\",cv=Cv_optuna)\n",
    "    accuracy = score.mean()\n",
    "    return accuracy\n",
    " \n",
    "# Step 3: Running it\n",
    "study = optuna.create_study(direction=\"maximize\",sampler=optuna.samplers.TPESampler(seed=0))\n",
    "study.optimize(objective, n_trials=100, show_progress_bar=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "28ac7c97-6c21-4117-add1-12a7be2e8f2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best parameters are : \n",
      "{'max_depth': 5, 'max_features': 11, 'min_samples_split': 7}\n"
     ]
    }
   ],
   "source": [
    "# Getting the best parameters:\n",
    "print(f\"The best parameters are : \\n{study.best_params}\")\n",
    "# Setting the best model\n",
    "clf =DecisionTreeClassifier(max_depth = study.best_params['max_depth']\n",
    "              ,max_features = study.best_params['max_features']\n",
    "              #,n_estimators = study.best_params['n_estimators']\n",
    "              #,learning_rate = study.best_params['learning_rate']\n",
    "              ,min_samples_split= study.best_params['min_samples_split']\n",
    "              ,random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "c0b71e00-d630-4d2b-b1d4-a79589e02288",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mean</th>\n",
       "      <th>Se</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Accuracy_test</th>\n",
       "      <td>0.839419</td>\n",
       "      <td>0.008398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Accuracy_train</th>\n",
       "      <td>0.958067</td>\n",
       "      <td>0.002001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1 Score</th>\n",
       "      <td>0.559406</td>\n",
       "      <td>0.023390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Precision</th>\n",
       "      <td>0.642960</td>\n",
       "      <td>0.027193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recall</th>\n",
       "      <td>0.540000</td>\n",
       "      <td>0.028891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Roc_auc</th>\n",
       "      <td>0.732672</td>\n",
       "      <td>0.017574</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Mean        Se\n",
       "Accuracy_test   0.839419  0.008398\n",
       "Accuracy_train  0.958067  0.002001\n",
       "F1 Score        0.559406  0.023390\n",
       "Precision       0.642960  0.027193\n",
       "Recall          0.540000  0.028891\n",
       "Roc_auc         0.732672  0.017574"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Model2\n",
    "Model2=Model_results(clf,X,y,Cv_model)\n",
    "Model2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "e4359628-316f-47c6-bdef-b9471932492e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th>Method</th>\n",
       "      <th colspan=\"4\" halign=\"left\">DT</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model</th>\n",
       "      <th colspan=\"2\" halign=\"left\">Model 1</th>\n",
       "      <th colspan=\"2\" halign=\"left\">Model 2</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Values</th>\n",
       "      <th>Mean</th>\n",
       "      <th>Se</th>\n",
       "      <th>Mean</th>\n",
       "      <th>Se</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Accuracy_test</th>\n",
       "      <td>0.815828</td>\n",
       "      <td>0.008490</td>\n",
       "      <td>0.839419</td>\n",
       "      <td>0.008398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Accuracy_train</th>\n",
       "      <td>0.994904</td>\n",
       "      <td>0.000564</td>\n",
       "      <td>0.958067</td>\n",
       "      <td>0.002001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1 Score</th>\n",
       "      <td>0.493578</td>\n",
       "      <td>0.026905</td>\n",
       "      <td>0.559406</td>\n",
       "      <td>0.023390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Precision</th>\n",
       "      <td>0.541437</td>\n",
       "      <td>0.030501</td>\n",
       "      <td>0.642960</td>\n",
       "      <td>0.027193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recall</th>\n",
       "      <td>0.483333</td>\n",
       "      <td>0.029907</td>\n",
       "      <td>0.540000</td>\n",
       "      <td>0.028891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Roc_auc</th>\n",
       "      <td>0.692214</td>\n",
       "      <td>0.015877</td>\n",
       "      <td>0.732672</td>\n",
       "      <td>0.017574</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Method                DT                              \n",
       "Model            Model 1             Model 2          \n",
       "Values              Mean        Se      Mean        Se\n",
       "Accuracy_test   0.815828  0.008490  0.839419  0.008398\n",
       "Accuracy_train  0.994904  0.000564  0.958067  0.002001\n",
       "F1 Score        0.493578  0.026905  0.559406  0.023390\n",
       "Precision       0.541437  0.030501  0.642960  0.027193\n",
       "Recall          0.483333  0.029907  0.540000  0.028891\n",
       "Roc_auc         0.692214  0.015877  0.732672  0.017574"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Saving the data of model performance\n",
    "Model_data=pd.concat([Model1,Model2],axis=1)\n",
    "Model_data.columns = [['DT']*4,['Model 1','Model 1', 'Model 2','Model 2'], ['Mean', 'Se', 'Mean', 'Se']]  \n",
    "Model_data.columns.names=['Method','Model','Values']\n",
    "Model_data.to_csv(\"./DT_model_lasso_data.csv\",sep=',')\n",
    "Model_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6047485d-89ab-471b-b393-08d893b317bc",
   "metadata": {},
   "source": [
    "## 1.2 LR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "7e67efc5-4154-43ea-ad89-57f6ba68ec1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf=LogisticRegression(solver='liblinear',random_state=0,dual=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "4e72f778-0bc0-4da2-b17d-d66357ab161c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mean</th>\n",
       "      <th>Se</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Accuracy_test</th>\n",
       "      <td>0.832839</td>\n",
       "      <td>0.004275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Accuracy_train</th>\n",
       "      <td>0.867599</td>\n",
       "      <td>0.002416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1 Score</th>\n",
       "      <td>0.329908</td>\n",
       "      <td>0.026033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Precision</th>\n",
       "      <td>0.699905</td>\n",
       "      <td>0.052053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recall</th>\n",
       "      <td>0.233333</td>\n",
       "      <td>0.021602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Roc_auc</th>\n",
       "      <td>0.842453</td>\n",
       "      <td>0.011783</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Mean        Se\n",
       "Accuracy_test   0.832839  0.004275\n",
       "Accuracy_train  0.867599  0.002416\n",
       "F1 Score        0.329908  0.026033\n",
       "Precision       0.699905  0.052053\n",
       "Recall          0.233333  0.021602\n",
       "Roc_auc         0.842453  0.011783"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Model1 \n",
    "Model1_clf=clf\n",
    "#Model1\n",
    "Model1=Model_results(Model1_clf,X,y,Cv_model)\n",
    "Model1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "b9338635-62a3-4fe9-912b-6acc77ef994a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2024-11-14 02:24:08,823]\u001b[0m A new study created in memory with name: no-name-2ae67034-fbb1-401c-ad79-ac4f6501c7e5\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 02:24:11,524]\u001b[0m Trial 0 finished with value: 0.8013118279569891 and parameters: {'logreg_c': 0.3177840006884068, 'l1_ratio': 0.7482920440979423, 'max_iter': 100}. Best is trial 0 with value: 0.8013118279569891.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 02:24:11,574]\u001b[0m Trial 1 finished with value: 0.8025806451612902 and parameters: {'logreg_c': 0.0651621545821569, 'l1_ratio': 0.23208030173540176, 'max_iter': 275}. Best is trial 1 with value: 0.8025806451612902.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 02:24:11,614]\u001b[0m Trial 2 finished with value: 0.8025806451612902 and parameters: {'logreg_c': 0.013108749615263334, 'l1_ratio': 0.411004654338743, 'max_iter': 854}. Best is trial 1 with value: 0.8025806451612902.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 02:24:11,650]\u001b[0m Trial 3 finished with value: 0.8472903225806451 and parameters: {'logreg_c': 1.7096232052870346, 'l1_ratio': 0.4772750629629653, 'max_iter': 1402}. Best is trial 3 with value: 0.8472903225806451.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 02:24:11,682]\u001b[0m Trial 4 finished with value: 0.8025806451612902 and parameters: {'logreg_c': 0.016854407828169382, 'l1_ratio': 0.8903056927518509, 'max_iter': 152}. Best is trial 3 with value: 0.8472903225806451.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 02:24:11,725]\u001b[0m Trial 5 finished with value: 0.877010752688172 and parameters: {'logreg_c': 10.539137268289434, 'l1_ratio': 0.4755743221304143, 'max_iter': 1162}. Best is trial 5 with value: 0.877010752688172.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 02:24:11,755]\u001b[0m Trial 6 finished with value: 0.8025806451612902 and parameters: {'logreg_c': 0.006955392321661603, 'l1_ratio': 0.2782913401763909, 'max_iter': 1622}. Best is trial 5 with value: 0.877010752688172.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 02:24:11,800]\u001b[0m Trial 7 finished with value: 0.8521290322580645 and parameters: {'logreg_c': 645.0144652189372, 'l1_ratio': 0.38208176034331853, 'max_iter': 1416}. Best is trial 5 with value: 0.877010752688172.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 02:24:11,841]\u001b[0m Trial 8 finished with value: 0.8639569892473118 and parameters: {'logreg_c': 181.27374779133626, 'l1_ratio': 0.9051459971534626, 'max_iter': 261}. Best is trial 5 with value: 0.877010752688172.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 02:24:11,877]\u001b[0m Trial 9 finished with value: 0.8025806451612902 and parameters: {'logreg_c': 0.001715255021408637, 'l1_ratio': 0.25284737760811204, 'max_iter': 1769}. Best is trial 5 with value: 0.877010752688172.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 02:24:11,914]\u001b[0m Trial 10 finished with value: 0.881032258064516 and parameters: {'logreg_c': 27.542812131948647, 'l1_ratio': 0.655368941318724, 'max_iter': 845}. Best is trial 10 with value: 0.881032258064516.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 02:24:11,958]\u001b[0m Trial 11 finished with value: 0.8756989247311828 and parameters: {'logreg_c': 16.40049815291859, 'l1_ratio': 0.6357475149295672, 'max_iter': 834}. Best is trial 10 with value: 0.881032258064516.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 02:24:12,001]\u001b[0m Trial 12 finished with value: 0.8770107526881721 and parameters: {'logreg_c': 17.797037653328026, 'l1_ratio': 0.6275895804235085, 'max_iter': 1090}. Best is trial 10 with value: 0.881032258064516.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 02:24:12,043]\u001b[0m Trial 13 finished with value: 0.8776774193548387 and parameters: {'logreg_c': 18.12120438471593, 'l1_ratio': 0.6540833539128966, 'max_iter': 662}. Best is trial 10 with value: 0.881032258064516.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 02:24:12,087]\u001b[0m Trial 14 finished with value: 0.8698494623655916 and parameters: {'logreg_c': 113.13019134439, 'l1_ratio': 0.7592749913330036, 'max_iter': 569}. Best is trial 10 with value: 0.881032258064516.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 02:24:12,129]\u001b[0m Trial 15 finished with value: 0.8518709677419355 and parameters: {'logreg_c': 2.3533690713887387, 'l1_ratio': 0.11342714523990888, 'max_iter': 612}. Best is trial 10 with value: 0.881032258064516.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 02:24:12,171]\u001b[0m Trial 16 finished with value: 0.8712043010752688 and parameters: {'logreg_c': 91.00476473622366, 'l1_ratio': 0.7232605518637505, 'max_iter': 562}. Best is trial 10 with value: 0.881032258064516.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 02:24:12,212]\u001b[0m Trial 17 finished with value: 0.8039569892473116 and parameters: {'logreg_c': 0.3535034680388183, 'l1_ratio': 0.650159292319262, 'max_iter': 855}. Best is trial 10 with value: 0.881032258064516.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 02:24:12,254]\u001b[0m Trial 18 finished with value: 0.8716774193548389 and parameters: {'logreg_c': 6.050929167625315, 'l1_ratio': 0.9749291910297851, 'max_iter': 457}. Best is trial 10 with value: 0.881032258064516.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 02:24:12,296]\u001b[0m Trial 19 finished with value: 0.8527741935483871 and parameters: {'logreg_c': 739.6095151711961, 'l1_ratio': 0.5599957129844463, 'max_iter': 1275}. Best is trial 10 with value: 0.881032258064516.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 02:24:12,336]\u001b[0m Trial 20 finished with value: 0.879763440860215 and parameters: {'logreg_c': 40.71953379920725, 'l1_ratio': 0.8215631146408071, 'max_iter': 898}. Best is trial 10 with value: 0.881032258064516.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 02:24:12,379]\u001b[0m Trial 21 finished with value: 0.8791182795698925 and parameters: {'logreg_c': 45.78335389822183, 'l1_ratio': 0.8351519944677332, 'max_iter': 918}. Best is trial 10 with value: 0.881032258064516.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 02:24:12,426]\u001b[0m Trial 22 finished with value: 0.8778064516129033 and parameters: {'logreg_c': 57.86154921918543, 'l1_ratio': 0.8207159991633485, 'max_iter': 962}. Best is trial 10 with value: 0.881032258064516.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 02:24:12,475]\u001b[0m Trial 23 finished with value: 0.8804301075268818 and parameters: {'logreg_c': 41.61307350052944, 'l1_ratio': 0.8370789932125346, 'max_iter': 756}. Best is trial 10 with value: 0.881032258064516.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 02:24:12,522]\u001b[0m Trial 24 finished with value: 0.8599569892473119 and parameters: {'logreg_c': 262.05819270476724, 'l1_ratio': 0.9597401935284394, 'max_iter': 733}. Best is trial 10 with value: 0.881032258064516.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 02:24:12,569]\u001b[0m Trial 25 finished with value: 0.8683870967741936 and parameters: {'logreg_c': 4.444222596822107, 'l1_ratio': 0.8211690718345999, 'max_iter': 1054}. Best is trial 10 with value: 0.881032258064516.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 02:24:12,612]\u001b[0m Trial 26 finished with value: 0.8804086021505377 and parameters: {'logreg_c': 36.53421361472711, 'l1_ratio': 0.7026812607163192, 'max_iter': 402}. Best is trial 10 with value: 0.881032258064516.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 02:24:12,655]\u001b[0m Trial 27 finished with value: 0.8612903225806453 and parameters: {'logreg_c': 220.61254452370613, 'l1_ratio': 0.5558233756902167, 'max_iter': 420}. Best is trial 10 with value: 0.881032258064516.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 02:24:12,695]\u001b[0m Trial 28 finished with value: 0.8210537634408602 and parameters: {'logreg_c': 0.7530810413347697, 'l1_ratio': 0.7419683771013172, 'max_iter': 391}. Best is trial 10 with value: 0.881032258064516.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 02:24:12,750]\u001b[0m Trial 29 finished with value: 0.7993333333333332 and parameters: {'logreg_c': 0.2249183886409124, 'l1_ratio': 0.7169843453783027, 'max_iter': 691}. Best is trial 10 with value: 0.881032258064516.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 02:24:12,795]\u001b[0m Trial 30 finished with value: 0.8624516129032258 and parameters: {'logreg_c': 3.6449114284613504, 'l1_ratio': 0.8770167436642398, 'max_iter': 116}. Best is trial 10 with value: 0.881032258064516.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 02:24:12,839]\u001b[0m Trial 31 finished with value: 0.8776774193548387 and parameters: {'logreg_c': 20.441558981741604, 'l1_ratio': 0.7698596534044868, 'max_iter': 758}. Best is trial 10 with value: 0.881032258064516.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 02:24:12,887]\u001b[0m Trial 32 finished with value: 0.8790967741935484 and parameters: {'logreg_c': 38.74632978181572, 'l1_ratio': 0.6886828915563681, 'max_iter': 1200}. Best is trial 10 with value: 0.881032258064516.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 02:24:12,931]\u001b[0m Trial 33 finished with value: 0.879763440860215 and parameters: {'logreg_c': 38.05246445530975, 'l1_ratio': 0.8064051708203435, 'max_iter': 987}. Best is trial 10 with value: 0.881032258064516.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 02:24:12,972]\u001b[0m Trial 34 finished with value: 0.8743010752688173 and parameters: {'logreg_c': 7.348135760225892, 'l1_ratio': 0.5899386267383478, 'max_iter': 1014}. Best is trial 10 with value: 0.881032258064516.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 02:24:13,014]\u001b[0m Trial 35 finished with value: 0.858021505376344 and parameters: {'logreg_c': 369.35799822268376, 'l1_ratio': 0.9264137594075736, 'max_iter': 268}. Best is trial 10 with value: 0.881032258064516.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 02:24:13,058]\u001b[0m Trial 36 finished with value: 0.8705161290322582 and parameters: {'logreg_c': 101.76266008248439, 'l1_ratio': 0.8737185877105962, 'max_iter': 484}. Best is trial 10 with value: 0.881032258064516.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 02:24:13,100]\u001b[0m Trial 37 finished with value: 0.8328387096774195 and parameters: {'logreg_c': 1.0075124045002002, 'l1_ratio': 0.48898342406861994, 'max_iter': 1306}. Best is trial 10 with value: 0.881032258064516.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 02:24:13,142]\u001b[0m Trial 38 finished with value: 0.8025806451612902 and parameters: {'logreg_c': 0.04710532421976147, 'l1_ratio': 0.7885104797298279, 'max_iter': 784}. Best is trial 10 with value: 0.881032258064516.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 02:24:13,180]\u001b[0m Trial 39 finished with value: 0.8803655913978494 and parameters: {'logreg_c': 28.860134032522982, 'l1_ratio': 0.9980284006501041, 'max_iter': 336}. Best is trial 10 with value: 0.881032258064516.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 02:24:13,224]\u001b[0m Trial 40 finished with value: 0.8553978494623656 and parameters: {'logreg_c': 488.76734667931225, 'l1_ratio': 0.9976011038185876, 'max_iter': 342}. Best is trial 10 with value: 0.881032258064516.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 02:24:13,265]\u001b[0m Trial 41 finished with value: 0.8763440860215055 and parameters: {'logreg_c': 11.011239581309145, 'l1_ratio': 0.6847614669207366, 'max_iter': 235}. Best is trial 10 with value: 0.881032258064516.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 02:24:13,297]\u001b[0m Trial 42 finished with value: 0.8810322580645162 and parameters: {'logreg_c': 29.597571026748778, 'l1_ratio': 0.933438675245377, 'max_iter': 898}. Best is trial 42 with value: 0.8810322580645162.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 02:24:13,332]\u001b[0m Trial 43 finished with value: 0.8679139784946238 and parameters: {'logreg_c': 140.0900601074511, 'l1_ratio': 0.9227288431442142, 'max_iter': 530}. Best is trial 42 with value: 0.8810322580645162.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 02:24:13,365]\u001b[0m Trial 44 finished with value: 0.8796989247311828 and parameters: {'logreg_c': 25.576055462765733, 'l1_ratio': 0.9353446233810087, 'max_iter': 189}. Best is trial 42 with value: 0.8810322580645162.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 02:24:13,400]\u001b[0m Trial 45 finished with value: 0.8751827956989249 and parameters: {'logreg_c': 74.54928012816818, 'l1_ratio': 0.8604018041351407, 'max_iter': 1996}. Best is trial 42 with value: 0.8810322580645162.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 02:24:13,433]\u001b[0m Trial 46 finished with value: 0.8770322580645162 and parameters: {'logreg_c': 11.950267972190073, 'l1_ratio': 0.9545788893850765, 'max_iter': 334}. Best is trial 42 with value: 0.8810322580645162.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 02:24:13,472]\u001b[0m Trial 47 finished with value: 0.8538494623655914 and parameters: {'logreg_c': 2.541235214444589, 'l1_ratio': 0.8942241916326457, 'max_iter': 1113}. Best is trial 42 with value: 0.8810322580645162.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 02:24:13,508]\u001b[0m Trial 48 finished with value: 0.876258064516129 and parameters: {'logreg_c': 7.863072939792303, 'l1_ratio': 0.9963444128554898, 'max_iter': 660}. Best is trial 42 with value: 0.8810322580645162.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 02:24:13,555]\u001b[0m Trial 49 finished with value: 0.8347956989247313 and parameters: {'logreg_c': 1.1656886692507074, 'l1_ratio': 0.38487583053838714, 'max_iter': 1525}. Best is trial 42 with value: 0.8810322580645162.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 02:24:13,598]\u001b[0m Trial 50 finished with value: 0.8639569892473118 and parameters: {'logreg_c': 173.7898856647563, 'l1_ratio': 0.49324857197466027, 'max_iter': 816}. Best is trial 42 with value: 0.8810322580645162.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 02:24:13,635]\u001b[0m Trial 51 finished with value: 0.8778064516129033 and parameters: {'logreg_c': 61.426651794747734, 'l1_ratio': 0.858280826286891, 'max_iter': 920}. Best is trial 42 with value: 0.8810322580645162.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 02:24:13,673]\u001b[0m Trial 52 finished with value: 0.8803655913978494 and parameters: {'logreg_c': 27.921448453175213, 'l1_ratio': 0.6129425871001107, 'max_iter': 885}. Best is trial 42 with value: 0.8810322580645162.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 02:24:13,712]\u001b[0m Trial 53 finished with value: 0.8790107526881721 and parameters: {'logreg_c': 19.18180975003746, 'l1_ratio': 0.5993486484982595, 'max_iter': 627}. Best is trial 42 with value: 0.8810322580645162.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 02:24:13,747]\u001b[0m Trial 54 finished with value: 0.8810322580645162 and parameters: {'logreg_c': 30.65879054580304, 'l1_ratio': 0.5283698823405598, 'max_iter': 512}. Best is trial 42 with value: 0.8810322580645162.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 02:24:13,782]\u001b[0m Trial 55 finished with value: 0.8770322580645162 and parameters: {'logreg_c': 12.124957286393721, 'l1_ratio': 0.4353782691035846, 'max_iter': 851}. Best is trial 42 with value: 0.8810322580645162.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 02:24:13,815]\u001b[0m Trial 56 finished with value: 0.8751827956989249 and parameters: {'logreg_c': 76.46733246987802, 'l1_ratio': 0.5234718010843901, 'max_iter': 533}. Best is trial 42 with value: 0.8810322580645162.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 02:24:13,848]\u001b[0m Trial 57 finished with value: 0.8696774193548387 and parameters: {'logreg_c': 4.746059411895023, 'l1_ratio': 0.6801887728806819, 'max_iter': 718}. Best is trial 42 with value: 0.8810322580645162.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 02:24:13,881]\u001b[0m Trial 58 finished with value: 0.8586666666666666 and parameters: {'logreg_c': 333.21917260611383, 'l1_ratio': 0.6118288906283669, 'max_iter': 1176}. Best is trial 42 with value: 0.8810322580645162.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 02:24:13,918]\u001b[0m Trial 59 finished with value: 0.8521075268817203 and parameters: {'logreg_c': 968.0757297989713, 'l1_ratio': 0.7244267500562473, 'max_iter': 357}. Best is trial 42 with value: 0.8810322580645162.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 02:24:13,951]\u001b[0m Trial 60 finished with value: 0.8025806451612902 and parameters: {'logreg_c': 0.0014647914843692897, 'l1_ratio': 0.4548269662986597, 'max_iter': 574}. Best is trial 42 with value: 0.8810322580645162.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 02:24:13,991]\u001b[0m Trial 61 finished with value: 0.8803655913978494 and parameters: {'logreg_c': 27.950699850244177, 'l1_ratio': 0.5296748331032094, 'max_iter': 481}. Best is trial 42 with value: 0.8810322580645162.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 02:24:14,027]\u001b[0m Trial 62 finished with value: 0.8810107526881721 and parameters: {'logreg_c': 29.30121487039755, 'l1_ratio': 0.5184989951414316, 'max_iter': 472}. Best is trial 42 with value: 0.8810322580645162.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 02:24:14,065]\u001b[0m Trial 63 finished with value: 0.8791182795698925 and parameters: {'logreg_c': 46.37470652840113, 'l1_ratio': 0.3003385262542917, 'max_iter': 874}. Best is trial 42 with value: 0.8810322580645162.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 02:24:14,107]\u001b[0m Trial 64 finished with value: 0.8698494623655916 and parameters: {'logreg_c': 113.14219355424522, 'l1_ratio': 0.652034703986264, 'max_iter': 402}. Best is trial 42 with value: 0.8810322580645162.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 02:24:14,151]\u001b[0m Trial 65 finished with value: 0.8776774193548387 and parameters: {'logreg_c': 20.549944366897886, 'l1_ratio': 0.5204537670412499, 'max_iter': 453}. Best is trial 42 with value: 0.8810322580645162.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 02:24:14,184]\u001b[0m Trial 66 finished with value: 0.8769462365591397 and parameters: {'logreg_c': 8.942332019718307, 'l1_ratio': 0.5724014090983562, 'max_iter': 495}. Best is trial 42 with value: 0.8810322580645162.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 02:24:14,216]\u001b[0m Trial 67 finished with value: 0.8025806451612902 and parameters: {'logreg_c': 0.003114708027338804, 'l1_ratio': 0.5374980334141909, 'max_iter': 607}. Best is trial 42 with value: 0.8810322580645162.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 02:24:14,250]\u001b[0m Trial 68 finished with value: 0.8804086021505377 and parameters: {'logreg_c': 36.43410128765025, 'l1_ratio': 0.7814496863734726, 'max_iter': 207}. Best is trial 42 with value: 0.8810322580645162.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 02:24:14,286]\u001b[0m Trial 69 finished with value: 0.8578279569892473 and parameters: {'logreg_c': 2.8431336687278237, 'l1_ratio': 0.7799214215866592, 'max_iter': 116}. Best is trial 42 with value: 0.8810322580645162.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 02:24:14,320]\u001b[0m Trial 70 finished with value: 0.8770107526881722 and parameters: {'logreg_c': 14.761801576457477, 'l1_ratio': 0.7583125324085978, 'max_iter': 202}. Best is trial 42 with value: 0.8810322580645162.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 02:24:14,353]\u001b[0m Trial 71 finished with value: 0.8797204301075269 and parameters: {'logreg_c': 34.11949399646899, 'l1_ratio': 0.5725768470229265, 'max_iter': 311}. Best is trial 42 with value: 0.8810322580645162.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 02:24:14,387]\u001b[0m Trial 72 finished with value: 0.8738494623655914 and parameters: {'logreg_c': 81.1683509565935, 'l1_ratio': 0.6393393962054569, 'max_iter': 962}. Best is trial 42 with value: 0.8810322580645162.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 02:24:14,420]\u001b[0m Trial 73 finished with value: 0.8791182795698925 and parameters: {'logreg_c': 48.246843928424376, 'l1_ratio': 0.846180014761195, 'max_iter': 251}. Best is trial 42 with value: 0.8810322580645162.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 02:24:14,452]\u001b[0m Trial 74 finished with value: 0.8639569892473118 and parameters: {'logreg_c': 181.3540549888624, 'l1_ratio': 0.9652986762855754, 'max_iter': 430}. Best is trial 42 with value: 0.8810322580645162.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 02:24:14,486]\u001b[0m Trial 75 finished with value: 0.8778064516129033 and parameters: {'logreg_c': 56.96507445877564, 'l1_ratio': 0.7061328560410184, 'max_iter': 774}. Best is trial 42 with value: 0.8810322580645162.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 02:24:14,522]\u001b[0m Trial 76 finished with value: 0.8716774193548389 and parameters: {'logreg_c': 5.988053157578258, 'l1_ratio': 0.6231687597948399, 'max_iter': 1064}. Best is trial 42 with value: 0.8810322580645162.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 02:24:14,556]\u001b[0m Trial 77 finished with value: 0.8770107526881722 and parameters: {'logreg_c': 16.188022956168815, 'l1_ratio': 0.7980044248052339, 'max_iter': 371}. Best is trial 42 with value: 0.8810322580645162.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 02:24:14,592]\u001b[0m Trial 78 finished with value: 0.8810322580645162 and parameters: {'logreg_c': 29.682328909139482, 'l1_ratio': 0.5150292433043476, 'max_iter': 668}. Best is trial 42 with value: 0.8810322580645162.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 02:24:14,628]\u001b[0m Trial 79 finished with value: 0.8712043010752688 and parameters: {'logreg_c': 94.77905676776504, 'l1_ratio': 0.42366397466173217, 'max_iter': 668}. Best is trial 42 with value: 0.8810322580645162.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 02:24:14,662]\u001b[0m Trial 80 finished with value: 0.808516129032258 and parameters: {'logreg_c': 0.4659984297542277, 'l1_ratio': 0.7408062428562756, 'max_iter': 717}. Best is trial 42 with value: 0.8810322580645162.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 02:24:14,695]\u001b[0m Trial 81 finished with value: 0.879763440860215 and parameters: {'logreg_c': 38.350549211991044, 'l1_ratio': 0.4670213943286734, 'max_iter': 499}. Best is trial 42 with value: 0.8810322580645162.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 02:24:14,732]\u001b[0m Trial 82 finished with value: 0.881032258064516 and parameters: {'logreg_c': 26.16017953086965, 'l1_ratio': 0.507173040536369, 'max_iter': 794}. Best is trial 42 with value: 0.8810322580645162.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 02:24:14,773]\u001b[0m Trial 83 finished with value: 0.8796989247311828 and parameters: {'logreg_c': 24.245925166105835, 'l1_ratio': 0.5517223978782408, 'max_iter': 824}. Best is trial 42 with value: 0.8810322580645162.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 02:24:14,812]\u001b[0m Trial 84 finished with value: 0.8770107526881721 and parameters: {'logreg_c': 13.39390815824398, 'l1_ratio': 0.5015299745533501, 'max_iter': 619}. Best is trial 42 with value: 0.8810322580645162.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 02:24:14,844]\u001b[0m Trial 85 finished with value: 0.8778064516129033 and parameters: {'logreg_c': 56.692014609132144, 'l1_ratio': 0.3395267870959375, 'max_iter': 776}. Best is trial 42 with value: 0.8810322580645162.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 02:24:14,878]\u001b[0m Trial 86 finished with value: 0.8672473118279571 and parameters: {'logreg_c': 154.88539142985712, 'l1_ratio': 0.45151845704522064, 'max_iter': 949}. Best is trial 42 with value: 0.8810322580645162.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 02:24:14,912]\u001b[0m Trial 87 finished with value: 0.8716774193548389 and parameters: {'logreg_c': 6.247073291994826, 'l1_ratio': 0.406940196456343, 'max_iter': 1008}. Best is trial 42 with value: 0.8810322580645162.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 02:24:14,945]\u001b[0m Trial 88 finished with value: 0.8025806451612902 and parameters: {'logreg_c': 0.09121922104163335, 'l1_ratio': 0.5801185649457714, 'max_iter': 579}. Best is trial 42 with value: 0.8810322580645162.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 02:24:14,983]\u001b[0m Trial 89 finished with value: 0.8698494623655916 and parameters: {'logreg_c': 118.39240503802007, 'l1_ratio': 0.15672764213947155, 'max_iter': 699}. Best is trial 42 with value: 0.8810322580645162.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 02:24:15,020]\u001b[0m Trial 90 finished with value: 0.8776774193548387 and parameters: {'logreg_c': 21.283301124961273, 'l1_ratio': 0.9033685022191145, 'max_iter': 165}. Best is trial 42 with value: 0.8810322580645162.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 02:24:15,058]\u001b[0m Trial 91 finished with value: 0.8810322580645162 and parameters: {'logreg_c': 31.36625744509804, 'l1_ratio': 0.5083758637128148, 'max_iter': 893}. Best is trial 42 with value: 0.8810322580645162.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 02:24:15,094]\u001b[0m Trial 92 finished with value: 0.8804086021505377 and parameters: {'logreg_c': 36.57250803521373, 'l1_ratio': 0.5038545384541538, 'max_iter': 817}. Best is trial 42 with value: 0.8810322580645162.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 02:24:15,135]\u001b[0m Trial 93 finished with value: 0.8758494623655915 and parameters: {'logreg_c': 69.5486012982474, 'l1_ratio': 0.4948877077586531, 'max_iter': 798}. Best is trial 42 with value: 0.8810322580645162.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 02:24:15,171]\u001b[0m Trial 94 finished with value: 0.8803655913978494 and parameters: {'logreg_c': 28.844804940751523, 'l1_ratio': 0.5155180775501418, 'max_iter': 913}. Best is trial 42 with value: 0.8810322580645162.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 02:24:15,209]\u001b[0m Trial 95 finished with value: 0.8776129032258065 and parameters: {'logreg_c': 9.441022461154374, 'l1_ratio': 0.47676845817839086, 'max_iter': 866}. Best is trial 42 with value: 0.8810322580645162.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 02:24:15,248]\u001b[0m Trial 96 finished with value: 0.8599569892473117 and parameters: {'logreg_c': 246.16599811754696, 'l1_ratio': 0.5520296101465637, 'max_iter': 732}. Best is trial 42 with value: 0.8810322580645162.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 02:24:15,288]\u001b[0m Trial 97 finished with value: 0.8770107526881721 and parameters: {'logreg_c': 17.054581616875293, 'l1_ratio': 0.5136896200457253, 'max_iter': 1114}. Best is trial 42 with value: 0.8810322580645162.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 02:24:15,332]\u001b[0m Trial 98 finished with value: 0.87847311827957 and parameters: {'logreg_c': 54.38263486829692, 'l1_ratio': 0.6636943314139458, 'max_iter': 667}. Best is trial 42 with value: 0.8810322580645162.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 02:24:15,373]\u001b[0m Trial 99 finished with value: 0.8803870967741935 and parameters: {'logreg_c': 35.17024933278501, 'l1_ratio': 0.8237476224137363, 'max_iter': 290}. Best is trial 42 with value: 0.8810322580645162.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "#Tuning hyperparameters\n",
    "#Step 1. Define an objective function to be maximized.\n",
    "def objective(trial):\n",
    "    logreg_c = trial.suggest_float(\"logreg_c\", 1e-3,  1e3, log=True)\n",
    "    l1_ratio = trial.suggest_float(\"l1_ratio\",0.1,1,log=False) \n",
    "    #penalty = trial.suggest_categorical(\"penalty\",['l1','l2'])\n",
    "    max_iter = trial.suggest_int(\"max_iter\", 100,2000)\n",
    "    model =LogisticRegression(C=logreg_c,\n",
    "                              max_iter=max_iter,\n",
    "                              l1_ratio=l1_ratio,\n",
    "                              solver='liblinear',random_state=1)\n",
    "    \n",
    "# Step 2: Scoring method:\n",
    "    score = model_selection.cross_val_score(model, X, y, n_jobs=8, scoring=\"accuracy\",cv=Cv_optuna)\n",
    "    accuracy = score.mean()\n",
    "    return accuracy\n",
    "\n",
    "# Step 3: Running it\n",
    "study = optuna.create_study(direction=\"maximize\",sampler=optuna.samplers.TPESampler(seed=1))\n",
    "study.optimize(objective, n_trials=100, show_progress_bar=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "cd09afa2-c7ae-4f28-acb3-9a0c06e89504",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best parameters are : \n",
      "{'logreg_c': 29.597571026748778, 'l1_ratio': 0.933438675245377, 'max_iter': 898}\n"
     ]
    }
   ],
   "source": [
    "# Getting the best parameters:\n",
    "print(f\"The best parameters are : \\n{study.best_params}\")\n",
    "# Setting the best model\n",
    "clf=LogisticRegression(C=study.best_params['logreg_c'],\n",
    "                              max_iter=study.best_params['max_iter'],\n",
    "                              l1_ratio=study.best_params['l1_ratio'],\n",
    "                              solver='liblinear',\n",
    "                              random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "18f98263-5b44-4a58-ad76-bd2288347abf",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mean</th>\n",
       "      <th>Se</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Accuracy_test</th>\n",
       "      <td>0.881032</td>\n",
       "      <td>0.005531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Accuracy_train</th>\n",
       "      <td>0.954926</td>\n",
       "      <td>0.001425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1 Score</th>\n",
       "      <td>0.658452</td>\n",
       "      <td>0.019469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Precision</th>\n",
       "      <td>0.784282</td>\n",
       "      <td>0.023684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recall</th>\n",
       "      <td>0.616667</td>\n",
       "      <td>0.027988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Roc_auc</th>\n",
       "      <td>0.850025</td>\n",
       "      <td>0.013598</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Mean        Se\n",
       "Accuracy_test   0.881032  0.005531\n",
       "Accuracy_train  0.954926  0.001425\n",
       "F1 Score        0.658452  0.019469\n",
       "Precision       0.784282  0.023684\n",
       "Recall          0.616667  0.027988\n",
       "Roc_auc         0.850025  0.013598"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Model2\n",
    "Model2=Model_results(clf,X,y,Cv_model)\n",
    "Model2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "0eba0a05-824b-4da4-8a16-535220341d36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th>Method</th>\n",
       "      <th colspan=\"4\" halign=\"left\">LR</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model</th>\n",
       "      <th colspan=\"2\" halign=\"left\">Model 1</th>\n",
       "      <th colspan=\"2\" halign=\"left\">Model 2</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Values</th>\n",
       "      <th>Mean</th>\n",
       "      <th>Se</th>\n",
       "      <th>Mean</th>\n",
       "      <th>Se</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Accuracy_test</th>\n",
       "      <td>0.832839</td>\n",
       "      <td>0.004275</td>\n",
       "      <td>0.881032</td>\n",
       "      <td>0.005531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Accuracy_train</th>\n",
       "      <td>0.867599</td>\n",
       "      <td>0.002416</td>\n",
       "      <td>0.954926</td>\n",
       "      <td>0.001425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1 Score</th>\n",
       "      <td>0.329908</td>\n",
       "      <td>0.026033</td>\n",
       "      <td>0.658452</td>\n",
       "      <td>0.019469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Precision</th>\n",
       "      <td>0.699905</td>\n",
       "      <td>0.052053</td>\n",
       "      <td>0.784282</td>\n",
       "      <td>0.023684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recall</th>\n",
       "      <td>0.233333</td>\n",
       "      <td>0.021602</td>\n",
       "      <td>0.616667</td>\n",
       "      <td>0.027988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Roc_auc</th>\n",
       "      <td>0.842453</td>\n",
       "      <td>0.011783</td>\n",
       "      <td>0.850025</td>\n",
       "      <td>0.013598</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Method                LR                              \n",
       "Model            Model 1             Model 2          \n",
       "Values              Mean        Se      Mean        Se\n",
       "Accuracy_test   0.832839  0.004275  0.881032  0.005531\n",
       "Accuracy_train  0.867599  0.002416  0.954926  0.001425\n",
       "F1 Score        0.329908  0.026033  0.658452  0.019469\n",
       "Precision       0.699905  0.052053  0.784282  0.023684\n",
       "Recall          0.233333  0.021602  0.616667  0.027988\n",
       "Roc_auc         0.842453  0.011783  0.850025  0.013598"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Saving the data of model performance\n",
    "Model_data=pd.concat([Model1,Model2],axis=1)\n",
    "Model_data.columns = [['LR']*4,['Model 1','Model 1', 'Model 2','Model 2'], ['Mean', 'Se', 'Mean', 'Se']]  \n",
    "Model_data.columns.names=['Method','Model','Values']\n",
    "Model_data.to_csv(\"./LR_model_lasso_data.csv\",sep=',')\n",
    "Model_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0844c7c8-f6b1-410a-b253-879aedd14e57",
   "metadata": {},
   "source": [
    "## 1.3 RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "d9c4731c-bbfe-47eb-bb7f-7d8b2909ea2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf=RandomForestClassifier(random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "ffdd2f35-ec29-4ef8-8309-6a84646f4539",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mean</th>\n",
       "      <th>Se</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Accuracy_test</th>\n",
       "      <td>0.823720</td>\n",
       "      <td>0.008227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Accuracy_train</th>\n",
       "      <td>0.994904</td>\n",
       "      <td>0.000564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1 Score</th>\n",
       "      <td>0.454477</td>\n",
       "      <td>0.024982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Precision</th>\n",
       "      <td>0.604476</td>\n",
       "      <td>0.032470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recall</th>\n",
       "      <td>0.390000</td>\n",
       "      <td>0.025652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Roc_auc</th>\n",
       "      <td>0.866739</td>\n",
       "      <td>0.011111</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Mean        Se\n",
       "Accuracy_test   0.823720  0.008227\n",
       "Accuracy_train  0.994904  0.000564\n",
       "F1 Score        0.454477  0.024982\n",
       "Precision       0.604476  0.032470\n",
       "Recall          0.390000  0.025652\n",
       "Roc_auc         0.866739  0.011111"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Model1 （4175 descriptors）\n",
    "Model1_clf=clf\n",
    "#Model1\n",
    "Model1=Model_results(Model1_clf,X,y,Cv_model)\n",
    "Model1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "6f4b6d2b-6cf0-4f44-8bd5-02b5d1377add",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2024-11-14 02:25:15,910]\u001b[0m A new study created in memory with name: no-name-312145da-c670-4377-8740-6146bea91d23\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 02:25:19,792]\u001b[0m Trial 0 finished with value: 0.8025806451612902 and parameters: {'n_estimators': 594, 'max_depth': 16, 'max_features': 20, 'min_impurity_decrease': 2.724415914984484}. Best is trial 0 with value: 0.8025806451612902.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 02:25:22,955]\u001b[0m Trial 1 finished with value: 0.8025806451612902 and parameters: {'n_estimators': 481, 'max_depth': 15, 'max_features': 16, 'min_impurity_decrease': 4.4588650039103985}. Best is trial 0 with value: 0.8025806451612902.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 02:25:29,050]\u001b[0m Trial 2 finished with value: 0.8025806451612902 and parameters: {'n_estimators': 968, 'max_depth': 11, 'max_features': 25, 'min_impurity_decrease': 2.644474598764522}. Best is trial 0 with value: 0.8025806451612902.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 02:25:32,879]\u001b[0m Trial 3 finished with value: 0.8025806451612902 and parameters: {'n_estimators': 611, 'max_depth': 19, 'max_features': 6, 'min_impurity_decrease': 0.43564649850770354}. Best is trial 0 with value: 0.8025806451612902.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 02:25:33,699]\u001b[0m Trial 4 finished with value: 0.8025806451612902 and parameters: {'n_estimators': 118, 'max_depth': 18, 'max_features': 25, 'min_impurity_decrease': 4.3500607412340955}. Best is trial 0 with value: 0.8025806451612902.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 02:25:39,687]\u001b[0m Trial 5 finished with value: 0.8025806451612902 and parameters: {'n_estimators': 981, 'max_depth': 17, 'max_features': 16, 'min_impurity_decrease': 3.902645881432277}. Best is trial 0 with value: 0.8025806451612902.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 02:25:41,107]\u001b[0m Trial 6 finished with value: 0.8025806451612902 and parameters: {'n_estimators': 206, 'max_depth': 15, 'max_features': 8, 'min_impurity_decrease': 4.7233445852479194}. Best is trial 0 with value: 0.8025806451612902.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 02:25:44,656]\u001b[0m Trial 7 finished with value: 0.8025806451612902 and parameters: {'n_estimators': 570, 'max_depth': 11, 'max_features': 11, 'min_impurity_decrease': 3.871168447171083}. Best is trial 0 with value: 0.8025806451612902.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 02:25:47,873]\u001b[0m Trial 8 finished with value: 0.8025806451612902 and parameters: {'n_estimators': 510, 'max_depth': 14, 'max_features': 5, 'min_impurity_decrease': 3.0881774853793855}. Best is trial 0 with value: 0.8025806451612902.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 02:25:52,055]\u001b[0m Trial 9 finished with value: 0.8025806451612902 and parameters: {'n_estimators': 651, 'max_depth': 14, 'max_features': 29, 'min_impurity_decrease': 3.409101495517417}. Best is trial 0 with value: 0.8025806451612902.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 02:25:56,968]\u001b[0m Trial 10 finished with value: 0.8025806451612902 and parameters: {'n_estimators': 790, 'max_depth': 7, 'max_features': 21, 'min_impurity_decrease': 1.5046577569438309}. Best is trial 0 with value: 0.8025806451612902.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 02:25:59,357]\u001b[0m Trial 11 finished with value: 0.8025806451612902 and parameters: {'n_estimators': 397, 'max_depth': 20, 'max_features': 16, 'min_impurity_decrease': 1.9887909510549393}. Best is trial 0 with value: 0.8025806451612902.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 02:26:01,567]\u001b[0m Trial 12 finished with value: 0.8025806451612902 and parameters: {'n_estimators': 353, 'max_depth': 16, 'max_features': 20, 'min_impurity_decrease': 0.702937495519433}. Best is trial 0 with value: 0.8025806451612902.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 02:26:04,045]\u001b[0m Trial 13 finished with value: 0.8025806451612902 and parameters: {'n_estimators': 411, 'max_depth': 12, 'max_features': 12, 'min_impurity_decrease': 4.931175650908394}. Best is trial 0 with value: 0.8025806451612902.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 02:26:08,558]\u001b[0m Trial 14 finished with value: 0.8025806451612902 and parameters: {'n_estimators': 743, 'max_depth': 7, 'max_features': 19, 'min_impurity_decrease': 1.5253121430442045}. Best is trial 0 with value: 0.8025806451612902.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 02:26:13,085]\u001b[0m Trial 15 finished with value: 0.8025806451612902 and parameters: {'n_estimators': 757, 'max_depth': 13, 'max_features': 12, 'min_impurity_decrease': 2.668111844473928}. Best is trial 0 with value: 0.8025806451612902.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 02:26:14,843]\u001b[0m Trial 16 finished with value: 0.8025806451612902 and parameters: {'n_estimators': 286, 'max_depth': 9, 'max_features': 24, 'min_impurity_decrease': 3.4814210246729473}. Best is trial 0 with value: 0.8025806451612902.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 02:26:19,664]\u001b[0m Trial 17 finished with value: 0.8025806451612902 and parameters: {'n_estimators': 807, 'max_depth': 5, 'max_features': 19, 'min_impurity_decrease': 1.4307627258174405}. Best is trial 0 with value: 0.8025806451612902.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 02:26:23,936]\u001b[0m Trial 18 finished with value: 0.8025806451612902 and parameters: {'n_estimators': 714, 'max_depth': 13, 'max_features': 12, 'min_impurity_decrease': 2.5740699841477164}. Best is trial 0 with value: 0.8025806451612902.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 02:26:25,749]\u001b[0m Trial 19 finished with value: 0.8025806451612902 and parameters: {'n_estimators': 291, 'max_depth': 8, 'max_features': 24, 'min_impurity_decrease': 3.3144569973486893}. Best is trial 0 with value: 0.8025806451612902.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 02:26:30,968]\u001b[0m Trial 20 finished with value: 0.8025806451612902 and parameters: {'n_estimators': 871, 'max_depth': 5, 'max_features': 29, 'min_impurity_decrease': 1.0528796896599455}. Best is trial 0 with value: 0.8025806451612902.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 02:26:34,990]\u001b[0m Trial 21 finished with value: 0.8025806451612902 and parameters: {'n_estimators': 670, 'max_depth': 10, 'max_features': 14, 'min_impurity_decrease': 2.1272690676619233}. Best is trial 0 with value: 0.8025806451612902.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 02:26:38,025]\u001b[0m Trial 22 finished with value: 0.8025806451612902 and parameters: {'n_estimators': 502, 'max_depth': 9, 'max_features': 23, 'min_impurity_decrease': 3.0212243946132658}. Best is trial 0 with value: 0.8025806451612902.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 02:26:43,288]\u001b[0m Trial 23 finished with value: 0.8025806451612902 and parameters: {'n_estimators': 871, 'max_depth': 6, 'max_features': 30, 'min_impurity_decrease': 0.8924229302747376}. Best is trial 0 with value: 0.8025806451612902.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 02:26:47,367]\u001b[0m Trial 24 finished with value: 0.8025806451612902 and parameters: {'n_estimators': 673, 'max_depth': 11, 'max_features': 28, 'min_impurity_decrease': 2.1839582613393773}. Best is trial 0 with value: 0.8025806451612902.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 02:26:50,700]\u001b[0m Trial 25 finished with value: 0.8025806451612902 and parameters: {'n_estimators': 548, 'max_depth': 9, 'max_features': 22, 'min_impurity_decrease': 2.0762642939740097}. Best is trial 0 with value: 0.8025806451612902.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 02:26:56,440]\u001b[0m Trial 26 finished with value: 0.8176774193548388 and parameters: {'n_estimators': 859, 'max_depth': 7, 'max_features': 27, 'min_impurity_decrease': 0.05016303754931073}. Best is trial 26 with value: 0.8176774193548388.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 02:27:02,892]\u001b[0m Trial 27 finished with value: 0.8295698924731183 and parameters: {'n_estimators': 889, 'max_depth': 6, 'max_features': 27, 'min_impurity_decrease': 0.0085734336612443}. Best is trial 27 with value: 0.8295698924731183.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 02:27:09,078]\u001b[0m Trial 28 finished with value: 0.8229892473118281 and parameters: {'n_estimators': 901, 'max_depth': 7, 'max_features': 27, 'min_impurity_decrease': 0.0444905724402096}. Best is trial 27 with value: 0.8295698924731183.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 02:27:15,025]\u001b[0m Trial 29 finished with value: 0.8012688172043009 and parameters: {'n_estimators': 918, 'max_depth': 7, 'max_features': 27, 'min_impurity_decrease': 0.06568686852538644}. Best is trial 27 with value: 0.8295698924731183.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 02:27:20,204]\u001b[0m Trial 30 finished with value: 0.8025806451612902 and parameters: {'n_estimators': 855, 'max_depth': 6, 'max_features': 26, 'min_impurity_decrease': 0.3179551086113592}. Best is trial 27 with value: 0.8295698924731183.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 02:27:25,832]\u001b[0m Trial 31 finished with value: 0.8025806451612902 and parameters: {'n_estimators': 921, 'max_depth': 8, 'max_features': 27, 'min_impurity_decrease': 0.23398073841386186}. Best is trial 27 with value: 0.8295698924731183.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 02:27:32,889]\u001b[0m Trial 32 finished with value: 0.8276129032258064 and parameters: {'n_estimators': 990, 'max_depth': 5, 'max_features': 30, 'min_impurity_decrease': 0.014470121697879635}. Best is trial 27 with value: 0.8295698924731183.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 02:27:39,929]\u001b[0m Trial 33 finished with value: 0.832215053763441 and parameters: {'n_estimators': 974, 'max_depth': 5, 'max_features': 30, 'min_impurity_decrease': 0.0020653183224312883}. Best is trial 33 with value: 0.832215053763441.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 02:27:45,973]\u001b[0m Trial 34 finished with value: 0.8025806451612902 and parameters: {'n_estimators': 993, 'max_depth': 5, 'max_features': 30, 'min_impurity_decrease': 0.6299600959488391}. Best is trial 33 with value: 0.832215053763441.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 02:27:51,587]\u001b[0m Trial 35 finished with value: 0.8025806451612902 and parameters: {'n_estimators': 932, 'max_depth': 6, 'max_features': 30, 'min_impurity_decrease': 1.116553091996068}. Best is trial 33 with value: 0.832215053763441.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 02:27:57,294]\u001b[0m Trial 36 finished with value: 0.8025806451612902 and parameters: {'n_estimators': 940, 'max_depth': 5, 'max_features': 25, 'min_impurity_decrease': 0.5211697686396031}. Best is trial 33 with value: 0.832215053763441.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 02:28:02,291]\u001b[0m Trial 37 finished with value: 0.8025806451612902 and parameters: {'n_estimators': 818, 'max_depth': 6, 'max_features': 28, 'min_impurity_decrease': 0.356134600920089}. Best is trial 33 with value: 0.832215053763441.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 02:28:08,816]\u001b[0m Trial 38 finished with value: 0.8019139784946236 and parameters: {'n_estimators': 998, 'max_depth': 8, 'max_features': 26, 'min_impurity_decrease': 0.06415477353345975}. Best is trial 33 with value: 0.832215053763441.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 02:28:14,309]\u001b[0m Trial 39 finished with value: 0.8025806451612902 and parameters: {'n_estimators': 907, 'max_depth': 5, 'max_features': 28, 'min_impurity_decrease': 0.7444867452798501}. Best is trial 33 with value: 0.832215053763441.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 02:28:20,108]\u001b[0m Trial 40 finished with value: 0.8025806451612902 and parameters: {'n_estimators': 960, 'max_depth': 6, 'max_features': 29, 'min_impurity_decrease': 1.2530333907876274}. Best is trial 33 with value: 0.832215053763441.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 02:28:25,858]\u001b[0m Trial 41 finished with value: 0.8104731182795699 and parameters: {'n_estimators': 853, 'max_depth': 7, 'max_features': 26, 'min_impurity_decrease': 0.052866770873616756}. Best is trial 33 with value: 0.832215053763441.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 02:28:31,248]\u001b[0m Trial 42 finished with value: 0.8025806451612902 and parameters: {'n_estimators': 892, 'max_depth': 7, 'max_features': 27, 'min_impurity_decrease': 0.35537949030850763}. Best is trial 33 with value: 0.832215053763441.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 02:28:36,905]\u001b[0m Trial 43 finished with value: 0.8236344086021505 and parameters: {'n_estimators': 823, 'max_depth': 8, 'max_features': 24, 'min_impurity_decrease': 0.0363911341977023}. Best is trial 33 with value: 0.832215053763441.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 02:28:42,810]\u001b[0m Trial 44 finished with value: 0.8025806451612902 and parameters: {'n_estimators': 960, 'max_depth': 8, 'max_features': 24, 'min_impurity_decrease': 0.49362867274137795}. Best is trial 33 with value: 0.832215053763441.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 02:28:47,728]\u001b[0m Trial 45 finished with value: 0.8025806451612902 and parameters: {'n_estimators': 818, 'max_depth': 10, 'max_features': 22, 'min_impurity_decrease': 0.9072566496041408}. Best is trial 33 with value: 0.832215053763441.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 02:28:52,404]\u001b[0m Trial 46 finished with value: 0.8025806451612902 and parameters: {'n_estimators': 769, 'max_depth': 6, 'max_features': 30, 'min_impurity_decrease': 0.2555603035914258}. Best is trial 33 with value: 0.832215053763441.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 02:28:58,246]\u001b[0m Trial 47 finished with value: 0.8025806451612902 and parameters: {'n_estimators': 962, 'max_depth': 5, 'max_features': 28, 'min_impurity_decrease': 0.6816047837540029}. Best is trial 33 with value: 0.832215053763441.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 02:29:02,594]\u001b[0m Trial 48 finished with value: 0.8025806451612902 and parameters: {'n_estimators': 710, 'max_depth': 8, 'max_features': 25, 'min_impurity_decrease': 1.7554372932180642}. Best is trial 33 with value: 0.832215053763441.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 02:29:03,300]\u001b[0m Trial 49 finished with value: 0.8025806451612902 and parameters: {'n_estimators': 107, 'max_depth': 6, 'max_features': 29, 'min_impurity_decrease': 0.19062861357009453}. Best is trial 33 with value: 0.832215053763441.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 02:29:09,202]\u001b[0m Trial 50 finished with value: 0.8296129032258064 and parameters: {'n_estimators': 826, 'max_depth': 7, 'max_features': 17, 'min_impurity_decrease': 0.0016278474652756392}. Best is trial 33 with value: 0.832215053763441.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 02:29:14,198]\u001b[0m Trial 51 finished with value: 0.8025806451612902 and parameters: {'n_estimators': 830, 'max_depth': 7, 'max_features': 18, 'min_impurity_decrease': 0.4996743830137399}. Best is trial 33 with value: 0.832215053763441.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 02:29:19,632]\u001b[0m Trial 52 finished with value: 0.8025806451612902 and parameters: {'n_estimators': 900, 'max_depth': 5, 'max_features': 16, 'min_impurity_decrease': 0.20945384686699886}. Best is trial 33 with value: 0.832215053763441.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 02:29:24,315]\u001b[0m Trial 53 finished with value: 0.8025806451612902 and parameters: {'n_estimators': 778, 'max_depth': 10, 'max_features': 14, 'min_impurity_decrease': 0.8091200795004378}. Best is trial 33 with value: 0.832215053763441.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 02:29:31,175]\u001b[0m Trial 54 finished with value: 0.8310107526881721 and parameters: {'n_estimators': 954, 'max_depth': 9, 'max_features': 21, 'min_impurity_decrease': 0.0002084238079327963}. Best is trial 33 with value: 0.832215053763441.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 02:29:37,196]\u001b[0m Trial 55 finished with value: 0.8025806451612902 and parameters: {'n_estimators': 997, 'max_depth': 9, 'max_features': 20, 'min_impurity_decrease': 0.4973594460426598}. Best is trial 33 with value: 0.832215053763441.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 02:29:40,871]\u001b[0m Trial 56 finished with value: 0.8025806451612902 and parameters: {'n_estimators': 615, 'max_depth': 12, 'max_features': 21, 'min_impurity_decrease': 4.063447563238093}. Best is trial 33 with value: 0.832215053763441.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 02:29:47,681]\u001b[0m Trial 57 finished with value: 0.8283010752688174 and parameters: {'n_estimators': 957, 'max_depth': 8, 'max_features': 17, 'min_impurity_decrease': 0.007051219363486183}. Best is trial 33 with value: 0.832215053763441.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 02:29:53,514]\u001b[0m Trial 58 finished with value: 0.8025806451612902 and parameters: {'n_estimators': 949, 'max_depth': 17, 'max_features': 17, 'min_impurity_decrease': 0.41758977190711427}. Best is trial 33 with value: 0.832215053763441.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 02:29:59,929]\u001b[0m Trial 59 finished with value: 0.8025806451612902 and parameters: {'n_estimators': 940, 'max_depth': 6, 'max_features': 9, 'min_impurity_decrease': 1.0649986501074014}. Best is trial 33 with value: 0.832215053763441.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 02:30:06,174]\u001b[0m Trial 60 finished with value: 0.8025806451612902 and parameters: {'n_estimators': 973, 'max_depth': 9, 'max_features': 15, 'min_impurity_decrease': 2.3325041140325435}. Best is trial 33 with value: 0.832215053763441.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 02:30:12,557]\u001b[0m Trial 61 finished with value: 0.828989247311828 and parameters: {'n_estimators': 847, 'max_depth': 8, 'max_features': 17, 'min_impurity_decrease': 0.008123194334826514}. Best is trial 33 with value: 0.832215053763441.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 02:30:17,990]\u001b[0m Trial 62 finished with value: 0.8025806451612902 and parameters: {'n_estimators': 873, 'max_depth': 10, 'max_features': 18, 'min_impurity_decrease': 0.21668318693705024}. Best is trial 33 with value: 0.832215053763441.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 02:30:23,558]\u001b[0m Trial 63 finished with value: 0.8025806451612902 and parameters: {'n_estimators': 894, 'max_depth': 8, 'max_features': 17, 'min_impurity_decrease': 0.1926438836261714}. Best is trial 33 with value: 0.832215053763441.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 02:30:29,768]\u001b[0m Trial 64 finished with value: 0.8025806451612902 and parameters: {'n_estimators': 1000, 'max_depth': 7, 'max_features': 19, 'min_impurity_decrease': 0.589797985950903}. Best is trial 33 with value: 0.832215053763441.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 02:30:34,191]\u001b[0m Trial 65 finished with value: 0.8025806451612902 and parameters: {'n_estimators': 726, 'max_depth': 5, 'max_features': 15, 'min_impurity_decrease': 0.3666751185586251}. Best is trial 33 with value: 0.832215053763441.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 02:30:40,897]\u001b[0m Trial 66 finished with value: 0.82952688172043 and parameters: {'n_estimators': 928, 'max_depth': 11, 'max_features': 16, 'min_impurity_decrease': 0.01737750594352438}. Best is trial 33 with value: 0.832215053763441.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 02:30:45,680]\u001b[0m Trial 67 finished with value: 0.8025806451612902 and parameters: {'n_estimators': 795, 'max_depth': 11, 'max_features': 14, 'min_impurity_decrease': 0.17988994593460603}. Best is trial 33 with value: 0.832215053763441.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 02:30:50,728]\u001b[0m Trial 68 finished with value: 0.8025806451612902 and parameters: {'n_estimators': 844, 'max_depth': 12, 'max_features': 15, 'min_impurity_decrease': 0.8889686967425583}. Best is trial 33 with value: 0.832215053763441.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 02:30:56,334]\u001b[0m Trial 69 finished with value: 0.8025806451612902 and parameters: {'n_estimators': 930, 'max_depth': 9, 'max_features': 13, 'min_impurity_decrease': 0.6650598143149754}. Best is trial 33 with value: 0.832215053763441.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 02:31:01,843]\u001b[0m Trial 70 finished with value: 0.8025806451612902 and parameters: {'n_estimators': 881, 'max_depth': 11, 'max_features': 20, 'min_impurity_decrease': 0.3699218203110278}. Best is trial 33 with value: 0.832215053763441.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 02:31:07,981]\u001b[0m Trial 71 finished with value: 0.8025806451612902 and parameters: {'n_estimators': 966, 'max_depth': 6, 'max_features': 16, 'min_impurity_decrease': 0.08590526653818167}. Best is trial 33 with value: 0.832215053763441.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 02:31:14,652]\u001b[0m Trial 72 finished with value: 0.8229247311827956 and parameters: {'n_estimators': 915, 'max_depth': 7, 'max_features': 17, 'min_impurity_decrease': 0.030568536785010727}. Best is trial 33 with value: 0.832215053763441.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 02:31:20,799]\u001b[0m Trial 73 finished with value: 0.8025806451612902 and parameters: {'n_estimators': 981, 'max_depth': 20, 'max_features': 18, 'min_impurity_decrease': 0.2869453406804311}. Best is trial 33 with value: 0.832215053763441.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 02:31:26,783]\u001b[0m Trial 74 finished with value: 0.8025806451612902 and parameters: {'n_estimators': 934, 'max_depth': 13, 'max_features': 19, 'min_impurity_decrease': 0.16536070258549063}. Best is trial 33 with value: 0.832215053763441.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 02:31:28,406]\u001b[0m Trial 75 finished with value: 0.8282795698924731 and parameters: {'n_estimators': 216, 'max_depth': 15, 'max_features': 17, 'min_impurity_decrease': 0.003337305260820815}. Best is trial 33 with value: 0.832215053763441.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 02:31:29,494]\u001b[0m Trial 76 finished with value: 0.8025806451612902 and parameters: {'n_estimators': 159, 'max_depth': 15, 'max_features': 17, 'min_impurity_decrease': 0.4103531412222686}. Best is trial 33 with value: 0.832215053763441.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 02:31:31,829]\u001b[0m Trial 77 finished with value: 0.828258064516129 and parameters: {'n_estimators': 318, 'max_depth': 14, 'max_features': 16, 'min_impurity_decrease': 0.013867218003712546}. Best is trial 33 with value: 0.832215053763441.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 02:31:34,824]\u001b[0m Trial 78 finished with value: 0.8025806451612902 and parameters: {'n_estimators': 457, 'max_depth': 10, 'max_features': 21, 'min_impurity_decrease': 0.5199197908379947}. Best is trial 33 with value: 0.832215053763441.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 02:31:39,948]\u001b[0m Trial 79 finished with value: 0.8025806451612902 and parameters: {'n_estimators': 838, 'max_depth': 18, 'max_features': 18, 'min_impurity_decrease': 2.9108942993735676}. Best is trial 33 with value: 0.832215053763441.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 02:31:41,403]\u001b[0m Trial 80 finished with value: 0.8025806451612902 and parameters: {'n_estimators': 221, 'max_depth': 15, 'max_features': 13, 'min_impurity_decrease': 0.281758374388446}. Best is trial 33 with value: 0.832215053763441.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 02:31:43,593]\u001b[0m Trial 81 finished with value: 0.8276559139784946 and parameters: {'n_estimators': 291, 'max_depth': 14, 'max_features': 16, 'min_impurity_decrease': 0.006292164578151396}. Best is trial 33 with value: 0.832215053763441.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 02:31:44,833]\u001b[0m Trial 82 finished with value: 0.8025806451612902 and parameters: {'n_estimators': 198, 'max_depth': 14, 'max_features': 15, 'min_impurity_decrease': 0.14546238156600932}. Best is trial 33 with value: 0.832215053763441.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 02:31:46,302]\u001b[0m Trial 83 finished with value: 0.8025806451612902 and parameters: {'n_estimators': 223, 'max_depth': 16, 'max_features': 16, 'min_impurity_decrease': 0.2932680461618005}. Best is trial 33 with value: 0.832215053763441.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 02:31:47,352]\u001b[0m Trial 84 finished with value: 0.8388602150537635 and parameters: {'n_estimators': 133, 'max_depth': 16, 'max_features': 17, 'min_impurity_decrease': 0.0038424140335707804}. Best is trial 84 with value: 0.8388602150537635.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 02:31:48,345]\u001b[0m Trial 85 finished with value: 0.8025806451612902 and parameters: {'n_estimators': 153, 'max_depth': 17, 'max_features': 19, 'min_impurity_decrease': 0.16556093433172428}. Best is trial 84 with value: 0.8388602150537635.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 02:31:49,242]\u001b[0m Trial 86 finished with value: 0.8025806451612902 and parameters: {'n_estimators': 133, 'max_depth': 16, 'max_features': 17, 'min_impurity_decrease': 0.5848263261397242}. Best is trial 84 with value: 0.8388602150537635.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 02:31:51,992]\u001b[0m Trial 87 finished with value: 0.8025806451612902 and parameters: {'n_estimators': 432, 'max_depth': 8, 'max_features': 19, 'min_impurity_decrease': 0.4431640863147425}. Best is trial 84 with value: 0.8388602150537635.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 02:31:55,671]\u001b[0m Trial 88 finished with value: 0.8025806451612902 and parameters: {'n_estimators': 545, 'max_depth': 8, 'max_features': 22, 'min_impurity_decrease': 0.8105484903759221}. Best is trial 84 with value: 0.8388602150537635.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 02:31:58,151]\u001b[0m Trial 89 finished with value: 0.8025806451612902 and parameters: {'n_estimators': 375, 'max_depth': 17, 'max_features': 18, 'min_impurity_decrease': 0.11673311997293079}. Best is trial 84 with value: 0.8388602150537635.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 02:31:59,366]\u001b[0m Trial 90 finished with value: 0.8025806451612902 and parameters: {'n_estimators': 182, 'max_depth': 9, 'max_features': 20, 'min_impurity_decrease': 4.493469463689617}. Best is trial 84 with value: 0.8388602150537635.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 02:32:01,425]\u001b[0m Trial 91 finished with value: 0.828301075268817 and parameters: {'n_estimators': 265, 'max_depth': 15, 'max_features': 16, 'min_impurity_decrease': 0.007826427498523877}. Best is trial 84 with value: 0.8388602150537635.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 02:32:03,208]\u001b[0m Trial 92 finished with value: 0.8025806451612902 and parameters: {'n_estimators': 255, 'max_depth': 15, 'max_features': 14, 'min_impurity_decrease': 0.29314588306562384}. Best is trial 84 with value: 0.8388602150537635.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 02:32:05,078]\u001b[0m Trial 93 finished with value: 0.8025806451612902 and parameters: {'n_estimators': 264, 'max_depth': 16, 'max_features': 15, 'min_impurity_decrease': 0.14040984625323874}. Best is trial 84 with value: 0.8388602150537635.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 02:32:06,094]\u001b[0m Trial 94 finished with value: 0.8025806451612902 and parameters: {'n_estimators': 128, 'max_depth': 18, 'max_features': 17, 'min_impurity_decrease': 0.34970551201546674}. Best is trial 84 with value: 0.8388602150537635.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 02:32:08,829]\u001b[0m Trial 95 finished with value: 0.8276559139784948 and parameters: {'n_estimators': 340, 'max_depth': 15, 'max_features': 16, 'min_impurity_decrease': 0.005748198134294144}. Best is trial 84 with value: 0.8388602150537635.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 02:32:15,195]\u001b[0m Trial 96 finished with value: 0.8025806451612902 and parameters: {'n_estimators': 873, 'max_depth': 13, 'max_features': 18, 'min_impurity_decrease': 0.13799456264116366}. Best is trial 84 with value: 0.8388602150537635.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 02:32:22,197]\u001b[0m Trial 97 finished with value: 0.8025806451612902 and parameters: {'n_estimators': 911, 'max_depth': 7, 'max_features': 13, 'min_impurity_decrease': 0.25029790427471366}. Best is trial 84 with value: 0.8388602150537635.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 02:32:23,801]\u001b[0m Trial 98 finished with value: 0.8316559139784947 and parameters: {'n_estimators': 176, 'max_depth': 16, 'max_features': 10, 'min_impurity_decrease': 0.0005897666309661979}. Best is trial 84 with value: 0.8388602150537635.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 02:32:25,075]\u001b[0m Trial 99 finished with value: 0.8025806451612902 and parameters: {'n_estimators': 169, 'max_depth': 16, 'max_features': 6, 'min_impurity_decrease': 0.5697725198061568}. Best is trial 84 with value: 0.8388602150537635.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "#Tuning hyperparameters\n",
    "#Step 1. Define an objective function to be maximized.\n",
    "def objective(trial):\n",
    "    n_estimators = trial.suggest_int(\"n_estimators\",100,1000,1) \n",
    "    max_depth = trial.suggest_int(\"max_depth\",5,20,1)\n",
    "    max_features = trial.suggest_int(\"max_features\",5,30,1)\n",
    "    min_impurity_decrease = trial.suggest_float(\"min_impurity_decrease\",0,5,log=False) \n",
    "    model = RandomForestClassifier(n_estimators = n_estimators\n",
    "              ,max_depth = max_depth\n",
    "              ,max_features = max_features\n",
    "              ,min_impurity_decrease = min_impurity_decrease\n",
    "              ,random_state=1\n",
    "              ,verbose=False\n",
    "              ,n_jobs=8)\n",
    "\n",
    "# Step 2: Scoring method:\n",
    "    score = model_selection.cross_val_score(model, X, y, n_jobs=8, scoring=\"accuracy\",cv=Cv_optuna)\n",
    "    accuracy = score.mean()\n",
    "    return accuracy\n",
    " \n",
    "# Step 3: Running it\n",
    "study = optuna.create_study(direction=\"maximize\",sampler=optuna.samplers.TPESampler(seed=0))\n",
    "study.optimize(objective, n_trials=100, show_progress_bar=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "3ea7fc26-11ae-497b-ab4a-949cd12a43a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best parameters are : \n",
      "{'n_estimators': 133, 'max_depth': 16, 'max_features': 17, 'min_impurity_decrease': 0.0038424140335707804}\n"
     ]
    }
   ],
   "source": [
    "# Getting the best parameters:\n",
    "print(f\"The best parameters are : \\n{study.best_params}\")\n",
    "# Setting the best model\n",
    "clf=RandomForestClassifier(n_estimators = study.best_params['n_estimators']\n",
    "              ,max_depth = study.best_params['max_depth']\n",
    "              ,max_features = study.best_params['max_features']\n",
    "              ,min_impurity_decrease = study.best_params['min_impurity_decrease']\n",
    "              ,random_state=0\n",
    "              ,verbose=False\n",
    "              ,n_jobs=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "90cca67e-3df8-43ff-8b96-2c9bec87ee43",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mean</th>\n",
       "      <th>Se</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Accuracy_test</th>\n",
       "      <td>0.831591</td>\n",
       "      <td>0.007737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Accuracy_train</th>\n",
       "      <td>0.994904</td>\n",
       "      <td>0.000564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1 Score</th>\n",
       "      <td>0.466679</td>\n",
       "      <td>0.025538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Precision</th>\n",
       "      <td>0.646048</td>\n",
       "      <td>0.032705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recall</th>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.027487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Roc_auc</th>\n",
       "      <td>0.866442</td>\n",
       "      <td>0.010530</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Mean        Se\n",
       "Accuracy_test   0.831591  0.007737\n",
       "Accuracy_train  0.994904  0.000564\n",
       "F1 Score        0.466679  0.025538\n",
       "Precision       0.646048  0.032705\n",
       "Recall          0.400000  0.027487\n",
       "Roc_auc         0.866442  0.010530"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Model2\n",
    "Model2=Model_results(clf,X,y,Cv_model)\n",
    "Model2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "346eea08-6a51-48fc-bfcd-1a8d913649a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th>Method</th>\n",
       "      <th colspan=\"4\" halign=\"left\">RF</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model</th>\n",
       "      <th colspan=\"2\" halign=\"left\">Model 1</th>\n",
       "      <th colspan=\"2\" halign=\"left\">Model 2</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Values</th>\n",
       "      <th>Mean</th>\n",
       "      <th>Se</th>\n",
       "      <th>Mean</th>\n",
       "      <th>Se</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Accuracy_test</th>\n",
       "      <td>0.823720</td>\n",
       "      <td>0.008227</td>\n",
       "      <td>0.831591</td>\n",
       "      <td>0.007737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Accuracy_train</th>\n",
       "      <td>0.994904</td>\n",
       "      <td>0.000564</td>\n",
       "      <td>0.994904</td>\n",
       "      <td>0.000564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1 Score</th>\n",
       "      <td>0.454477</td>\n",
       "      <td>0.024982</td>\n",
       "      <td>0.466679</td>\n",
       "      <td>0.025538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Precision</th>\n",
       "      <td>0.604476</td>\n",
       "      <td>0.032470</td>\n",
       "      <td>0.646048</td>\n",
       "      <td>0.032705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recall</th>\n",
       "      <td>0.390000</td>\n",
       "      <td>0.025652</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.027487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Roc_auc</th>\n",
       "      <td>0.866739</td>\n",
       "      <td>0.011111</td>\n",
       "      <td>0.866442</td>\n",
       "      <td>0.010530</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Method                RF                              \n",
       "Model            Model 1             Model 2          \n",
       "Values              Mean        Se      Mean        Se\n",
       "Accuracy_test   0.823720  0.008227  0.831591  0.007737\n",
       "Accuracy_train  0.994904  0.000564  0.994904  0.000564\n",
       "F1 Score        0.454477  0.024982  0.466679  0.025538\n",
       "Precision       0.604476  0.032470  0.646048  0.032705\n",
       "Recall          0.390000  0.025652  0.400000  0.027487\n",
       "Roc_auc         0.866739  0.011111  0.866442  0.010530"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Saving the data of model performance\n",
    "Model_data=pd.concat([Model1,Model2],axis=1)\n",
    "Model_data.columns = [['RF']*4,['Model 1','Model 1', 'Model 2','Model 2'], ['Mean', 'Se', 'Mean', 'Se']]  \n",
    "Model_data.columns.names=['Method','Model','Values']\n",
    "Model_data.to_csv(\"./RF_model_lasso_data.csv\",sep=',')\n",
    "Model_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "115be659-b066-4abf-85ac-59fccd101ad4",
   "metadata": {},
   "source": [
    "## 1.4 XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "3ff2324c-d316-43ae-96dc-e58f404273a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf=xgb.XGBClassifier(random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "03979633-d8bb-44e7-a9d7-b7050c4c32c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mean</th>\n",
       "      <th>Se</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Accuracy_test</th>\n",
       "      <td>0.845355</td>\n",
       "      <td>0.008474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Accuracy_train</th>\n",
       "      <td>0.994904</td>\n",
       "      <td>0.000564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1 Score</th>\n",
       "      <td>0.534738</td>\n",
       "      <td>0.027872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Precision</th>\n",
       "      <td>0.661317</td>\n",
       "      <td>0.032690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recall</th>\n",
       "      <td>0.483333</td>\n",
       "      <td>0.030641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Roc_auc</th>\n",
       "      <td>0.854125</td>\n",
       "      <td>0.012827</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Mean        Se\n",
       "Accuracy_test   0.845355  0.008474\n",
       "Accuracy_train  0.994904  0.000564\n",
       "F1 Score        0.534738  0.027872\n",
       "Precision       0.661317  0.032690\n",
       "Recall          0.483333  0.030641\n",
       "Roc_auc         0.854125  0.012827"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Model1 \n",
    "Model1_clf=clf\n",
    "#Model1\n",
    "Model1=Model_results(Model1_clf,X,y,Cv_model)\n",
    "Model1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "c6e5e42b-3688-4c6f-aa87-cf0fe5b1ff05",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2024-11-14 02:32:40,271]\u001b[0m A new study created in memory with name: no-name-7e8d39a0-b3ee-4361-b5a0-80028c308d33\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_37008\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_37008\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-11-14 02:32:43,059]\u001b[0m Trial 0 finished with value: 0.8487526881720429 and parameters: {'lambda': 0.15676677195506075, 'alpha': 0.7257005721594281, 'colsample_bytree': 0.7, 'subsample': 0.7000000000000001, 'learning_rate': 0.0801, 'n_estimators': 664}. Best is trial 0 with value: 0.8487526881720429.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_37008\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_37008\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-11-14 02:32:44,481]\u001b[0m Trial 1 finished with value: 0.8394193548387098 and parameters: {'lambda': 0.0562793204741517, 'alpha': 3.6905577292137624, 'colsample_bytree': 1.0, 'subsample': 0.6000000000000001, 'learning_rate': 0.1551, 'n_estimators': 552}. Best is trial 0 with value: 0.8487526881720429.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_37008\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_37008\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-11-14 02:32:47,049]\u001b[0m Trial 2 finished with value: 0.8025806451612902 and parameters: {'lambda': 0.18714500686240676, 'alpha': 5.039489598671215, 'colsample_bytree': 0.3, 'subsample': 0.4, 'learning_rate': 0.0001, 'n_estimators': 841}. Best is trial 0 with value: 0.8487526881720429.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_37008\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_37008\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-11-14 02:32:49,333]\u001b[0m Trial 3 finished with value: 0.8447956989247313 and parameters: {'lambda': 1.2960656597279736, 'alpha': 3.0202896401586674, 'colsample_bytree': 1.0, 'subsample': 0.9, 'learning_rate': 0.0901, 'n_estimators': 792}. Best is trial 0 with value: 0.8487526881720429.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_37008\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_37008\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-11-14 02:32:50,629]\u001b[0m Trial 4 finished with value: 0.8441935483870968 and parameters: {'lambda': 0.0029723346443356552, 'alpha': 0.3628140404024381, 'colsample_bytree': 0.4, 'subsample': 1.0, 'learning_rate': 0.10010000000000001, 'n_estimators': 444}. Best is trial 0 with value: 0.8487526881720429.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_37008\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_37008\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-11-14 02:32:53,859]\u001b[0m Trial 5 finished with value: 0.8289032258064515 and parameters: {'lambda': 0.011434638743472197, 'alpha': 1.2500712230836255, 'colsample_bytree': 0.6000000000000001, 'subsample': 0.7000000000000001, 'learning_rate': 0.0001, 'n_estimators': 637}. Best is trial 0 with value: 0.8487526881720429.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_37008\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_37008\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-11-14 02:32:55,593]\u001b[0m Trial 6 finished with value: 0.8487311827956989 and parameters: {'lambda': 0.2807908107885728, 'alpha': 0.2935864364395359, 'colsample_bytree': 1.0, 'subsample': 0.8, 'learning_rate': 0.07010000000000001, 'n_estimators': 465}. Best is trial 0 with value: 0.8487526881720429.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_37008\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_37008\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-11-14 02:32:56,537]\u001b[0m Trial 7 finished with value: 0.8414408602150537 and parameters: {'lambda': 0.6173405204074314, 'alpha': 0.0017414134181586202, 'colsample_bytree': 0.8, 'subsample': 0.8, 'learning_rate': 0.040100000000000004, 'n_estimators': 172}. Best is trial 0 with value: 0.8487526881720429.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_37008\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_37008\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-11-14 02:32:57,084]\u001b[0m Trial 8 finished with value: 0.8448817204301077 and parameters: {'lambda': 0.01826894228153233, 'alpha': 0.028499883436971588, 'colsample_bytree': 0.7, 'subsample': 0.7000000000000001, 'learning_rate': 0.1951, 'n_estimators': 147}. Best is trial 0 with value: 0.8487526881720429.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_37008\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_37008\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-11-14 02:32:58,133]\u001b[0m Trial 9 finished with value: 0.8421505376344086 and parameters: {'lambda': 0.006847105576684045, 'alpha': 0.004418125737902547, 'colsample_bytree': 0.8, 'subsample': 0.5, 'learning_rate': 0.0901, 'n_estimators': 282}. Best is trial 0 with value: 0.8487526881720429.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_37008\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_37008\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-11-14 02:33:01,094]\u001b[0m Trial 10 finished with value: 0.8415483870967742 and parameters: {'lambda': 5.790132527437159, 'alpha': 0.034364938361176656, 'colsample_bytree': 0.5, 'subsample': 0.5, 'learning_rate': 0.1351, 'n_estimators': 980}. Best is trial 0 with value: 0.8487526881720429.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_37008\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_37008\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-11-14 02:33:02,802]\u001b[0m Trial 11 finished with value: 0.8467741935483872 and parameters: {'lambda': 0.20193596847755327, 'alpha': 0.2979091959734134, 'colsample_bytree': 0.9000000000000001, 'subsample': 0.8, 'learning_rate': 0.0551, 'n_estimators': 410}. Best is trial 0 with value: 0.8487526881720429.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_37008\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_37008\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-11-14 02:33:04,999]\u001b[0m Trial 12 finished with value: 0.8415268817204303 and parameters: {'lambda': 0.05868944285728292, 'alpha': 0.213141835103914, 'colsample_bytree': 0.6000000000000001, 'subsample': 0.8, 'learning_rate': 0.050100000000000006, 'n_estimators': 678}. Best is trial 0 with value: 0.8487526881720429.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_37008\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_37008\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-11-14 02:33:06,141]\u001b[0m Trial 13 finished with value: 0.8394623655913978 and parameters: {'lambda': 1.4626691270385177, 'alpha': 0.8842298250911143, 'colsample_bytree': 0.8, 'subsample': 1.0, 'learning_rate': 0.1201, 'n_estimators': 345}. Best is trial 0 with value: 0.8487526881720429.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_37008\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_37008\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-11-14 02:33:07,942]\u001b[0m Trial 14 finished with value: 0.8461505376344085 and parameters: {'lambda': 0.37679709972350633, 'alpha': 0.051431996716705244, 'colsample_bytree': 0.9000000000000001, 'subsample': 0.6000000000000001, 'learning_rate': 0.0601, 'n_estimators': 556}. Best is trial 0 with value: 0.8487526881720429.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_37008\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_37008\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-11-14 02:33:11,508]\u001b[0m Trial 15 finished with value: 0.8480645161290322 and parameters: {'lambda': 7.009847606825168, 'alpha': 0.010756492078066606, 'colsample_bytree': 0.7, 'subsample': 0.9, 'learning_rate': 0.0301, 'n_estimators': 749}. Best is trial 0 with value: 0.8487526881720429.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_37008\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_37008\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-11-14 02:33:13,234]\u001b[0m Trial 16 finished with value: 0.8395698924731182 and parameters: {'lambda': 0.040658538258014895, 'alpha': 0.1024282575262232, 'colsample_bytree': 0.5, 'subsample': 0.6000000000000001, 'learning_rate': 0.0801, 'n_estimators': 492}. Best is trial 0 with value: 0.8487526881720429.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_37008\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_37008\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-11-14 02:33:15,785]\u001b[0m Trial 17 finished with value: 0.8454193548387097 and parameters: {'lambda': 0.0010007385532741766, 'alpha': 0.8502550550411554, 'colsample_bytree': 0.9000000000000001, 'subsample': 0.9, 'learning_rate': 0.1201, 'n_estimators': 910}. Best is trial 0 with value: 0.8487526881720429.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_37008\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_37008\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-11-14 02:33:18,996]\u001b[0m Trial 18 finished with value: 0.8454623655913979 and parameters: {'lambda': 1.9340559591528863, 'alpha': 0.11594964309788192, 'colsample_bytree': 1.0, 'subsample': 0.7000000000000001, 'learning_rate': 0.0251, 'n_estimators': 669}. Best is trial 0 with value: 0.8487526881720429.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_37008\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_37008\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-11-14 02:33:20,172]\u001b[0m Trial 19 finished with value: 0.8467311827956989 and parameters: {'lambda': 0.1810745509621278, 'alpha': 1.6815874447759909, 'colsample_bytree': 0.5, 'subsample': 0.8, 'learning_rate': 0.07010000000000001, 'n_estimators': 289}. Best is trial 0 with value: 0.8487526881720429.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_37008\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_37008\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-11-14 02:33:21,939]\u001b[0m Trial 20 finished with value: 0.8323225806451613 and parameters: {'lambda': 0.02997658654754592, 'alpha': 0.4680884024080613, 'colsample_bytree': 0.3, 'subsample': 0.7000000000000001, 'learning_rate': 0.1601, 'n_estimators': 615}. Best is trial 0 with value: 0.8487526881720429.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_37008\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_37008\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-11-14 02:33:25,730]\u001b[0m Trial 21 finished with value: 0.8441720430107528 and parameters: {'lambda': 8.06591704603432, 'alpha': 0.015873576397983303, 'colsample_bytree': 0.7, 'subsample': 0.9, 'learning_rate': 0.0251, 'n_estimators': 742}. Best is trial 0 with value: 0.8487526881720429.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_37008\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_37008\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-11-14 02:33:28,871]\u001b[0m Trial 22 finished with value: 0.8454408602150538 and parameters: {'lambda': 2.908038293533634, 'alpha': 0.00856179019576783, 'colsample_bytree': 0.7, 'subsample': 0.9, 'learning_rate': 0.0301, 'n_estimators': 739}. Best is trial 0 with value: 0.8487526881720429.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_37008\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_37008\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-11-14 02:33:31,446]\u001b[0m Trial 23 finished with value: 0.838215053763441 and parameters: {'lambda': 0.608738177382616, 'alpha': 0.0028017436972920364, 'colsample_bytree': 0.6000000000000001, 'subsample': 0.8, 'learning_rate': 0.0751, 'n_estimators': 849}. Best is trial 0 with value: 0.8487526881720429.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_37008\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_37008\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-11-14 02:33:33,451]\u001b[0m Trial 24 finished with value: 0.842795698924731 and parameters: {'lambda': 0.10084538658040337, 'alpha': 0.16531932892523668, 'colsample_bytree': 0.8, 'subsample': 1.0, 'learning_rate': 0.1051, 'n_estimators': 566}. Best is trial 0 with value: 0.8487526881720429.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_37008\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_37008\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-11-14 02:33:37,267]\u001b[0m Trial 25 finished with value: 0.8447956989247313 and parameters: {'lambda': 4.015312929486887, 'alpha': 0.0011194724551657205, 'colsample_bytree': 0.7, 'subsample': 0.9, 'learning_rate': 0.015099999999999999, 'n_estimators': 736}. Best is trial 0 with value: 0.8487526881720429.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_37008\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_37008\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-11-14 02:33:39,162]\u001b[0m Trial 26 finished with value: 0.8441290322580646 and parameters: {'lambda': 0.5989769734564, 'alpha': 0.059737956006898955, 'colsample_bytree': 0.9000000000000001, 'subsample': 0.7000000000000001, 'learning_rate': 0.0451, 'n_estimators': 462}. Best is trial 0 with value: 0.8487526881720429.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_37008\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_37008\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-11-14 02:33:40,363]\u001b[0m Trial 27 finished with value: 0.8402150537634409 and parameters: {'lambda': 0.10783016000366506, 'alpha': 0.00901709250087776, 'colsample_bytree': 0.4, 'subsample': 0.8, 'learning_rate': 0.0601, 'n_estimators': 355}. Best is trial 0 with value: 0.8487526881720429.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_37008\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_37008\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-11-14 02:33:42,525]\u001b[0m Trial 28 finished with value: 0.8025806451612902 and parameters: {'lambda': 0.9094563684685303, 'alpha': 7.6497821451075, 'colsample_bytree': 0.6000000000000001, 'subsample': 0.6000000000000001, 'learning_rate': 0.07010000000000001, 'n_estimators': 925}. Best is trial 0 with value: 0.8487526881720429.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_37008\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_37008\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-11-14 02:33:44,894]\u001b[0m Trial 29 finished with value: 0.8487311827956989 and parameters: {'lambda': 0.33154359354949414, 'alpha': 0.5277127595207798, 'colsample_bytree': 1.0, 'subsample': 0.5, 'learning_rate': 0.035100000000000006, 'n_estimators': 605}. Best is trial 0 with value: 0.8487526881720429.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_37008\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_37008\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-11-14 02:33:46,514]\u001b[0m Trial 30 finished with value: 0.8526666666666667 and parameters: {'lambda': 0.36190954503262796, 'alpha': 2.308339959533686, 'colsample_bytree': 1.0, 'subsample': 0.4, 'learning_rate': 0.1401, 'n_estimators': 531}. Best is trial 30 with value: 0.8526666666666667.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_37008\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_37008\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-11-14 02:33:47,973]\u001b[0m Trial 31 finished with value: 0.8526451612903226 and parameters: {'lambda': 0.304638023529622, 'alpha': 2.531657662313185, 'colsample_bytree': 1.0, 'subsample': 0.4, 'learning_rate': 0.1651, 'n_estimators': 530}. Best is trial 30 with value: 0.8526666666666667.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_37008\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_37008\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-11-14 02:33:49,495]\u001b[0m Trial 32 finished with value: 0.8565806451612903 and parameters: {'lambda': 0.3609868449199187, 'alpha': 2.505434441006156, 'colsample_bytree': 1.0, 'subsample': 0.4, 'learning_rate': 0.1601, 'n_estimators': 581}. Best is trial 32 with value: 0.8565806451612903.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_37008\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_37008\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-11-14 02:33:50,910]\u001b[0m Trial 33 finished with value: 0.8526236559139784 and parameters: {'lambda': 0.08210003339772622, 'alpha': 3.034708802456597, 'colsample_bytree': 1.0, 'subsample': 0.4, 'learning_rate': 0.1651, 'n_estimators': 533}. Best is trial 32 with value: 0.8565806451612903.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_37008\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_37008\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-11-14 02:33:52,320]\u001b[0m Trial 34 finished with value: 0.8546451612903225 and parameters: {'lambda': 0.07787207263472053, 'alpha': 2.421125146408564, 'colsample_bytree': 1.0, 'subsample': 0.4, 'learning_rate': 0.1701, 'n_estimators': 527}. Best is trial 32 with value: 0.8565806451612903.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_37008\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_37008\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-11-14 02:33:53,298]\u001b[0m Trial 35 finished with value: 0.8025806451612902 and parameters: {'lambda': 0.1111488754937287, 'alpha': 9.68294376394837, 'colsample_bytree': 0.9000000000000001, 'subsample': 0.4, 'learning_rate': 0.18009999999999998, 'n_estimators': 401}. Best is trial 32 with value: 0.8565806451612903.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_37008\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_37008\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-11-14 02:33:54,910]\u001b[0m Trial 36 finished with value: 0.8514193548387097 and parameters: {'lambda': 0.39737140951573346, 'alpha': 2.0551540683340486, 'colsample_bytree': 1.0, 'subsample': 0.4, 'learning_rate': 0.14509999999999998, 'n_estimators': 511}. Best is trial 32 with value: 0.8565806451612903.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_37008\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_37008\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-11-14 02:33:56,310]\u001b[0m Trial 37 finished with value: 0.8236344086021506 and parameters: {'lambda': 0.19526548607217364, 'alpha': 4.833874617591902, 'colsample_bytree': 1.0, 'subsample': 0.4, 'learning_rate': 0.1751, 'n_estimators': 560}. Best is trial 32 with value: 0.8565806451612903.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_37008\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_37008\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-11-14 02:33:58,243]\u001b[0m Trial 38 finished with value: 0.8579354838709677 and parameters: {'lambda': 0.9382352109916214, 'alpha': 2.043398308520369, 'colsample_bytree': 0.9000000000000001, 'subsample': 0.5, 'learning_rate': 0.14509999999999998, 'n_estimators': 687}. Best is trial 38 with value: 0.8579354838709677.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_37008\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_37008\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-11-14 02:34:00,330]\u001b[0m Trial 39 finished with value: 0.8513763440860216 and parameters: {'lambda': 1.0630498877972527, 'alpha': 1.3328366741352828, 'colsample_bytree': 0.9000000000000001, 'subsample': 0.5, 'learning_rate': 0.14509999999999998, 'n_estimators': 690}. Best is trial 38 with value: 0.8579354838709677.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_37008\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_37008\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-11-14 02:34:02,385]\u001b[0m Trial 40 finished with value: 0.8347956989247313 and parameters: {'lambda': 2.2403292629092943, 'alpha': 4.411540374122932, 'colsample_bytree': 0.9000000000000001, 'subsample': 0.5, 'learning_rate': 0.1951, 'n_estimators': 801}. Best is trial 38 with value: 0.8579354838709677.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_37008\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_37008\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-11-14 02:34:02,681]\u001b[0m Trial 41 finished with value: 0.8393333333333334 and parameters: {'lambda': 0.7109785664133984, 'alpha': 2.1903687166895165, 'colsample_bytree': 1.0, 'subsample': 0.4, 'learning_rate': 0.1751, 'n_estimators': 51}. Best is trial 38 with value: 0.8579354838709677.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_37008\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_37008\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-11-14 02:34:04,224]\u001b[0m Trial 42 finished with value: 0.8025591397849462 and parameters: {'lambda': 0.2858805727107471, 'alpha': 6.319254596614693, 'colsample_bytree': 1.0, 'subsample': 0.4, 'learning_rate': 0.15009999999999998, 'n_estimators': 590}. Best is trial 38 with value: 0.8579354838709677.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_37008\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_37008\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-11-14 02:34:06,021]\u001b[0m Trial 43 finished with value: 0.850021505376344 and parameters: {'lambda': 0.4447959378393162, 'alpha': 3.2088626367665194, 'colsample_bytree': 1.0, 'subsample': 0.5, 'learning_rate': 0.1301, 'n_estimators': 641}. Best is trial 38 with value: 0.8579354838709677.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_37008\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_37008\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-11-14 02:34:07,411]\u001b[0m Trial 44 finished with value: 0.8421720430107529 and parameters: {'lambda': 0.02710178766747938, 'alpha': 1.0655117544484212, 'colsample_bytree': 0.9000000000000001, 'subsample': 0.4, 'learning_rate': 0.1851, 'n_estimators': 485}. Best is trial 38 with value: 0.8579354838709677.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_37008\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_37008\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-11-14 02:34:08,642]\u001b[0m Trial 45 finished with value: 0.8356129032258066 and parameters: {'lambda': 0.062440957218921664, 'alpha': 0.6251072181614327, 'colsample_bytree': 0.8, 'subsample': 0.4, 'learning_rate': 0.1701, 'n_estimators': 411}. Best is trial 38 with value: 0.8579354838709677.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_37008\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_37008\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-11-14 02:34:10,170]\u001b[0m Trial 46 finished with value: 0.8553333333333332 and parameters: {'lambda': 0.15325123236050692, 'alpha': 2.327862904802452, 'colsample_bytree': 1.0, 'subsample': 0.5, 'learning_rate': 0.1551, 'n_estimators': 515}. Best is trial 38 with value: 0.8579354838709677.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_37008\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_37008\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-11-14 02:34:11,633]\u001b[0m Trial 47 finished with value: 0.8507526881720431 and parameters: {'lambda': 0.15402140132194075, 'alpha': 1.6074998335005846, 'colsample_bytree': 0.9000000000000001, 'subsample': 0.5, 'learning_rate': 0.1351, 'n_estimators': 434}. Best is trial 38 with value: 0.8579354838709677.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_37008\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_37008\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-11-14 02:34:13,386]\u001b[0m Trial 48 finished with value: 0.8321505376344086 and parameters: {'lambda': 0.016113151725909547, 'alpha': 4.826173796092341, 'colsample_bytree': 1.0, 'subsample': 0.6000000000000001, 'learning_rate': 0.15009999999999998, 'n_estimators': 644}. Best is trial 38 with value: 0.8579354838709677.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_37008\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_37008\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-11-14 02:34:15,300]\u001b[0m Trial 49 finished with value: 0.8480860215053764 and parameters: {'lambda': 1.492205406551833, 'alpha': 1.0433113847404174, 'colsample_bytree': 0.8, 'subsample': 0.5, 'learning_rate': 0.1201, 'n_estimators': 586}. Best is trial 38 with value: 0.8579354838709677.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_37008\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_37008\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-11-14 02:34:17,414]\u001b[0m Trial 50 finished with value: 0.8376129032258065 and parameters: {'lambda': 0.16595507899590964, 'alpha': 0.3866142051988156, 'colsample_bytree': 1.0, 'subsample': 0.5, 'learning_rate': 0.1101, 'n_estimators': 695}. Best is trial 38 with value: 0.8579354838709677.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_37008\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_37008\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-11-14 02:34:18,879]\u001b[0m Trial 51 finished with value: 0.852 and parameters: {'lambda': 0.27082814743123385, 'alpha': 2.5137167651061345, 'colsample_bytree': 1.0, 'subsample': 0.4, 'learning_rate': 0.1601, 'n_estimators': 526}. Best is trial 38 with value: 0.8579354838709677.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_37008\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_37008\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-11-14 02:34:20,204]\u001b[0m Trial 52 finished with value: 0.8426021505376344 and parameters: {'lambda': 0.5020951496177051, 'alpha': 3.7928509532722767, 'colsample_bytree': 1.0, 'subsample': 0.4, 'learning_rate': 0.1851, 'n_estimators': 510}. Best is trial 38 with value: 0.8579354838709677.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_37008\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_37008\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-11-14 02:34:21,473]\u001b[0m Trial 53 finished with value: 0.8474193548387098 and parameters: {'lambda': 0.23198970190171167, 'alpha': 1.6792710467427143, 'colsample_bytree': 0.9000000000000001, 'subsample': 0.4, 'learning_rate': 0.1401, 'n_estimators': 350}. Best is trial 38 with value: 0.8579354838709677.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_37008\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_37008\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-11-14 02:34:23,008]\u001b[0m Trial 54 finished with value: 0.8559354838709677 and parameters: {'lambda': 1.0190428131380616, 'alpha': 2.7290829873667466, 'colsample_bytree': 1.0, 'subsample': 0.6000000000000001, 'learning_rate': 0.1551, 'n_estimators': 470}. Best is trial 38 with value: 0.8579354838709677.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_37008\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_37008\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-11-14 02:34:24,215]\u001b[0m Trial 55 finished with value: 0.8006021505376344 and parameters: {'lambda': 0.8280636130498803, 'alpha': 7.147858841177119, 'colsample_bytree': 0.9000000000000001, 'subsample': 0.6000000000000001, 'learning_rate': 0.1551, 'n_estimators': 447}. Best is trial 38 with value: 0.8579354838709677.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_37008\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_37008\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-11-14 02:34:25,347]\u001b[0m Trial 56 finished with value: 0.8500430107526882 and parameters: {'lambda': 0.04155474849497957, 'alpha': 1.3926811683867526, 'colsample_bytree': 1.0, 'subsample': 0.6000000000000001, 'learning_rate': 0.1301, 'n_estimators': 290}. Best is trial 38 with value: 0.8579354838709677.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_37008\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_37008\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-11-14 02:34:27,123]\u001b[0m Trial 57 finished with value: 0.8480645161290323 and parameters: {'lambda': 1.259452388013657, 'alpha': 0.8820813074062165, 'colsample_bytree': 1.0, 'subsample': 0.5, 'learning_rate': 0.1601, 'n_estimators': 475}. Best is trial 38 with value: 0.8579354838709677.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_37008\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_37008\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-11-14 02:34:28,732]\u001b[0m Trial 58 finished with value: 0.8467096774193549 and parameters: {'lambda': 0.1310967384491447, 'alpha': 3.472425534793075, 'colsample_bytree': 0.9000000000000001, 'subsample': 0.5, 'learning_rate': 0.15009999999999998, 'n_estimators': 607}. Best is trial 38 with value: 0.8579354838709677.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_37008\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_37008\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-11-14 02:34:30,405]\u001b[0m Trial 59 finished with value: 0.8448172043010753 and parameters: {'lambda': 0.08044561445425738, 'alpha': 0.7738454239915377, 'colsample_bytree': 1.0, 'subsample': 0.5, 'learning_rate': 0.1851, 'n_estimators': 568}. Best is trial 38 with value: 0.8579354838709677.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_37008\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_37008\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-11-14 02:34:31,837]\u001b[0m Trial 60 finished with value: 0.8447741935483871 and parameters: {'lambda': 2.3722330463564867, 'alpha': 0.26089594847655917, 'colsample_bytree': 0.9000000000000001, 'subsample': 0.6000000000000001, 'learning_rate': 0.1301, 'n_estimators': 385}. Best is trial 38 with value: 0.8579354838709677.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_37008\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_37008\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-11-14 02:34:33,351]\u001b[0m Trial 61 finished with value: 0.8513548387096773 and parameters: {'lambda': 0.43679287957573826, 'alpha': 2.469832370126116, 'colsample_bytree': 1.0, 'subsample': 0.4, 'learning_rate': 0.1701, 'n_estimators': 538}. Best is trial 38 with value: 0.8579354838709677.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_37008\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_37008\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-11-14 02:34:34,865]\u001b[0m Trial 62 finished with value: 0.8500430107526883 and parameters: {'lambda': 0.23502547051916584, 'alpha': 1.8322718762956576, 'colsample_bytree': 1.0, 'subsample': 0.4, 'learning_rate': 0.1651, 'n_estimators': 500}. Best is trial 38 with value: 0.8579354838709677.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_37008\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_37008\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-11-14 02:34:36,413]\u001b[0m Trial 63 finished with value: 0.8025806451612902 and parameters: {'lambda': 1.5675528223598776, 'alpha': 9.853278548927031, 'colsample_bytree': 1.0, 'subsample': 0.5, 'learning_rate': 0.1551, 'n_estimators': 627}. Best is trial 38 with value: 0.8579354838709677.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_37008\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_37008\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-11-14 02:34:37,630]\u001b[0m Trial 64 finished with value: 0.8025806451612902 and parameters: {'lambda': 3.8748905552974473, 'alpha': 6.4934470813712055, 'colsample_bytree': 0.9000000000000001, 'subsample': 0.4, 'learning_rate': 0.1401, 'n_estimators': 439}. Best is trial 38 with value: 0.8579354838709677.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_37008\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_37008\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-11-14 02:34:39,174]\u001b[0m Trial 65 finished with value: 0.8539784946236558 and parameters: {'lambda': 0.007638580386222665, 'alpha': 3.0021469537182752, 'colsample_bytree': 1.0, 'subsample': 0.5, 'learning_rate': 0.1701, 'n_estimators': 542}. Best is trial 38 with value: 0.8579354838709677.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_37008\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_37008\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-11-14 02:34:40,817]\u001b[0m Trial 66 finished with value: 0.8440430107526882 and parameters: {'lambda': 0.002006761342638159, 'alpha': 3.708628042972789, 'colsample_bytree': 0.8, 'subsample': 0.6000000000000001, 'learning_rate': 0.1751, 'n_estimators': 675}. Best is trial 38 with value: 0.8579354838709677.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_37008\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_37008\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-11-14 02:34:42,428]\u001b[0m Trial 67 finished with value: 0.8441075268817205 and parameters: {'lambda': 0.002079195562607831, 'alpha': 1.2145086629830877, 'colsample_bytree': 1.0, 'subsample': 0.5, 'learning_rate': 0.1951, 'n_estimators': 578}. Best is trial 38 with value: 0.8579354838709677.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_37008\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_37008\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-11-14 02:34:44,301]\u001b[0m Trial 68 finished with value: 0.8552473118279571 and parameters: {'lambda': 0.006325096567761435, 'alpha': 2.5274782751190057, 'colsample_bytree': 0.9000000000000001, 'subsample': 0.6000000000000001, 'learning_rate': 0.14509999999999998, 'n_estimators': 715}. Best is trial 38 with value: 0.8579354838709677.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_37008\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_37008\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-11-14 02:34:46,219]\u001b[0m Trial 69 finished with value: 0.8209892473118279 and parameters: {'lambda': 0.006200883136599892, 'alpha': 5.444100909455597, 'colsample_bytree': 0.8, 'subsample': 0.7000000000000001, 'learning_rate': 0.11510000000000001, 'n_estimators': 766}. Best is trial 38 with value: 0.8579354838709677.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_37008\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_37008\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-11-14 02:34:48,125]\u001b[0m Trial 70 finished with value: 0.8526021505376344 and parameters: {'lambda': 0.003804979794126558, 'alpha': 3.0875023743645946, 'colsample_bytree': 0.9000000000000001, 'subsample': 0.6000000000000001, 'learning_rate': 0.0951, 'n_estimators': 650}. Best is trial 38 with value: 0.8579354838709677.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_37008\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_37008\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-11-14 02:34:50,098]\u001b[0m Trial 71 finished with value: 0.8461720430107527 and parameters: {'lambda': 0.008195310236123896, 'alpha': 1.863397456397051, 'colsample_bytree': 1.0, 'subsample': 0.5, 'learning_rate': 0.14509999999999998, 'n_estimators': 698}. Best is trial 38 with value: 0.8579354838709677.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_37008\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_37008\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-11-14 02:34:52,177]\u001b[0m Trial 72 finished with value: 0.8493548387096775 and parameters: {'lambda': 0.012884822199516121, 'alpha': 2.284595098104383, 'colsample_bytree': 0.9000000000000001, 'subsample': 0.7000000000000001, 'learning_rate': 0.1551, 'n_estimators': 714}. Best is trial 38 with value: 0.8579354838709677.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_37008\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_37008\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-11-14 02:34:53,641]\u001b[0m Trial 73 finished with value: 0.834795698924731 and parameters: {'lambda': 0.00563569454930801, 'alpha': 4.277227970122182, 'colsample_bytree': 1.0, 'subsample': 0.5, 'learning_rate': 0.1701, 'n_estimators': 550}. Best is trial 38 with value: 0.8579354838709677.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_37008\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_37008\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-11-14 02:34:55,990]\u001b[0m Trial 74 finished with value: 0.8520215053763441 and parameters: {'lambda': 0.004161942860464301, 'alpha': 1.3765953630947037, 'colsample_bytree': 0.9000000000000001, 'subsample': 0.6000000000000001, 'learning_rate': 0.1601, 'n_estimators': 810}. Best is trial 38 with value: 0.8579354838709677.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_37008\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_37008\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-11-14 02:34:57,605]\u001b[0m Trial 75 finished with value: 0.8415268817204303 and parameters: {'lambda': 0.024511620127634033, 'alpha': 0.6407176091854835, 'colsample_bytree': 1.0, 'subsample': 0.6000000000000001, 'learning_rate': 0.1401, 'n_estimators': 487}. Best is trial 38 with value: 0.8579354838709677.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_37008\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_37008\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-11-14 02:34:59,965]\u001b[0m Trial 76 finished with value: 0.8533333333333333 and parameters: {'lambda': 0.0011273296147167535, 'alpha': 2.729601131348503, 'colsample_bytree': 1.0, 'subsample': 0.5, 'learning_rate': 0.1251, 'n_estimators': 846}. Best is trial 38 with value: 0.8579354838709677.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_37008\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_37008\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-11-14 02:35:02,378]\u001b[0m Trial 77 finished with value: 0.8572473118279571 and parameters: {'lambda': 0.009398245208539855, 'alpha': 2.6705721545419068, 'colsample_bytree': 0.9000000000000001, 'subsample': 0.5, 'learning_rate': 0.1251, 'n_estimators': 853}. Best is trial 38 with value: 0.8579354838709677.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_37008\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_37008\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-11-14 02:35:04,352]\u001b[0m Trial 78 finished with value: 0.8248817204301075 and parameters: {'lambda': 0.007332205462148389, 'alpha': 5.597956528447134, 'colsample_bytree': 0.8, 'subsample': 0.5, 'learning_rate': 0.18009999999999998, 'n_estimators': 893}. Best is trial 38 with value: 0.8579354838709677.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_37008\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_37008\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-11-14 02:35:07,160]\u001b[0m Trial 79 finished with value: 0.8493333333333334 and parameters: {'lambda': 0.010072558127183552, 'alpha': 1.0276219876757622, 'colsample_bytree': 0.9000000000000001, 'subsample': 0.6000000000000001, 'learning_rate': 0.1351, 'n_estimators': 991}. Best is trial 38 with value: 0.8579354838709677.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_37008\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_37008\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-11-14 02:35:09,321]\u001b[0m Trial 80 finished with value: 0.8025806451612902 and parameters: {'lambda': 0.019364992212121405, 'alpha': 7.834091620969701, 'colsample_bytree': 0.8, 'subsample': 0.5, 'learning_rate': 0.15009999999999998, 'n_estimators': 900}. Best is trial 38 with value: 0.8579354838709677.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_37008\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_37008\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-11-14 02:35:11,674]\u001b[0m Trial 81 finished with value: 0.8546236559139784 and parameters: {'lambda': 0.0010945825723138976, 'alpha': 2.9519047272457297, 'colsample_bytree': 1.0, 'subsample': 0.5, 'learning_rate': 0.1251, 'n_estimators': 847}. Best is trial 38 with value: 0.8579354838709677.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_37008\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_37008\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-11-14 02:35:13,879]\u001b[0m Trial 82 finished with value: 0.8419999999999999 and parameters: {'lambda': 0.0015888504241664693, 'alpha': 3.8423110685776996, 'colsample_bytree': 0.9000000000000001, 'subsample': 0.5, 'learning_rate': 0.1651, 'n_estimators': 873}. Best is trial 38 with value: 0.8579354838709677.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_37008\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_37008\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-11-14 02:35:16,082]\u001b[0m Trial 83 finished with value: 0.8487526881720432 and parameters: {'lambda': 0.004217776859780715, 'alpha': 1.8971396796714677, 'colsample_bytree': 1.0, 'subsample': 0.5, 'learning_rate': 0.1251, 'n_estimators': 784}. Best is trial 38 with value: 0.8579354838709677.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_37008\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_37008\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-11-14 02:35:17,952]\u001b[0m Trial 84 finished with value: 0.8427096774193548 and parameters: {'lambda': 0.0033835259614368794, 'alpha': 2.928924202441789, 'colsample_bytree': 0.4, 'subsample': 0.6000000000000001, 'learning_rate': 0.1101, 'n_estimators': 721}. Best is trial 38 with value: 0.8579354838709677.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_37008\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_37008\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-11-14 02:35:20,634]\u001b[0m Trial 85 finished with value: 0.8427956989247312 and parameters: {'lambda': 0.009357706480391446, 'alpha': 1.5252485428741216, 'colsample_bytree': 1.0, 'subsample': 0.5, 'learning_rate': 0.14509999999999998, 'n_estimators': 970}. Best is trial 38 with value: 0.8579354838709677.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_37008\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_37008\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-11-14 02:35:22,529]\u001b[0m Trial 86 finished with value: 0.8341075268817204 and parameters: {'lambda': 0.0372446671491995, 'alpha': 4.401954021853401, 'colsample_bytree': 1.0, 'subsample': 0.7000000000000001, 'learning_rate': 0.1601, 'n_estimators': 770}. Best is trial 38 with value: 0.8579354838709677.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_37008\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_37008\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-11-14 02:35:24,845]\u001b[0m Trial 87 finished with value: 0.853268817204301 and parameters: {'lambda': 0.01194484301927658, 'alpha': 3.0447821623393585, 'colsample_bytree': 0.9000000000000001, 'subsample': 0.5, 'learning_rate': 0.15009999999999998, 'n_estimators': 951}. Best is trial 38 with value: 0.8579354838709677.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_37008\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_37008\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-11-14 02:35:26,829]\u001b[0m Trial 88 finished with value: 0.8058709677419355 and parameters: {'lambda': 0.0024242287207070627, 'alpha': 5.709358929905896, 'colsample_bytree': 1.0, 'subsample': 0.4, 'learning_rate': 0.10010000000000001, 'n_estimators': 822}. Best is trial 38 with value: 0.8579354838709677.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_37008\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_37008\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-11-14 02:35:28,641]\u001b[0m Trial 89 finished with value: 0.8552473118279569 and parameters: {'lambda': 1.0024612258310515, 'alpha': 2.1616681565474316, 'colsample_bytree': 0.9000000000000001, 'subsample': 0.6000000000000001, 'learning_rate': 0.1351, 'n_estimators': 598}. Best is trial 38 with value: 0.8579354838709677.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_37008\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_37008\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-11-14 02:35:30,868]\u001b[0m Trial 90 finished with value: 0.8540000000000001 and parameters: {'lambda': 1.0333913328731357, 'alpha': 1.105644441288075, 'colsample_bytree': 0.9000000000000001, 'subsample': 0.6000000000000001, 'learning_rate': 0.1351, 'n_estimators': 663}. Best is trial 38 with value: 0.8579354838709677.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_37008\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_37008\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-11-14 02:35:32,845]\u001b[0m Trial 91 finished with value: 0.8558709677419354 and parameters: {'lambda': 0.5744755220764298, 'alpha': 2.048961849958534, 'colsample_bytree': 0.9000000000000001, 'subsample': 0.6000000000000001, 'learning_rate': 0.1351, 'n_estimators': 660}. Best is trial 38 with value: 0.8579354838709677.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_37008\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_37008\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-11-14 02:35:34,691]\u001b[0m Trial 92 finished with value: 0.8513333333333334 and parameters: {'lambda': 0.5928341221817167, 'alpha': 1.9596176768557494, 'colsample_bytree': 0.9000000000000001, 'subsample': 0.7000000000000001, 'learning_rate': 0.1201, 'n_estimators': 607}. Best is trial 38 with value: 0.8579354838709677.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_37008\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_37008\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-11-14 02:35:36,974]\u001b[0m Trial 93 finished with value: 0.8552688172043011 and parameters: {'lambda': 0.8147436733914437, 'alpha': 2.4237178661531957, 'colsample_bytree': 0.8, 'subsample': 0.6000000000000001, 'learning_rate': 0.1251, 'n_estimators': 876}. Best is trial 38 with value: 0.8579354838709677.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_37008\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_37008\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-11-14 02:35:38,798]\u001b[0m Trial 94 finished with value: 0.8539569892473118 and parameters: {'lambda': 0.71592100847723, 'alpha': 2.33016004319379, 'colsample_bytree': 0.8, 'subsample': 0.6000000000000001, 'learning_rate': 0.1301, 'n_estimators': 633}. Best is trial 38 with value: 0.8579354838709677.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_37008\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_37008\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-11-14 02:35:41,040]\u001b[0m Trial 95 finished with value: 0.8368817204301076 and parameters: {'lambda': 0.8761216612894734, 'alpha': 0.07110461800141989, 'colsample_bytree': 0.7, 'subsample': 0.6000000000000001, 'learning_rate': 0.1551, 'n_estimators': 933}. Best is trial 38 with value: 0.8579354838709677.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_37008\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_37008\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-11-14 02:35:43,048]\u001b[0m Trial 96 finished with value: 0.8513548387096774 and parameters: {'lambda': 1.2414086413495027, 'alpha': 1.5488100319469509, 'colsample_bytree': 0.9000000000000001, 'subsample': 0.7000000000000001, 'learning_rate': 0.1401, 'n_estimators': 592}. Best is trial 38 with value: 0.8579354838709677.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_37008\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_37008\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-11-14 02:35:44,940]\u001b[0m Trial 97 finished with value: 0.8513763440860216 and parameters: {'lambda': 1.9733394983106893, 'alpha': 1.2350657798976394, 'colsample_bytree': 0.8, 'subsample': 0.6000000000000001, 'learning_rate': 0.11510000000000001, 'n_estimators': 515}. Best is trial 38 with value: 0.8579354838709677.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_37008\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_37008\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-11-14 02:35:46,733]\u001b[0m Trial 98 finished with value: 0.8433763440860215 and parameters: {'lambda': 0.5431733502896973, 'alpha': 3.7837646468522146, 'colsample_bytree': 0.9000000000000001, 'subsample': 0.6000000000000001, 'learning_rate': 0.14509999999999998, 'n_estimators': 660}. Best is trial 38 with value: 0.8579354838709677.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_37008\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_37008\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-11-14 02:35:49,274]\u001b[0m Trial 99 finished with value: 0.8572473118279571 and parameters: {'lambda': 1.7318252075315954, 'alpha': 2.118873239959844, 'colsample_bytree': 0.9000000000000001, 'subsample': 0.6000000000000001, 'learning_rate': 0.1351, 'n_estimators': 871}. Best is trial 38 with value: 0.8579354838709677.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "#Tuning hyperparameters\n",
    "#Step 1. Define an objective function to be maximized.\n",
    "def objective(trial):\n",
    "    param = {\n",
    "        'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
    "        'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
    "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.3,1.0,step=0.1),\n",
    "        'subsample': trial.suggest_float('subsample', 0.4, 1.0, step=0.1),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.0001, 0.2, step=0.005),\n",
    "        'n_estimators': trial.suggest_int(\"n_estimators\",50,1000,1)\n",
    "        #'min_child_weight': trial.suggest_int('min_child_weight', 1, 300),\n",
    "    }\n",
    "    model = xgb.XGBClassifier(**param,random_state=1,n_jobs=8)\n",
    "\n",
    " \n",
    "# Step 2: Scoring method:\n",
    "    score = model_selection.cross_val_score(model, X, y, n_jobs=8, scoring=\"accuracy\",cv=Cv_optuna)\n",
    "    accuracy = score.mean()\n",
    "    return accuracy\n",
    "\n",
    "# Step 3: Running it\n",
    "study = optuna.create_study(direction=\"maximize\",sampler=optuna.samplers.TPESampler(seed=0))\n",
    "study.optimize(objective, n_trials=100, show_progress_bar=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "b2be4542-3f0e-438f-8e41-c67d96410fab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best parameters are : \n",
      "{'lambda': 0.9382352109916214, 'alpha': 2.043398308520369, 'colsample_bytree': 0.9000000000000001, 'subsample': 0.5, 'learning_rate': 0.14509999999999998, 'n_estimators': 687}\n"
     ]
    }
   ],
   "source": [
    "# Getting the best parameters:\n",
    "print(f\"The best parameters are : \\n{study.best_params}\")\n",
    "# Setting the best model\n",
    "clf=xgb.XGBClassifier(alpha = study.best_params['alpha']\n",
    "              ,colsample_bytree = study.best_params['colsample_bytree']\n",
    "              ,subsample = study.best_params['subsample']\n",
    "              ,n_estimators = study.best_params['n_estimators']\n",
    "              ,learning_rate= study.best_params['learning_rate'], n_jobs=8\n",
    "              ,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "d0687ace-1f1a-44a0-9329-fc50b681ff53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mean</th>\n",
       "      <th>Se</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Accuracy_test</th>\n",
       "      <td>0.853355</td>\n",
       "      <td>0.008064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Accuracy_train</th>\n",
       "      <td>0.981580</td>\n",
       "      <td>0.001131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1 Score</th>\n",
       "      <td>0.554430</td>\n",
       "      <td>0.024336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Precision</th>\n",
       "      <td>0.730770</td>\n",
       "      <td>0.032665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recall</th>\n",
       "      <td>0.480000</td>\n",
       "      <td>0.026516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Roc_auc</th>\n",
       "      <td>0.853308</td>\n",
       "      <td>0.011498</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Mean        Se\n",
       "Accuracy_test   0.853355  0.008064\n",
       "Accuracy_train  0.981580  0.001131\n",
       "F1 Score        0.554430  0.024336\n",
       "Precision       0.730770  0.032665\n",
       "Recall          0.480000  0.026516\n",
       "Roc_auc         0.853308  0.011498"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Model2\n",
    "Model2=Model_results(clf,X,y,Cv_model)\n",
    "Model2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "0bb46026-eb5e-4693-8e81-0a0a2ed16564",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th>Method</th>\n",
       "      <th colspan=\"4\" halign=\"left\">XGB</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model</th>\n",
       "      <th colspan=\"2\" halign=\"left\">Model 1</th>\n",
       "      <th colspan=\"2\" halign=\"left\">Model 2</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Values</th>\n",
       "      <th>Mean</th>\n",
       "      <th>Se</th>\n",
       "      <th>Mean</th>\n",
       "      <th>Se</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Accuracy_test</th>\n",
       "      <td>0.845355</td>\n",
       "      <td>0.008474</td>\n",
       "      <td>0.853355</td>\n",
       "      <td>0.008064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Accuracy_train</th>\n",
       "      <td>0.994904</td>\n",
       "      <td>0.000564</td>\n",
       "      <td>0.981580</td>\n",
       "      <td>0.001131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1 Score</th>\n",
       "      <td>0.534738</td>\n",
       "      <td>0.027872</td>\n",
       "      <td>0.554430</td>\n",
       "      <td>0.024336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Precision</th>\n",
       "      <td>0.661317</td>\n",
       "      <td>0.032690</td>\n",
       "      <td>0.730770</td>\n",
       "      <td>0.032665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recall</th>\n",
       "      <td>0.483333</td>\n",
       "      <td>0.030641</td>\n",
       "      <td>0.480000</td>\n",
       "      <td>0.026516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Roc_auc</th>\n",
       "      <td>0.854125</td>\n",
       "      <td>0.012827</td>\n",
       "      <td>0.853308</td>\n",
       "      <td>0.011498</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Method               XGB                              \n",
       "Model            Model 1             Model 2          \n",
       "Values              Mean        Se      Mean        Se\n",
       "Accuracy_test   0.845355  0.008474  0.853355  0.008064\n",
       "Accuracy_train  0.994904  0.000564  0.981580  0.001131\n",
       "F1 Score        0.534738  0.027872  0.554430  0.024336\n",
       "Precision       0.661317  0.032690  0.730770  0.032665\n",
       "Recall          0.483333  0.030641  0.480000  0.026516\n",
       "Roc_auc         0.854125  0.012827  0.853308  0.011498"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Saving the data of model performance\n",
    "Model_data=pd.concat([Model1,Model2],axis=1)\n",
    "Model_data.columns = [['XGB']*4,['Model 1','Model 1', 'Model 2','Model 2'], ['Mean', 'Se', 'Mean', 'Se']]  \n",
    "Model_data.columns.names=['Method','Model','Values']\n",
    "Model_data.to_csv(\"./XGB_model_lasso_data.csv\",sep=',')\n",
    "Model_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "208fbfd4-b156-43fb-b7b8-5f38ee0e24ef",
   "metadata": {},
   "source": [
    "# 2. MLREM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "45019f5e-5468-4d1b-a4de-8b8c86e33654",
   "metadata": {},
   "outputs": [],
   "source": [
    "col_data= pd.read_csv(\"./Results/MLREM_col.csv\",header=0,index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "f6d91ba6-9049-4060-818a-8cf59d7a47b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MW</th>\n",
       "      <th>D/Dtr09</th>\n",
       "      <th>ZM1MulPer</th>\n",
       "      <th>ECC</th>\n",
       "      <th>CENT</th>\n",
       "      <th>SMTI</th>\n",
       "      <th>SMTIV</th>\n",
       "      <th>GMTIV</th>\n",
       "      <th>Wap</th>\n",
       "      <th>IDMT</th>\n",
       "      <th>...</th>\n",
       "      <th>ATSC5s</th>\n",
       "      <th>P_VSA_MR_3</th>\n",
       "      <th>P_VSA_ppp_ar</th>\n",
       "      <th>P_VSA_ppp_con</th>\n",
       "      <th>P_VSA_charge_2</th>\n",
       "      <th>SM15_EA(ed)</th>\n",
       "      <th>T(O..Br)</th>\n",
       "      <th>TPSA(Tot)</th>\n",
       "      <th>SAdon</th>\n",
       "      <th>Vx</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Ma_2019_A</th>\n",
       "      <td>267.28</td>\n",
       "      <td>66.871159</td>\n",
       "      <td>348.869542</td>\n",
       "      <td>135.0</td>\n",
       "      <td>383.0</td>\n",
       "      <td>2886.0</td>\n",
       "      <td>5576.0</td>\n",
       "      <td>10547.0</td>\n",
       "      <td>5729.0</td>\n",
       "      <td>4739.692713</td>\n",
       "      <td>...</td>\n",
       "      <td>90.763661</td>\n",
       "      <td>139.049917</td>\n",
       "      <td>75.680233</td>\n",
       "      <td>63.202194</td>\n",
       "      <td>1.899093</td>\n",
       "      <td>36.892542</td>\n",
       "      <td>0.0</td>\n",
       "      <td>139.54</td>\n",
       "      <td>160.947217</td>\n",
       "      <td>291.295681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ma_2019_U</th>\n",
       "      <td>244.23</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>340.039426</td>\n",
       "      <td>118.0</td>\n",
       "      <td>295.0</td>\n",
       "      <td>2084.0</td>\n",
       "      <td>4432.0</td>\n",
       "      <td>8734.0</td>\n",
       "      <td>2194.0</td>\n",
       "      <td>3416.557603</td>\n",
       "      <td>...</td>\n",
       "      <td>139.839496</td>\n",
       "      <td>139.049917</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>48.373245</td>\n",
       "      <td>46.279992</td>\n",
       "      <td>36.205320</td>\n",
       "      <td>0.0</td>\n",
       "      <td>124.78</td>\n",
       "      <td>146.060780</td>\n",
       "      <td>262.840532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ma_2019_C</th>\n",
       "      <td>243.25</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>319.988367</td>\n",
       "      <td>118.0</td>\n",
       "      <td>295.0</td>\n",
       "      <td>2084.0</td>\n",
       "      <td>4240.0</td>\n",
       "      <td>7972.0</td>\n",
       "      <td>2194.0</td>\n",
       "      <td>3416.557603</td>\n",
       "      <td>...</td>\n",
       "      <td>137.031903</td>\n",
       "      <td>139.049917</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>67.057867</td>\n",
       "      <td>3.124314</td>\n",
       "      <td>36.205320</td>\n",
       "      <td>0.0</td>\n",
       "      <td>130.83</td>\n",
       "      <td>160.947217</td>\n",
       "      <td>269.667774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ma_2019_G</th>\n",
       "      <td>283.28</td>\n",
       "      <td>71.547747</td>\n",
       "      <td>387.546658</td>\n",
       "      <td>144.0</td>\n",
       "      <td>446.0</td>\n",
       "      <td>3270.0</td>\n",
       "      <td>6542.0</td>\n",
       "      <td>12768.0</td>\n",
       "      <td>6578.0</td>\n",
       "      <td>5547.544286</td>\n",
       "      <td>...</td>\n",
       "      <td>117.471961</td>\n",
       "      <td>139.049917</td>\n",
       "      <td>32.387883</td>\n",
       "      <td>80.922082</td>\n",
       "      <td>45.054770</td>\n",
       "      <td>36.939118</td>\n",
       "      <td>0.0</td>\n",
       "      <td>159.51</td>\n",
       "      <td>178.957968</td>\n",
       "      <td>301.046512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ma_2019_dA</th>\n",
       "      <td>251.28</td>\n",
       "      <td>63.146800</td>\n",
       "      <td>315.599992</td>\n",
       "      <td>128.0</td>\n",
       "      <td>336.0</td>\n",
       "      <td>2584.0</td>\n",
       "      <td>4822.0</td>\n",
       "      <td>8812.0</td>\n",
       "      <td>5068.0</td>\n",
       "      <td>4099.715332</td>\n",
       "      <td>...</td>\n",
       "      <td>52.221046</td>\n",
       "      <td>96.366574</td>\n",
       "      <td>75.680233</td>\n",
       "      <td>63.202194</td>\n",
       "      <td>1.899093</td>\n",
       "      <td>36.335611</td>\n",
       "      <td>0.0</td>\n",
       "      <td>119.31</td>\n",
       "      <td>118.263874</td>\n",
       "      <td>281.544850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tang_2019_ArabinoC</th>\n",
       "      <td>243.25</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>319.988367</td>\n",
       "      <td>118.0</td>\n",
       "      <td>295.0</td>\n",
       "      <td>2084.0</td>\n",
       "      <td>4240.0</td>\n",
       "      <td>7972.0</td>\n",
       "      <td>2194.0</td>\n",
       "      <td>3416.557603</td>\n",
       "      <td>...</td>\n",
       "      <td>137.031903</td>\n",
       "      <td>139.049917</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>67.057867</td>\n",
       "      <td>3.124314</td>\n",
       "      <td>36.205320</td>\n",
       "      <td>0.0</td>\n",
       "      <td>130.83</td>\n",
       "      <td>160.947217</td>\n",
       "      <td>269.667774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tang_2019_DideoxyC</th>\n",
       "      <td>211.25</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>253.494297</td>\n",
       "      <td>103.0</td>\n",
       "      <td>213.0</td>\n",
       "      <td>1585.0</td>\n",
       "      <td>2963.0</td>\n",
       "      <td>5062.0</td>\n",
       "      <td>1633.0</td>\n",
       "      <td>2398.199373</td>\n",
       "      <td>...</td>\n",
       "      <td>59.519699</td>\n",
       "      <td>53.683231</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>67.057867</td>\n",
       "      <td>3.124314</td>\n",
       "      <td>34.619300</td>\n",
       "      <td>0.0</td>\n",
       "      <td>90.37</td>\n",
       "      <td>75.580531</td>\n",
       "      <td>250.166113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Peters_2014_3</th>\n",
       "      <td>268.26</td>\n",
       "      <td>66.871159</td>\n",
       "      <td>369.000658</td>\n",
       "      <td>135.0</td>\n",
       "      <td>383.0</td>\n",
       "      <td>2886.0</td>\n",
       "      <td>5763.0</td>\n",
       "      <td>11275.0</td>\n",
       "      <td>5729.0</td>\n",
       "      <td>4739.692713</td>\n",
       "      <td>...</td>\n",
       "      <td>100.945467</td>\n",
       "      <td>139.049917</td>\n",
       "      <td>32.387883</td>\n",
       "      <td>87.641582</td>\n",
       "      <td>27.044020</td>\n",
       "      <td>36.892542</td>\n",
       "      <td>0.0</td>\n",
       "      <td>133.49</td>\n",
       "      <td>146.060780</td>\n",
       "      <td>284.468439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Plank_2016_2</th>\n",
       "      <td>393.17</td>\n",
       "      <td>71.547747</td>\n",
       "      <td>412.608258</td>\n",
       "      <td>144.0</td>\n",
       "      <td>446.0</td>\n",
       "      <td>3270.0</td>\n",
       "      <td>6760.0</td>\n",
       "      <td>13668.0</td>\n",
       "      <td>6578.0</td>\n",
       "      <td>5547.544286</td>\n",
       "      <td>...</td>\n",
       "      <td>73.852917</td>\n",
       "      <td>96.366574</td>\n",
       "      <td>32.387883</td>\n",
       "      <td>80.922082</td>\n",
       "      <td>45.054770</td>\n",
       "      <td>36.939118</td>\n",
       "      <td>0.0</td>\n",
       "      <td>139.28</td>\n",
       "      <td>136.274624</td>\n",
       "      <td>334.202658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Du2021_L_G</th>\n",
       "      <td>283.28</td>\n",
       "      <td>71.547747</td>\n",
       "      <td>387.546658</td>\n",
       "      <td>144.0</td>\n",
       "      <td>446.0</td>\n",
       "      <td>3270.0</td>\n",
       "      <td>6542.0</td>\n",
       "      <td>12768.0</td>\n",
       "      <td>6578.0</td>\n",
       "      <td>5547.544286</td>\n",
       "      <td>...</td>\n",
       "      <td>117.471961</td>\n",
       "      <td>139.049917</td>\n",
       "      <td>32.387883</td>\n",
       "      <td>80.922082</td>\n",
       "      <td>45.054770</td>\n",
       "      <td>36.939118</td>\n",
       "      <td>0.0</td>\n",
       "      <td>159.51</td>\n",
       "      <td>178.957968</td>\n",
       "      <td>301.046512</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>71 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        MW    D/Dtr09   ZM1MulPer    ECC   CENT    SMTI  \\\n",
       "ID                                                                        \n",
       "Ma_2019_A           267.28  66.871159  348.869542  135.0  383.0  2886.0   \n",
       "Ma_2019_U           244.23   0.000000  340.039426  118.0  295.0  2084.0   \n",
       "Ma_2019_C           243.25   0.000000  319.988367  118.0  295.0  2084.0   \n",
       "Ma_2019_G           283.28  71.547747  387.546658  144.0  446.0  3270.0   \n",
       "Ma_2019_dA          251.28  63.146800  315.599992  128.0  336.0  2584.0   \n",
       "...                    ...        ...         ...    ...    ...     ...   \n",
       "Tang_2019_ArabinoC  243.25   0.000000  319.988367  118.0  295.0  2084.0   \n",
       "Tang_2019_DideoxyC  211.25   0.000000  253.494297  103.0  213.0  1585.0   \n",
       "Peters_2014_3       268.26  66.871159  369.000658  135.0  383.0  2886.0   \n",
       "Plank_2016_2        393.17  71.547747  412.608258  144.0  446.0  3270.0   \n",
       "Du2021_L_G          283.28  71.547747  387.546658  144.0  446.0  3270.0   \n",
       "\n",
       "                     SMTIV    GMTIV     Wap         IDMT  ...      ATSC5s  \\\n",
       "ID                                                        ...               \n",
       "Ma_2019_A           5576.0  10547.0  5729.0  4739.692713  ...   90.763661   \n",
       "Ma_2019_U           4432.0   8734.0  2194.0  3416.557603  ...  139.839496   \n",
       "Ma_2019_C           4240.0   7972.0  2194.0  3416.557603  ...  137.031903   \n",
       "Ma_2019_G           6542.0  12768.0  6578.0  5547.544286  ...  117.471961   \n",
       "Ma_2019_dA          4822.0   8812.0  5068.0  4099.715332  ...   52.221046   \n",
       "...                    ...      ...     ...          ...  ...         ...   \n",
       "Tang_2019_ArabinoC  4240.0   7972.0  2194.0  3416.557603  ...  137.031903   \n",
       "Tang_2019_DideoxyC  2963.0   5062.0  1633.0  2398.199373  ...   59.519699   \n",
       "Peters_2014_3       5763.0  11275.0  5729.0  4739.692713  ...  100.945467   \n",
       "Plank_2016_2        6760.0  13668.0  6578.0  5547.544286  ...   73.852917   \n",
       "Du2021_L_G          6542.0  12768.0  6578.0  5547.544286  ...  117.471961   \n",
       "\n",
       "                    P_VSA_MR_3  P_VSA_ppp_ar  P_VSA_ppp_con  P_VSA_charge_2  \\\n",
       "ID                                                                            \n",
       "Ma_2019_A           139.049917     75.680233      63.202194        1.899093   \n",
       "Ma_2019_U           139.049917      0.000000      48.373245       46.279992   \n",
       "Ma_2019_C           139.049917      0.000000      67.057867        3.124314   \n",
       "Ma_2019_G           139.049917     32.387883      80.922082       45.054770   \n",
       "Ma_2019_dA           96.366574     75.680233      63.202194        1.899093   \n",
       "...                        ...           ...            ...             ...   \n",
       "Tang_2019_ArabinoC  139.049917      0.000000      67.057867        3.124314   \n",
       "Tang_2019_DideoxyC   53.683231      0.000000      67.057867        3.124314   \n",
       "Peters_2014_3       139.049917     32.387883      87.641582       27.044020   \n",
       "Plank_2016_2         96.366574     32.387883      80.922082       45.054770   \n",
       "Du2021_L_G          139.049917     32.387883      80.922082       45.054770   \n",
       "\n",
       "                    SM15_EA(ed)  T(O..Br)  TPSA(Tot)       SAdon          Vx  \n",
       "ID                                                                            \n",
       "Ma_2019_A             36.892542       0.0     139.54  160.947217  291.295681  \n",
       "Ma_2019_U             36.205320       0.0     124.78  146.060780  262.840532  \n",
       "Ma_2019_C             36.205320       0.0     130.83  160.947217  269.667774  \n",
       "Ma_2019_G             36.939118       0.0     159.51  178.957968  301.046512  \n",
       "Ma_2019_dA            36.335611       0.0     119.31  118.263874  281.544850  \n",
       "...                         ...       ...        ...         ...         ...  \n",
       "Tang_2019_ArabinoC    36.205320       0.0     130.83  160.947217  269.667774  \n",
       "Tang_2019_DideoxyC    34.619300       0.0      90.37   75.580531  250.166113  \n",
       "Peters_2014_3         36.892542       0.0     133.49  146.060780  284.468439  \n",
       "Plank_2016_2          36.939118       0.0     139.28  136.274624  334.202658  \n",
       "Du2021_L_G            36.939118       0.0     159.51  178.957968  301.046512  \n",
       "\n",
       "[71 rows x 28 columns]"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MRLEM_data=X_NAomit_data[col_data.index]\n",
    "MRLEM_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "6d8bf42e-2223-4c7b-9bd2-7c2787032802",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MW</th>\n",
       "      <th>D/Dtr09</th>\n",
       "      <th>ZM1MulPer</th>\n",
       "      <th>ECC</th>\n",
       "      <th>CENT</th>\n",
       "      <th>SMTI</th>\n",
       "      <th>SMTIV</th>\n",
       "      <th>GMTIV</th>\n",
       "      <th>Wap</th>\n",
       "      <th>IDMT</th>\n",
       "      <th>...</th>\n",
       "      <th>ATSC5s</th>\n",
       "      <th>P_VSA_MR_3</th>\n",
       "      <th>P_VSA_ppp_ar</th>\n",
       "      <th>P_VSA_ppp_con</th>\n",
       "      <th>P_VSA_charge_2</th>\n",
       "      <th>SM15_EA(ed)</th>\n",
       "      <th>T(O..Br)</th>\n",
       "      <th>TPSA(Tot)</th>\n",
       "      <th>SAdon</th>\n",
       "      <th>Vx</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Ma_2019_A</th>\n",
       "      <td>0.128645</td>\n",
       "      <td>0.181294</td>\n",
       "      <td>0.193207</td>\n",
       "      <td>0.036281</td>\n",
       "      <td>0.026667</td>\n",
       "      <td>0.030815</td>\n",
       "      <td>0.037803</td>\n",
       "      <td>0.044265</td>\n",
       "      <td>0.024087</td>\n",
       "      <td>0.024617</td>\n",
       "      <td>...</td>\n",
       "      <td>0.176802</td>\n",
       "      <td>0.999046</td>\n",
       "      <td>0.285905</td>\n",
       "      <td>0.104723</td>\n",
       "      <td>0.015761</td>\n",
       "      <td>0.446054</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.472652</td>\n",
       "      <td>0.769847</td>\n",
       "      <td>0.069993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ma_2019_U</th>\n",
       "      <td>0.075722</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.175319</td>\n",
       "      <td>0.017007</td>\n",
       "      <td>0.012863</td>\n",
       "      <td>0.011819</td>\n",
       "      <td>0.021252</td>\n",
       "      <td>0.029633</td>\n",
       "      <td>0.003299</td>\n",
       "      <td>0.010706</td>\n",
       "      <td>...</td>\n",
       "      <td>0.401921</td>\n",
       "      <td>0.999046</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.031193</td>\n",
       "      <td>0.384100</td>\n",
       "      <td>0.311208</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.330770</td>\n",
       "      <td>0.665700</td>\n",
       "      <td>0.021569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ma_2019_C</th>\n",
       "      <td>0.073472</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.134701</td>\n",
       "      <td>0.017007</td>\n",
       "      <td>0.012863</td>\n",
       "      <td>0.011819</td>\n",
       "      <td>0.018475</td>\n",
       "      <td>0.023484</td>\n",
       "      <td>0.003299</td>\n",
       "      <td>0.010706</td>\n",
       "      <td>...</td>\n",
       "      <td>0.389042</td>\n",
       "      <td>0.999046</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.123842</td>\n",
       "      <td>0.025930</td>\n",
       "      <td>0.311208</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.388926</td>\n",
       "      <td>0.769847</td>\n",
       "      <td>0.033187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ma_2019_G</th>\n",
       "      <td>0.165381</td>\n",
       "      <td>0.193972</td>\n",
       "      <td>0.271557</td>\n",
       "      <td>0.046485</td>\n",
       "      <td>0.036549</td>\n",
       "      <td>0.039910</td>\n",
       "      <td>0.051778</td>\n",
       "      <td>0.062188</td>\n",
       "      <td>0.029080</td>\n",
       "      <td>0.033111</td>\n",
       "      <td>...</td>\n",
       "      <td>0.299317</td>\n",
       "      <td>0.999046</td>\n",
       "      <td>0.122355</td>\n",
       "      <td>0.192589</td>\n",
       "      <td>0.373931</td>\n",
       "      <td>0.455193</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.664616</td>\n",
       "      <td>0.895853</td>\n",
       "      <td>0.086587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ma_2019_dA</th>\n",
       "      <td>0.091909</td>\n",
       "      <td>0.171197</td>\n",
       "      <td>0.125811</td>\n",
       "      <td>0.028345</td>\n",
       "      <td>0.019294</td>\n",
       "      <td>0.023662</td>\n",
       "      <td>0.026894</td>\n",
       "      <td>0.030263</td>\n",
       "      <td>0.020200</td>\n",
       "      <td>0.017889</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.666030</td>\n",
       "      <td>0.285905</td>\n",
       "      <td>0.104723</td>\n",
       "      <td>0.015761</td>\n",
       "      <td>0.336774</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.278189</td>\n",
       "      <td>0.471230</td>\n",
       "      <td>0.053399</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  MW   D/Dtr09  ZM1MulPer       ECC      CENT      SMTI  \\\n",
       "ID                                                                        \n",
       "Ma_2019_A   0.128645  0.181294   0.193207  0.036281  0.026667  0.030815   \n",
       "Ma_2019_U   0.075722  0.000000   0.175319  0.017007  0.012863  0.011819   \n",
       "Ma_2019_C   0.073472  0.000000   0.134701  0.017007  0.012863  0.011819   \n",
       "Ma_2019_G   0.165381  0.193972   0.271557  0.046485  0.036549  0.039910   \n",
       "Ma_2019_dA  0.091909  0.171197   0.125811  0.028345  0.019294  0.023662   \n",
       "\n",
       "               SMTIV     GMTIV       Wap      IDMT  ...    ATSC5s  P_VSA_MR_3  \\\n",
       "ID                                                  ...                         \n",
       "Ma_2019_A   0.037803  0.044265  0.024087  0.024617  ...  0.176802    0.999046   \n",
       "Ma_2019_U   0.021252  0.029633  0.003299  0.010706  ...  0.401921    0.999046   \n",
       "Ma_2019_C   0.018475  0.023484  0.003299  0.010706  ...  0.389042    0.999046   \n",
       "Ma_2019_G   0.051778  0.062188  0.029080  0.033111  ...  0.299317    0.999046   \n",
       "Ma_2019_dA  0.026894  0.030263  0.020200  0.017889  ...  0.000000    0.666030   \n",
       "\n",
       "            P_VSA_ppp_ar  P_VSA_ppp_con  P_VSA_charge_2  SM15_EA(ed)  \\\n",
       "ID                                                                     \n",
       "Ma_2019_A       0.285905       0.104723        0.015761     0.446054   \n",
       "Ma_2019_U       0.000000       0.031193        0.384100     0.311208   \n",
       "Ma_2019_C       0.000000       0.123842        0.025930     0.311208   \n",
       "Ma_2019_G       0.122355       0.192589        0.373931     0.455193   \n",
       "Ma_2019_dA      0.285905       0.104723        0.015761     0.336774   \n",
       "\n",
       "            T(O..Br)  TPSA(Tot)     SAdon        Vx  \n",
       "ID                                                   \n",
       "Ma_2019_A        0.0   0.472652  0.769847  0.069993  \n",
       "Ma_2019_U        0.0   0.330770  0.665700  0.021569  \n",
       "Ma_2019_C        0.0   0.388926  0.769847  0.033187  \n",
       "Ma_2019_G        0.0   0.664616  0.895853  0.086587  \n",
       "Ma_2019_dA       0.0   0.278189  0.471230  0.053399  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Scale data\n",
    "Scaler = preprocessing.MinMaxScaler() #StandardScaler\n",
    "Transformer =Scaler.fit(MRLEM_data)\n",
    "X_scaled_data=Transformer.transform(MRLEM_data)\n",
    "X_scaled_data =pd.DataFrame(X_scaled_data)\n",
    "X_scaled_data.columns=MRLEM_data.columns\n",
    "X_scaled_data.index=Raw_data.index\n",
    "X_scaled_data.to_csv(\"./Original data/MRLEM_data_X_scaled_data.csv\",sep=',',header=1,index=1)\n",
    "joblib.dump(Transformer, './Models/MRLEM_data_Scaler_transformer.pkl')\n",
    "\n",
    "X_scaled_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "c5eb8b75-76bc-4fcb-aad5-6762048df1c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Model_results(Model_clf,X_test,y,Cv_model):\n",
    "    Model_scores= cross_validate(estimator=Model_clf, X=X_test, y=y, cv=Cv_model,scoring=( 'accuracy','f1','precision','recall','roc_auc'), return_train_score=True)\n",
    "    Model_score= cross_validate(estimator=Model_clf, X=X_test, y=y, cv=Cv_model,scoring=( 'accuracy','f1','precision','recall','roc_auc'), return_train_score=False)\n",
    "#Accuracy\n",
    "    Model_Accuracy_test_mean=Model_scores['test_accuracy'].mean()\n",
    "    Model_Accuracy_test_se=(Model_scores['test_accuracy'].std()/math.sqrt(len(Model_scores['test_accuracy']))) \n",
    "    Model_Accuracy_train_mean=Model_scores['train_accuracy'].mean()\n",
    "    Model_Accuracy_train_se=(Model_scores['train_accuracy'].std()/math.sqrt(len(Model_scores['train_accuracy']))) \n",
    "#f1\n",
    "    Model_f1_mean=Model_score['test_f1'].mean()\n",
    "    Model_f1_se=(Model_score['test_f1'].std()/math.sqrt(len(Model_score['test_f1']))) \n",
    "#precision\n",
    "    Model_precision_mean=Model_score['test_precision'].mean()\n",
    "    Model_precision_se=(Model_score['test_precision'].std()/math.sqrt(len(Model_score['test_precision']))) \n",
    "#recall\n",
    "    Model_recall_mean=Model_score['test_recall'].mean()\n",
    "    Model_recall_se=(Model_score['test_recall'].std()/math.sqrt(len(Model_score['test_recall']))) \n",
    "#roc_auc\n",
    "    Model_roc_auc_mean=Model_score['test_roc_auc'].mean()\n",
    "    Model_roc_auc_se=(Model_score['test_roc_auc'].std()/math.sqrt(len(Model_score['test_roc_auc']))) \n",
    "    Model = {'Mean':[Model_Accuracy_test_mean,Model_Accuracy_train_mean,Model_f1_mean,Model_precision_mean,Model_recall_mean,Model_roc_auc_mean],\n",
    "        'Se':[Model_Accuracy_test_se,Model_Accuracy_train_se,Model_f1_se,Model_precision_se,Model_recall_se,Model_roc_auc_se]}\n",
    "    Model = pd.DataFrame(Model, index=['Accuracy_test','Accuracy_train','F1 Score','Precision','Recall','Roc_auc'])\n",
    "    return Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "43024221-dcb1-4c20-a862-8ba15cc4978a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setting the KFold \n",
    "Cv_optuna= RepeatedStratifiedKFold(n_splits=5, n_repeats=10, random_state=0)\n",
    "Cv_model= RepeatedStratifiedKFold(n_splits=5, n_repeats=10, random_state=0)\n",
    "Cv_RFECV= RepeatedStratifiedKFold(n_splits=5, n_repeats=10, random_state=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "ef2d9106-5c7e-4daa-89d3-1c228a5ac78a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data pre-processing of models\n",
    "X=np.array(X_scaled_data)\n",
    "y=Raw_data['Hydrogel-forming ability'].values\n",
    "clf=LogisticRegression(solver='liblinear',random_state=0,dual=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48b68d6d-1a1e-439b-aee8-42486486d23e",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 2.1 DT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "74f1bf04-5bde-4d51-bc10-aee4e7d2c583",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf=DecisionTreeClassifier(random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "7c30897c-633f-4a53-96c3-a415fd50308c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mean</th>\n",
       "      <th>Se</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Accuracy_test</th>\n",
       "      <td>0.629333</td>\n",
       "      <td>0.015032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Accuracy_train</th>\n",
       "      <td>0.729981</td>\n",
       "      <td>0.004700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1 Score</th>\n",
       "      <td>0.697627</td>\n",
       "      <td>0.013235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Precision</th>\n",
       "      <td>0.620752</td>\n",
       "      <td>0.011961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recall</th>\n",
       "      <td>0.811071</td>\n",
       "      <td>0.020893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Roc_auc</th>\n",
       "      <td>0.664796</td>\n",
       "      <td>0.020543</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Mean        Se\n",
       "Accuracy_test   0.629333  0.015032\n",
       "Accuracy_train  0.729981  0.004700\n",
       "F1 Score        0.697627  0.013235\n",
       "Precision       0.620752  0.011961\n",
       "Recall          0.811071  0.020893\n",
       "Roc_auc         0.664796  0.020543"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Model1 \n",
    "Model1_clf=clf\n",
    "#Model1\n",
    "Model1=Model_results(Model1_clf,X,y,Cv_model)\n",
    "Model1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "f86a6975-0d73-46e6-9ba4-c3c488b2a565",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2024-01-12 01:29:56,212]\u001b[0m A new study created in memory with name: no-name-6a0b1671-0ec2-4905-98f9-69d2f7e33654\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:29:57,476]\u001b[0m Trial 0 finished with value: 0.6312380952380953 and parameters: {'max_depth': 4, 'max_features': 17, 'min_samples_split': 16}. Best is trial 0 with value: 0.6312380952380953.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:29:57,505]\u001b[0m Trial 1 finished with value: 0.5926666666666667 and parameters: {'max_depth': 4, 'max_features': 14, 'min_samples_split': 17}. Best is trial 0 with value: 0.6312380952380953.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:29:57,530]\u001b[0m Trial 2 finished with value: 0.6375238095238095 and parameters: {'max_depth': 4, 'max_features': 19, 'min_samples_split': 25}. Best is trial 2 with value: 0.6375238095238095.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:29:57,554]\u001b[0m Trial 3 finished with value: 0.6208571428571428 and parameters: {'max_depth': 4, 'max_features': 18, 'min_samples_split': 14}. Best is trial 2 with value: 0.6375238095238095.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:29:57,579]\u001b[0m Trial 4 finished with value: 0.6296190476190476 and parameters: {'max_depth': 4, 'max_features': 20, 'min_samples_split': 3}. Best is trial 2 with value: 0.6375238095238095.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:29:57,600]\u001b[0m Trial 5 finished with value: 0.6120952380952381 and parameters: {'max_depth': 3, 'max_features': 10, 'min_samples_split': 21}. Best is trial 2 with value: 0.6375238095238095.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:29:57,624]\u001b[0m Trial 6 finished with value: 0.6318095238095238 and parameters: {'max_depth': 5, 'max_features': 19, 'min_samples_split': 25}. Best is trial 2 with value: 0.6375238095238095.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:29:57,646]\u001b[0m Trial 7 finished with value: 0.5998095238095238 and parameters: {'max_depth': 5, 'max_features': 15, 'min_samples_split': 20}. Best is trial 2 with value: 0.6375238095238095.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:29:57,666]\u001b[0m Trial 8 finished with value: 0.6439999999999999 and parameters: {'max_depth': 3, 'max_features': 17, 'min_samples_split': 5}. Best is trial 8 with value: 0.6439999999999999.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:29:57,689]\u001b[0m Trial 9 finished with value: 0.6057142857142856 and parameters: {'max_depth': 5, 'max_features': 15, 'min_samples_split': 11}. Best is trial 8 with value: 0.6439999999999999.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:29:57,714]\u001b[0m Trial 10 finished with value: 0.601047619047619 and parameters: {'max_depth': 3, 'max_features': 12, 'min_samples_split': 2}. Best is trial 8 with value: 0.6439999999999999.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:29:57,739]\u001b[0m Trial 11 finished with value: 0.6411428571428571 and parameters: {'max_depth': 3, 'max_features': 17, 'min_samples_split': 8}. Best is trial 8 with value: 0.6439999999999999.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:29:57,765]\u001b[0m Trial 12 finished with value: 0.6411428571428571 and parameters: {'max_depth': 3, 'max_features': 17, 'min_samples_split': 9}. Best is trial 8 with value: 0.6439999999999999.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:29:57,789]\u001b[0m Trial 13 finished with value: 0.6411428571428571 and parameters: {'max_depth': 3, 'max_features': 17, 'min_samples_split': 7}. Best is trial 8 with value: 0.6439999999999999.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:29:57,813]\u001b[0m Trial 14 finished with value: 0.6280952380952382 and parameters: {'max_depth': 3, 'max_features': 13, 'min_samples_split': 6}. Best is trial 8 with value: 0.6439999999999999.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:29:57,838]\u001b[0m Trial 15 finished with value: 0.64 and parameters: {'max_depth': 3, 'max_features': 16, 'min_samples_split': 5}. Best is trial 8 with value: 0.6439999999999999.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:29:57,862]\u001b[0m Trial 16 finished with value: 0.64 and parameters: {'max_depth': 3, 'max_features': 16, 'min_samples_split': 10}. Best is trial 8 with value: 0.6439999999999999.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:29:57,887]\u001b[0m Trial 17 finished with value: 0.6042857142857144 and parameters: {'max_depth': 3, 'max_features': 20, 'min_samples_split': 6}. Best is trial 8 with value: 0.6439999999999999.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:29:57,914]\u001b[0m Trial 18 finished with value: 0.6207619047619047 and parameters: {'max_depth': 4, 'max_features': 18, 'min_samples_split': 12}. Best is trial 8 with value: 0.6439999999999999.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:29:57,939]\u001b[0m Trial 19 finished with value: 0.6295238095238096 and parameters: {'max_depth': 3, 'max_features': 13, 'min_samples_split': 4}. Best is trial 8 with value: 0.6439999999999999.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:29:57,964]\u001b[0m Trial 20 finished with value: 0.6385714285714286 and parameters: {'max_depth': 3, 'max_features': 16, 'min_samples_split': 7}. Best is trial 8 with value: 0.6439999999999999.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:29:57,989]\u001b[0m Trial 21 finished with value: 0.6411428571428571 and parameters: {'max_depth': 3, 'max_features': 17, 'min_samples_split': 9}. Best is trial 8 with value: 0.6439999999999999.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:29:58,013]\u001b[0m Trial 22 finished with value: 0.6111428571428571 and parameters: {'max_depth': 3, 'max_features': 18, 'min_samples_split': 13}. Best is trial 8 with value: 0.6439999999999999.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:29:58,038]\u001b[0m Trial 23 finished with value: 0.6411428571428571 and parameters: {'max_depth': 3, 'max_features': 17, 'min_samples_split': 8}. Best is trial 8 with value: 0.6439999999999999.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:29:58,063]\u001b[0m Trial 24 finished with value: 0.6253333333333333 and parameters: {'max_depth': 3, 'max_features': 19, 'min_samples_split': 9}. Best is trial 8 with value: 0.6439999999999999.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:29:58,088]\u001b[0m Trial 25 finished with value: 0.6405714285714285 and parameters: {'max_depth': 4, 'max_features': 16, 'min_samples_split': 10}. Best is trial 8 with value: 0.6439999999999999.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:29:58,114]\u001b[0m Trial 26 finished with value: 0.6097142857142858 and parameters: {'max_depth': 3, 'max_features': 14, 'min_samples_split': 4}. Best is trial 8 with value: 0.6439999999999999.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:29:58,137]\u001b[0m Trial 27 finished with value: 0.6129523809523809 and parameters: {'max_depth': 3, 'max_features': 15, 'min_samples_split': 6}. Best is trial 8 with value: 0.6439999999999999.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:29:58,163]\u001b[0m Trial 28 finished with value: 0.6222857142857143 and parameters: {'max_depth': 4, 'max_features': 18, 'min_samples_split': 7}. Best is trial 8 with value: 0.6439999999999999.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:29:58,187]\u001b[0m Trial 29 finished with value: 0.6396190476190476 and parameters: {'max_depth': 4, 'max_features': 17, 'min_samples_split': 14}. Best is trial 8 with value: 0.6439999999999999.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:29:58,212]\u001b[0m Trial 30 finished with value: 0.6363809523809524 and parameters: {'max_depth': 3, 'max_features': 19, 'min_samples_split': 16}. Best is trial 8 with value: 0.6439999999999999.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:29:58,237]\u001b[0m Trial 31 finished with value: 0.6411428571428571 and parameters: {'max_depth': 3, 'max_features': 17, 'min_samples_split': 8}. Best is trial 8 with value: 0.6439999999999999.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:29:58,260]\u001b[0m Trial 32 finished with value: 0.6385714285714286 and parameters: {'max_depth': 3, 'max_features': 16, 'min_samples_split': 9}. Best is trial 8 with value: 0.6439999999999999.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:29:58,285]\u001b[0m Trial 33 finished with value: 0.624 and parameters: {'max_depth': 3, 'max_features': 18, 'min_samples_split': 2}. Best is trial 8 with value: 0.6439999999999999.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:29:58,312]\u001b[0m Trial 34 finished with value: 0.6411428571428571 and parameters: {'max_depth': 3, 'max_features': 17, 'min_samples_split': 11}. Best is trial 8 with value: 0.6439999999999999.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:29:58,335]\u001b[0m Trial 35 finished with value: 0.614 and parameters: {'max_depth': 4, 'max_features': 15, 'min_samples_split': 4}. Best is trial 8 with value: 0.6439999999999999.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:29:58,360]\u001b[0m Trial 36 finished with value: 0.6111428571428571 and parameters: {'max_depth': 3, 'max_features': 18, 'min_samples_split': 12}. Best is trial 8 with value: 0.6439999999999999.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:29:58,386]\u001b[0m Trial 37 finished with value: 0.6011428571428571 and parameters: {'max_depth': 4, 'max_features': 14, 'min_samples_split': 7}. Best is trial 8 with value: 0.6439999999999999.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:29:58,413]\u001b[0m Trial 38 finished with value: 0.6281904761904762 and parameters: {'max_depth': 3, 'max_features': 19, 'min_samples_split': 5}. Best is trial 8 with value: 0.6439999999999999.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:29:58,439]\u001b[0m Trial 39 finished with value: 0.6067619047619047 and parameters: {'max_depth': 4, 'max_features': 10, 'min_samples_split': 16}. Best is trial 8 with value: 0.6439999999999999.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:29:58,466]\u001b[0m Trial 40 finished with value: 0.6393333333333333 and parameters: {'max_depth': 5, 'max_features': 16, 'min_samples_split': 11}. Best is trial 8 with value: 0.6439999999999999.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:29:58,491]\u001b[0m Trial 41 finished with value: 0.6411428571428571 and parameters: {'max_depth': 3, 'max_features': 17, 'min_samples_split': 9}. Best is trial 8 with value: 0.6439999999999999.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:29:58,519]\u001b[0m Trial 42 finished with value: 0.6368571428571428 and parameters: {'max_depth': 3, 'max_features': 17, 'min_samples_split': 14}. Best is trial 8 with value: 0.6439999999999999.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:29:58,545]\u001b[0m Trial 43 finished with value: 0.6411428571428571 and parameters: {'max_depth': 3, 'max_features': 17, 'min_samples_split': 8}. Best is trial 8 with value: 0.6439999999999999.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:29:58,570]\u001b[0m Trial 44 finished with value: 0.614 and parameters: {'max_depth': 3, 'max_features': 18, 'min_samples_split': 10}. Best is trial 8 with value: 0.6439999999999999.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:29:58,597]\u001b[0m Trial 45 finished with value: 0.6411428571428571 and parameters: {'max_depth': 3, 'max_features': 17, 'min_samples_split': 8}. Best is trial 8 with value: 0.6439999999999999.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:29:58,624]\u001b[0m Trial 46 finished with value: 0.6056190476190477 and parameters: {'max_depth': 3, 'max_features': 20, 'min_samples_split': 5}. Best is trial 8 with value: 0.6439999999999999.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:29:58,651]\u001b[0m Trial 47 finished with value: 0.64 and parameters: {'max_depth': 3, 'max_features': 16, 'min_samples_split': 3}. Best is trial 8 with value: 0.6439999999999999.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:29:58,678]\u001b[0m Trial 48 finished with value: 0.6143809523809524 and parameters: {'max_depth': 3, 'max_features': 15, 'min_samples_split': 8}. Best is trial 8 with value: 0.6439999999999999.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:29:58,704]\u001b[0m Trial 49 finished with value: 0.6180952380952381 and parameters: {'max_depth': 3, 'max_features': 18, 'min_samples_split': 21}. Best is trial 8 with value: 0.6439999999999999.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:29:58,729]\u001b[0m Trial 50 finished with value: 0.6406666666666666 and parameters: {'max_depth': 3, 'max_features': 11, 'min_samples_split': 3}. Best is trial 8 with value: 0.6439999999999999.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:29:58,758]\u001b[0m Trial 51 finished with value: 0.6411428571428571 and parameters: {'max_depth': 3, 'max_features': 17, 'min_samples_split': 11}. Best is trial 8 with value: 0.6439999999999999.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:29:58,785]\u001b[0m Trial 52 finished with value: 0.6411428571428571 and parameters: {'max_depth': 3, 'max_features': 17, 'min_samples_split': 11}. Best is trial 8 with value: 0.6439999999999999.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:29:58,811]\u001b[0m Trial 53 finished with value: 0.6371428571428572 and parameters: {'max_depth': 3, 'max_features': 16, 'min_samples_split': 12}. Best is trial 8 with value: 0.6439999999999999.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:29:58,838]\u001b[0m Trial 54 finished with value: 0.6425714285714286 and parameters: {'max_depth': 3, 'max_features': 17, 'min_samples_split': 6}. Best is trial 8 with value: 0.6439999999999999.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:29:58,863]\u001b[0m Trial 55 finished with value: 0.6211428571428571 and parameters: {'max_depth': 3, 'max_features': 18, 'min_samples_split': 6}. Best is trial 8 with value: 0.6439999999999999.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:29:58,888]\u001b[0m Trial 56 finished with value: 0.6375238095238095 and parameters: {'max_depth': 3, 'max_features': 19, 'min_samples_split': 24}. Best is trial 8 with value: 0.6439999999999999.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:29:58,915]\u001b[0m Trial 57 finished with value: 0.6422857142857145 and parameters: {'max_depth': 5, 'max_features': 16, 'min_samples_split': 7}. Best is trial 8 with value: 0.6439999999999999.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:29:58,941]\u001b[0m Trial 58 finished with value: 0.6604761904761905 and parameters: {'max_depth': 5, 'max_features': 16, 'min_samples_split': 5}. Best is trial 58 with value: 0.6604761904761905.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:29:58,966]\u001b[0m Trial 59 finished with value: 0.6406666666666666 and parameters: {'max_depth': 5, 'max_features': 15, 'min_samples_split': 6}. Best is trial 58 with value: 0.6604761904761905.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:29:58,992]\u001b[0m Trial 60 finished with value: 0.6604761904761905 and parameters: {'max_depth': 5, 'max_features': 16, 'min_samples_split': 5}. Best is trial 58 with value: 0.6604761904761905.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:29:59,017]\u001b[0m Trial 61 finished with value: 0.6604761904761905 and parameters: {'max_depth': 5, 'max_features': 16, 'min_samples_split': 5}. Best is trial 58 with value: 0.6604761904761905.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:29:59,044]\u001b[0m Trial 62 finished with value: 0.647904761904762 and parameters: {'max_depth': 5, 'max_features': 14, 'min_samples_split': 3}. Best is trial 58 with value: 0.6604761904761905.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:29:59,073]\u001b[0m Trial 63 finished with value: 0.6742857142857143 and parameters: {'max_depth': 5, 'max_features': 13, 'min_samples_split': 2}. Best is trial 63 with value: 0.6742857142857143.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:29:59,099]\u001b[0m Trial 64 finished with value: 0.6520952380952381 and parameters: {'max_depth': 5, 'max_features': 14, 'min_samples_split': 2}. Best is trial 63 with value: 0.6742857142857143.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:29:59,125]\u001b[0m Trial 65 finished with value: 0.6742857142857143 and parameters: {'max_depth': 5, 'max_features': 13, 'min_samples_split': 2}. Best is trial 63 with value: 0.6742857142857143.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:29:59,151]\u001b[0m Trial 66 finished with value: 0.68 and parameters: {'max_depth': 5, 'max_features': 13, 'min_samples_split': 3}. Best is trial 66 with value: 0.68.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:29:59,176]\u001b[0m Trial 67 finished with value: 0.6742857142857143 and parameters: {'max_depth': 5, 'max_features': 13, 'min_samples_split': 2}. Best is trial 66 with value: 0.68.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:29:59,201]\u001b[0m Trial 68 finished with value: 0.6742857142857143 and parameters: {'max_depth': 5, 'max_features': 13, 'min_samples_split': 2}. Best is trial 66 with value: 0.68.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:29:59,226]\u001b[0m Trial 69 finished with value: 0.6742857142857143 and parameters: {'max_depth': 5, 'max_features': 13, 'min_samples_split': 2}. Best is trial 66 with value: 0.68.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:29:59,252]\u001b[0m Trial 70 finished with value: 0.6742857142857143 and parameters: {'max_depth': 5, 'max_features': 13, 'min_samples_split': 2}. Best is trial 66 with value: 0.68.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:29:59,278]\u001b[0m Trial 71 finished with value: 0.6742857142857143 and parameters: {'max_depth': 5, 'max_features': 13, 'min_samples_split': 2}. Best is trial 66 with value: 0.68.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:29:59,302]\u001b[0m Trial 72 finished with value: 0.6742857142857143 and parameters: {'max_depth': 5, 'max_features': 13, 'min_samples_split': 2}. Best is trial 66 with value: 0.68.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:29:59,328]\u001b[0m Trial 73 finished with value: 0.6690476190476191 and parameters: {'max_depth': 5, 'max_features': 12, 'min_samples_split': 3}. Best is trial 66 with value: 0.68.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:29:59,355]\u001b[0m Trial 74 finished with value: 0.6761904761904762 and parameters: {'max_depth': 5, 'max_features': 12, 'min_samples_split': 2}. Best is trial 66 with value: 0.68.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:29:59,380]\u001b[0m Trial 75 finished with value: 0.6676190476190478 and parameters: {'max_depth': 5, 'max_features': 12, 'min_samples_split': 4}. Best is trial 66 with value: 0.68.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:29:59,416]\u001b[0m Trial 76 finished with value: 0.6742857142857143 and parameters: {'max_depth': 5, 'max_features': 13, 'min_samples_split': 2}. Best is trial 66 with value: 0.68.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:29:59,444]\u001b[0m Trial 77 finished with value: 0.6690476190476191 and parameters: {'max_depth': 5, 'max_features': 12, 'min_samples_split': 3}. Best is trial 66 with value: 0.68.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:29:59,471]\u001b[0m Trial 78 finished with value: 0.6451428571428572 and parameters: {'max_depth': 5, 'max_features': 11, 'min_samples_split': 4}. Best is trial 66 with value: 0.68.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:29:59,496]\u001b[0m Trial 79 finished with value: 0.6742857142857143 and parameters: {'max_depth': 5, 'max_features': 13, 'min_samples_split': 2}. Best is trial 66 with value: 0.68.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:29:59,522]\u001b[0m Trial 80 finished with value: 0.6676190476190478 and parameters: {'max_depth': 5, 'max_features': 12, 'min_samples_split': 4}. Best is trial 66 with value: 0.68.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:29:59,548]\u001b[0m Trial 81 finished with value: 0.6742857142857143 and parameters: {'max_depth': 5, 'max_features': 13, 'min_samples_split': 2}. Best is trial 66 with value: 0.68.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:29:59,573]\u001b[0m Trial 82 finished with value: 0.68 and parameters: {'max_depth': 5, 'max_features': 13, 'min_samples_split': 3}. Best is trial 66 with value: 0.68.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:29:59,599]\u001b[0m Trial 83 finished with value: 0.647904761904762 and parameters: {'max_depth': 5, 'max_features': 14, 'min_samples_split': 3}. Best is trial 66 with value: 0.68.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:29:59,624]\u001b[0m Trial 84 finished with value: 0.6478095238095238 and parameters: {'max_depth': 5, 'max_features': 11, 'min_samples_split': 3}. Best is trial 66 with value: 0.68.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:29:59,649]\u001b[0m Trial 85 finished with value: 0.6759999999999999 and parameters: {'max_depth': 5, 'max_features': 13, 'min_samples_split': 4}. Best is trial 66 with value: 0.68.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:29:59,675]\u001b[0m Trial 86 finished with value: 0.6676190476190478 and parameters: {'max_depth': 5, 'max_features': 12, 'min_samples_split': 4}. Best is trial 66 with value: 0.68.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:29:59,701]\u001b[0m Trial 87 finished with value: 0.6337142857142858 and parameters: {'max_depth': 5, 'max_features': 12, 'min_samples_split': 18}. Best is trial 66 with value: 0.68.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:29:59,729]\u001b[0m Trial 88 finished with value: 0.68 and parameters: {'max_depth': 5, 'max_features': 13, 'min_samples_split': 3}. Best is trial 66 with value: 0.68.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:29:59,758]\u001b[0m Trial 89 finished with value: 0.647904761904762 and parameters: {'max_depth': 5, 'max_features': 14, 'min_samples_split': 3}. Best is trial 66 with value: 0.68.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:29:59,784]\u001b[0m Trial 90 finished with value: 0.68 and parameters: {'max_depth': 5, 'max_features': 13, 'min_samples_split': 3}. Best is trial 66 with value: 0.68.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:29:59,809]\u001b[0m Trial 91 finished with value: 0.6759999999999999 and parameters: {'max_depth': 5, 'max_features': 13, 'min_samples_split': 4}. Best is trial 66 with value: 0.68.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:29:59,836]\u001b[0m Trial 92 finished with value: 0.6759999999999999 and parameters: {'max_depth': 5, 'max_features': 13, 'min_samples_split': 4}. Best is trial 66 with value: 0.68.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:29:59,862]\u001b[0m Trial 93 finished with value: 0.6759999999999999 and parameters: {'max_depth': 5, 'max_features': 13, 'min_samples_split': 4}. Best is trial 66 with value: 0.68.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:29:59,889]\u001b[0m Trial 94 finished with value: 0.6379047619047619 and parameters: {'max_depth': 5, 'max_features': 14, 'min_samples_split': 4}. Best is trial 66 with value: 0.68.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:29:59,915]\u001b[0m Trial 95 finished with value: 0.6676190476190478 and parameters: {'max_depth': 5, 'max_features': 12, 'min_samples_split': 4}. Best is trial 66 with value: 0.68.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:29:59,942]\u001b[0m Trial 96 finished with value: 0.68 and parameters: {'max_depth': 5, 'max_features': 13, 'min_samples_split': 3}. Best is trial 66 with value: 0.68.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:29:59,968]\u001b[0m Trial 97 finished with value: 0.6421904761904762 and parameters: {'max_depth': 5, 'max_features': 14, 'min_samples_split': 5}. Best is trial 66 with value: 0.68.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:29:59,993]\u001b[0m Trial 98 finished with value: 0.6634285714285714 and parameters: {'max_depth': 5, 'max_features': 12, 'min_samples_split': 5}. Best is trial 66 with value: 0.68.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:30:00,019]\u001b[0m Trial 99 finished with value: 0.6478095238095238 and parameters: {'max_depth': 5, 'max_features': 11, 'min_samples_split': 3}. Best is trial 66 with value: 0.68.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "#Tuning hyperparameters\n",
    "#Step 1. Define an objective function to be maximized.\n",
    "def objective(trial):\n",
    "    param = {\n",
    "        'max_depth': trial.suggest_int('max_depth',3,5,1),\n",
    "        'max_features' : trial.suggest_int(\"max_features\",10,20,1),\n",
    "        'min_samples_split':trial.suggest_int('min_samples_split',2,25,1)\n",
    "    }\n",
    "    model = DecisionTreeClassifier(**param,random_state=1)\n",
    "\n",
    " \n",
    "# Step 2: Scoring method:\n",
    "    score = model_selection.cross_val_score(model, X, y, n_jobs=8, scoring=\"accuracy\",cv=Cv_optuna)\n",
    "    accuracy = score.mean()\n",
    "    return accuracy\n",
    " \n",
    "# Step 3: Running it\n",
    "study = optuna.create_study(direction=\"maximize\",sampler=optuna.samplers.TPESampler(seed=0))\n",
    "study.optimize(objective, n_trials=100, show_progress_bar=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "6ec0811a-1713-4b39-b21f-cb09e9594c4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best parameters are : \n",
      "{'max_depth': 5, 'max_features': 13, 'min_samples_split': 3}\n"
     ]
    }
   ],
   "source": [
    "# Getting the best parameters:\n",
    "print(f\"The best parameters are : \\n{study.best_params}\")\n",
    "# Setting the best model\n",
    "clf =DecisionTreeClassifier(max_depth = study.best_params['max_depth']\n",
    "              ,max_features = study.best_params['max_features']\n",
    "              #,n_estimators = study.best_params['n_estimators']\n",
    "              #,learning_rate = study.best_params['learning_rate']\n",
    "              ,min_samples_split= study.best_params['min_samples_split']\n",
    "              ,random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "9d1899f3-a5c0-4f3d-8fb2-176c72ea4a4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mean</th>\n",
       "      <th>Se</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Accuracy_test</th>\n",
       "      <td>0.680000</td>\n",
       "      <td>0.012329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Accuracy_train</th>\n",
       "      <td>0.925345</td>\n",
       "      <td>0.005584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1 Score</th>\n",
       "      <td>0.706865</td>\n",
       "      <td>0.012092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Precision</th>\n",
       "      <td>0.698240</td>\n",
       "      <td>0.013460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recall</th>\n",
       "      <td>0.735714</td>\n",
       "      <td>0.020076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Roc_auc</th>\n",
       "      <td>0.690561</td>\n",
       "      <td>0.015281</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Mean        Se\n",
       "Accuracy_test   0.680000  0.012329\n",
       "Accuracy_train  0.925345  0.005584\n",
       "F1 Score        0.706865  0.012092\n",
       "Precision       0.698240  0.013460\n",
       "Recall          0.735714  0.020076\n",
       "Roc_auc         0.690561  0.015281"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Model2\n",
    "Model2=Model_results(clf,X,y,Cv_model)\n",
    "Model2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "390c5554-ccf3-490e-9e3e-7d53299bb3bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th>Method</th>\n",
       "      <th colspan=\"4\" halign=\"left\">DT</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model</th>\n",
       "      <th colspan=\"2\" halign=\"left\">Model 1</th>\n",
       "      <th colspan=\"2\" halign=\"left\">Model 2</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Values</th>\n",
       "      <th>Mean</th>\n",
       "      <th>Se</th>\n",
       "      <th>Mean</th>\n",
       "      <th>Se</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Accuracy_test</th>\n",
       "      <td>0.629333</td>\n",
       "      <td>0.015032</td>\n",
       "      <td>0.680000</td>\n",
       "      <td>0.012329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Accuracy_train</th>\n",
       "      <td>0.729981</td>\n",
       "      <td>0.004700</td>\n",
       "      <td>0.925345</td>\n",
       "      <td>0.005584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1 Score</th>\n",
       "      <td>0.697627</td>\n",
       "      <td>0.013235</td>\n",
       "      <td>0.706865</td>\n",
       "      <td>0.012092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Precision</th>\n",
       "      <td>0.620752</td>\n",
       "      <td>0.011961</td>\n",
       "      <td>0.698240</td>\n",
       "      <td>0.013460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recall</th>\n",
       "      <td>0.811071</td>\n",
       "      <td>0.020893</td>\n",
       "      <td>0.735714</td>\n",
       "      <td>0.020076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Roc_auc</th>\n",
       "      <td>0.664796</td>\n",
       "      <td>0.020543</td>\n",
       "      <td>0.690561</td>\n",
       "      <td>0.015281</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Method                DT                              \n",
       "Model            Model 1             Model 2          \n",
       "Values              Mean        Se      Mean        Se\n",
       "Accuracy_test   0.629333  0.015032  0.680000  0.012329\n",
       "Accuracy_train  0.729981  0.004700  0.925345  0.005584\n",
       "F1 Score        0.697627  0.013235  0.706865  0.012092\n",
       "Precision       0.620752  0.011961  0.698240  0.013460\n",
       "Recall          0.811071  0.020893  0.735714  0.020076\n",
       "Roc_auc         0.664796  0.020543  0.690561  0.015281"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Saving the data of model performance\n",
    "Model_data=pd.concat([Model1,Model2],axis=1)\n",
    "Model_data.columns = [['DT']*4,['Model 1','Model 1', 'Model 2','Model 2'], ['Mean', 'Se', 'Mean', 'Se']]  \n",
    "Model_data.columns.names=['Method','Model','Values']\n",
    "Model_data.to_csv(\"./Results/DT_model_mlrem_data.csv\",sep=',')\n",
    "Model_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff716df6-f48a-4890-819b-cca04c92e57c",
   "metadata": {},
   "source": [
    "## 2.2 LR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "96eeb954-8032-43c2-afb2-e47f675b2d15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mean</th>\n",
       "      <th>Se</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Accuracy_test</th>\n",
       "      <td>0.680000</td>\n",
       "      <td>0.012329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Accuracy_train</th>\n",
       "      <td>0.925345</td>\n",
       "      <td>0.005584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1 Score</th>\n",
       "      <td>0.706865</td>\n",
       "      <td>0.012092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Precision</th>\n",
       "      <td>0.698240</td>\n",
       "      <td>0.013460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recall</th>\n",
       "      <td>0.735714</td>\n",
       "      <td>0.020076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Roc_auc</th>\n",
       "      <td>0.690561</td>\n",
       "      <td>0.015281</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Mean        Se\n",
       "Accuracy_test   0.680000  0.012329\n",
       "Accuracy_train  0.925345  0.005584\n",
       "F1 Score        0.706865  0.012092\n",
       "Precision       0.698240  0.013460\n",
       "Recall          0.735714  0.020076\n",
       "Roc_auc         0.690561  0.015281"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Model1\n",
    "Model1_clf=clf\n",
    "#Model1\n",
    "Model1=Model_results(Model1_clf,X,y,Cv_model)\n",
    "Model1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "662dc3e0-7ca9-41f6-ad45-99db640a18b8",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2024-01-12 01:33:46,194]\u001b[0m A new study created in memory with name: no-name-e4ba7b5b-b8fd-4929-82c3-50137ca4832b\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:33:46,218]\u001b[0m Trial 0 finished with value: 0.6096190476190476 and parameters: {'logreg_c': 0.3177840006884068, 'l1_ratio': 0.7482920440979423, 'max_iter': 100}. Best is trial 0 with value: 0.6096190476190476.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:33:46,239]\u001b[0m Trial 1 finished with value: 0.6195238095238095 and parameters: {'logreg_c': 0.0651621545821569, 'l1_ratio': 0.23208030173540176, 'max_iter': 275}. Best is trial 1 with value: 0.6195238095238095.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:33:46,262]\u001b[0m Trial 2 finished with value: 0.570095238095238 and parameters: {'logreg_c': 0.013108749615263334, 'l1_ratio': 0.411004654338743, 'max_iter': 854}. Best is trial 1 with value: 0.6195238095238095.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:33:46,284]\u001b[0m Trial 3 finished with value: 0.6294285714285714 and parameters: {'logreg_c': 1.7096232052870346, 'l1_ratio': 0.4772750629629653, 'max_iter': 1402}. Best is trial 3 with value: 0.6294285714285714.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:33:46,305]\u001b[0m Trial 4 finished with value: 0.574095238095238 and parameters: {'logreg_c': 0.016854407828169382, 'l1_ratio': 0.8903056927518509, 'max_iter': 152}. Best is trial 3 with value: 0.6294285714285714.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:33:46,328]\u001b[0m Trial 5 finished with value: 0.6167619047619047 and parameters: {'logreg_c': 10.539137268289434, 'l1_ratio': 0.4755743221304143, 'max_iter': 1162}. Best is trial 3 with value: 0.6294285714285714.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:33:46,351]\u001b[0m Trial 6 finished with value: 0.5672380952380952 and parameters: {'logreg_c': 0.006955392321661603, 'l1_ratio': 0.2782913401763909, 'max_iter': 1622}. Best is trial 3 with value: 0.6294285714285714.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:33:46,373]\u001b[0m Trial 7 finished with value: 0.6282857142857143 and parameters: {'logreg_c': 645.0144652189372, 'l1_ratio': 0.38208176034331853, 'max_iter': 1416}. Best is trial 3 with value: 0.6294285714285714.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:33:46,397]\u001b[0m Trial 8 finished with value: 0.6093333333333334 and parameters: {'logreg_c': 181.27374779133626, 'l1_ratio': 0.9051459971534626, 'max_iter': 261}. Best is trial 3 with value: 0.6294285714285714.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:33:46,418]\u001b[0m Trial 9 finished with value: 0.5601904761904761 and parameters: {'logreg_c': 0.001715255021408637, 'l1_ratio': 0.25284737760811204, 'max_iter': 1769}. Best is trial 3 with value: 0.6294285714285714.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:33:46,444]\u001b[0m Trial 10 finished with value: 0.6153333333333333 and parameters: {'logreg_c': 9.589685409552947, 'l1_ratio': 0.6553689413187243, 'max_iter': 845}. Best is trial 3 with value: 0.6294285714285714.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:33:46,469]\u001b[0m Trial 11 finished with value: 0.6268571428571428 and parameters: {'logreg_c': 843.2126062012233, 'l1_ratio': 0.5380831473609496, 'max_iter': 1376}. Best is trial 3 with value: 0.6294285714285714.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:33:46,493]\u001b[0m Trial 12 finished with value: 0.6167619047619047 and parameters: {'logreg_c': 7.624466107886496, 'l1_ratio': 0.378272352651409, 'max_iter': 1494}. Best is trial 3 with value: 0.6294285714285714.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:33:46,518]\u001b[0m Trial 13 finished with value: 0.6162857142857143 and parameters: {'logreg_c': 51.786339691986214, 'l1_ratio': 0.6316370562712422, 'max_iter': 1128}. Best is trial 3 with value: 0.6294285714285714.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:33:46,543]\u001b[0m Trial 14 finished with value: 0.627904761904762 and parameters: {'logreg_c': 0.8529452363532304, 'l1_ratio': 0.13738672304214128, 'max_iter': 1780}. Best is trial 3 with value: 0.6294285714285714.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:33:46,570]\u001b[0m Trial 15 finished with value: 0.6281904761904762 and parameters: {'logreg_c': 763.5588094994378, 'l1_ratio': 0.3689322680983461, 'max_iter': 1971}. Best is trial 3 with value: 0.6294285714285714.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:33:46,596]\u001b[0m Trial 16 finished with value: 0.6195238095238096 and parameters: {'logreg_c': 0.13707192890174966, 'l1_ratio': 0.5845266407991517, 'max_iter': 1309}. Best is trial 3 with value: 0.6294285714285714.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:33:46,623]\u001b[0m Trial 17 finished with value: 0.6120000000000001 and parameters: {'logreg_c': 76.37303329769077, 'l1_ratio': 0.7683639981317943, 'max_iter': 716}. Best is trial 3 with value: 0.6294285714285714.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:33:46,649]\u001b[0m Trial 18 finished with value: 0.6252380952380953 and parameters: {'logreg_c': 2.932001936719566, 'l1_ratio': 0.10084185856253824, 'max_iter': 553}. Best is trial 3 with value: 0.6294285714285714.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:33:46,674]\u001b[0m Trial 19 finished with value: 0.6307619047619046 and parameters: {'logreg_c': 1.3160447446956969, 'l1_ratio': 0.4671561613242705, 'max_iter': 1312}. Best is trial 19 with value: 0.6307619047619046.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:33:46,701]\u001b[0m Trial 20 finished with value: 0.6293333333333333 and parameters: {'logreg_c': 1.4651691779773963, 'l1_ratio': 0.4935134748265029, 'max_iter': 983}. Best is trial 19 with value: 0.6307619047619046.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:33:46,725]\u001b[0m Trial 21 finished with value: 0.6237142857142858 and parameters: {'logreg_c': 0.8287025892084571, 'l1_ratio': 0.5199862466969595, 'max_iter': 1054}. Best is trial 19 with value: 0.6307619047619046.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:33:46,751]\u001b[0m Trial 22 finished with value: 0.6238095238095238 and parameters: {'logreg_c': 3.1654611271505058, 'l1_ratio': 0.4597028916076701, 'max_iter': 1266}. Best is trial 19 with value: 0.6307619047619046.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:33:46,777]\u001b[0m Trial 23 finished with value: 0.6166666666666667 and parameters: {'logreg_c': 0.1535200845989714, 'l1_ratio': 0.6782814588832947, 'max_iter': 981}. Best is trial 19 with value: 0.6307619047619046.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:33:46,803]\u001b[0m Trial 24 finished with value: 0.6294285714285714 and parameters: {'logreg_c': 1.8873063599506599, 'l1_ratio': 0.326102166138698, 'max_iter': 1522}. Best is trial 19 with value: 0.6307619047619046.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:33:46,827]\u001b[0m Trial 25 finished with value: 0.6180952380952381 and parameters: {'logreg_c': 0.41516225975438653, 'l1_ratio': 0.2979284535359352, 'max_iter': 1547}. Best is trial 19 with value: 0.6307619047619046.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:33:46,853]\u001b[0m Trial 26 finished with value: 0.6191428571428571 and parameters: {'logreg_c': 17.953162228525414, 'l1_ratio': 0.31727555023219167, 'max_iter': 1687}. Best is trial 19 with value: 0.6307619047619046.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:33:46,878]\u001b[0m Trial 27 finished with value: 0.6266666666666666 and parameters: {'logreg_c': 2.602409837373429, 'l1_ratio': 0.19868034857393024, 'max_iter': 1919}. Best is trial 19 with value: 0.6307619047619046.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:33:46,905]\u001b[0m Trial 28 finished with value: 0.6195238095238095 and parameters: {'logreg_c': 0.07229078967635784, 'l1_ratio': 0.42868388614084174, 'max_iter': 1511}. Best is trial 19 with value: 0.6307619047619046.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:33:46,931]\u001b[0m Trial 29 finished with value: 0.6194285714285716 and parameters: {'logreg_c': 0.3860177138367054, 'l1_ratio': 0.8158505713189557, 'max_iter': 1211}. Best is trial 19 with value: 0.6307619047619046.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:33:46,956]\u001b[0m Trial 30 finished with value: 0.6168571428571429 and parameters: {'logreg_c': 4.8505444157280655, 'l1_ratio': 0.989090737470458, 'max_iter': 1389}. Best is trial 19 with value: 0.6307619047619046.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:33:46,984]\u001b[0m Trial 31 finished with value: 0.6293333333333334 and parameters: {'logreg_c': 1.2065391735314397, 'l1_ratio': 0.4963584342131737, 'max_iter': 1011}. Best is trial 19 with value: 0.6307619047619046.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:33:47,011]\u001b[0m Trial 32 finished with value: 0.6162857142857143 and parameters: {'logreg_c': 28.72272514710678, 'l1_ratio': 0.581199409657952, 'max_iter': 582}. Best is trial 19 with value: 0.6307619047619046.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:33:47,038]\u001b[0m Trial 33 finished with value: 0.6293333333333333 and parameters: {'logreg_c': 1.3696220900607625, 'l1_ratio': 0.42558482659301816, 'max_iter': 1297}. Best is trial 19 with value: 0.6307619047619046.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:33:47,063]\u001b[0m Trial 34 finished with value: 0.6067619047619047 and parameters: {'logreg_c': 0.2875637249472787, 'l1_ratio': 0.3482207466346646, 'max_iter': 1109}. Best is trial 19 with value: 0.6307619047619046.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:33:47,088]\u001b[0m Trial 35 finished with value: 0.6009523809523809 and parameters: {'logreg_c': 0.03576221722627603, 'l1_ratio': 0.5765441371212959, 'max_iter': 870}. Best is trial 19 with value: 0.6307619047619046.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:33:47,116]\u001b[0m Trial 36 finished with value: 0.6209523809523809 and parameters: {'logreg_c': 0.6626791637945557, 'l1_ratio': 0.20185400717777569, 'max_iter': 1676}. Best is trial 19 with value: 0.6307619047619046.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:33:47,140]\u001b[0m Trial 37 finished with value: 0.6294285714285714 and parameters: {'logreg_c': 1.9120072183363928, 'l1_ratio': 0.4733809188346099, 'max_iter': 1467}. Best is trial 19 with value: 0.6307619047619046.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:33:47,165]\u001b[0m Trial 38 finished with value: 0.6177142857142858 and parameters: {'logreg_c': 19.34210830669201, 'l1_ratio': 0.44990617999528343, 'max_iter': 1557}. Best is trial 19 with value: 0.6307619047619046.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:33:47,192]\u001b[0m Trial 39 finished with value: 0.6139047619047618 and parameters: {'logreg_c': 0.22059945415572177, 'l1_ratio': 0.3267785933880323, 'max_iter': 1424}. Best is trial 19 with value: 0.6307619047619046.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:33:47,219]\u001b[0m Trial 40 finished with value: 0.6139047619047618 and parameters: {'logreg_c': 5.702688279032213, 'l1_ratio': 0.706870700092175, 'max_iter': 1216}. Best is trial 19 with value: 0.6307619047619046.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:33:47,247]\u001b[0m Trial 41 finished with value: 0.6307619047619047 and parameters: {'logreg_c': 2.1083445203193767, 'l1_ratio': 0.5013573618384977, 'max_iter': 1814}. Best is trial 41 with value: 0.6307619047619047.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:33:47,273]\u001b[0m Trial 42 finished with value: 0.6294285714285714 and parameters: {'logreg_c': 1.8778046360697456, 'l1_ratio': 0.39812276354777576, 'max_iter': 1899}. Best is trial 41 with value: 0.6307619047619047.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:33:47,308]\u001b[0m Trial 43 finished with value: 0.6196190476190475 and parameters: {'logreg_c': 4.005595097886426, 'l1_ratio': 0.40683807642605113, 'max_iter': 1851}. Best is trial 41 with value: 0.6307619047619047.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:33:47,335]\u001b[0m Trial 44 finished with value: 0.6153333333333333 and parameters: {'logreg_c': 10.51995398501394, 'l1_ratio': 0.5242462748652383, 'max_iter': 1635}. Best is trial 41 with value: 0.6307619047619047.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:33:47,361]\u001b[0m Trial 45 finished with value: 0.6166666666666667 and parameters: {'logreg_c': 0.43649305773415953, 'l1_ratio': 0.62669435281089, 'max_iter': 1803}. Best is trial 41 with value: 0.6307619047619047.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:33:47,387]\u001b[0m Trial 46 finished with value: 0.6195238095238095 and parameters: {'logreg_c': 0.07187646725784044, 'l1_ratio': 0.281967448657918, 'max_iter': 1917}. Best is trial 41 with value: 0.6307619047619047.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:33:47,414]\u001b[0m Trial 47 finished with value: 0.627904761904762 and parameters: {'logreg_c': 2.0310237754182316, 'l1_ratio': 0.39414395429506727, 'max_iter': 1726}. Best is trial 41 with value: 0.6307619047619047.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:33:47,441]\u001b[0m Trial 48 finished with value: 0.620952380952381 and parameters: {'logreg_c': 0.6082079556285477, 'l1_ratio': 0.5660058818783812, 'max_iter': 1618}. Best is trial 41 with value: 0.6307619047619047.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:33:47,466]\u001b[0m Trial 49 finished with value: 0.6108571428571429 and parameters: {'logreg_c': 240.59569344033093, 'l1_ratio': 0.24451803344912826, 'max_iter': 1985}. Best is trial 41 with value: 0.6307619047619047.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:33:47,492]\u001b[0m Trial 50 finished with value: 0.5643809523809523 and parameters: {'logreg_c': 0.003166482546125131, 'l1_ratio': 0.4598078240788601, 'max_iter': 1365}. Best is trial 41 with value: 0.6307619047619047.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:33:47,518]\u001b[0m Trial 51 finished with value: 0.6167619047619047 and parameters: {'logreg_c': 7.943065063340901, 'l1_ratio': 0.3551537545361903, 'max_iter': 1474}. Best is trial 41 with value: 0.6307619047619047.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:33:47,545]\u001b[0m Trial 52 finished with value: 0.6294285714285714 and parameters: {'logreg_c': 1.8518389019522237, 'l1_ratio': 0.49224974644280434, 'max_iter': 1844}. Best is trial 41 with value: 0.6307619047619047.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:33:47,571]\u001b[0m Trial 53 finished with value: 0.627904761904762 and parameters: {'logreg_c': 1.3572714107165977, 'l1_ratio': 0.49277895678099476, 'max_iter': 1458}. Best is trial 41 with value: 0.6307619047619047.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:33:47,598]\u001b[0m Trial 54 finished with value: 0.6210476190476191 and parameters: {'logreg_c': 3.7115076962149858, 'l1_ratio': 0.6102000361609092, 'max_iter': 1590}. Best is trial 41 with value: 0.6307619047619047.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:33:47,625]\u001b[0m Trial 55 finished with value: 0.6264761904761904 and parameters: {'logreg_c': 0.8911994905571492, 'l1_ratio': 0.3993140649769618, 'max_iter': 1883}. Best is trial 41 with value: 0.6307619047619047.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:33:47,651]\u001b[0m Trial 56 finished with value: 0.6294285714285714 and parameters: {'logreg_c': 2.2506604255090674, 'l1_ratio': 0.5420213510321465, 'max_iter': 1719}. Best is trial 41 with value: 0.6307619047619047.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:33:47,678]\u001b[0m Trial 57 finished with value: 0.6191428571428571 and parameters: {'logreg_c': 19.197800367683012, 'l1_ratio': 0.4652438210429772, 'max_iter': 1762}. Best is trial 41 with value: 0.6307619047619047.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:33:47,705]\u001b[0m Trial 58 finished with value: 0.6195238095238096 and parameters: {'logreg_c': 0.17391612699617703, 'l1_ratio': 0.5464710550797393, 'max_iter': 1365}. Best is trial 41 with value: 0.6307619047619047.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:33:47,730]\u001b[0m Trial 59 finished with value: 0.613904761904762 and parameters: {'logreg_c': 6.575270743844423, 'l1_ratio': 0.5466415698694522, 'max_iter': 1686}. Best is trial 41 with value: 0.6307619047619047.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:33:47,758]\u001b[0m Trial 60 finished with value: 0.6163809523809525 and parameters: {'logreg_c': 54.54049186437329, 'l1_ratio': 0.4325278919043865, 'max_iter': 1996}. Best is trial 41 with value: 0.6307619047619047.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:33:47,784]\u001b[0m Trial 61 finished with value: 0.6307619047619047 and parameters: {'logreg_c': 2.096362271932597, 'l1_ratio': 0.5160078527964562, 'max_iter': 1556}. Best is trial 41 with value: 0.6307619047619047.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:33:47,811]\u001b[0m Trial 62 finished with value: 0.6266666666666666 and parameters: {'logreg_c': 2.538893199184801, 'l1_ratio': 0.504806699044337, 'max_iter': 1744}. Best is trial 41 with value: 0.6307619047619047.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:33:47,838]\u001b[0m Trial 63 finished with value: 0.6308571428571428 and parameters: {'logreg_c': 1.6491171164828378, 'l1_ratio': 0.37983614680640526, 'max_iter': 1831}. Best is trial 63 with value: 0.6308571428571428.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:33:47,865]\u001b[0m Trial 64 finished with value: 0.6207619047619048 and parameters: {'logreg_c': 0.5680946103743453, 'l1_ratio': 0.6124516385720995, 'max_iter': 1804}. Best is trial 63 with value: 0.6308571428571428.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:33:47,891]\u001b[0m Trial 65 finished with value: 0.6194285714285714 and parameters: {'logreg_c': 12.835933863876129, 'l1_ratio': 0.3307896654069705, 'max_iter': 1545}. Best is trial 63 with value: 0.6308571428571428.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:33:47,916]\u001b[0m Trial 66 finished with value: 0.6167619047619047 and parameters: {'logreg_c': 4.284809135627299, 'l1_ratio': 0.49198373373937326, 'max_iter': 1318}. Best is trial 63 with value: 0.6308571428571428.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:33:47,944]\u001b[0m Trial 67 finished with value: 0.6307619047619047 and parameters: {'logreg_c': 0.9489377554918126, 'l1_ratio': 0.37627684812340034, 'max_iter': 1225}. Best is trial 63 with value: 0.6308571428571428.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:33:47,968]\u001b[0m Trial 68 finished with value: 0.6292380952380953 and parameters: {'logreg_c': 1.0538708885678392, 'l1_ratio': 0.6781276320502876, 'max_iter': 1209}. Best is trial 63 with value: 0.6308571428571428.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:33:47,993]\u001b[0m Trial 69 finished with value: 0.6067619047619047 and parameters: {'logreg_c': 0.29155306833483985, 'l1_ratio': 0.36263117743566936, 'max_iter': 1660}. Best is trial 63 with value: 0.6308571428571428.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:33:48,018]\u001b[0m Trial 70 finished with value: 0.6251428571428571 and parameters: {'logreg_c': 0.8333203040302765, 'l1_ratio': 0.43197726798313846, 'max_iter': 1169}. Best is trial 63 with value: 0.6308571428571428.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:33:48,045]\u001b[0m Trial 71 finished with value: 0.6224761904761905 and parameters: {'logreg_c': 3.2825957984619203, 'l1_ratio': 0.52930545567372, 'max_iter': 1902}. Best is trial 63 with value: 0.6308571428571428.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:33:48,071]\u001b[0m Trial 72 finished with value: 0.6294285714285714 and parameters: {'logreg_c': 1.707563442346071, 'l1_ratio': 0.2692265008939825, 'max_iter': 1804}. Best is trial 63 with value: 0.6308571428571428.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:33:48,098]\u001b[0m Trial 73 finished with value: 0.627904761904762 and parameters: {'logreg_c': 1.244565542128993, 'l1_ratio': 0.22628313375302067, 'max_iter': 1283}. Best is trial 63 with value: 0.6308571428571428.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:33:48,124]\u001b[0m Trial 74 finished with value: 0.617904761904762 and parameters: {'logreg_c': 0.5423233219501331, 'l1_ratio': 0.37441966805804505, 'max_iter': 1429}. Best is trial 63 with value: 0.6308571428571428.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:33:48,150]\u001b[0m Trial 75 finished with value: 0.6238095238095238 and parameters: {'logreg_c': 2.6428530082211377, 'l1_ratio': 0.2853040906189891, 'max_iter': 1736}. Best is trial 63 with value: 0.6308571428571428.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:33:48,175]\u001b[0m Trial 76 finished with value: 0.6209523809523809 and parameters: {'logreg_c': 0.10939627711828923, 'l1_ratio': 0.4735312789321377, 'max_iter': 1846}. Best is trial 63 with value: 0.6308571428571428.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:33:48,201]\u001b[0m Trial 77 finished with value: 0.6264761904761904 and parameters: {'logreg_c': 0.8745518604877525, 'l1_ratio': 0.442590140651025, 'max_iter': 1078}. Best is trial 63 with value: 0.6308571428571428.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:33:48,227]\u001b[0m Trial 78 finished with value: 0.6154285714285713 and parameters: {'logreg_c': 5.330321809025692, 'l1_ratio': 0.4137370416803211, 'max_iter': 1943}. Best is trial 63 with value: 0.6308571428571428.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:33:48,254]\u001b[0m Trial 79 finished with value: 0.6321904761904762 and parameters: {'logreg_c': 1.5684558195868687, 'l1_ratio': 0.51063148634346, 'max_iter': 1863}. Best is trial 79 with value: 0.6321904761904762.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:33:48,280]\u001b[0m Trial 80 finished with value: 0.6194285714285716 and parameters: {'logreg_c': 0.37976816840820854, 'l1_ratio': 0.34025799616210806, 'max_iter': 1579}. Best is trial 79 with value: 0.6321904761904762.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:33:48,304]\u001b[0m Trial 81 finished with value: 0.6308571428571428 and parameters: {'logreg_c': 1.5835184104709785, 'l1_ratio': 0.5016015552438089, 'max_iter': 1871}. Best is trial 79 with value: 0.6321904761904762.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:33:48,327]\u001b[0m Trial 82 finished with value: 0.6308571428571428 and parameters: {'logreg_c': 1.6594874201724938, 'l1_ratio': 0.3063290111973975, 'max_iter': 1960}. Best is trial 79 with value: 0.6321904761904762.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:33:48,352]\u001b[0m Trial 83 finished with value: 0.6307619047619046 and parameters: {'logreg_c': 1.343979148614231, 'l1_ratio': 0.5176219420701993, 'max_iter': 1967}. Best is trial 79 with value: 0.6321904761904762.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:33:48,376]\u001b[0m Trial 84 finished with value: 0.6223809523809524 and parameters: {'logreg_c': 0.7187697779331849, 'l1_ratio': 0.5672396458148798, 'max_iter': 1939}. Best is trial 79 with value: 0.6321904761904762.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:33:48,402]\u001b[0m Trial 85 finished with value: 0.6293333333333334 and parameters: {'logreg_c': 1.2029830464414577, 'l1_ratio': 0.5185295899090988, 'max_iter': 1859}. Best is trial 79 with value: 0.6321904761904762.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:33:48,427]\u001b[0m Trial 86 finished with value: 0.6266666666666666 and parameters: {'logreg_c': 2.9061910777908393, 'l1_ratio': 0.3132992841051993, 'max_iter': 1949}. Best is trial 79 with value: 0.6321904761904762.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:33:48,450]\u001b[0m Trial 87 finished with value: 0.6096190476190476 and parameters: {'logreg_c': 0.2725593715364528, 'l1_ratio': 0.3860887328318272, 'max_iter': 1796}. Best is trial 79 with value: 0.6321904761904762.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:33:48,475]\u001b[0m Trial 88 finished with value: 0.6165714285714287 and parameters: {'logreg_c': 0.4912865251268892, 'l1_ratio': 0.5945013797755109, 'max_iter': 2000}. Best is trial 79 with value: 0.6321904761904762.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:33:48,499]\u001b[0m Trial 89 finished with value: 0.6153333333333333 and parameters: {'logreg_c': 8.240833064906228, 'l1_ratio': 0.5139563256443173, 'max_iter': 162}. Best is trial 79 with value: 0.6321904761904762.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:33:48,523]\u001b[0m Trial 90 finished with value: 0.6307619047619047 and parameters: {'logreg_c': 1.4731369609639198, 'l1_ratio': 0.4554672724433561, 'max_iter': 1883}. Best is trial 79 with value: 0.6321904761904762.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:33:48,546]\u001b[0m Trial 91 finished with value: 0.627904761904762 and parameters: {'logreg_c': 1.2362306827283187, 'l1_ratio': 0.45224194854848165, 'max_iter': 1869}. Best is trial 79 with value: 0.6321904761904762.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:33:48,572]\u001b[0m Trial 92 finished with value: 0.628 and parameters: {'logreg_c': 1.8218108234980488, 'l1_ratio': 0.47339867982647943, 'max_iter': 1823}. Best is trial 79 with value: 0.6321904761904762.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:33:48,595]\u001b[0m Trial 93 finished with value: 0.6167619047619047 and parameters: {'logreg_c': 4.271962308570505, 'l1_ratio': 0.5609556013046808, 'max_iter': 1914}. Best is trial 79 with value: 0.6321904761904762.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:33:48,618]\u001b[0m Trial 94 finished with value: 0.6307619047619047 and parameters: {'logreg_c': 0.9774627856036887, 'l1_ratio': 0.42302130014987804, 'max_iter': 1700}. Best is trial 79 with value: 0.6321904761904762.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:33:48,643]\u001b[0m Trial 95 finished with value: 0.6222857142857143 and parameters: {'logreg_c': 0.8082919920657609, 'l1_ratio': 0.41564559443826843, 'max_iter': 1765}. Best is trial 79 with value: 0.6321904761904762.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:33:48,667]\u001b[0m Trial 96 finished with value: 0.6308571428571428 and parameters: {'logreg_c': 1.576347619069216, 'l1_ratio': 0.37665937232889934, 'max_iter': 1705}. Best is trial 79 with value: 0.6321904761904762.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:33:48,691]\u001b[0m Trial 97 finished with value: 0.6252380952380953 and parameters: {'logreg_c': 3.119735317205072, 'l1_ratio': 0.3724348739191003, 'max_iter': 1701}. Best is trial 79 with value: 0.6321904761904762.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:33:48,715]\u001b[0m Trial 98 finished with value: 0.613904761904762 and parameters: {'logreg_c': 6.204154164274675, 'l1_ratio': 0.3480031298152046, 'max_iter': 1631}. Best is trial 79 with value: 0.6321904761904762.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:33:48,739]\u001b[0m Trial 99 finished with value: 0.6195238095238096 and parameters: {'logreg_c': 0.6240590821298014, 'l1_ratio': 0.39483273607916664, 'max_iter': 1765}. Best is trial 79 with value: 0.6321904761904762.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "#Tuning hyperparameters\n",
    "#Step 1. Define an objective function to be maximized.\n",
    "def objective(trial):\n",
    "    logreg_c = trial.suggest_float(\"logreg_c\", 1e-3,  1e3, log=True)\n",
    "    l1_ratio = trial.suggest_float(\"l1_ratio\",0.1,1,log=False) \n",
    "    #penalty = trial.suggest_categorical(\"penalty\",['l1','l2'])\n",
    "    max_iter = trial.suggest_int(\"max_iter\", 100,2000)\n",
    "    model =LogisticRegression(C=logreg_c,\n",
    "                              max_iter=max_iter,\n",
    "                              l1_ratio=l1_ratio,\n",
    "                              solver='liblinear',random_state=1)\n",
    "    \n",
    "# Step 2: Scoring method:\n",
    "    score = model_selection.cross_val_score(model, X, y, n_jobs=8, scoring=\"accuracy\",cv=Cv_optuna)\n",
    "    accuracy = score.mean()\n",
    "    return accuracy\n",
    "\n",
    "# Step 3: Running it\n",
    "study = optuna.create_study(direction=\"maximize\",sampler=optuna.samplers.TPESampler(seed=1))\n",
    "study.optimize(objective, n_trials=100, show_progress_bar=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "36a76651-b007-4715-a58f-8776deab4b8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best parameters are : \n",
      "{'logreg_c': 1.5684558195868687, 'l1_ratio': 0.51063148634346, 'max_iter': 1863}\n"
     ]
    }
   ],
   "source": [
    "# Getting the best parameters:\n",
    "print(f\"The best parameters are : \\n{study.best_params}\")\n",
    "# Setting the best model\n",
    "clf=LogisticRegression(C=study.best_params['logreg_c'],\n",
    "                              max_iter=study.best_params['max_iter'],\n",
    "                              l1_ratio=study.best_params['l1_ratio'],\n",
    "                              solver='liblinear',\n",
    "                              random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "b3ae0d1b-badc-4865-802b-396e3ee1b6cf",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mean</th>\n",
       "      <th>Se</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Accuracy_test</th>\n",
       "      <td>0.632190</td>\n",
       "      <td>0.014648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Accuracy_train</th>\n",
       "      <td>0.735909</td>\n",
       "      <td>0.004541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1 Score</th>\n",
       "      <td>0.694496</td>\n",
       "      <td>0.013341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Precision</th>\n",
       "      <td>0.627650</td>\n",
       "      <td>0.012121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recall</th>\n",
       "      <td>0.794643</td>\n",
       "      <td>0.021058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Roc_auc</th>\n",
       "      <td>0.673325</td>\n",
       "      <td>0.020325</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Mean        Se\n",
       "Accuracy_test   0.632190  0.014648\n",
       "Accuracy_train  0.735909  0.004541\n",
       "F1 Score        0.694496  0.013341\n",
       "Precision       0.627650  0.012121\n",
       "Recall          0.794643  0.021058\n",
       "Roc_auc         0.673325  0.020325"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Model2\n",
    "Model2=Model_results(clf,X,y,Cv_model)\n",
    "Model2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "a5007e9c-21fb-4007-bc2e-d5875dabe240",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th>Method</th>\n",
       "      <th colspan=\"4\" halign=\"left\">LR</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model</th>\n",
       "      <th colspan=\"2\" halign=\"left\">Model 1</th>\n",
       "      <th colspan=\"2\" halign=\"left\">Model 2</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Values</th>\n",
       "      <th>Mean</th>\n",
       "      <th>Se</th>\n",
       "      <th>Mean</th>\n",
       "      <th>Se</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Accuracy_test</th>\n",
       "      <td>0.680000</td>\n",
       "      <td>0.012329</td>\n",
       "      <td>0.632190</td>\n",
       "      <td>0.014648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Accuracy_train</th>\n",
       "      <td>0.925345</td>\n",
       "      <td>0.005584</td>\n",
       "      <td>0.735909</td>\n",
       "      <td>0.004541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1 Score</th>\n",
       "      <td>0.706865</td>\n",
       "      <td>0.012092</td>\n",
       "      <td>0.694496</td>\n",
       "      <td>0.013341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Precision</th>\n",
       "      <td>0.698240</td>\n",
       "      <td>0.013460</td>\n",
       "      <td>0.627650</td>\n",
       "      <td>0.012121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recall</th>\n",
       "      <td>0.735714</td>\n",
       "      <td>0.020076</td>\n",
       "      <td>0.794643</td>\n",
       "      <td>0.021058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Roc_auc</th>\n",
       "      <td>0.690561</td>\n",
       "      <td>0.015281</td>\n",
       "      <td>0.673325</td>\n",
       "      <td>0.020325</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Method                LR                              \n",
       "Model            Model 1             Model 2          \n",
       "Values              Mean        Se      Mean        Se\n",
       "Accuracy_test   0.680000  0.012329  0.632190  0.014648\n",
       "Accuracy_train  0.925345  0.005584  0.735909  0.004541\n",
       "F1 Score        0.706865  0.012092  0.694496  0.013341\n",
       "Precision       0.698240  0.013460  0.627650  0.012121\n",
       "Recall          0.735714  0.020076  0.794643  0.021058\n",
       "Roc_auc         0.690561  0.015281  0.673325  0.020325"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Saving the data of model performance\n",
    "Model_data=pd.concat([Model1,Model2],axis=1)\n",
    "Model_data.columns = [['LR']*4,['Model 1','Model 1', 'Model 2','Model 2'], ['Mean', 'Se', 'Mean', 'Se']]  \n",
    "Model_data.columns.names=['Method','Model','Values']\n",
    "Model_data.to_csv(\"./Results/LR_model_mlrem_data.csv\",sep=',')\n",
    "Model_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "892cd0c1-3914-4d08-a63a-550ffd5f60fb",
   "metadata": {},
   "source": [
    "## 2.3 RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "570a3fc5-5ce1-4bd8-a18a-b9209126a44e",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf=RandomForestClassifier(random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "4448a0ec-3f59-45ad-be0b-3713b3c0072b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mean</th>\n",
       "      <th>Se</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Accuracy_test</th>\n",
       "      <td>0.676381</td>\n",
       "      <td>0.014691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Accuracy_train</th>\n",
       "      <td>0.978164</td>\n",
       "      <td>0.001539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1 Score</th>\n",
       "      <td>0.711877</td>\n",
       "      <td>0.013423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Precision</th>\n",
       "      <td>0.688878</td>\n",
       "      <td>0.014746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recall</th>\n",
       "      <td>0.757857</td>\n",
       "      <td>0.020561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Roc_auc</th>\n",
       "      <td>0.756424</td>\n",
       "      <td>0.017012</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Mean        Se\n",
       "Accuracy_test   0.676381  0.014691\n",
       "Accuracy_train  0.978164  0.001539\n",
       "F1 Score        0.711877  0.013423\n",
       "Precision       0.688878  0.014746\n",
       "Recall          0.757857  0.020561\n",
       "Roc_auc         0.756424  0.017012"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Model1\n",
    "Model1_clf=clf\n",
    "#Model1\n",
    "Model1=Model_results(Model1_clf,X,y,Cv_model)\n",
    "Model1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "d0f9ce84-3537-484b-9862-bf7cefca94b8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2024-01-12 01:35:16,075]\u001b[0m A new study created in memory with name: no-name-0e368382-34a5-42fd-91ba-b1b1a0a8e3bf\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:35:19,314]\u001b[0m Trial 0 finished with value: 0.5352380952380952 and parameters: {'n_estimators': 594, 'max_depth': 16, 'max_features': 20, 'min_impurity_decrease': 2.724415914984484}. Best is trial 0 with value: 0.5352380952380952.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:35:21,908]\u001b[0m Trial 1 finished with value: 0.5352380952380952 and parameters: {'n_estimators': 481, 'max_depth': 15, 'max_features': 16, 'min_impurity_decrease': 4.4588650039103985}. Best is trial 0 with value: 0.5352380952380952.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:35:27,120]\u001b[0m Trial 2 finished with value: 0.5352380952380952 and parameters: {'n_estimators': 968, 'max_depth': 11, 'max_features': 25, 'min_impurity_decrease': 2.644474598764522}. Best is trial 0 with value: 0.5352380952380952.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:35:30,335]\u001b[0m Trial 3 finished with value: 0.5352380952380952 and parameters: {'n_estimators': 611, 'max_depth': 19, 'max_features': 6, 'min_impurity_decrease': 0.43564649850770354}. Best is trial 0 with value: 0.5352380952380952.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:35:31,006]\u001b[0m Trial 4 finished with value: 0.5352380952380952 and parameters: {'n_estimators': 118, 'max_depth': 18, 'max_features': 25, 'min_impurity_decrease': 4.3500607412340955}. Best is trial 0 with value: 0.5352380952380952.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:35:36,134]\u001b[0m Trial 5 finished with value: 0.5352380952380952 and parameters: {'n_estimators': 981, 'max_depth': 17, 'max_features': 16, 'min_impurity_decrease': 3.902645881432277}. Best is trial 0 with value: 0.5352380952380952.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:35:37,261]\u001b[0m Trial 6 finished with value: 0.5352380952380952 and parameters: {'n_estimators': 206, 'max_depth': 15, 'max_features': 8, 'min_impurity_decrease': 4.7233445852479194}. Best is trial 0 with value: 0.5352380952380952.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:35:40,255]\u001b[0m Trial 7 finished with value: 0.5352380952380952 and parameters: {'n_estimators': 570, 'max_depth': 11, 'max_features': 11, 'min_impurity_decrease': 3.871168447171083}. Best is trial 0 with value: 0.5352380952380952.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:35:42,854]\u001b[0m Trial 8 finished with value: 0.5352380952380952 and parameters: {'n_estimators': 510, 'max_depth': 14, 'max_features': 5, 'min_impurity_decrease': 3.0881774853793855}. Best is trial 0 with value: 0.5352380952380952.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:35:46,294]\u001b[0m Trial 9 finished with value: 0.5352380952380952 and parameters: {'n_estimators': 651, 'max_depth': 14, 'max_features': 29, 'min_impurity_decrease': 3.409101495517417}. Best is trial 0 with value: 0.5352380952380952.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:35:50,414]\u001b[0m Trial 10 finished with value: 0.5352380952380952 and parameters: {'n_estimators': 790, 'max_depth': 7, 'max_features': 21, 'min_impurity_decrease': 1.5046577569438309}. Best is trial 0 with value: 0.5352380952380952.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:35:52,562]\u001b[0m Trial 11 finished with value: 0.5352380952380952 and parameters: {'n_estimators': 397, 'max_depth': 20, 'max_features': 16, 'min_impurity_decrease': 1.9887909510549393}. Best is trial 0 with value: 0.5352380952380952.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:35:54,439]\u001b[0m Trial 12 finished with value: 0.5352380952380952 and parameters: {'n_estimators': 353, 'max_depth': 16, 'max_features': 20, 'min_impurity_decrease': 0.7029374955194359}. Best is trial 0 with value: 0.5352380952380952.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:35:56,713]\u001b[0m Trial 13 finished with value: 0.5352380952380952 and parameters: {'n_estimators': 411, 'max_depth': 12, 'max_features': 12, 'min_impurity_decrease': 4.931175650908394}. Best is trial 0 with value: 0.5352380952380952.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:36:00,636]\u001b[0m Trial 14 finished with value: 0.5352380952380952 and parameters: {'n_estimators': 743, 'max_depth': 7, 'max_features': 19, 'min_impurity_decrease': 1.5253121430442067}. Best is trial 0 with value: 0.5352380952380952.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:36:04,681]\u001b[0m Trial 15 finished with value: 0.5352380952380952 and parameters: {'n_estimators': 757, 'max_depth': 13, 'max_features': 12, 'min_impurity_decrease': 2.668111844473928}. Best is trial 0 with value: 0.5352380952380952.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:36:06,269]\u001b[0m Trial 16 finished with value: 0.5352380952380952 and parameters: {'n_estimators': 286, 'max_depth': 9, 'max_features': 24, 'min_impurity_decrease': 3.4814210246729473}. Best is trial 0 with value: 0.5352380952380952.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:36:10,648]\u001b[0m Trial 17 finished with value: 0.5352380952380952 and parameters: {'n_estimators': 807, 'max_depth': 5, 'max_features': 19, 'min_impurity_decrease': 1.4307627258174422}. Best is trial 0 with value: 0.5352380952380952.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:36:14,484]\u001b[0m Trial 18 finished with value: 0.5352380952380952 and parameters: {'n_estimators': 714, 'max_depth': 13, 'max_features': 12, 'min_impurity_decrease': 2.574069984147719}. Best is trial 0 with value: 0.5352380952380952.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:36:16,040]\u001b[0m Trial 19 finished with value: 0.5352380952380952 and parameters: {'n_estimators': 291, 'max_depth': 8, 'max_features': 24, 'min_impurity_decrease': 3.3144569973486893}. Best is trial 0 with value: 0.5352380952380952.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:36:20,679]\u001b[0m Trial 20 finished with value: 0.5352380952380952 and parameters: {'n_estimators': 871, 'max_depth': 5, 'max_features': 29, 'min_impurity_decrease': 1.0528796896599464}. Best is trial 0 with value: 0.5352380952380952.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:36:24,313]\u001b[0m Trial 21 finished with value: 0.5352380952380952 and parameters: {'n_estimators': 670, 'max_depth': 10, 'max_features': 14, 'min_impurity_decrease': 2.1272690676619246}. Best is trial 0 with value: 0.5352380952380952.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:36:27,036]\u001b[0m Trial 22 finished with value: 0.5352380952380952 and parameters: {'n_estimators': 502, 'max_depth': 9, 'max_features': 23, 'min_impurity_decrease': 3.0212243946132653}. Best is trial 0 with value: 0.5352380952380952.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:36:31,734]\u001b[0m Trial 23 finished with value: 0.5352380952380952 and parameters: {'n_estimators': 871, 'max_depth': 6, 'max_features': 30, 'min_impurity_decrease': 0.8924229302747374}. Best is trial 0 with value: 0.5352380952380952.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:36:35,612]\u001b[0m Trial 24 finished with value: 0.5352380952380952 and parameters: {'n_estimators': 673, 'max_depth': 11, 'max_features': 28, 'min_impurity_decrease': 2.183958261339378}. Best is trial 0 with value: 0.5352380952380952.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:36:41,146]\u001b[0m Trial 25 finished with value: 0.5352380952380952 and parameters: {'n_estimators': 548, 'max_depth': 9, 'max_features': 22, 'min_impurity_decrease': 2.0762642939740097}. Best is trial 0 with value: 0.5352380952380952.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:36:51,062]\u001b[0m Trial 26 finished with value: 0.6323809523809524 and parameters: {'n_estimators': 859, 'max_depth': 7, 'max_features': 27, 'min_impurity_decrease': 0.05016303754931206}. Best is trial 26 with value: 0.6323809523809524.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:37:01,691]\u001b[0m Trial 27 finished with value: 0.672 and parameters: {'n_estimators': 889, 'max_depth': 6, 'max_features': 27, 'min_impurity_decrease': 0.008573433661244079}. Best is trial 27 with value: 0.672.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:37:11,727]\u001b[0m Trial 28 finished with value: 0.6322857142857143 and parameters: {'n_estimators': 901, 'max_depth': 7, 'max_features': 27, 'min_impurity_decrease': 0.04449057244021093}. Best is trial 27 with value: 0.672.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:37:22,093]\u001b[0m Trial 29 finished with value: 0.6254285714285714 and parameters: {'n_estimators': 918, 'max_depth': 7, 'max_features': 27, 'min_impurity_decrease': 0.06568686852538762}. Best is trial 27 with value: 0.672.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:37:30,555]\u001b[0m Trial 30 finished with value: 0.5352380952380952 and parameters: {'n_estimators': 855, 'max_depth': 6, 'max_features': 26, 'min_impurity_decrease': 0.3179551086113602}. Best is trial 27 with value: 0.672.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:37:38,485]\u001b[0m Trial 31 finished with value: 0.597047619047619 and parameters: {'n_estimators': 937, 'max_depth': 7, 'max_features': 27, 'min_impurity_decrease': 0.18490386200494244}. Best is trial 27 with value: 0.672.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:37:46,299]\u001b[0m Trial 32 finished with value: 0.6747619047619048 and parameters: {'n_estimators': 913, 'max_depth': 8, 'max_features': 27, 'min_impurity_decrease': 0.004905793398417582}. Best is trial 32 with value: 0.6747619047619048.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:37:56,619]\u001b[0m Trial 33 finished with value: 0.6761904761904762 and parameters: {'n_estimators': 917, 'max_depth': 6, 'max_features': 30, 'min_impurity_decrease': 0.0020653183224317627}. Best is trial 33 with value: 0.6761904761904762.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:38:05,942]\u001b[0m Trial 34 finished with value: 0.5352380952380952 and parameters: {'n_estimators': 989, 'max_depth': 5, 'max_features': 29, 'min_impurity_decrease': 0.6299600959488392}. Best is trial 33 with value: 0.6761904761904762.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:38:13,475]\u001b[0m Trial 35 finished with value: 0.5352380952380952 and parameters: {'n_estimators': 815, 'max_depth': 8, 'max_features': 30, 'min_impurity_decrease': 0.4674586648441808}. Best is trial 33 with value: 0.6761904761904762.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:38:23,053]\u001b[0m Trial 36 finished with value: 0.5352380952380952 and parameters: {'n_estimators': 961, 'max_depth': 6, 'max_features': 25, 'min_impurity_decrease': 1.1357603095945366}. Best is trial 33 with value: 0.6761904761904762.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:38:31,082]\u001b[0m Trial 37 finished with value: 0.5352380952380952 and parameters: {'n_estimators': 840, 'max_depth': 8, 'max_features': 26, 'min_impurity_decrease': 0.4114799952729883}. Best is trial 33 with value: 0.6761904761904762.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:38:40,979]\u001b[0m Trial 38 finished with value: 0.5352380952380952 and parameters: {'n_estimators': 998, 'max_depth': 10, 'max_features': 23, 'min_impurity_decrease': 0.7115028745023322}. Best is trial 33 with value: 0.6761904761904762.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:38:51,024]\u001b[0m Trial 39 finished with value: 0.6297142857142857 and parameters: {'n_estimators': 903, 'max_depth': 6, 'max_features': 28, 'min_impurity_decrease': 0.06208220513260173}. Best is trial 33 with value: 0.6761904761904762.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:38:58,675]\u001b[0m Trial 40 finished with value: 0.5352380952380952 and parameters: {'n_estimators': 758, 'max_depth': 5, 'max_features': 25, 'min_impurity_decrease': 1.2530333907876288}. Best is trial 33 with value: 0.6761904761904762.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:39:08,515]\u001b[0m Trial 41 finished with value: 0.6322857142857143 and parameters: {'n_estimators': 907, 'max_depth': 8, 'max_features': 27, 'min_impurity_decrease': 0.05286677087361633}. Best is trial 33 with value: 0.6761904761904762.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:39:17,698]\u001b[0m Trial 42 finished with value: 0.5352380952380952 and parameters: {'n_estimators': 942, 'max_depth': 8, 'max_features': 30, 'min_impurity_decrease': 0.5113387488083093}. Best is trial 33 with value: 0.6761904761904762.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:39:26,348]\u001b[0m Trial 43 finished with value: 0.5421904761904762 and parameters: {'n_estimators': 888, 'max_depth': 10, 'max_features': 28, 'min_impurity_decrease': 0.22488874368369016}. Best is trial 33 with value: 0.6761904761904762.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:39:34,856]\u001b[0m Trial 44 finished with value: 0.5352380952380952 and parameters: {'n_estimators': 829, 'max_depth': 6, 'max_features': 26, 'min_impurity_decrease': 0.9284394996974525}. Best is trial 33 with value: 0.6761904761904762.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:39:45,663]\u001b[0m Trial 45 finished with value: 0.6718095238095237 and parameters: {'n_estimators': 948, 'max_depth': 9, 'max_features': 28, 'min_impurity_decrease': 0.0222031983719142}. Best is trial 33 with value: 0.6761904761904762.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:39:55,567]\u001b[0m Trial 46 finished with value: 0.5352380952380952 and parameters: {'n_estimators': 949, 'max_depth': 9, 'max_features': 29, 'min_impurity_decrease': 0.3420653743587697}. Best is trial 33 with value: 0.6761904761904762.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:40:02,772]\u001b[0m Trial 47 finished with value: 0.5352380952380952 and parameters: {'n_estimators': 785, 'max_depth': 7, 'max_features': 9, 'min_impurity_decrease': 0.6816047837540026}. Best is trial 33 with value: 0.6761904761904762.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:40:08,909]\u001b[0m Trial 48 finished with value: 0.5352380952380952 and parameters: {'n_estimators': 622, 'max_depth': 6, 'max_features': 24, 'min_impurity_decrease': 0.8511767213202808}. Best is trial 33 with value: 0.6761904761904762.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:40:09,968]\u001b[0m Trial 49 finished with value: 0.5309523809523808 and parameters: {'n_estimators': 107, 'max_depth': 10, 'max_features': 21, 'min_impurity_decrease': 0.26320721389361473}. Best is trial 33 with value: 0.6761904761904762.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:40:17,265]\u001b[0m Trial 50 finished with value: 0.5352380952380952 and parameters: {'n_estimators': 708, 'max_depth': 12, 'max_features': 28, 'min_impurity_decrease': 1.8082382735708258}. Best is trial 33 with value: 0.6761904761904762.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:40:28,042]\u001b[0m Trial 51 finished with value: 0.676095238095238 and parameters: {'n_estimators': 962, 'max_depth': 7, 'max_features': 27, 'min_impurity_decrease': 0.02106459317315383}. Best is trial 33 with value: 0.6761904761904762.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:40:37,749]\u001b[0m Trial 52 finished with value: 0.5352380952380952 and parameters: {'n_estimators': 955, 'max_depth': 7, 'max_features': 26, 'min_impurity_decrease': 0.49937746742507}. Best is trial 33 with value: 0.6761904761904762.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:40:47,221]\u001b[0m Trial 53 finished with value: 0.5323809523809523 and parameters: {'n_estimators': 989, 'max_depth': 5, 'max_features': 30, 'min_impurity_decrease': 0.24933984959020736}. Best is trial 33 with value: 0.6761904761904762.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:40:57,354]\u001b[0m Trial 54 finished with value: 0.671904761904762 and parameters: {'n_estimators': 850, 'max_depth': 8, 'max_features': 29, 'min_impurity_decrease': 0.00020460322913867096}. Best is trial 33 with value: 0.6761904761904762.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:41:06,231]\u001b[0m Trial 55 finished with value: 0.5352380952380952 and parameters: {'n_estimators': 926, 'max_depth': 8, 'max_features': 29, 'min_impurity_decrease': 0.5829495913183985}. Best is trial 33 with value: 0.6761904761904762.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:41:13,996]\u001b[0m Trial 56 finished with value: 0.5352380952380952 and parameters: {'n_estimators': 807, 'max_depth': 9, 'max_features': 25, 'min_impurity_decrease': 4.063447563238093}. Best is trial 33 with value: 0.6761904761904762.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:41:24,402]\u001b[0m Trial 57 finished with value: 0.6761904761904762 and parameters: {'n_estimators': 880, 'max_depth': 11, 'max_features': 28, 'min_impurity_decrease': 0.007051219363487071}. Best is trial 33 with value: 0.6761904761904762.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:41:26,100]\u001b[0m Trial 58 finished with value: 0.5352380952380952 and parameters: {'n_estimators': 167, 'max_depth': 11, 'max_features': 29, 'min_impurity_decrease': 0.798147610103549}. Best is trial 33 with value: 0.6761904761904762.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:41:33,758]\u001b[0m Trial 59 finished with value: 0.5352380952380952 and parameters: {'n_estimators': 770, 'max_depth': 18, 'max_features': 30, 'min_impurity_decrease': 0.382341636539112}. Best is trial 33 with value: 0.6761904761904762.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:41:41,537]\u001b[0m Trial 60 finished with value: 0.5309523809523808 and parameters: {'n_estimators': 843, 'max_depth': 16, 'max_features': 17, 'min_impurity_decrease': 0.2654469511283595}. Best is trial 33 with value: 0.6761904761904762.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:41:52,032]\u001b[0m Trial 61 finished with value: 0.6776190476190476 and parameters: {'n_estimators': 879, 'max_depth': 9, 'max_features': 28, 'min_impurity_decrease': 0.008123194334826785}. Best is trial 61 with value: 0.6776190476190476.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:42:01,231]\u001b[0m Trial 62 finished with value: 0.5956190476190477 and parameters: {'n_estimators': 876, 'max_depth': 12, 'max_features': 28, 'min_impurity_decrease': 0.18049512848250882}. Best is trial 61 with value: 0.6776190476190476.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:42:09,726]\u001b[0m Trial 63 finished with value: 0.5352380952380952 and parameters: {'n_estimators': 889, 'max_depth': 8, 'max_features': 26, 'min_impurity_decrease': 0.5086713670369812}. Best is trial 61 with value: 0.6776190476190476.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:42:16,982]\u001b[0m Trial 64 finished with value: 0.5983809523809525 and parameters: {'n_estimators': 736, 'max_depth': 14, 'max_features': 23, 'min_impurity_decrease': 0.17773926474715257}. Best is trial 61 with value: 0.6776190476190476.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:42:26,203]\u001b[0m Trial 65 finished with value: 0.5352380952380952 and parameters: {'n_estimators': 969, 'max_depth': 10, 'max_features': 29, 'min_impurity_decrease': 0.33631758132430556}. Best is trial 61 with value: 0.6776190476190476.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:42:35,065]\u001b[0m Trial 66 finished with value: 0.6165714285714285 and parameters: {'n_estimators': 925, 'max_depth': 11, 'max_features': 27, 'min_impurity_decrease': 0.1425798717417805}. Best is trial 61 with value: 0.6776190476190476.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:42:44,003]\u001b[0m Trial 67 finished with value: 0.5352380952380952 and parameters: {'n_estimators': 862, 'max_depth': 6, 'max_features': 24, 'min_impurity_decrease': 2.868193262665083}. Best is trial 61 with value: 0.6776190476190476.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:42:51,348]\u001b[0m Trial 68 finished with value: 0.5352380952380952 and parameters: {'n_estimators': 797, 'max_depth': 9, 'max_features': 25, 'min_impurity_decrease': 0.994325851568861}. Best is trial 61 with value: 0.6776190476190476.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:43:00,977]\u001b[0m Trial 69 finished with value: 0.6535238095238095 and parameters: {'n_estimators': 828, 'max_depth': 7, 'max_features': 30, 'min_impurity_decrease': 0.031484934359399815}. Best is trial 61 with value: 0.6776190476190476.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:43:09,542]\u001b[0m Trial 70 finished with value: 0.5352380952380952 and parameters: {'n_estimators': 974, 'max_depth': 8, 'max_features': 15, 'min_impurity_decrease': 0.634550934357082}. Best is trial 61 with value: 0.6776190476190476.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:43:19,004]\u001b[0m Trial 71 finished with value: 0.5352380952380952 and parameters: {'n_estimators': 931, 'max_depth': 9, 'max_features': 28, 'min_impurity_decrease': 0.38649297888281287}. Best is trial 61 with value: 0.6776190476190476.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:43:29,212]\u001b[0m Trial 72 finished with value: 0.6577142857142857 and parameters: {'n_estimators': 899, 'max_depth': 9, 'max_features': 28, 'min_impurity_decrease': 0.030118637469662382}. Best is trial 61 with value: 0.6776190476190476.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:43:40,472]\u001b[0m Trial 73 finished with value: 0.6464761904761906 and parameters: {'n_estimators': 997, 'max_depth': 8, 'max_features': 27, 'min_impurity_decrease': 0.03301911564319314}. Best is trial 61 with value: 0.6776190476190476.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:43:49,058]\u001b[0m Trial 74 finished with value: 0.5832380952380952 and parameters: {'n_estimators': 869, 'max_depth': 7, 'max_features': 29, 'min_impurity_decrease': 0.19804900719497173}. Best is trial 61 with value: 0.6776190476190476.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:44:00,411]\u001b[0m Trial 75 finished with value: 0.6733333333333333 and parameters: {'n_estimators': 960, 'max_depth': 11, 'max_features': 27, 'min_impurity_decrease': 0.0033010724541531968}. Best is trial 61 with value: 0.6776190476190476.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:44:09,453]\u001b[0m Trial 76 finished with value: 0.5352380952380952 and parameters: {'n_estimators': 913, 'max_depth': 11, 'max_features': 26, 'min_impurity_decrease': 0.42939915296424785}. Best is trial 61 with value: 0.6776190476190476.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:44:18,106]\u001b[0m Trial 77 finished with value: 0.5941904761904763 and parameters: {'n_estimators': 841, 'max_depth': 13, 'max_features': 27, 'min_impurity_decrease': 0.16676348958431253}. Best is trial 61 with value: 0.6776190476190476.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:44:22,894]\u001b[0m Trial 78 finished with value: 0.5352380952380952 and parameters: {'n_estimators': 457, 'max_depth': 6, 'max_features': 29, 'min_impurity_decrease': 0.7933694921818996}. Best is trial 61 with value: 0.6776190476190476.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:44:31,918]\u001b[0m Trial 79 finished with value: 0.5352380952380952 and parameters: {'n_estimators': 965, 'max_depth': 12, 'max_features': 26, 'min_impurity_decrease': 0.5862286818332793}. Best is trial 61 with value: 0.6776190476190476.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:44:40,745]\u001b[0m Trial 80 finished with value: 0.5352380952380952 and parameters: {'n_estimators': 894, 'max_depth': 10, 'max_features': 30, 'min_impurity_decrease': 0.3144294030115981}. Best is trial 61 with value: 0.6776190476190476.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:44:51,308]\u001b[0m Trial 81 finished with value: 0.6733333333333335 and parameters: {'n_estimators': 934, 'max_depth': 10, 'max_features': 28, 'min_impurity_decrease': 0.006323452295319941}. Best is trial 61 with value: 0.6776190476190476.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:45:00,829]\u001b[0m Trial 82 finished with value: 0.6165714285714285 and parameters: {'n_estimators': 927, 'max_depth': 10, 'max_features': 28, 'min_impurity_decrease': 0.14545468932474404}. Best is trial 61 with value: 0.6776190476190476.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:45:10,329]\u001b[0m Trial 83 finished with value: 0.5352380952380952 and parameters: {'n_estimators': 975, 'max_depth': 5, 'max_features': 27, 'min_impurity_decrease': 0.33087900745123566}. Best is trial 61 with value: 0.6776190476190476.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:45:19,087]\u001b[0m Trial 84 finished with value: 0.5352380952380952 and parameters: {'n_estimators': 874, 'max_depth': 10, 'max_features': 28, 'min_impurity_decrease': 2.387601930957447}. Best is trial 61 with value: 0.6776190476190476.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:45:29,929]\u001b[0m Trial 85 finished with value: 0.6748571428571429 and parameters: {'n_estimators': 952, 'max_depth': 11, 'max_features': 25, 'min_impurity_decrease': 0.0007392099609671288}. Best is trial 61 with value: 0.6776190476190476.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:45:39,247]\u001b[0m Trial 86 finished with value: 0.5352380952380952 and parameters: {'n_estimators': 947, 'max_depth': 11, 'max_features': 26, 'min_impurity_decrease': 0.48146683809049023}. Best is trial 61 with value: 0.6776190476190476.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:45:47,789]\u001b[0m Trial 87 finished with value: 0.6207619047619047 and parameters: {'n_estimators': 915, 'max_depth': 13, 'max_features': 24, 'min_impurity_decrease': 0.13757031221334323}. Best is trial 61 with value: 0.6776190476190476.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:45:58,181]\u001b[0m Trial 88 finished with value: 0.5352380952380952 and parameters: {'n_estimators': 998, 'max_depth': 12, 'max_features': 25, 'min_impurity_decrease': 0.30676748165353357}. Best is trial 61 with value: 0.6776190476190476.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:46:07,313]\u001b[0m Trial 89 finished with value: 0.5352380952380952 and parameters: {'n_estimators': 956, 'max_depth': 11, 'max_features': 27, 'min_impurity_decrease': 4.576798205075603}. Best is trial 61 with value: 0.6776190476190476.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:46:10,360]\u001b[0m Trial 90 finished with value: 0.620952380952381 and parameters: {'n_estimators': 289, 'max_depth': 12, 'max_features': 7, 'min_impurity_decrease': 0.1288307028354426}. Best is trial 61 with value: 0.6776190476190476.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:46:20,365]\u001b[0m Trial 91 finished with value: 0.6761904761904762 and parameters: {'n_estimators': 852, 'max_depth': 7, 'max_features': 29, 'min_impurity_decrease': 0.007725264887275658}. Best is trial 61 with value: 0.6776190476190476.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:46:29,221]\u001b[0m Trial 92 finished with value: 0.5295238095238095 and parameters: {'n_estimators': 889, 'max_depth': 11, 'max_features': 30, 'min_impurity_decrease': 0.2520599220602134}. Best is trial 61 with value: 0.6776190476190476.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:46:38,312]\u001b[0m Trial 93 finished with value: 0.6732380952380952 and parameters: {'n_estimators': 822, 'max_depth': 7, 'max_features': 29, 'min_impurity_decrease': 0.02259369678524981}. Best is trial 61 with value: 0.6776190476190476.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:46:42,912]\u001b[0m Trial 94 finished with value: 0.617904761904762 and parameters: {'n_estimators': 812, 'max_depth': 7, 'max_features': 29, 'min_impurity_decrease': 0.14831488771027054}. Best is trial 61 with value: 0.6776190476190476.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:46:48,995]\u001b[0m Trial 95 finished with value: 0.6761904761904762 and parameters: {'n_estimators': 940, 'max_depth': 7, 'max_features': 28, 'min_impurity_decrease': 0.005823654890190223}. Best is trial 61 with value: 0.6776190476190476.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:46:54,400]\u001b[0m Trial 96 finished with value: 0.5352380952380952 and parameters: {'n_estimators': 938, 'max_depth': 9, 'max_features': 28, 'min_impurity_decrease': 0.4235083475944678}. Best is trial 61 with value: 0.6776190476190476.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:46:59,625]\u001b[0m Trial 97 finished with value: 0.5352380952380952 and parameters: {'n_estimators': 978, 'max_depth': 10, 'max_features': 27, 'min_impurity_decrease': 0.5367328068166792}. Best is trial 61 with value: 0.6776190476190476.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:47:05,409]\u001b[0m Trial 98 finished with value: 0.6733333333333335 and parameters: {'n_estimators': 919, 'max_depth': 8, 'max_features': 30, 'min_impurity_decrease': 0.0005874942435908203}. Best is trial 61 with value: 0.6776190476190476.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:47:10,306]\u001b[0m Trial 99 finished with value: 0.5352380952380952 and parameters: {'n_estimators': 909, 'max_depth': 8, 'max_features': 30, 'min_impurity_decrease': 0.719689906318086}. Best is trial 61 with value: 0.6776190476190476.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "#Tuning hyperparameters\n",
    "#Step 1. Define an objective function to be maximized.\n",
    "def objective(trial):\n",
    "    n_estimators = trial.suggest_int(\"n_estimators\",100,1000,1) \n",
    "    max_depth = trial.suggest_int(\"max_depth\",5,20,1)\n",
    "    max_features = trial.suggest_int(\"max_features\",5,30,1)\n",
    "    min_impurity_decrease = trial.suggest_float(\"min_impurity_decrease\",0,5,log=False) \n",
    "    model = RandomForestClassifier(n_estimators = n_estimators\n",
    "              ,max_depth = max_depth\n",
    "              ,max_features = max_features\n",
    "              ,min_impurity_decrease = min_impurity_decrease\n",
    "              ,random_state=1\n",
    "              ,verbose=False\n",
    "              ,n_jobs=8)\n",
    "\n",
    "# Step 2: Scoring method:\n",
    "    score = model_selection.cross_val_score(model, X, y, n_jobs=8, scoring=\"accuracy\",cv=Cv_optuna)\n",
    "    accuracy = score.mean()\n",
    "    return accuracy\n",
    " \n",
    "# Step 3: Running it\n",
    "study = optuna.create_study(direction=\"maximize\",sampler=optuna.samplers.TPESampler(seed=0))\n",
    "study.optimize(objective, n_trials=100, show_progress_bar=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "9b88d250-7567-4062-b7d5-0a9638d732c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best parameters are : \n",
      "{'n_estimators': 879, 'max_depth': 9, 'max_features': 28, 'min_impurity_decrease': 0.008123194334826785}\n"
     ]
    }
   ],
   "source": [
    "# Getting the best parameters:\n",
    "print(f\"The best parameters are : \\n{study.best_params}\")\n",
    "# Setting the best model\n",
    "clf=RandomForestClassifier(n_estimators = study.best_params['n_estimators']\n",
    "              ,max_depth = study.best_params['max_depth']\n",
    "              ,max_features = study.best_params['max_features']\n",
    "              ,min_impurity_decrease = study.best_params['min_impurity_decrease']\n",
    "              ,random_state=0\n",
    "              ,verbose=False\n",
    "              ,n_jobs=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "a4281260-9ed3-4ed2-93c1-ed1888b7625f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mean</th>\n",
       "      <th>Se</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Accuracy_test</th>\n",
       "      <td>0.670571</td>\n",
       "      <td>0.013460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Accuracy_train</th>\n",
       "      <td>0.974643</td>\n",
       "      <td>0.001874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1 Score</th>\n",
       "      <td>0.703054</td>\n",
       "      <td>0.013994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Precision</th>\n",
       "      <td>0.681364</td>\n",
       "      <td>0.014131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recall</th>\n",
       "      <td>0.749643</td>\n",
       "      <td>0.022551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Roc_auc</th>\n",
       "      <td>0.752985</td>\n",
       "      <td>0.015938</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Mean        Se\n",
       "Accuracy_test   0.670571  0.013460\n",
       "Accuracy_train  0.974643  0.001874\n",
       "F1 Score        0.703054  0.013994\n",
       "Precision       0.681364  0.014131\n",
       "Recall          0.749643  0.022551\n",
       "Roc_auc         0.752985  0.015938"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Model2\n",
    "Model2=Model_results(clf,X,y,Cv_model)\n",
    "Model2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "c06b82a5-a8ce-4b80-b011-d93c0ab3a6cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th>Method</th>\n",
       "      <th colspan=\"4\" halign=\"left\">RF</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model</th>\n",
       "      <th colspan=\"2\" halign=\"left\">Model 1</th>\n",
       "      <th colspan=\"2\" halign=\"left\">Model 2</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Values</th>\n",
       "      <th>Mean</th>\n",
       "      <th>Se</th>\n",
       "      <th>Mean</th>\n",
       "      <th>Se</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Accuracy_test</th>\n",
       "      <td>0.676381</td>\n",
       "      <td>0.014691</td>\n",
       "      <td>0.670571</td>\n",
       "      <td>0.013460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Accuracy_train</th>\n",
       "      <td>0.978164</td>\n",
       "      <td>0.001539</td>\n",
       "      <td>0.974643</td>\n",
       "      <td>0.001874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1 Score</th>\n",
       "      <td>0.711877</td>\n",
       "      <td>0.013423</td>\n",
       "      <td>0.703054</td>\n",
       "      <td>0.013994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Precision</th>\n",
       "      <td>0.688878</td>\n",
       "      <td>0.014746</td>\n",
       "      <td>0.681364</td>\n",
       "      <td>0.014131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recall</th>\n",
       "      <td>0.757857</td>\n",
       "      <td>0.020561</td>\n",
       "      <td>0.749643</td>\n",
       "      <td>0.022551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Roc_auc</th>\n",
       "      <td>0.756424</td>\n",
       "      <td>0.017012</td>\n",
       "      <td>0.752985</td>\n",
       "      <td>0.015938</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Method                RF                              \n",
       "Model            Model 1             Model 2          \n",
       "Values              Mean        Se      Mean        Se\n",
       "Accuracy_test   0.676381  0.014691  0.670571  0.013460\n",
       "Accuracy_train  0.978164  0.001539  0.974643  0.001874\n",
       "F1 Score        0.711877  0.013423  0.703054  0.013994\n",
       "Precision       0.688878  0.014746  0.681364  0.014131\n",
       "Recall          0.757857  0.020561  0.749643  0.022551\n",
       "Roc_auc         0.756424  0.017012  0.752985  0.015938"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Saving the data of model performance\n",
    "Model_data=pd.concat([Model1,Model2],axis=1)\n",
    "Model_data.columns = [['RF']*4,['Model 1','Model 1', 'Model 2','Model 2'], ['Mean', 'Se', 'Mean', 'Se']]  \n",
    "Model_data.columns.names=['Method','Model','Values']\n",
    "Model_data.to_csv(\"./Results/RF_model_mlrem_data.csv\",sep=',')\n",
    "Model_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de27d5ec-8039-4cfd-8629-ad30d87ca90f",
   "metadata": {},
   "source": [
    "## 2.4 XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "19aa8297-4182-4dac-8857-008a9ad45f1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf=xgb.XGBClassifier(random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "66336653-640b-407f-8c25-80c9e29b3651",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mean</th>\n",
       "      <th>Se</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Accuracy_test</th>\n",
       "      <td>0.662476</td>\n",
       "      <td>0.016918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Accuracy_train</th>\n",
       "      <td>0.978164</td>\n",
       "      <td>0.001539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1 Score</th>\n",
       "      <td>0.693483</td>\n",
       "      <td>0.017356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Precision</th>\n",
       "      <td>0.671509</td>\n",
       "      <td>0.015551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recall</th>\n",
       "      <td>0.737143</td>\n",
       "      <td>0.025112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Roc_auc</th>\n",
       "      <td>0.749660</td>\n",
       "      <td>0.017686</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Mean        Se\n",
       "Accuracy_test   0.662476  0.016918\n",
       "Accuracy_train  0.978164  0.001539\n",
       "F1 Score        0.693483  0.017356\n",
       "Precision       0.671509  0.015551\n",
       "Recall          0.737143  0.025112\n",
       "Roc_auc         0.749660  0.017686"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Model1 \n",
    "Model1_clf=clf\n",
    "#Model1\n",
    "Model1=Model_results(Model1_clf,X,y,Cv_model)\n",
    "Model1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "2184b863-0c03-4641-8e98-2b00c0fd5878",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2024-01-12 01:49:39,219]\u001b[0m A new study created in memory with name: no-name-9bfd5a88-8b2a-4996-844c-9f159bf96100\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-01-12 01:49:44,945]\u001b[0m Trial 0 finished with value: 0.6608571428571429 and parameters: {'lambda': 0.15676677195506075, 'alpha': 0.7257005721594281, 'colsample_bytree': 0.7, 'subsample': 0.7000000000000001, 'learning_rate': 0.0801, 'n_estimators': 664}. Best is trial 0 with value: 0.6608571428571429.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-01-12 01:49:47,925]\u001b[0m Trial 1 finished with value: 0.6323809523809524 and parameters: {'lambda': 0.0562793204741517, 'alpha': 3.6905577292137624, 'colsample_bytree': 1.0, 'subsample': 0.6000000000000001, 'learning_rate': 0.1551, 'n_estimators': 552}. Best is trial 0 with value: 0.6608571428571429.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-01-12 01:49:51,796]\u001b[0m Trial 2 finished with value: 0.5408571428571428 and parameters: {'lambda': 0.18714500686240676, 'alpha': 5.039489598671215, 'colsample_bytree': 0.3, 'subsample': 0.4, 'learning_rate': 0.0001, 'n_estimators': 841}. Best is trial 0 with value: 0.6608571428571429.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-01-12 01:49:56,159]\u001b[0m Trial 3 finished with value: 0.6392380952380953 and parameters: {'lambda': 1.2960656597279736, 'alpha': 3.0202896401586674, 'colsample_bytree': 1.0, 'subsample': 0.9, 'learning_rate': 0.0901, 'n_estimators': 792}. Best is trial 0 with value: 0.6608571428571429.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-01-12 01:49:59,349]\u001b[0m Trial 4 finished with value: 0.6553333333333334 and parameters: {'lambda': 0.0029723346443356552, 'alpha': 0.3628140404024381, 'colsample_bytree': 0.4, 'subsample': 1.0, 'learning_rate': 0.10010000000000001, 'n_estimators': 444}. Best is trial 0 with value: 0.6608571428571429.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-01-12 01:50:06,638]\u001b[0m Trial 5 finished with value: 0.638 and parameters: {'lambda': 0.011434638743472197, 'alpha': 1.2500712230836255, 'colsample_bytree': 0.6000000000000001, 'subsample': 0.7000000000000001, 'learning_rate': 0.0001, 'n_estimators': 637}. Best is trial 0 with value: 0.6608571428571429.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-01-12 01:50:10,699]\u001b[0m Trial 6 finished with value: 0.6510476190476191 and parameters: {'lambda': 0.2807908107885728, 'alpha': 0.2935864364395359, 'colsample_bytree': 1.0, 'subsample': 0.8, 'learning_rate': 0.07010000000000001, 'n_estimators': 465}. Best is trial 0 with value: 0.6608571428571429.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-01-12 01:50:12,762]\u001b[0m Trial 7 finished with value: 0.6508571428571429 and parameters: {'lambda': 0.6173405204074314, 'alpha': 0.0017414134181586202, 'colsample_bytree': 0.8, 'subsample': 0.8, 'learning_rate': 0.040100000000000004, 'n_estimators': 172}. Best is trial 0 with value: 0.6608571428571429.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-01-12 01:50:13,989]\u001b[0m Trial 8 finished with value: 0.6779047619047618 and parameters: {'lambda': 0.01826894228153233, 'alpha': 0.028499883436971588, 'colsample_bytree': 0.7, 'subsample': 0.7000000000000001, 'learning_rate': 0.1951, 'n_estimators': 147}. Best is trial 8 with value: 0.6779047619047618.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-01-12 01:50:16,120]\u001b[0m Trial 9 finished with value: 0.667904761904762 and parameters: {'lambda': 0.006847105576684045, 'alpha': 0.004418125737902547, 'colsample_bytree': 0.8, 'subsample': 0.5, 'learning_rate': 0.0901, 'n_estimators': 282}. Best is trial 8 with value: 0.6779047619047618.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-01-12 01:50:16,755]\u001b[0m Trial 10 finished with value: 0.6451428571428572 and parameters: {'lambda': 5.790132527437195, 'alpha': 0.025043968115100592, 'colsample_bytree': 0.5, 'subsample': 0.5, 'learning_rate': 0.1901, 'n_estimators': 57}. Best is trial 8 with value: 0.6779047619047618.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-01-12 01:50:18,686]\u001b[0m Trial 11 finished with value: 0.6690476190476192 and parameters: {'lambda': 0.017123553109627314, 'alpha': 0.013676263870483537, 'colsample_bytree': 0.8, 'subsample': 0.5, 'learning_rate': 0.14509999999999998, 'n_estimators': 277}. Best is trial 8 with value: 0.6779047619047618.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-01-12 01:50:20,734]\u001b[0m Trial 12 finished with value: 0.6763809523809523 and parameters: {'lambda': 0.02491353701899208, 'alpha': 0.023063141329483616, 'colsample_bytree': 0.8, 'subsample': 0.4, 'learning_rate': 0.15009999999999998, 'n_estimators': 319}. Best is trial 8 with value: 0.6779047619047618.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-01-12 01:50:22,688]\u001b[0m Trial 13 finished with value: 0.662 and parameters: {'lambda': 0.04474111800996658, 'alpha': 0.038990832725213885, 'colsample_bytree': 0.6000000000000001, 'subsample': 0.4, 'learning_rate': 0.1951, 'n_estimators': 316}. Best is trial 8 with value: 0.6779047619047618.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-01-12 01:50:23,622]\u001b[0m Trial 14 finished with value: 0.6509523809523808 and parameters: {'lambda': 0.0012140452982167488, 'alpha': 0.06910620324453418, 'colsample_bytree': 0.7, 'subsample': 0.6000000000000001, 'learning_rate': 0.1551, 'n_estimators': 94}. Best is trial 8 with value: 0.6779047619047618.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-01-12 01:50:25,465]\u001b[0m Trial 15 finished with value: 0.6680000000000001 and parameters: {'lambda': 0.027126643489253296, 'alpha': 0.0045017087887461935, 'colsample_bytree': 0.9000000000000001, 'subsample': 1.0, 'learning_rate': 0.1301, 'n_estimators': 204}. Best is trial 8 with value: 0.6779047619047618.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-01-12 01:50:27,896]\u001b[0m Trial 16 finished with value: 0.6703809523809525 and parameters: {'lambda': 0.004818440651909064, 'alpha': 0.16888877355169551, 'colsample_bytree': 0.5, 'subsample': 0.6000000000000001, 'learning_rate': 0.1751, 'n_estimators': 358}. Best is trial 8 with value: 0.6779047619047618.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-01-12 01:50:29,534]\u001b[0m Trial 17 finished with value: 0.6649523809523811 and parameters: {'lambda': 0.0010007385532741818, 'alpha': 0.009646273191219181, 'colsample_bytree': 0.9000000000000001, 'subsample': 0.8, 'learning_rate': 0.1201, 'n_estimators': 181}. Best is trial 8 with value: 0.6779047619047618.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-01-12 01:50:31,793]\u001b[0m Trial 18 finished with value: 0.6763809523809524 and parameters: {'lambda': 0.061634227943790754, 'alpha': 0.07305295568841107, 'colsample_bytree': 0.7, 'subsample': 0.4, 'learning_rate': 0.1701, 'n_estimators': 367}. Best is trial 8 with value: 0.6779047619047618.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-01-12 01:50:36,908]\u001b[0m Trial 19 finished with value: 0.6748571428571429 and parameters: {'lambda': 0.08189216606299816, 'alpha': 0.09137793328553549, 'colsample_bytree': 0.5, 'subsample': 0.6000000000000001, 'learning_rate': 0.1751, 'n_estimators': 930}. Best is trial 8 with value: 0.6779047619047618.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-01-12 01:50:40,298]\u001b[0m Trial 20 finished with value: 0.6764761904761906 and parameters: {'lambda': 1.6767154928982846, 'alpha': 0.0016483661900255071, 'colsample_bytree': 0.7, 'subsample': 0.9, 'learning_rate': 0.1751, 'n_estimators': 429}. Best is trial 8 with value: 0.6779047619047618.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-01-12 01:50:44,316]\u001b[0m Trial 21 finished with value: 0.6525714285714286 and parameters: {'lambda': 7.401604059812908, 'alpha': 0.0010968075467978052, 'colsample_bytree': 0.7, 'subsample': 0.9, 'learning_rate': 0.18009999999999998, 'n_estimators': 421}. Best is trial 8 with value: 0.6779047619047618.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-01-12 01:50:48,618]\u001b[0m Trial 22 finished with value: 0.6694285714285715 and parameters: {'lambda': 2.0928422583512405, 'alpha': 0.0036652235601470915, 'colsample_bytree': 0.6000000000000001, 'subsample': 0.9, 'learning_rate': 0.1701, 'n_estimators': 558}. Best is trial 8 with value: 0.6779047619047618.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-01-12 01:50:51,373]\u001b[0m Trial 23 finished with value: 0.6751428571428572 and parameters: {'lambda': 0.6439279076937869, 'alpha': 0.04386602055339343, 'colsample_bytree': 0.7, 'subsample': 0.7000000000000001, 'learning_rate': 0.1951, 'n_estimators': 391}. Best is trial 8 with value: 0.6779047619047618.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-01-12 01:50:54,900]\u001b[0m Trial 24 finished with value: 0.6764761904761905 and parameters: {'lambda': 0.3883136303907193, 'alpha': 0.010049953917114773, 'colsample_bytree': 0.6000000000000001, 'subsample': 0.8, 'learning_rate': 0.1301, 'n_estimators': 496}. Best is trial 8 with value: 0.6779047619047618.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-01-12 01:50:59,980]\u001b[0m Trial 25 finished with value: 0.6653333333333333 and parameters: {'lambda': 2.7802503139996473, 'alpha': 0.008337657822509066, 'colsample_bytree': 0.6000000000000001, 'subsample': 0.8, 'learning_rate': 0.1301, 'n_estimators': 656}. Best is trial 8 with value: 0.6779047619047618.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-01-12 01:51:05,250]\u001b[0m Trial 26 finished with value: 0.6790476190476192 and parameters: {'lambda': 0.5989769734564016, 'alpha': 0.001754204354028918, 'colsample_bytree': 0.4, 'subsample': 0.9, 'learning_rate': 0.11510000000000001, 'n_estimators': 725}. Best is trial 26 with value: 0.6790476190476192.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-01-12 01:51:12,244]\u001b[0m Trial 27 finished with value: 0.6693333333333336 and parameters: {'lambda': 1.2518838419016274, 'alpha': 0.002084110757581769, 'colsample_bytree': 0.4, 'subsample': 0.9, 'learning_rate': 0.0451, 'n_estimators': 779}. Best is trial 26 with value: 0.6790476190476192.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-01-12 01:51:21,465]\u001b[0m Trial 28 finished with value: 0.6609523809523811 and parameters: {'lambda': 4.723187635059192, 'alpha': 0.002467585771750723, 'colsample_bytree': 0.3, 'subsample': 1.0, 'learning_rate': 0.050100000000000006, 'n_estimators': 916}. Best is trial 26 with value: 0.6790476190476192.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-01-12 01:51:26,158]\u001b[0m Trial 29 finished with value: 0.6861904761904764 and parameters: {'lambda': 0.1357530766063751, 'alpha': 0.00604912334356112, 'colsample_bytree': 0.4, 'subsample': 0.7000000000000001, 'learning_rate': 0.11510000000000001, 'n_estimators': 740}. Best is trial 29 with value: 0.6861904761904764.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-01-12 01:51:30,752]\u001b[0m Trial 30 finished with value: 0.6750476190476192 and parameters: {'lambda': 0.18092199214591256, 'alpha': 0.0010057216538091605, 'colsample_bytree': 0.4, 'subsample': 0.7000000000000001, 'learning_rate': 0.1101, 'n_estimators': 709}. Best is trial 29 with value: 0.6861904761904764.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-01-12 01:51:35,311]\u001b[0m Trial 31 finished with value: 0.6751428571428572 and parameters: {'lambda': 0.11119277519798368, 'alpha': 0.006118149756823851, 'colsample_bytree': 0.5, 'subsample': 0.7000000000000001, 'learning_rate': 0.11510000000000001, 'n_estimators': 723}. Best is trial 29 with value: 0.6861904761904764.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-01-12 01:51:40,257]\u001b[0m Trial 32 finished with value: 0.6821904761904765 and parameters: {'lambda': 0.6301118583785598, 'alpha': 0.01900920382279658, 'colsample_bytree': 0.4, 'subsample': 0.9, 'learning_rate': 0.0651, 'n_estimators': 591}. Best is trial 29 with value: 0.6861904761904764.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-01-12 01:51:45,058]\u001b[0m Trial 33 finished with value: 0.6763809523809524 and parameters: {'lambda': 0.6999320996994477, 'alpha': 0.016156842125445648, 'colsample_bytree': 0.3, 'subsample': 0.7000000000000001, 'learning_rate': 0.0601, 'n_estimators': 588}. Best is trial 29 with value: 0.6861904761904764.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-01-12 01:51:52,041]\u001b[0m Trial 34 finished with value: 0.674952380952381 and parameters: {'lambda': 0.3527627967271589, 'alpha': 0.030241715405447074, 'colsample_bytree': 0.4, 'subsample': 0.8, 'learning_rate': 0.0751, 'n_estimators': 991}. Best is trial 29 with value: 0.6861904761904764.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-01-12 01:51:59,408]\u001b[0m Trial 35 finished with value: 0.6609523809523811 and parameters: {'lambda': 0.14364941444825624, 'alpha': 0.017627889213148507, 'colsample_bytree': 0.3, 'subsample': 0.6000000000000001, 'learning_rate': 0.0201, 'n_estimators': 836}. Best is trial 29 with value: 0.6861904761904764.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-01-12 01:52:04,321]\u001b[0m Trial 36 finished with value: 0.6680000000000001 and parameters: {'lambda': 1.0360787933743876, 'alpha': 0.006610100039382611, 'colsample_bytree': 0.4, 'subsample': 1.0, 'learning_rate': 0.10010000000000001, 'n_estimators': 590}. Best is trial 29 with value: 0.6861904761904764.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-01-12 01:52:07,614]\u001b[0m Trial 37 finished with value: 0.5927619047619048 and parameters: {'lambda': 0.24008342239429287, 'alpha': 8.861629685772453, 'colsample_bytree': 0.5, 'subsample': 0.7000000000000001, 'learning_rate': 0.08510000000000001, 'n_estimators': 730}. Best is trial 29 with value: 0.6861904761904764.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-01-12 01:52:14,227]\u001b[0m Trial 38 finished with value: 0.6707619047619049 and parameters: {'lambda': 0.037769804089962805, 'alpha': 0.17532934883981124, 'colsample_bytree': 0.4, 'subsample': 0.9, 'learning_rate': 0.0201, 'n_estimators': 622}. Best is trial 29 with value: 0.6861904761904764.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-01-12 01:52:17,939]\u001b[0m Trial 39 finished with value: 0.677904761904762 and parameters: {'lambda': 0.08654988469845346, 'alpha': 0.0033305961239733462, 'colsample_bytree': 0.3, 'subsample': 0.8, 'learning_rate': 0.1401, 'n_estimators': 535}. Best is trial 29 with value: 0.6861904761904764.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-01-12 01:52:22,157]\u001b[0m Trial 40 finished with value: 0.667904761904762 and parameters: {'lambda': 0.4364559577785702, 'alpha': 0.002986127875870649, 'colsample_bytree': 0.3, 'subsample': 0.8, 'learning_rate': 0.1051, 'n_estimators': 529}. Best is trial 29 with value: 0.6861904761904764.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-01-12 01:52:26,780]\u001b[0m Trial 41 finished with value: 0.6820952380952382 and parameters: {'lambda': 0.012041246302698917, 'alpha': 0.005755556753698326, 'colsample_bytree': 0.3, 'subsample': 0.9, 'learning_rate': 0.1401, 'n_estimators': 679}. Best is trial 29 with value: 0.6861904761904764.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-01-12 01:52:30,094]\u001b[0m Trial 42 finished with value: 0.6821904761904761 and parameters: {'lambda': 0.00976530253589791, 'alpha': 0.004521658633426094, 'colsample_bytree': 0.3, 'subsample': 0.9, 'learning_rate': 0.1401, 'n_estimators': 692}. Best is trial 29 with value: 0.6861904761904764.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-01-12 01:52:31,968]\u001b[0m Trial 43 finished with value: 0.6820952380952382 and parameters: {'lambda': 0.009533938648370993, 'alpha': 0.005142380479852608, 'colsample_bytree': 0.4, 'subsample': 0.9, 'learning_rate': 0.1201, 'n_estimators': 779}. Best is trial 29 with value: 0.6861904761904764.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-01-12 01:52:34,015]\u001b[0m Trial 44 finished with value: 0.701714285714286 and parameters: {'lambda': 0.008556178294461857, 'alpha': 0.00559859295117001, 'colsample_bytree': 0.3, 'subsample': 1.0, 'learning_rate': 0.1601, 'n_estimators': 792}. Best is trial 44 with value: 0.701714285714286.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-01-12 01:52:35,874]\u001b[0m Trial 45 finished with value: 0.7003809523809525 and parameters: {'lambda': 0.002736395942107596, 'alpha': 0.010967284413723879, 'colsample_bytree': 0.3, 'subsample': 1.0, 'learning_rate': 0.1601, 'n_estimators': 687}. Best is trial 44 with value: 0.701714285714286.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-01-12 01:52:38,163]\u001b[0m Trial 46 finished with value: 0.6960952380952382 and parameters: {'lambda': 0.0028166231869091456, 'alpha': 0.009994188044722196, 'colsample_bytree': 0.3, 'subsample': 1.0, 'learning_rate': 0.1651, 'n_estimators': 830}. Best is trial 44 with value: 0.701714285714286.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-01-12 01:52:40,457]\u001b[0m Trial 47 finished with value: 0.6947619047619049 and parameters: {'lambda': 0.0019027548784550043, 'alpha': 0.012393652417147363, 'colsample_bytree': 0.3, 'subsample': 1.0, 'learning_rate': 0.0651, 'n_estimators': 836}. Best is trial 44 with value: 0.701714285714286.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-01-12 01:52:42,704]\u001b[0m Trial 48 finished with value: 0.6960952380952381 and parameters: {'lambda': 0.0024183815673537484, 'alpha': 0.011729643522042612, 'colsample_bytree': 0.3, 'subsample': 1.0, 'learning_rate': 0.1851, 'n_estimators': 846}. Best is trial 44 with value: 0.701714285714286.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-01-12 01:52:44,291]\u001b[0m Trial 49 finished with value: 0.6551428571428572 and parameters: {'lambda': 0.0019408046467350051, 'alpha': 1.0433113847404174, 'colsample_bytree': 0.3, 'subsample': 1.0, 'learning_rate': 0.1851, 'n_estimators': 854}. Best is trial 44 with value: 0.701714285714286.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-01-12 01:52:46,542]\u001b[0m Trial 50 finished with value: 0.7002857142857144 and parameters: {'lambda': 0.0033591891295767654, 'alpha': 0.01382541664678391, 'colsample_bytree': 0.3, 'subsample': 1.0, 'learning_rate': 0.1601, 'n_estimators': 874}. Best is trial 44 with value: 0.701714285714286.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-01-12 01:52:48,705]\u001b[0m Trial 51 finished with value: 0.7017142857142857 and parameters: {'lambda': 0.0034229051056133657, 'alpha': 0.012871271791450633, 'colsample_bytree': 0.3, 'subsample': 1.0, 'learning_rate': 0.1601, 'n_estimators': 866}. Best is trial 44 with value: 0.701714285714286.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-01-12 01:52:51,053]\u001b[0m Trial 52 finished with value: 0.7001904761904763 and parameters: {'lambda': 0.004225220871455537, 'alpha': 0.011370294688030805, 'colsample_bytree': 0.3, 'subsample': 1.0, 'learning_rate': 0.1601, 'n_estimators': 890}. Best is trial 44 with value: 0.701714285714286.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-01-12 01:52:53,527]\u001b[0m Trial 53 finished with value: 0.6960000000000002 and parameters: {'lambda': 0.004103597114144333, 'alpha': 0.04967022533268807, 'colsample_bytree': 0.3, 'subsample': 1.0, 'learning_rate': 0.1601, 'n_estimators': 920}. Best is trial 44 with value: 0.701714285714286.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-01-12 01:52:55,907]\u001b[0m Trial 54 finished with value: 0.7031428571428572 and parameters: {'lambda': 0.004043834319918063, 'alpha': 0.029633425764158693, 'colsample_bytree': 0.3, 'subsample': 1.0, 'learning_rate': 0.1601, 'n_estimators': 894}. Best is trial 54 with value: 0.7031428571428572.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-01-12 01:52:58,610]\u001b[0m Trial 55 finished with value: 0.6975238095238098 and parameters: {'lambda': 0.004980224075064425, 'alpha': 0.03510787695470061, 'colsample_bytree': 0.3, 'subsample': 1.0, 'learning_rate': 0.1551, 'n_estimators': 995}. Best is trial 54 with value: 0.7031428571428572.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-01-12 01:53:00,935]\u001b[0m Trial 56 finished with value: 0.7102857142857144 and parameters: {'lambda': 0.0013221304985698086, 'alpha': 0.02305461805888264, 'colsample_bytree': 0.3, 'subsample': 1.0, 'learning_rate': 0.15009999999999998, 'n_estimators': 884}. Best is trial 56 with value: 0.7102857142857144.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-01-12 01:53:03,490]\u001b[0m Trial 57 finished with value: 0.6793333333333333 and parameters: {'lambda': 0.0012446922418356734, 'alpha': 0.022077479688830965, 'colsample_bytree': 0.4, 'subsample': 1.0, 'learning_rate': 0.15009999999999998, 'n_estimators': 962}. Best is trial 56 with value: 0.7102857142857144.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-01-12 01:53:05,883]\u001b[0m Trial 58 finished with value: 0.6791428571428573 and parameters: {'lambda': 0.006622004577595627, 'alpha': 0.1431496104944084, 'colsample_bytree': 0.3, 'subsample': 1.0, 'learning_rate': 0.1651, 'n_estimators': 885}. Best is trial 56 with value: 0.7102857142857144.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-01-12 01:53:08,000]\u001b[0m Trial 59 finished with value: 0.6751428571428572 and parameters: {'lambda': 0.0014168536815106854, 'alpha': 0.02621704841078774, 'colsample_bytree': 0.5, 'subsample': 1.0, 'learning_rate': 0.15009999999999998, 'n_estimators': 803}. Best is trial 56 with value: 0.7102857142857144.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-01-12 01:53:10,527]\u001b[0m Trial 60 finished with value: 0.677904761904762 and parameters: {'lambda': 0.003453061915516729, 'alpha': 0.06591221885128822, 'colsample_bytree': 0.4, 'subsample': 1.0, 'learning_rate': 0.1701, 'n_estimators': 955}. Best is trial 56 with value: 0.7102857142857144.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-01-12 01:53:12,750]\u001b[0m Trial 61 finished with value: 0.6932380952380953 and parameters: {'lambda': 0.006241233717411143, 'alpha': 0.008377211507259008, 'colsample_bytree': 0.3, 'subsample': 1.0, 'learning_rate': 0.1601, 'n_estimators': 885}. Best is trial 56 with value: 0.7102857142857144.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-01-12 01:53:15,123]\u001b[0m Trial 62 finished with value: 0.7001904761904763 and parameters: {'lambda': 0.00199673319822298, 'alpha': 0.01284143905578283, 'colsample_bytree': 0.3, 'subsample': 1.0, 'learning_rate': 0.1601, 'n_estimators': 875}. Best is trial 56 with value: 0.7102857142857144.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-01-12 01:53:17,298]\u001b[0m Trial 63 finished with value: 0.6935238095238097 and parameters: {'lambda': 0.0018104838952691495, 'alpha': 0.014581416070468362, 'colsample_bytree': 0.3, 'subsample': 1.0, 'learning_rate': 0.18009999999999998, 'n_estimators': 804}. Best is trial 56 with value: 0.7102857142857144.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-01-12 01:53:19,428]\u001b[0m Trial 64 finished with value: 0.7004761904761907 and parameters: {'lambda': 0.0024756254478756406, 'alpha': 0.052568127938742146, 'colsample_bytree': 0.3, 'subsample': 1.0, 'learning_rate': 0.14509999999999998, 'n_estimators': 764}. Best is trial 56 with value: 0.7102857142857144.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-01-12 01:53:21,329]\u001b[0m Trial 65 finished with value: 0.6792380952380952 and parameters: {'lambda': 0.0028689485895962183, 'alpha': 0.04629073394230276, 'colsample_bytree': 0.9000000000000001, 'subsample': 0.9, 'learning_rate': 0.1351, 'n_estimators': 765}. Best is trial 56 with value: 0.7102857142857144.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-01-12 01:53:22,970]\u001b[0m Trial 66 finished with value: 0.6595238095238096 and parameters: {'lambda': 0.001014578900194637, 'alpha': 0.36043897298369987, 'colsample_bytree': 0.4, 'subsample': 1.0, 'learning_rate': 0.14509999999999998, 'n_estimators': 761}. Best is trial 56 with value: 0.7102857142857144.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-01-12 01:53:25,064]\u001b[0m Trial 67 finished with value: 0.6751428571428572 and parameters: {'lambda': 0.01737522874540943, 'alpha': 0.05780931059819181, 'colsample_bytree': 1.0, 'subsample': 0.9, 'learning_rate': 0.15009999999999998, 'n_estimators': 815}. Best is trial 56 with value: 0.7102857142857144.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-01-12 01:53:27,445]\u001b[0m Trial 68 finished with value: 0.6863809523809524 and parameters: {'lambda': 0.0015222664201042758, 'alpha': 0.11020953113272494, 'colsample_bytree': 0.3, 'subsample': 1.0, 'learning_rate': 0.1301, 'n_estimators': 936}. Best is trial 56 with value: 0.7102857142857144.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-01-12 01:53:29,694]\u001b[0m Trial 69 finished with value: 0.6778095238095238 and parameters: {'lambda': 0.003426341240967464, 'alpha': 0.03256146187092011, 'colsample_bytree': 0.4, 'subsample': 1.0, 'learning_rate': 0.1751, 'n_estimators': 866}. Best is trial 56 with value: 0.7102857142857144.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-01-12 01:53:31,832]\u001b[0m Trial 70 finished with value: 0.6820952380952382 and parameters: {'lambda': 0.005384501751833538, 'alpha': 0.022922639033061288, 'colsample_bytree': 0.4, 'subsample': 0.9, 'learning_rate': 0.14509999999999998, 'n_estimators': 905}. Best is trial 56 with value: 0.7102857142857144.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-01-12 01:53:34,361]\u001b[0m Trial 71 finished with value: 0.6932380952380954 and parameters: {'lambda': 0.0038325905699101567, 'alpha': 0.02051598231771764, 'colsample_bytree': 0.3, 'subsample': 1.0, 'learning_rate': 0.1651, 'n_estimators': 965}. Best is trial 56 with value: 0.7102857142857144.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-01-12 01:53:36,703]\u001b[0m Trial 72 finished with value: 0.7002857142857144 and parameters: {'lambda': 0.0024577069483295065, 'alpha': 0.007109582478627625, 'colsample_bytree': 0.3, 'subsample': 1.0, 'learning_rate': 0.1551, 'n_estimators': 896}. Best is trial 56 with value: 0.7102857142857144.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-01-12 01:53:38,713]\u001b[0m Trial 73 finished with value: 0.6973333333333335 and parameters: {'lambda': 0.0024282570038449054, 'alpha': 0.08294927790166803, 'colsample_bytree': 0.3, 'subsample': 1.0, 'learning_rate': 0.1551, 'n_estimators': 752}. Best is trial 56 with value: 0.7102857142857144.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-01-12 01:53:40,765]\u001b[0m Trial 74 finished with value: 0.6973333333333335 and parameters: {'lambda': 0.008296731719590096, 'alpha': 0.0073542298983549645, 'colsample_bytree': 0.3, 'subsample': 1.0, 'learning_rate': 0.1701, 'n_estimators': 787}. Best is trial 56 with value: 0.7102857142857144.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-01-12 01:53:42,888]\u001b[0m Trial 75 finished with value: 0.678952380952381 and parameters: {'lambda': 0.013459544298683093, 'alpha': 0.01606555197132388, 'colsample_bytree': 0.3, 'subsample': 0.5, 'learning_rate': 0.1251, 'n_estimators': 938}. Best is trial 56 with value: 0.7102857142857144.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-01-12 01:53:45,243]\u001b[0m Trial 76 finished with value: 0.6835238095238096 and parameters: {'lambda': 0.002432929541319386, 'alpha': 0.03867844669314933, 'colsample_bytree': 0.4, 'subsample': 1.0, 'learning_rate': 0.1551, 'n_estimators': 905}. Best is trial 56 with value: 0.7102857142857144.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-01-12 01:53:46,786]\u001b[0m Trial 77 finished with value: 0.6908571428571428 and parameters: {'lambda': 0.0014775448337385007, 'alpha': 0.008379965030471833, 'colsample_bytree': 0.3, 'subsample': 0.9, 'learning_rate': 0.1901, 'n_estimators': 647}. Best is trial 56 with value: 0.7102857142857144.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-01-12 01:53:48,713]\u001b[0m Trial 78 finished with value: 0.6807619047619049 and parameters: {'lambda': 0.006701372418938602, 'alpha': 0.004045620666985065, 'colsample_bytree': 0.4, 'subsample': 0.9, 'learning_rate': 0.14509999999999998, 'n_estimators': 820}. Best is trial 56 with value: 0.7102857142857144.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-01-12 01:53:50,849]\u001b[0m Trial 79 finished with value: 0.6876190476190479 and parameters: {'lambda': 0.003127746609011728, 'alpha': 0.025715495289677936, 'colsample_bytree': 0.3, 'subsample': 1.0, 'learning_rate': 0.18009999999999998, 'n_estimators': 858}. Best is trial 56 with value: 0.7102857142857144.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-01-12 01:53:52,896]\u001b[0m Trial 80 finished with value: 0.6960952380952383 and parameters: {'lambda': 0.0011720575701298413, 'alpha': 0.016807260672059614, 'colsample_bytree': 0.3, 'subsample': 1.0, 'learning_rate': 0.1651, 'n_estimators': 797}. Best is trial 56 with value: 0.7102857142857144.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-01-12 01:53:55,044]\u001b[0m Trial 81 finished with value: 0.7044761904761907 and parameters: {'lambda': 0.0020203854446397642, 'alpha': 0.013357193776383159, 'colsample_bytree': 0.3, 'subsample': 1.0, 'learning_rate': 0.1601, 'n_estimators': 877}. Best is trial 56 with value: 0.7102857142857144.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-01-12 01:53:57,400]\u001b[0m Trial 82 finished with value: 0.698857142857143 and parameters: {'lambda': 0.005019268124724571, 'alpha': 0.009246692653937827, 'colsample_bytree': 0.3, 'subsample': 1.0, 'learning_rate': 0.1701, 'n_estimators': 903}. Best is trial 56 with value: 0.7102857142857144.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-01-12 01:53:59,710]\u001b[0m Trial 83 finished with value: 0.6962857142857143 and parameters: {'lambda': 0.002471192899337615, 'alpha': 0.014195787739054177, 'colsample_bytree': 0.3, 'subsample': 1.0, 'learning_rate': 0.1351, 'n_estimators': 863}. Best is trial 56 with value: 0.7102857142857144.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-01-12 01:54:01,031]\u001b[0m Trial 84 finished with value: 0.6265714285714286 and parameters: {'lambda': 0.0020518609785551635, 'alpha': 2.3474089145676693, 'colsample_bytree': 0.3, 'subsample': 1.0, 'learning_rate': 0.1551, 'n_estimators': 709}. Best is trial 56 with value: 0.7102857142857144.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-01-12 01:54:03,502]\u001b[0m Trial 85 finished with value: 0.6877142857142857 and parameters: {'lambda': 0.0016715687766010845, 'alpha': 0.007252154293450322, 'colsample_bytree': 0.4, 'subsample': 1.0, 'learning_rate': 0.1401, 'n_estimators': 973}. Best is trial 56 with value: 0.7102857142857144.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-01-12 01:54:05,680]\u001b[0m Trial 86 finished with value: 0.6807619047619048 and parameters: {'lambda': 0.004042017054172613, 'alpha': 0.019549267963618795, 'colsample_bytree': 0.3, 'subsample': 0.9, 'learning_rate': 0.15009999999999998, 'n_estimators': 938}. Best is trial 56 with value: 0.7102857142857144.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-01-12 01:54:07,852]\u001b[0m Trial 87 finished with value: 0.7031428571428572 and parameters: {'lambda': 0.023473634497896897, 'alpha': 0.005636601005747783, 'colsample_bytree': 0.3, 'subsample': 1.0, 'learning_rate': 0.1601, 'n_estimators': 848}. Best is trial 56 with value: 0.7102857142857144.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-01-12 01:54:10,073]\u001b[0m Trial 88 finished with value: 0.6862857142857144 and parameters: {'lambda': 0.03357853084274716, 'alpha': 0.004764047018815245, 'colsample_bytree': 0.4, 'subsample': 1.0, 'learning_rate': 0.1751, 'n_estimators': 843}. Best is trial 56 with value: 0.7102857142857144.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-01-12 01:54:12,340]\u001b[0m Trial 89 finished with value: 0.7031428571428572 and parameters: {'lambda': 0.00851847070190272, 'alpha': 0.010913691529586302, 'colsample_bytree': 0.3, 'subsample': 1.0, 'learning_rate': 0.1651, 'n_estimators': 816}. Best is trial 56 with value: 0.7102857142857144.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-01-12 01:54:14,158]\u001b[0m Trial 90 finished with value: 0.6907619047619049 and parameters: {'lambda': 0.026298523095546197, 'alpha': 0.002337637077580732, 'colsample_bytree': 0.3, 'subsample': 0.9, 'learning_rate': 0.18009999999999998, 'n_estimators': 767}. Best is trial 56 with value: 0.7102857142857144.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-01-12 01:54:16,189]\u001b[0m Trial 91 finished with value: 0.6889523809523811 and parameters: {'lambda': 0.007679646889123362, 'alpha': 0.003095610150491639, 'colsample_bytree': 0.3, 'subsample': 1.0, 'learning_rate': 0.1651, 'n_estimators': 817}. Best is trial 56 with value: 0.7102857142857144.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-01-12 01:54:18,346]\u001b[0m Trial 92 finished with value: 0.698857142857143 and parameters: {'lambda': 0.019627147648464925, 'alpha': 0.010308846754474606, 'colsample_bytree': 0.3, 'subsample': 1.0, 'learning_rate': 0.14509999999999998, 'n_estimators': 789}. Best is trial 56 with value: 0.7102857142857144.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-01-12 01:54:20,399]\u001b[0m Trial 93 finished with value: 0.6989523809523811 and parameters: {'lambda': 0.012104952676441646, 'alpha': 0.03039331547668624, 'colsample_bytree': 0.3, 'subsample': 1.0, 'learning_rate': 0.1601, 'n_estimators': 742}. Best is trial 56 with value: 0.7102857142857144.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-01-12 01:54:21,764]\u001b[0m Trial 94 finished with value: 0.7060000000000001 and parameters: {'lambda': 0.005758744911796952, 'alpha': 0.00592458636159379, 'colsample_bytree': 0.3, 'subsample': 1.0, 'learning_rate': 0.1551, 'n_estimators': 489}. Best is trial 56 with value: 0.7102857142857144.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-01-12 01:54:23,361]\u001b[0m Trial 95 finished with value: 0.7003809523809525 and parameters: {'lambda': 0.05944768953566761, 'alpha': 0.00537721962184014, 'colsample_bytree': 0.3, 'subsample': 1.0, 'learning_rate': 0.15009999999999998, 'n_estimators': 559}. Best is trial 56 with value: 0.7102857142857144.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-01-12 01:54:24,709]\u001b[0m Trial 96 finished with value: 0.6947619047619048 and parameters: {'lambda': 0.04615810486191638, 'alpha': 0.005041871944751029, 'colsample_bytree': 0.3, 'subsample': 1.0, 'learning_rate': 0.15009999999999998, 'n_estimators': 482}. Best is trial 56 with value: 0.7102857142857144.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-01-12 01:54:25,993]\u001b[0m Trial 97 finished with value: 0.6821904761904762 and parameters: {'lambda': 0.009891164357898056, 'alpha': 0.0036417886687594215, 'colsample_bytree': 0.4, 'subsample': 1.0, 'learning_rate': 0.1701, 'n_estimators': 462}. Best is trial 56 with value: 0.7102857142857144.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-01-12 01:54:28,093]\u001b[0m Trial 98 finished with value: 0.6793333333333336 and parameters: {'lambda': 0.07346609827384647, 'alpha': 0.0017648041937854684, 'colsample_bytree': 0.3, 'subsample': 0.9, 'learning_rate': 0.1351, 'n_estimators': 557}. Best is trial 56 with value: 0.7102857142857144.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-01-12 01:54:32,881]\u001b[0m Trial 99 finished with value: 0.6862857142857142 and parameters: {'lambda': 0.005843712147701568, 'alpha': 0.010227730927162207, 'colsample_bytree': 0.4, 'subsample': 1.0, 'learning_rate': 0.1651, 'n_estimators': 681}. Best is trial 56 with value: 0.7102857142857144.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "#Tuning hyperparameters\n",
    "#Step 1. Define an objective function to be maximized.\n",
    "def objective(trial):\n",
    "    param = {\n",
    "        'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
    "        'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
    "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.3,1.0,step=0.1),\n",
    "        'subsample': trial.suggest_float('subsample', 0.4, 1.0, step=0.1),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.0001, 0.2, step=0.005),\n",
    "        'n_estimators': trial.suggest_int(\"n_estimators\",50,1000,1)\n",
    "        #'min_child_weight': trial.suggest_int('min_child_weight', 1, 300),\n",
    "    }\n",
    "    model = xgb.XGBClassifier(**param,random_state=1,n_jobs=8)\n",
    "\n",
    " \n",
    "# Step 2: Scoring method:\n",
    "    score = model_selection.cross_val_score(model, X, y, n_jobs=8, scoring=\"accuracy\",cv=Cv_optuna)\n",
    "    accuracy = score.mean()\n",
    "    return accuracy\n",
    "\n",
    "# Step 3: Running it\n",
    "study = optuna.create_study(direction=\"maximize\",sampler=optuna.samplers.TPESampler(seed=0))\n",
    "study.optimize(objective, n_trials=100, show_progress_bar=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "61fd4c6f-d6af-4f71-8f40-73e5cb7f1a34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best parameters are : \n",
      "{'lambda': 0.0013221304985698086, 'alpha': 0.02305461805888264, 'colsample_bytree': 0.3, 'subsample': 1.0, 'learning_rate': 0.15009999999999998, 'n_estimators': 884}\n"
     ]
    }
   ],
   "source": [
    "# Getting the best parameters:\n",
    "print(f\"The best parameters are : \\n{study.best_params}\")\n",
    "# Setting the best model\n",
    "clf=xgb.XGBClassifier(alpha = study.best_params['alpha']\n",
    "              ,colsample_bytree = study.best_params['colsample_bytree']\n",
    "              ,subsample = study.best_params['subsample']\n",
    "              ,n_estimators = study.best_params['n_estimators']\n",
    "              ,learning_rate= study.best_params['learning_rate'], n_jobs=8\n",
    "              ,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "4b5d7bd3-660b-42d3-9546-2633863cc8ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mean</th>\n",
       "      <th>Se</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Accuracy_test</th>\n",
       "      <td>0.682000</td>\n",
       "      <td>0.015467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Accuracy_train</th>\n",
       "      <td>0.978164</td>\n",
       "      <td>0.001539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1 Score</th>\n",
       "      <td>0.710276</td>\n",
       "      <td>0.015000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Precision</th>\n",
       "      <td>0.693874</td>\n",
       "      <td>0.013624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recall</th>\n",
       "      <td>0.748214</td>\n",
       "      <td>0.023279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Roc_auc</th>\n",
       "      <td>0.752117</td>\n",
       "      <td>0.018448</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Mean        Se\n",
       "Accuracy_test   0.682000  0.015467\n",
       "Accuracy_train  0.978164  0.001539\n",
       "F1 Score        0.710276  0.015000\n",
       "Precision       0.693874  0.013624\n",
       "Recall          0.748214  0.023279\n",
       "Roc_auc         0.752117  0.018448"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Model2=Model_results(clf,X,y,Cv_model)\n",
    "Model2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "a8261ab4-67a6-445c-8d21-feddad6b3796",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th>Method</th>\n",
       "      <th colspan=\"4\" halign=\"left\">XGB</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model</th>\n",
       "      <th colspan=\"2\" halign=\"left\">Model 1</th>\n",
       "      <th colspan=\"2\" halign=\"left\">Model 2</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Values</th>\n",
       "      <th>Mean</th>\n",
       "      <th>Se</th>\n",
       "      <th>Mean</th>\n",
       "      <th>Se</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Accuracy_test</th>\n",
       "      <td>0.662476</td>\n",
       "      <td>0.016918</td>\n",
       "      <td>0.682000</td>\n",
       "      <td>0.015467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Accuracy_train</th>\n",
       "      <td>0.978164</td>\n",
       "      <td>0.001539</td>\n",
       "      <td>0.978164</td>\n",
       "      <td>0.001539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1 Score</th>\n",
       "      <td>0.693483</td>\n",
       "      <td>0.017356</td>\n",
       "      <td>0.710276</td>\n",
       "      <td>0.015000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Precision</th>\n",
       "      <td>0.671509</td>\n",
       "      <td>0.015551</td>\n",
       "      <td>0.693874</td>\n",
       "      <td>0.013624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recall</th>\n",
       "      <td>0.737143</td>\n",
       "      <td>0.025112</td>\n",
       "      <td>0.748214</td>\n",
       "      <td>0.023279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Roc_auc</th>\n",
       "      <td>0.749660</td>\n",
       "      <td>0.017686</td>\n",
       "      <td>0.752117</td>\n",
       "      <td>0.018448</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Method               XGB                              \n",
       "Model            Model 1             Model 2          \n",
       "Values              Mean        Se      Mean        Se\n",
       "Accuracy_test   0.662476  0.016918  0.682000  0.015467\n",
       "Accuracy_train  0.978164  0.001539  0.978164  0.001539\n",
       "F1 Score        0.693483  0.017356  0.710276  0.015000\n",
       "Precision       0.671509  0.015551  0.693874  0.013624\n",
       "Recall          0.737143  0.025112  0.748214  0.023279\n",
       "Roc_auc         0.749660  0.017686  0.752117  0.018448"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Saving the data of model performance\n",
    "Model_data=pd.concat([Model1,Model2],axis=1)\n",
    "Model_data.columns = [['XGB']*4,['Model 1','Model 1', 'Model 2','Model 2'], ['Mean', 'Se', 'Mean', 'Se']]  \n",
    "Model_data.columns.names=['Method','Model','Values']\n",
    "Model_data.to_csv(\"./Results/XGB_model_mlrem_data.csv\",sep=',')\n",
    "Model_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec50adff-12d7-4284-a740-a33a46351d03",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hydrogel",
   "language": "python",
   "name": "hydrogel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
