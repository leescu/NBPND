{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "50559d19-ab40-4880-bae7-44a3dbe180a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Others\n",
    "import random\n",
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "from pandas import Series\n",
    "import numpy as np\n",
    "import math\n",
    "import os\n",
    "import warnings\n",
    "import optuna\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "70ff5d38-60c9-476d-a509-9e1419bea2b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing packages\n",
    "#Sklearn\n",
    "from sklearn import model_selection, linear_model\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.feature_selection import RFECV,SelectFromModel\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV,RandomizedSearchCV,RepeatedStratifiedKFold,cross_validate\n",
    "from sklearn.metrics import accuracy_score,precision_score,recall_score,f1_score,auc,roc_auc_score,roc_curve,classification_report\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.linear_model import Ridge, LinearRegression, Lasso\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "a6baca9e-4a5b-4e5f-9cd3-2db48c543dc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LassoCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "bc75945b-ce4f-4650-8380-f7bfb5ff1b51",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"C:/Users/A/Desktop/Bioactive/EBV\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "12865361-291e-449c-8ca4-53ed95b92f16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1146, 3918)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MW</th>\n",
       "      <th>AMW</th>\n",
       "      <th>Sv</th>\n",
       "      <th>Se</th>\n",
       "      <th>Sp</th>\n",
       "      <th>Si</th>\n",
       "      <th>Mv</th>\n",
       "      <th>Me</th>\n",
       "      <th>Mp</th>\n",
       "      <th>Mi</th>\n",
       "      <th>...</th>\n",
       "      <th>s1_numAroBonds</th>\n",
       "      <th>s2_numAroBonds</th>\n",
       "      <th>s3_numAroBonds</th>\n",
       "      <th>s4_numAroBonds</th>\n",
       "      <th>s34_size</th>\n",
       "      <th>s34_relSize</th>\n",
       "      <th>s34_phSize</th>\n",
       "      <th>s34_phRelSize</th>\n",
       "      <th>chiralMoment</th>\n",
       "      <th>chiralPhMoment</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OPTUM_LAB_ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3185712.0</th>\n",
       "      <td>536.72</td>\n",
       "      <td>7.667429</td>\n",
       "      <td>44.0231</td>\n",
       "      <td>70.4832</td>\n",
       "      <td>46.3981</td>\n",
       "      <td>79.1450</td>\n",
       "      <td>0.628901</td>\n",
       "      <td>1.006903</td>\n",
       "      <td>0.662830</td>\n",
       "      <td>1.130643</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>31.5</td>\n",
       "      <td>0.828947</td>\n",
       "      <td>9.5</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>40.917043</td>\n",
       "      <td>12.132410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3532333.0</th>\n",
       "      <td>359.86</td>\n",
       "      <td>9.470000</td>\n",
       "      <td>26.6692</td>\n",
       "      <td>38.6617</td>\n",
       "      <td>28.0001</td>\n",
       "      <td>42.2689</td>\n",
       "      <td>0.701821</td>\n",
       "      <td>1.017413</td>\n",
       "      <td>0.736845</td>\n",
       "      <td>1.112339</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16830460.0</th>\n",
       "      <td>472.41</td>\n",
       "      <td>8.589273</td>\n",
       "      <td>36.4596</td>\n",
       "      <td>55.6470</td>\n",
       "      <td>38.2673</td>\n",
       "      <td>61.9503</td>\n",
       "      <td>0.662902</td>\n",
       "      <td>1.011764</td>\n",
       "      <td>0.695769</td>\n",
       "      <td>1.126369</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3921421.0</th>\n",
       "      <td>468.59</td>\n",
       "      <td>7.437937</td>\n",
       "      <td>40.7504</td>\n",
       "      <td>62.9996</td>\n",
       "      <td>42.7276</td>\n",
       "      <td>70.2318</td>\n",
       "      <td>0.646832</td>\n",
       "      <td>0.999994</td>\n",
       "      <td>0.678216</td>\n",
       "      <td>1.114790</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>0.885714</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.114286</td>\n",
       "      <td>33.763886</td>\n",
       "      <td>4.472136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1314610.0</th>\n",
       "      <td>353.78</td>\n",
       "      <td>9.561622</td>\n",
       "      <td>26.6701</td>\n",
       "      <td>38.0290</td>\n",
       "      <td>27.0455</td>\n",
       "      <td>41.1431</td>\n",
       "      <td>0.720814</td>\n",
       "      <td>1.027811</td>\n",
       "      <td>0.730959</td>\n",
       "      <td>1.111976</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 3918 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  MW       AMW       Sv       Se       Sp       Si        Mv  \\\n",
       "OPTUM_LAB_ID                                                                   \n",
       "3185712.0     536.72  7.667429  44.0231  70.4832  46.3981  79.1450  0.628901   \n",
       "3532333.0     359.86  9.470000  26.6692  38.6617  28.0001  42.2689  0.701821   \n",
       "16830460.0    472.41  8.589273  36.4596  55.6470  38.2673  61.9503  0.662902   \n",
       "3921421.0     468.59  7.437937  40.7504  62.9996  42.7276  70.2318  0.646832   \n",
       "1314610.0     353.78  9.561622  26.6701  38.0290  27.0455  41.1431  0.720814   \n",
       "\n",
       "                    Me        Mp        Mi  ...  s1_numAroBonds  \\\n",
       "OPTUM_LAB_ID                                ...                   \n",
       "3185712.0     1.006903  0.662830  1.130643  ...             0.0   \n",
       "3532333.0     1.017413  0.736845  1.112339  ...             0.0   \n",
       "16830460.0    1.011764  0.695769  1.126369  ...             0.0   \n",
       "3921421.0     0.999994  0.678216  1.114790  ...             0.0   \n",
       "1314610.0     1.027811  0.730959  1.111976  ...             0.0   \n",
       "\n",
       "              s2_numAroBonds  s3_numAroBonds  s4_numAroBonds  s34_size  \\\n",
       "OPTUM_LAB_ID                                                             \n",
       "3185712.0                3.0             0.0            14.0      31.5   \n",
       "3532333.0                0.0             0.0             0.0       0.0   \n",
       "16830460.0               0.0             0.0             0.0       0.0   \n",
       "3921421.0                0.0             6.0            18.0      31.0   \n",
       "1314610.0                0.0             0.0             0.0       0.0   \n",
       "\n",
       "              s34_relSize  s34_phSize  s34_phRelSize  chiralMoment  \\\n",
       "OPTUM_LAB_ID                                                         \n",
       "3185712.0        0.828947         9.5       0.250000     40.917043   \n",
       "3532333.0        0.000000         0.0       0.000000      0.000000   \n",
       "16830460.0       0.000000         0.0       0.000000      0.000000   \n",
       "3921421.0        0.885714         4.0       0.114286     33.763886   \n",
       "1314610.0        0.000000         0.0       0.000000      0.000000   \n",
       "\n",
       "              chiralPhMoment  \n",
       "OPTUM_LAB_ID                  \n",
       "3185712.0          12.132410  \n",
       "3532333.0           0.000000  \n",
       "16830460.0          0.000000  \n",
       "3921421.0           4.472136  \n",
       "1314610.0           0.000000  \n",
       "\n",
       "[5 rows x 3918 columns]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Reading the data\n",
    "ML_data= pd.read_csv(\"./ML_data.csv\",header=0,index_col=0)\n",
    "X_NAomit_data= pd.read_csv(\"./X_NAomit_data.csv\",header=0,index_col=0)\n",
    "Raw_data = pd.read_csv('./data_psm.csv',index_col=0)\n",
    "\n",
    "#original data(descriptors= 4175）\n",
    "print(X_NAomit_data.shape)\n",
    "X_NAomit_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "a68cc910-dca6-4b63-ae90-8fac100e1ac6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MW</th>\n",
       "      <th>AMW</th>\n",
       "      <th>Sv</th>\n",
       "      <th>Se</th>\n",
       "      <th>Sp</th>\n",
       "      <th>Si</th>\n",
       "      <th>Mv</th>\n",
       "      <th>Me</th>\n",
       "      <th>Mp</th>\n",
       "      <th>Mi</th>\n",
       "      <th>...</th>\n",
       "      <th>s1_numAroBonds</th>\n",
       "      <th>s2_numAroBonds</th>\n",
       "      <th>s3_numAroBonds</th>\n",
       "      <th>s4_numAroBonds</th>\n",
       "      <th>s34_size</th>\n",
       "      <th>s34_relSize</th>\n",
       "      <th>s34_phSize</th>\n",
       "      <th>s34_phRelSize</th>\n",
       "      <th>chiralMoment</th>\n",
       "      <th>chiralPhMoment</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OPTUM_LAB_ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3185712.0</th>\n",
       "      <td>536.72</td>\n",
       "      <td>7.667429</td>\n",
       "      <td>44.0231</td>\n",
       "      <td>70.4832</td>\n",
       "      <td>46.3981</td>\n",
       "      <td>79.1450</td>\n",
       "      <td>0.628901</td>\n",
       "      <td>1.006903</td>\n",
       "      <td>0.662830</td>\n",
       "      <td>1.130643</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>31.5</td>\n",
       "      <td>0.828947</td>\n",
       "      <td>9.5</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>40.917043</td>\n",
       "      <td>12.132410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3532333.0</th>\n",
       "      <td>359.86</td>\n",
       "      <td>9.470000</td>\n",
       "      <td>26.6692</td>\n",
       "      <td>38.6617</td>\n",
       "      <td>28.0001</td>\n",
       "      <td>42.2689</td>\n",
       "      <td>0.701821</td>\n",
       "      <td>1.017413</td>\n",
       "      <td>0.736845</td>\n",
       "      <td>1.112339</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16830460.0</th>\n",
       "      <td>472.41</td>\n",
       "      <td>8.589273</td>\n",
       "      <td>36.4596</td>\n",
       "      <td>55.6470</td>\n",
       "      <td>38.2673</td>\n",
       "      <td>61.9503</td>\n",
       "      <td>0.662902</td>\n",
       "      <td>1.011764</td>\n",
       "      <td>0.695769</td>\n",
       "      <td>1.126369</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3921421.0</th>\n",
       "      <td>468.59</td>\n",
       "      <td>7.437937</td>\n",
       "      <td>40.7504</td>\n",
       "      <td>62.9996</td>\n",
       "      <td>42.7276</td>\n",
       "      <td>70.2318</td>\n",
       "      <td>0.646832</td>\n",
       "      <td>0.999994</td>\n",
       "      <td>0.678216</td>\n",
       "      <td>1.114790</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>0.885714</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.114286</td>\n",
       "      <td>33.763886</td>\n",
       "      <td>4.472136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1314610.0</th>\n",
       "      <td>353.78</td>\n",
       "      <td>9.561622</td>\n",
       "      <td>26.6701</td>\n",
       "      <td>38.0290</td>\n",
       "      <td>27.0455</td>\n",
       "      <td>41.1431</td>\n",
       "      <td>0.720814</td>\n",
       "      <td>1.027811</td>\n",
       "      <td>0.730959</td>\n",
       "      <td>1.111976</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>664630.0</th>\n",
       "      <td>272.38</td>\n",
       "      <td>6.809500</td>\n",
       "      <td>24.2136</td>\n",
       "      <td>39.8106</td>\n",
       "      <td>25.7730</td>\n",
       "      <td>45.1522</td>\n",
       "      <td>0.605340</td>\n",
       "      <td>0.995265</td>\n",
       "      <td>0.644325</td>\n",
       "      <td>1.128805</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3228536.0</th>\n",
       "      <td>395.47</td>\n",
       "      <td>8.788222</td>\n",
       "      <td>30.7981</td>\n",
       "      <td>45.8762</td>\n",
       "      <td>31.8126</td>\n",
       "      <td>50.1589</td>\n",
       "      <td>0.684402</td>\n",
       "      <td>1.019471</td>\n",
       "      <td>0.706947</td>\n",
       "      <td>1.114642</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.214286</td>\n",
       "      <td>17.748239</td>\n",
       "      <td>5.196152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>666815.0</th>\n",
       "      <td>397.48</td>\n",
       "      <td>7.643846</td>\n",
       "      <td>32.7074</td>\n",
       "      <td>52.7706</td>\n",
       "      <td>33.6991</td>\n",
       "      <td>59.0659</td>\n",
       "      <td>0.628988</td>\n",
       "      <td>1.014819</td>\n",
       "      <td>0.648060</td>\n",
       "      <td>1.135883</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16197082.0</th>\n",
       "      <td>471.61</td>\n",
       "      <td>7.993390</td>\n",
       "      <td>39.3893</td>\n",
       "      <td>59.0906</td>\n",
       "      <td>41.6082</td>\n",
       "      <td>65.2383</td>\n",
       "      <td>0.667615</td>\n",
       "      <td>1.001536</td>\n",
       "      <td>0.705224</td>\n",
       "      <td>1.105734</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>23.5</td>\n",
       "      <td>0.691176</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.117647</td>\n",
       "      <td>19.466228</td>\n",
       "      <td>5.098076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1519798.0</th>\n",
       "      <td>289.32</td>\n",
       "      <td>8.767273</td>\n",
       "      <td>23.4022</td>\n",
       "      <td>33.4871</td>\n",
       "      <td>23.7672</td>\n",
       "      <td>36.9465</td>\n",
       "      <td>0.709158</td>\n",
       "      <td>1.014761</td>\n",
       "      <td>0.720218</td>\n",
       "      <td>1.119591</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1146 rows × 3918 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  MW       AMW       Sv       Se       Sp       Si        Mv  \\\n",
       "OPTUM_LAB_ID                                                                   \n",
       "3185712.0     536.72  7.667429  44.0231  70.4832  46.3981  79.1450  0.628901   \n",
       "3532333.0     359.86  9.470000  26.6692  38.6617  28.0001  42.2689  0.701821   \n",
       "16830460.0    472.41  8.589273  36.4596  55.6470  38.2673  61.9503  0.662902   \n",
       "3921421.0     468.59  7.437937  40.7504  62.9996  42.7276  70.2318  0.646832   \n",
       "1314610.0     353.78  9.561622  26.6701  38.0290  27.0455  41.1431  0.720814   \n",
       "...              ...       ...      ...      ...      ...      ...       ...   \n",
       "664630.0      272.38  6.809500  24.2136  39.8106  25.7730  45.1522  0.605340   \n",
       "3228536.0     395.47  8.788222  30.7981  45.8762  31.8126  50.1589  0.684402   \n",
       "666815.0      397.48  7.643846  32.7074  52.7706  33.6991  59.0659  0.628988   \n",
       "16197082.0    471.61  7.993390  39.3893  59.0906  41.6082  65.2383  0.667615   \n",
       "1519798.0     289.32  8.767273  23.4022  33.4871  23.7672  36.9465  0.709158   \n",
       "\n",
       "                    Me        Mp        Mi  ...  s1_numAroBonds  \\\n",
       "OPTUM_LAB_ID                                ...                   \n",
       "3185712.0     1.006903  0.662830  1.130643  ...             0.0   \n",
       "3532333.0     1.017413  0.736845  1.112339  ...             0.0   \n",
       "16830460.0    1.011764  0.695769  1.126369  ...             0.0   \n",
       "3921421.0     0.999994  0.678216  1.114790  ...             0.0   \n",
       "1314610.0     1.027811  0.730959  1.111976  ...             0.0   \n",
       "...                ...       ...       ...  ...             ...   \n",
       "664630.0      0.995265  0.644325  1.128805  ...             0.0   \n",
       "3228536.0     1.019471  0.706947  1.114642  ...             0.0   \n",
       "666815.0      1.014819  0.648060  1.135883  ...             0.0   \n",
       "16197082.0    1.001536  0.705224  1.105734  ...             0.0   \n",
       "1519798.0     1.014761  0.720218  1.119591  ...             0.0   \n",
       "\n",
       "              s2_numAroBonds  s3_numAroBonds  s4_numAroBonds  s34_size  \\\n",
       "OPTUM_LAB_ID                                                             \n",
       "3185712.0                3.0             0.0            14.0      31.5   \n",
       "3532333.0                0.0             0.0             0.0       0.0   \n",
       "16830460.0               0.0             0.0             0.0       0.0   \n",
       "3921421.0                0.0             6.0            18.0      31.0   \n",
       "1314610.0                0.0             0.0             0.0       0.0   \n",
       "...                      ...             ...             ...       ...   \n",
       "664630.0                 0.0             0.0             0.0       0.0   \n",
       "3228536.0                6.0             5.0             9.0      21.0   \n",
       "666815.0                 0.0             0.0             0.0       0.0   \n",
       "16197082.0               8.0             8.0             6.0      23.5   \n",
       "1519798.0                0.0             0.0             0.0       0.0   \n",
       "\n",
       "              s34_relSize  s34_phSize  s34_phRelSize  chiralMoment  \\\n",
       "OPTUM_LAB_ID                                                         \n",
       "3185712.0        0.828947         9.5       0.250000     40.917043   \n",
       "3532333.0        0.000000         0.0       0.000000      0.000000   \n",
       "16830460.0       0.000000         0.0       0.000000      0.000000   \n",
       "3921421.0        0.885714         4.0       0.114286     33.763886   \n",
       "1314610.0        0.000000         0.0       0.000000      0.000000   \n",
       "...                   ...         ...            ...           ...   \n",
       "664630.0         0.000000         0.0       0.000000      0.000000   \n",
       "3228536.0        0.750000         6.0       0.214286     17.748239   \n",
       "666815.0         0.000000         0.0       0.000000      0.000000   \n",
       "16197082.0       0.691176         4.0       0.117647     19.466228   \n",
       "1519798.0        0.000000         0.0       0.000000      0.000000   \n",
       "\n",
       "              chiralPhMoment  \n",
       "OPTUM_LAB_ID                  \n",
       "3185712.0          12.132410  \n",
       "3532333.0           0.000000  \n",
       "16830460.0          0.000000  \n",
       "3921421.0           4.472136  \n",
       "1314610.0           0.000000  \n",
       "...                      ...  \n",
       "664630.0            0.000000  \n",
       "3228536.0           5.196152  \n",
       "666815.0            0.000000  \n",
       "16197082.0          5.098076  \n",
       "1519798.0           0.000000  \n",
       "\n",
       "[1146 rows x 3918 columns]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_NAomit_data= pd.read_csv(\"./X_NAomit_data.csv\",header=0,index_col=0)\n",
    "X_NAomit_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "e1c89e32-9d35-4229-a7fd-6dc4bc6e3b4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "col_data= pd.read_csv(\"./X_NAomit_data.csv\",header=0,index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "c075c2f5-c839-4ab6-8f1d-ee4e808c3238",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MW</th>\n",
       "      <th>AMW</th>\n",
       "      <th>Sv</th>\n",
       "      <th>Se</th>\n",
       "      <th>Sp</th>\n",
       "      <th>Si</th>\n",
       "      <th>Mv</th>\n",
       "      <th>Me</th>\n",
       "      <th>Mp</th>\n",
       "      <th>Mi</th>\n",
       "      <th>...</th>\n",
       "      <th>s1_numAroBonds</th>\n",
       "      <th>s2_numAroBonds</th>\n",
       "      <th>s3_numAroBonds</th>\n",
       "      <th>s4_numAroBonds</th>\n",
       "      <th>s34_size</th>\n",
       "      <th>s34_relSize</th>\n",
       "      <th>s34_phSize</th>\n",
       "      <th>s34_phRelSize</th>\n",
       "      <th>chiralMoment</th>\n",
       "      <th>chiralPhMoment</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OPTUM_LAB_ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3185712.0</th>\n",
       "      <td>536.72</td>\n",
       "      <td>7.667429</td>\n",
       "      <td>44.0231</td>\n",
       "      <td>70.4832</td>\n",
       "      <td>46.3981</td>\n",
       "      <td>79.1450</td>\n",
       "      <td>0.628901</td>\n",
       "      <td>1.006903</td>\n",
       "      <td>0.662830</td>\n",
       "      <td>1.130643</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>31.5</td>\n",
       "      <td>0.828947</td>\n",
       "      <td>9.5</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>40.917043</td>\n",
       "      <td>12.132410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3532333.0</th>\n",
       "      <td>359.86</td>\n",
       "      <td>9.470000</td>\n",
       "      <td>26.6692</td>\n",
       "      <td>38.6617</td>\n",
       "      <td>28.0001</td>\n",
       "      <td>42.2689</td>\n",
       "      <td>0.701821</td>\n",
       "      <td>1.017413</td>\n",
       "      <td>0.736845</td>\n",
       "      <td>1.112339</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16830460.0</th>\n",
       "      <td>472.41</td>\n",
       "      <td>8.589273</td>\n",
       "      <td>36.4596</td>\n",
       "      <td>55.6470</td>\n",
       "      <td>38.2673</td>\n",
       "      <td>61.9503</td>\n",
       "      <td>0.662902</td>\n",
       "      <td>1.011764</td>\n",
       "      <td>0.695769</td>\n",
       "      <td>1.126369</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3921421.0</th>\n",
       "      <td>468.59</td>\n",
       "      <td>7.437937</td>\n",
       "      <td>40.7504</td>\n",
       "      <td>62.9996</td>\n",
       "      <td>42.7276</td>\n",
       "      <td>70.2318</td>\n",
       "      <td>0.646832</td>\n",
       "      <td>0.999994</td>\n",
       "      <td>0.678216</td>\n",
       "      <td>1.114790</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>0.885714</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.114286</td>\n",
       "      <td>33.763886</td>\n",
       "      <td>4.472136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1314610.0</th>\n",
       "      <td>353.78</td>\n",
       "      <td>9.561622</td>\n",
       "      <td>26.6701</td>\n",
       "      <td>38.0290</td>\n",
       "      <td>27.0455</td>\n",
       "      <td>41.1431</td>\n",
       "      <td>0.720814</td>\n",
       "      <td>1.027811</td>\n",
       "      <td>0.730959</td>\n",
       "      <td>1.111976</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>664630.0</th>\n",
       "      <td>272.38</td>\n",
       "      <td>6.809500</td>\n",
       "      <td>24.2136</td>\n",
       "      <td>39.8106</td>\n",
       "      <td>25.7730</td>\n",
       "      <td>45.1522</td>\n",
       "      <td>0.605340</td>\n",
       "      <td>0.995265</td>\n",
       "      <td>0.644325</td>\n",
       "      <td>1.128805</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3228536.0</th>\n",
       "      <td>395.47</td>\n",
       "      <td>8.788222</td>\n",
       "      <td>30.7981</td>\n",
       "      <td>45.8762</td>\n",
       "      <td>31.8126</td>\n",
       "      <td>50.1589</td>\n",
       "      <td>0.684402</td>\n",
       "      <td>1.019471</td>\n",
       "      <td>0.706947</td>\n",
       "      <td>1.114642</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.214286</td>\n",
       "      <td>17.748239</td>\n",
       "      <td>5.196152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>666815.0</th>\n",
       "      <td>397.48</td>\n",
       "      <td>7.643846</td>\n",
       "      <td>32.7074</td>\n",
       "      <td>52.7706</td>\n",
       "      <td>33.6991</td>\n",
       "      <td>59.0659</td>\n",
       "      <td>0.628988</td>\n",
       "      <td>1.014819</td>\n",
       "      <td>0.648060</td>\n",
       "      <td>1.135883</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16197082.0</th>\n",
       "      <td>471.61</td>\n",
       "      <td>7.993390</td>\n",
       "      <td>39.3893</td>\n",
       "      <td>59.0906</td>\n",
       "      <td>41.6082</td>\n",
       "      <td>65.2383</td>\n",
       "      <td>0.667615</td>\n",
       "      <td>1.001536</td>\n",
       "      <td>0.705224</td>\n",
       "      <td>1.105734</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>23.5</td>\n",
       "      <td>0.691176</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.117647</td>\n",
       "      <td>19.466228</td>\n",
       "      <td>5.098076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1519798.0</th>\n",
       "      <td>289.32</td>\n",
       "      <td>8.767273</td>\n",
       "      <td>23.4022</td>\n",
       "      <td>33.4871</td>\n",
       "      <td>23.7672</td>\n",
       "      <td>36.9465</td>\n",
       "      <td>0.709158</td>\n",
       "      <td>1.014761</td>\n",
       "      <td>0.720218</td>\n",
       "      <td>1.119591</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1146 rows × 3918 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  MW       AMW       Sv       Se       Sp       Si        Mv  \\\n",
       "OPTUM_LAB_ID                                                                   \n",
       "3185712.0     536.72  7.667429  44.0231  70.4832  46.3981  79.1450  0.628901   \n",
       "3532333.0     359.86  9.470000  26.6692  38.6617  28.0001  42.2689  0.701821   \n",
       "16830460.0    472.41  8.589273  36.4596  55.6470  38.2673  61.9503  0.662902   \n",
       "3921421.0     468.59  7.437937  40.7504  62.9996  42.7276  70.2318  0.646832   \n",
       "1314610.0     353.78  9.561622  26.6701  38.0290  27.0455  41.1431  0.720814   \n",
       "...              ...       ...      ...      ...      ...      ...       ...   \n",
       "664630.0      272.38  6.809500  24.2136  39.8106  25.7730  45.1522  0.605340   \n",
       "3228536.0     395.47  8.788222  30.7981  45.8762  31.8126  50.1589  0.684402   \n",
       "666815.0      397.48  7.643846  32.7074  52.7706  33.6991  59.0659  0.628988   \n",
       "16197082.0    471.61  7.993390  39.3893  59.0906  41.6082  65.2383  0.667615   \n",
       "1519798.0     289.32  8.767273  23.4022  33.4871  23.7672  36.9465  0.709158   \n",
       "\n",
       "                    Me        Mp        Mi  ...  s1_numAroBonds  \\\n",
       "OPTUM_LAB_ID                                ...                   \n",
       "3185712.0     1.006903  0.662830  1.130643  ...             0.0   \n",
       "3532333.0     1.017413  0.736845  1.112339  ...             0.0   \n",
       "16830460.0    1.011764  0.695769  1.126369  ...             0.0   \n",
       "3921421.0     0.999994  0.678216  1.114790  ...             0.0   \n",
       "1314610.0     1.027811  0.730959  1.111976  ...             0.0   \n",
       "...                ...       ...       ...  ...             ...   \n",
       "664630.0      0.995265  0.644325  1.128805  ...             0.0   \n",
       "3228536.0     1.019471  0.706947  1.114642  ...             0.0   \n",
       "666815.0      1.014819  0.648060  1.135883  ...             0.0   \n",
       "16197082.0    1.001536  0.705224  1.105734  ...             0.0   \n",
       "1519798.0     1.014761  0.720218  1.119591  ...             0.0   \n",
       "\n",
       "              s2_numAroBonds  s3_numAroBonds  s4_numAroBonds  s34_size  \\\n",
       "OPTUM_LAB_ID                                                             \n",
       "3185712.0                3.0             0.0            14.0      31.5   \n",
       "3532333.0                0.0             0.0             0.0       0.0   \n",
       "16830460.0               0.0             0.0             0.0       0.0   \n",
       "3921421.0                0.0             6.0            18.0      31.0   \n",
       "1314610.0                0.0             0.0             0.0       0.0   \n",
       "...                      ...             ...             ...       ...   \n",
       "664630.0                 0.0             0.0             0.0       0.0   \n",
       "3228536.0                6.0             5.0             9.0      21.0   \n",
       "666815.0                 0.0             0.0             0.0       0.0   \n",
       "16197082.0               8.0             8.0             6.0      23.5   \n",
       "1519798.0                0.0             0.0             0.0       0.0   \n",
       "\n",
       "              s34_relSize  s34_phSize  s34_phRelSize  chiralMoment  \\\n",
       "OPTUM_LAB_ID                                                         \n",
       "3185712.0        0.828947         9.5       0.250000     40.917043   \n",
       "3532333.0        0.000000         0.0       0.000000      0.000000   \n",
       "16830460.0       0.000000         0.0       0.000000      0.000000   \n",
       "3921421.0        0.885714         4.0       0.114286     33.763886   \n",
       "1314610.0        0.000000         0.0       0.000000      0.000000   \n",
       "...                   ...         ...            ...           ...   \n",
       "664630.0         0.000000         0.0       0.000000      0.000000   \n",
       "3228536.0        0.750000         6.0       0.214286     17.748239   \n",
       "666815.0         0.000000         0.0       0.000000      0.000000   \n",
       "16197082.0       0.691176         4.0       0.117647     19.466228   \n",
       "1519798.0        0.000000         0.0       0.000000      0.000000   \n",
       "\n",
       "              chiralPhMoment  \n",
       "OPTUM_LAB_ID                  \n",
       "3185712.0          12.132410  \n",
       "3532333.0           0.000000  \n",
       "16830460.0          0.000000  \n",
       "3921421.0           4.472136  \n",
       "1314610.0           0.000000  \n",
       "...                      ...  \n",
       "664630.0            0.000000  \n",
       "3228536.0           5.196152  \n",
       "666815.0            0.000000  \n",
       "16197082.0          5.098076  \n",
       "1519798.0           0.000000  \n",
       "\n",
       "[1146 rows x 3918 columns]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_NAomit_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "8129de55-e5e1-44df-bea5-1de439f32345",
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 0.99  # 如果列中 0 的比例超过 90%，则移除该列\n",
    "non_zero_threshold = X_NAomit_data.shape[0] * (1 - threshold)\n",
    "X_NAomit_data =X_NAomit_data.loc[:, (X_NAomit_data != 0).sum(axis=0) > non_zero_threshold]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "25db298a-25a8-4f41-ba0a-23d279862cce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MW</th>\n",
       "      <th>AMW</th>\n",
       "      <th>Sv</th>\n",
       "      <th>Se</th>\n",
       "      <th>Sp</th>\n",
       "      <th>Si</th>\n",
       "      <th>Mv</th>\n",
       "      <th>Me</th>\n",
       "      <th>Mp</th>\n",
       "      <th>Mi</th>\n",
       "      <th>...</th>\n",
       "      <th>s4_numRotBonds</th>\n",
       "      <th>s2_numAroBonds</th>\n",
       "      <th>s3_numAroBonds</th>\n",
       "      <th>s4_numAroBonds</th>\n",
       "      <th>s34_size</th>\n",
       "      <th>s34_relSize</th>\n",
       "      <th>s34_phSize</th>\n",
       "      <th>s34_phRelSize</th>\n",
       "      <th>chiralMoment</th>\n",
       "      <th>chiralPhMoment</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OPTUM_LAB_ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3185712.0</th>\n",
       "      <td>536.72</td>\n",
       "      <td>7.667429</td>\n",
       "      <td>44.0231</td>\n",
       "      <td>70.4832</td>\n",
       "      <td>46.3981</td>\n",
       "      <td>79.1450</td>\n",
       "      <td>0.628901</td>\n",
       "      <td>1.006903</td>\n",
       "      <td>0.662830</td>\n",
       "      <td>1.130643</td>\n",
       "      <td>...</td>\n",
       "      <td>5.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>31.5</td>\n",
       "      <td>0.828947</td>\n",
       "      <td>9.5</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>40.917043</td>\n",
       "      <td>12.132410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3532333.0</th>\n",
       "      <td>359.86</td>\n",
       "      <td>9.470000</td>\n",
       "      <td>26.6692</td>\n",
       "      <td>38.6617</td>\n",
       "      <td>28.0001</td>\n",
       "      <td>42.2689</td>\n",
       "      <td>0.701821</td>\n",
       "      <td>1.017413</td>\n",
       "      <td>0.736845</td>\n",
       "      <td>1.112339</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16830460.0</th>\n",
       "      <td>472.41</td>\n",
       "      <td>8.589273</td>\n",
       "      <td>36.4596</td>\n",
       "      <td>55.6470</td>\n",
       "      <td>38.2673</td>\n",
       "      <td>61.9503</td>\n",
       "      <td>0.662902</td>\n",
       "      <td>1.011764</td>\n",
       "      <td>0.695769</td>\n",
       "      <td>1.126369</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3921421.0</th>\n",
       "      <td>468.59</td>\n",
       "      <td>7.437937</td>\n",
       "      <td>40.7504</td>\n",
       "      <td>62.9996</td>\n",
       "      <td>42.7276</td>\n",
       "      <td>70.2318</td>\n",
       "      <td>0.646832</td>\n",
       "      <td>0.999994</td>\n",
       "      <td>0.678216</td>\n",
       "      <td>1.114790</td>\n",
       "      <td>...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>0.885714</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.114286</td>\n",
       "      <td>33.763886</td>\n",
       "      <td>4.472136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1314610.0</th>\n",
       "      <td>353.78</td>\n",
       "      <td>9.561622</td>\n",
       "      <td>26.6701</td>\n",
       "      <td>38.0290</td>\n",
       "      <td>27.0455</td>\n",
       "      <td>41.1431</td>\n",
       "      <td>0.720814</td>\n",
       "      <td>1.027811</td>\n",
       "      <td>0.730959</td>\n",
       "      <td>1.111976</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>664630.0</th>\n",
       "      <td>272.38</td>\n",
       "      <td>6.809500</td>\n",
       "      <td>24.2136</td>\n",
       "      <td>39.8106</td>\n",
       "      <td>25.7730</td>\n",
       "      <td>45.1522</td>\n",
       "      <td>0.605340</td>\n",
       "      <td>0.995265</td>\n",
       "      <td>0.644325</td>\n",
       "      <td>1.128805</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3228536.0</th>\n",
       "      <td>395.47</td>\n",
       "      <td>8.788222</td>\n",
       "      <td>30.7981</td>\n",
       "      <td>45.8762</td>\n",
       "      <td>31.8126</td>\n",
       "      <td>50.1589</td>\n",
       "      <td>0.684402</td>\n",
       "      <td>1.019471</td>\n",
       "      <td>0.706947</td>\n",
       "      <td>1.114642</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.214286</td>\n",
       "      <td>17.748239</td>\n",
       "      <td>5.196152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>666815.0</th>\n",
       "      <td>397.48</td>\n",
       "      <td>7.643846</td>\n",
       "      <td>32.7074</td>\n",
       "      <td>52.7706</td>\n",
       "      <td>33.6991</td>\n",
       "      <td>59.0659</td>\n",
       "      <td>0.628988</td>\n",
       "      <td>1.014819</td>\n",
       "      <td>0.648060</td>\n",
       "      <td>1.135883</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16197082.0</th>\n",
       "      <td>471.61</td>\n",
       "      <td>7.993390</td>\n",
       "      <td>39.3893</td>\n",
       "      <td>59.0906</td>\n",
       "      <td>41.6082</td>\n",
       "      <td>65.2383</td>\n",
       "      <td>0.667615</td>\n",
       "      <td>1.001536</td>\n",
       "      <td>0.705224</td>\n",
       "      <td>1.105734</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>23.5</td>\n",
       "      <td>0.691176</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.117647</td>\n",
       "      <td>19.466228</td>\n",
       "      <td>5.098076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1519798.0</th>\n",
       "      <td>289.32</td>\n",
       "      <td>8.767273</td>\n",
       "      <td>23.4022</td>\n",
       "      <td>33.4871</td>\n",
       "      <td>23.7672</td>\n",
       "      <td>36.9465</td>\n",
       "      <td>0.709158</td>\n",
       "      <td>1.014761</td>\n",
       "      <td>0.720218</td>\n",
       "      <td>1.119591</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1146 rows × 2248 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  MW       AMW       Sv       Se       Sp       Si        Mv  \\\n",
       "OPTUM_LAB_ID                                                                   \n",
       "3185712.0     536.72  7.667429  44.0231  70.4832  46.3981  79.1450  0.628901   \n",
       "3532333.0     359.86  9.470000  26.6692  38.6617  28.0001  42.2689  0.701821   \n",
       "16830460.0    472.41  8.589273  36.4596  55.6470  38.2673  61.9503  0.662902   \n",
       "3921421.0     468.59  7.437937  40.7504  62.9996  42.7276  70.2318  0.646832   \n",
       "1314610.0     353.78  9.561622  26.6701  38.0290  27.0455  41.1431  0.720814   \n",
       "...              ...       ...      ...      ...      ...      ...       ...   \n",
       "664630.0      272.38  6.809500  24.2136  39.8106  25.7730  45.1522  0.605340   \n",
       "3228536.0     395.47  8.788222  30.7981  45.8762  31.8126  50.1589  0.684402   \n",
       "666815.0      397.48  7.643846  32.7074  52.7706  33.6991  59.0659  0.628988   \n",
       "16197082.0    471.61  7.993390  39.3893  59.0906  41.6082  65.2383  0.667615   \n",
       "1519798.0     289.32  8.767273  23.4022  33.4871  23.7672  36.9465  0.709158   \n",
       "\n",
       "                    Me        Mp        Mi  ...  s4_numRotBonds  \\\n",
       "OPTUM_LAB_ID                                ...                   \n",
       "3185712.0     1.006903  0.662830  1.130643  ...             5.5   \n",
       "3532333.0     1.017413  0.736845  1.112339  ...             0.0   \n",
       "16830460.0    1.011764  0.695769  1.126369  ...             0.0   \n",
       "3921421.0     0.999994  0.678216  1.114790  ...             6.0   \n",
       "1314610.0     1.027811  0.730959  1.111976  ...             0.0   \n",
       "...                ...       ...       ...  ...             ...   \n",
       "664630.0      0.995265  0.644325  1.128805  ...             0.0   \n",
       "3228536.0     1.019471  0.706947  1.114642  ...             2.0   \n",
       "666815.0      1.014819  0.648060  1.135883  ...             0.0   \n",
       "16197082.0    1.001536  0.705224  1.105734  ...             3.0   \n",
       "1519798.0     1.014761  0.720218  1.119591  ...             0.0   \n",
       "\n",
       "              s2_numAroBonds  s3_numAroBonds  s4_numAroBonds  s34_size  \\\n",
       "OPTUM_LAB_ID                                                             \n",
       "3185712.0                3.0             0.0            14.0      31.5   \n",
       "3532333.0                0.0             0.0             0.0       0.0   \n",
       "16830460.0               0.0             0.0             0.0       0.0   \n",
       "3921421.0                0.0             6.0            18.0      31.0   \n",
       "1314610.0                0.0             0.0             0.0       0.0   \n",
       "...                      ...             ...             ...       ...   \n",
       "664630.0                 0.0             0.0             0.0       0.0   \n",
       "3228536.0                6.0             5.0             9.0      21.0   \n",
       "666815.0                 0.0             0.0             0.0       0.0   \n",
       "16197082.0               8.0             8.0             6.0      23.5   \n",
       "1519798.0                0.0             0.0             0.0       0.0   \n",
       "\n",
       "              s34_relSize  s34_phSize  s34_phRelSize  chiralMoment  \\\n",
       "OPTUM_LAB_ID                                                         \n",
       "3185712.0        0.828947         9.5       0.250000     40.917043   \n",
       "3532333.0        0.000000         0.0       0.000000      0.000000   \n",
       "16830460.0       0.000000         0.0       0.000000      0.000000   \n",
       "3921421.0        0.885714         4.0       0.114286     33.763886   \n",
       "1314610.0        0.000000         0.0       0.000000      0.000000   \n",
       "...                   ...         ...            ...           ...   \n",
       "664630.0         0.000000         0.0       0.000000      0.000000   \n",
       "3228536.0        0.750000         6.0       0.214286     17.748239   \n",
       "666815.0         0.000000         0.0       0.000000      0.000000   \n",
       "16197082.0       0.691176         4.0       0.117647     19.466228   \n",
       "1519798.0        0.000000         0.0       0.000000      0.000000   \n",
       "\n",
       "              chiralPhMoment  \n",
       "OPTUM_LAB_ID                  \n",
       "3185712.0          12.132410  \n",
       "3532333.0           0.000000  \n",
       "16830460.0          0.000000  \n",
       "3921421.0           4.472136  \n",
       "1314610.0           0.000000  \n",
       "...                      ...  \n",
       "664630.0            0.000000  \n",
       "3228536.0           5.196152  \n",
       "666815.0            0.000000  \n",
       "16197082.0          5.098076  \n",
       "1519798.0           0.000000  \n",
       "\n",
       "[1146 rows x 2248 columns]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_NAomit_data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "1cf34dcf-3f11-4e44-83ca-67542efeea48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5.36720000e+02, 7.66742857e+00, 4.40231000e+01, ...,\n",
       "        2.50000000e-01, 4.09170434e+01, 1.21324101e+01],\n",
       "       [3.59860000e+02, 9.47000000e+00, 2.66692000e+01, ...,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "       [4.72410000e+02, 8.58927273e+00, 3.64596000e+01, ...,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "       ...,\n",
       "       [3.97480000e+02, 7.64384615e+00, 3.27074000e+01, ...,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "       [4.71610000e+02, 7.99338983e+00, 3.93893000e+01, ...,\n",
       "        1.17647059e-01, 1.94662278e+01, 5.09807621e+00],\n",
       "       [2.89320000e+02, 8.76727273e+00, 2.34022000e+01, ...,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00]])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X=np.array(X_NAomit_data)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "fd096547-56ce-48a2-9a6f-210d1e31be3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MW</th>\n",
       "      <th>AMW</th>\n",
       "      <th>Sv</th>\n",
       "      <th>Se</th>\n",
       "      <th>Sp</th>\n",
       "      <th>Si</th>\n",
       "      <th>Mv</th>\n",
       "      <th>Me</th>\n",
       "      <th>Mp</th>\n",
       "      <th>Mi</th>\n",
       "      <th>...</th>\n",
       "      <th>s4_numRotBonds</th>\n",
       "      <th>s2_numAroBonds</th>\n",
       "      <th>s3_numAroBonds</th>\n",
       "      <th>s4_numAroBonds</th>\n",
       "      <th>s34_size</th>\n",
       "      <th>s34_relSize</th>\n",
       "      <th>s34_phSize</th>\n",
       "      <th>s34_phRelSize</th>\n",
       "      <th>chiralMoment</th>\n",
       "      <th>chiralPhMoment</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OPTUM_LAB_ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3185712.0</th>\n",
       "      <td>536.72</td>\n",
       "      <td>7.667429</td>\n",
       "      <td>44.0231</td>\n",
       "      <td>70.4832</td>\n",
       "      <td>46.3981</td>\n",
       "      <td>79.1450</td>\n",
       "      <td>0.628901</td>\n",
       "      <td>1.006903</td>\n",
       "      <td>0.662830</td>\n",
       "      <td>1.130643</td>\n",
       "      <td>...</td>\n",
       "      <td>5.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>31.5</td>\n",
       "      <td>0.828947</td>\n",
       "      <td>9.5</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>40.917043</td>\n",
       "      <td>12.132410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3532333.0</th>\n",
       "      <td>359.86</td>\n",
       "      <td>9.470000</td>\n",
       "      <td>26.6692</td>\n",
       "      <td>38.6617</td>\n",
       "      <td>28.0001</td>\n",
       "      <td>42.2689</td>\n",
       "      <td>0.701821</td>\n",
       "      <td>1.017413</td>\n",
       "      <td>0.736845</td>\n",
       "      <td>1.112339</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16830460.0</th>\n",
       "      <td>472.41</td>\n",
       "      <td>8.589273</td>\n",
       "      <td>36.4596</td>\n",
       "      <td>55.6470</td>\n",
       "      <td>38.2673</td>\n",
       "      <td>61.9503</td>\n",
       "      <td>0.662902</td>\n",
       "      <td>1.011764</td>\n",
       "      <td>0.695769</td>\n",
       "      <td>1.126369</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3921421.0</th>\n",
       "      <td>468.59</td>\n",
       "      <td>7.437937</td>\n",
       "      <td>40.7504</td>\n",
       "      <td>62.9996</td>\n",
       "      <td>42.7276</td>\n",
       "      <td>70.2318</td>\n",
       "      <td>0.646832</td>\n",
       "      <td>0.999994</td>\n",
       "      <td>0.678216</td>\n",
       "      <td>1.114790</td>\n",
       "      <td>...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>0.885714</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.114286</td>\n",
       "      <td>33.763886</td>\n",
       "      <td>4.472136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1314610.0</th>\n",
       "      <td>353.78</td>\n",
       "      <td>9.561622</td>\n",
       "      <td>26.6701</td>\n",
       "      <td>38.0290</td>\n",
       "      <td>27.0455</td>\n",
       "      <td>41.1431</td>\n",
       "      <td>0.720814</td>\n",
       "      <td>1.027811</td>\n",
       "      <td>0.730959</td>\n",
       "      <td>1.111976</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>664630.0</th>\n",
       "      <td>272.38</td>\n",
       "      <td>6.809500</td>\n",
       "      <td>24.2136</td>\n",
       "      <td>39.8106</td>\n",
       "      <td>25.7730</td>\n",
       "      <td>45.1522</td>\n",
       "      <td>0.605340</td>\n",
       "      <td>0.995265</td>\n",
       "      <td>0.644325</td>\n",
       "      <td>1.128805</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3228536.0</th>\n",
       "      <td>395.47</td>\n",
       "      <td>8.788222</td>\n",
       "      <td>30.7981</td>\n",
       "      <td>45.8762</td>\n",
       "      <td>31.8126</td>\n",
       "      <td>50.1589</td>\n",
       "      <td>0.684402</td>\n",
       "      <td>1.019471</td>\n",
       "      <td>0.706947</td>\n",
       "      <td>1.114642</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.214286</td>\n",
       "      <td>17.748239</td>\n",
       "      <td>5.196152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>666815.0</th>\n",
       "      <td>397.48</td>\n",
       "      <td>7.643846</td>\n",
       "      <td>32.7074</td>\n",
       "      <td>52.7706</td>\n",
       "      <td>33.6991</td>\n",
       "      <td>59.0659</td>\n",
       "      <td>0.628988</td>\n",
       "      <td>1.014819</td>\n",
       "      <td>0.648060</td>\n",
       "      <td>1.135883</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16197082.0</th>\n",
       "      <td>471.61</td>\n",
       "      <td>7.993390</td>\n",
       "      <td>39.3893</td>\n",
       "      <td>59.0906</td>\n",
       "      <td>41.6082</td>\n",
       "      <td>65.2383</td>\n",
       "      <td>0.667615</td>\n",
       "      <td>1.001536</td>\n",
       "      <td>0.705224</td>\n",
       "      <td>1.105734</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>23.5</td>\n",
       "      <td>0.691176</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.117647</td>\n",
       "      <td>19.466228</td>\n",
       "      <td>5.098076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1519798.0</th>\n",
       "      <td>289.32</td>\n",
       "      <td>8.767273</td>\n",
       "      <td>23.4022</td>\n",
       "      <td>33.4871</td>\n",
       "      <td>23.7672</td>\n",
       "      <td>36.9465</td>\n",
       "      <td>0.709158</td>\n",
       "      <td>1.014761</td>\n",
       "      <td>0.720218</td>\n",
       "      <td>1.119591</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1146 rows × 2248 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  MW       AMW       Sv       Se       Sp       Si        Mv  \\\n",
       "OPTUM_LAB_ID                                                                   \n",
       "3185712.0     536.72  7.667429  44.0231  70.4832  46.3981  79.1450  0.628901   \n",
       "3532333.0     359.86  9.470000  26.6692  38.6617  28.0001  42.2689  0.701821   \n",
       "16830460.0    472.41  8.589273  36.4596  55.6470  38.2673  61.9503  0.662902   \n",
       "3921421.0     468.59  7.437937  40.7504  62.9996  42.7276  70.2318  0.646832   \n",
       "1314610.0     353.78  9.561622  26.6701  38.0290  27.0455  41.1431  0.720814   \n",
       "...              ...       ...      ...      ...      ...      ...       ...   \n",
       "664630.0      272.38  6.809500  24.2136  39.8106  25.7730  45.1522  0.605340   \n",
       "3228536.0     395.47  8.788222  30.7981  45.8762  31.8126  50.1589  0.684402   \n",
       "666815.0      397.48  7.643846  32.7074  52.7706  33.6991  59.0659  0.628988   \n",
       "16197082.0    471.61  7.993390  39.3893  59.0906  41.6082  65.2383  0.667615   \n",
       "1519798.0     289.32  8.767273  23.4022  33.4871  23.7672  36.9465  0.709158   \n",
       "\n",
       "                    Me        Mp        Mi  ...  s4_numRotBonds  \\\n",
       "OPTUM_LAB_ID                                ...                   \n",
       "3185712.0     1.006903  0.662830  1.130643  ...             5.5   \n",
       "3532333.0     1.017413  0.736845  1.112339  ...             0.0   \n",
       "16830460.0    1.011764  0.695769  1.126369  ...             0.0   \n",
       "3921421.0     0.999994  0.678216  1.114790  ...             6.0   \n",
       "1314610.0     1.027811  0.730959  1.111976  ...             0.0   \n",
       "...                ...       ...       ...  ...             ...   \n",
       "664630.0      0.995265  0.644325  1.128805  ...             0.0   \n",
       "3228536.0     1.019471  0.706947  1.114642  ...             2.0   \n",
       "666815.0      1.014819  0.648060  1.135883  ...             0.0   \n",
       "16197082.0    1.001536  0.705224  1.105734  ...             3.0   \n",
       "1519798.0     1.014761  0.720218  1.119591  ...             0.0   \n",
       "\n",
       "              s2_numAroBonds  s3_numAroBonds  s4_numAroBonds  s34_size  \\\n",
       "OPTUM_LAB_ID                                                             \n",
       "3185712.0                3.0             0.0            14.0      31.5   \n",
       "3532333.0                0.0             0.0             0.0       0.0   \n",
       "16830460.0               0.0             0.0             0.0       0.0   \n",
       "3921421.0                0.0             6.0            18.0      31.0   \n",
       "1314610.0                0.0             0.0             0.0       0.0   \n",
       "...                      ...             ...             ...       ...   \n",
       "664630.0                 0.0             0.0             0.0       0.0   \n",
       "3228536.0                6.0             5.0             9.0      21.0   \n",
       "666815.0                 0.0             0.0             0.0       0.0   \n",
       "16197082.0               8.0             8.0             6.0      23.5   \n",
       "1519798.0                0.0             0.0             0.0       0.0   \n",
       "\n",
       "              s34_relSize  s34_phSize  s34_phRelSize  chiralMoment  \\\n",
       "OPTUM_LAB_ID                                                         \n",
       "3185712.0        0.828947         9.5       0.250000     40.917043   \n",
       "3532333.0        0.000000         0.0       0.000000      0.000000   \n",
       "16830460.0       0.000000         0.0       0.000000      0.000000   \n",
       "3921421.0        0.885714         4.0       0.114286     33.763886   \n",
       "1314610.0        0.000000         0.0       0.000000      0.000000   \n",
       "...                   ...         ...            ...           ...   \n",
       "664630.0         0.000000         0.0       0.000000      0.000000   \n",
       "3228536.0        0.750000         6.0       0.214286     17.748239   \n",
       "666815.0         0.000000         0.0       0.000000      0.000000   \n",
       "16197082.0       0.691176         4.0       0.117647     19.466228   \n",
       "1519798.0        0.000000         0.0       0.000000      0.000000   \n",
       "\n",
       "              chiralPhMoment  \n",
       "OPTUM_LAB_ID                  \n",
       "3185712.0          12.132410  \n",
       "3532333.0           0.000000  \n",
       "16830460.0          0.000000  \n",
       "3921421.0           4.472136  \n",
       "1314610.0           0.000000  \n",
       "...                      ...  \n",
       "664630.0            0.000000  \n",
       "3228536.0           5.196152  \n",
       "666815.0            0.000000  \n",
       "16197082.0          5.098076  \n",
       "1519798.0           0.000000  \n",
       "\n",
       "[1146 rows x 2248 columns]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_NAomit_data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "f561878b-84e9-41a4-aecf-49bd8626f377",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>IsomericSMILES</th>\n",
       "      <th>Activity</th>\n",
       "      <th>Canonical_smiles</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OPTUM_LAB_ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3185712.0</th>\n",
       "      <td>CC1=CC=CC=C1N(C(C2=CC=C(C=C2)N(C)C)C(=O)NCC3CC...</td>\n",
       "      <td>1</td>\n",
       "      <td>Cc1ccccc1N(C(=O)c1snc(C(N)=O)c1N)C(C(=O)NCC1CC...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3532333.0</th>\n",
       "      <td>C1=CC=C2C(=C1)C(=O)N(C(=S)N2)CCC(=O)NC3=CC(=CC...</td>\n",
       "      <td>1</td>\n",
       "      <td>O=C(CCn1c(=S)[nH]c2ccccc2c1=O)Nc1cccc(Cl)c1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16830460.0</th>\n",
       "      <td>CN1CCN(CC1)C2=NN=C(C=C2)C3=CC(=CC=C3)NC(=O)COC...</td>\n",
       "      <td>1</td>\n",
       "      <td>CN1CCN(c2ccc(-c3cccc(NC(=O)COc4ccc(Cl)cc4Cl)c3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3921421.0</th>\n",
       "      <td>CC1=CC(=NC(=N1)OC(C(=O)O)C(C2=CC=CC=C2)(C3=CC=...</td>\n",
       "      <td>1</td>\n",
       "      <td>Cc1cc(C)nc(OC(C(=O)O)C(OCCc2ccccc2)(c2ccccc2)c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1314610.0</th>\n",
       "      <td>C1OC2=CC=CC(=C2O1)CNC3=C(N=C(O3)C4=CC=C(C=C4)C...</td>\n",
       "      <td>1</td>\n",
       "      <td>N#Cc1nc(-c2ccc(Cl)cc2)oc1NCc1cccc2c1OCO2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>664630.0</th>\n",
       "      <td>CCC(=O)N(CC1=CC2=CC=CC=C2NC1=O)C(C)C</td>\n",
       "      <td>0</td>\n",
       "      <td>CCC(=O)N(Cc1cc2ccccc2[nH]c1=O)C(C)C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3228536.0</th>\n",
       "      <td>CN1C2=C(C=C1C(=O)OC(C3=CC=NC=C3)C(=O)NCC4=CC=C...</td>\n",
       "      <td>0</td>\n",
       "      <td>Cn1c(C(=O)OC(C(=O)NCc2ccco2)c2ccncc2)cc2sccc21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>666815.0</th>\n",
       "      <td>CN1C2=C(C(=O)N(C1=O)C)N(C(=N2)CN3CCOCC3)CC(=O)...</td>\n",
       "      <td>0</td>\n",
       "      <td>Cn1c(=O)c2c(nc(CN3CCOCC3)n2CC(=O)c2ccccc2)n(C)...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16197082.0</th>\n",
       "      <td>C1[C@H](C=C(O[C@H]1OCC2=CC=C(C=C2)CO)C(=O)NC3=...</td>\n",
       "      <td>0</td>\n",
       "      <td>O=C(Nc1ccccc1)C1=C[C@H](c2csc3ccccc23)C[C@H](O...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1519798.0</th>\n",
       "      <td>C1=CC=C(C=C1)N2C(=NN=N2)OC3=CC=CC4=C3N=CC=C4</td>\n",
       "      <td>0</td>\n",
       "      <td>c1ccc(-n2nnnc2Oc2cccc3cccnc23)cc1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1146 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 IsomericSMILES  Activity  \\\n",
       "OPTUM_LAB_ID                                                                \n",
       "3185712.0     CC1=CC=CC=C1N(C(C2=CC=C(C=C2)N(C)C)C(=O)NCC3CC...         1   \n",
       "3532333.0     C1=CC=C2C(=C1)C(=O)N(C(=S)N2)CCC(=O)NC3=CC(=CC...         1   \n",
       "16830460.0    CN1CCN(CC1)C2=NN=C(C=C2)C3=CC(=CC=C3)NC(=O)COC...         1   \n",
       "3921421.0     CC1=CC(=NC(=N1)OC(C(=O)O)C(C2=CC=CC=C2)(C3=CC=...         1   \n",
       "1314610.0     C1OC2=CC=CC(=C2O1)CNC3=C(N=C(O3)C4=CC=C(C=C4)C...         1   \n",
       "...                                                         ...       ...   \n",
       "664630.0                   CCC(=O)N(CC1=CC2=CC=CC=C2NC1=O)C(C)C         0   \n",
       "3228536.0     CN1C2=C(C=C1C(=O)OC(C3=CC=NC=C3)C(=O)NCC4=CC=C...         0   \n",
       "666815.0      CN1C2=C(C(=O)N(C1=O)C)N(C(=N2)CN3CCOCC3)CC(=O)...         0   \n",
       "16197082.0    C1[C@H](C=C(O[C@H]1OCC2=CC=C(C=C2)CO)C(=O)NC3=...         0   \n",
       "1519798.0          C1=CC=C(C=C1)N2C(=NN=N2)OC3=CC=CC4=C3N=CC=C4         0   \n",
       "\n",
       "                                               Canonical_smiles  \n",
       "OPTUM_LAB_ID                                                     \n",
       "3185712.0     Cc1ccccc1N(C(=O)c1snc(C(N)=O)c1N)C(C(=O)NCC1CC...  \n",
       "3532333.0           O=C(CCn1c(=S)[nH]c2ccccc2c1=O)Nc1cccc(Cl)c1  \n",
       "16830460.0    CN1CCN(c2ccc(-c3cccc(NC(=O)COc4ccc(Cl)cc4Cl)c3...  \n",
       "3921421.0     Cc1cc(C)nc(OC(C(=O)O)C(OCCc2ccccc2)(c2ccccc2)c...  \n",
       "1314610.0              N#Cc1nc(-c2ccc(Cl)cc2)oc1NCc1cccc2c1OCO2  \n",
       "...                                                         ...  \n",
       "664630.0                    CCC(=O)N(Cc1cc2ccccc2[nH]c1=O)C(C)C  \n",
       "3228536.0        Cn1c(C(=O)OC(C(=O)NCc2ccco2)c2ccncc2)cc2sccc21  \n",
       "666815.0      Cn1c(=O)c2c(nc(CN3CCOCC3)n2CC(=O)c2ccccc2)n(C)...  \n",
       "16197082.0    O=C(Nc1ccccc1)C1=C[C@H](c2csc3ccccc23)C[C@H](O...  \n",
       "1519798.0                     c1ccc(-n2nnnc2Oc2cccc3cccnc23)cc1  \n",
       "\n",
       "[1146 rows x 3 columns]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Raw_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "066559ff-aefe-4de1-98aa-04e6e2d7d8de",
   "metadata": {},
   "outputs": [],
   "source": [
    "y=Raw_data['Activity']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "8f04d536-af36-4f80-8c82-b43e30cbf6d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "Cv_model= RepeatedStratifiedKFold(n_splits=5, n_repeats=10, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdf835fc-df29-4f95-ac06-6cc88fa619f2",
   "metadata": {},
   "source": [
    "# 1. LASSO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "07038cde-c52d-4ba2-b851-445a650f8dc7",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.388e-02, tolerance: 2.290e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.531e-02, tolerance: 2.290e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.189e-02, tolerance: 2.290e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.465e-02, tolerance: 2.290e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.560e-02, tolerance: 2.290e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.676e-01, tolerance: 2.290e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.284e-01, tolerance: 2.290e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.122e-01, tolerance: 2.290e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.091e-01, tolerance: 2.290e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.273e-01, tolerance: 2.290e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.004e-01, tolerance: 2.290e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.157e-01, tolerance: 2.290e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.159e-01, tolerance: 2.290e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.119e-01, tolerance: 2.290e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.595e-01, tolerance: 2.290e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.762e-01, tolerance: 2.290e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.697e-01, tolerance: 2.290e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.074e-01, tolerance: 2.290e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.680e-01, tolerance: 2.290e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.552e-01, tolerance: 2.290e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.929e-01, tolerance: 2.290e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.158e+00, tolerance: 2.290e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.424e+00, tolerance: 2.290e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.222e+00, tolerance: 2.290e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.082e+00, tolerance: 2.290e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.323e-01, tolerance: 2.290e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.640e-01, tolerance: 2.290e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.367e+00, tolerance: 2.290e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.704e+00, tolerance: 2.290e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.628e+00, tolerance: 2.290e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.805e+00, tolerance: 2.290e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.489e+00, tolerance: 2.290e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.433e+00, tolerance: 2.290e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.337e+00, tolerance: 2.290e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.518e+00, tolerance: 2.290e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.929e+00, tolerance: 2.290e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.032e+00, tolerance: 2.290e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.724e+00, tolerance: 2.290e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.916e+00, tolerance: 2.290e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.139e-02, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.740e-02, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.050e-02, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.066e-02, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.763e-02, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.035e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.254e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.224e-02, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.849e-02, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.173e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.323e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.463e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.479e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.307e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.109e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.346e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.147e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.492e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.950e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.136e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.562e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.454e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.836e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.179e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.805e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.460e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.902e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.108e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.845e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.530e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.303e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.633e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.719e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.906e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.566e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.772e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.101e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.308e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.267e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.213e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.243e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.142e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.232e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.121e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.263e-02, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.072e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.253e-02, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.353e-02, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.448e-02, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.656e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.608e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.485e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.154e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.654e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.386e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.840e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.019e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.699e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.407e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.730e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.446e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.224e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.077e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.630e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.443e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.461e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.488e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.134e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.600e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.941e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.137e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.064e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.861e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.761e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.653e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.606e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.667e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.662e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.724e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.983e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.263e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.494e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.546e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.656e-02, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.207e-02, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.404e-02, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.003e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.302e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.753e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.436e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.934e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.569e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.700e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.733e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.726e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.021e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.591e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.428e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.880e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.824e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.301e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.509e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.947e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.598e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.395e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.464e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.529e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.058e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.402e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.994e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.070e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.906e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.679e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.852e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.254e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.460e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.353e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.239e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.893e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.025e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.793e-02, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.078e-02, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.047e-02, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.962e-02, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.602e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.968e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.913e-02, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.096e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.240e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.497e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.544e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.886e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.042e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.466e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.116e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.518e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.408e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.363e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.374e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.036e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.928e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.183e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.334e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.272e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.198e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.050e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.566e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.472e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.610e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.846e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.060e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.185e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.446e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.357e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.407e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.656e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.537e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.631e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.601e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.041e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.996e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.139e-02, tolerance: 2.290e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.298e-02, tolerance: 2.290e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.442e-02, tolerance: 2.290e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.983e-02, tolerance: 2.290e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.086e-01, tolerance: 2.290e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.125e-01, tolerance: 2.290e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.411e-01, tolerance: 2.290e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.083e-01, tolerance: 2.290e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.889e-01, tolerance: 2.290e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.222e-01, tolerance: 2.290e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.504e-01, tolerance: 2.290e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.732e-01, tolerance: 2.290e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.680e-01, tolerance: 2.290e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.152e-01, tolerance: 2.290e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.327e+00, tolerance: 2.290e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.223e+00, tolerance: 2.290e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.687e-01, tolerance: 2.290e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.073e+00, tolerance: 2.290e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.344e+00, tolerance: 2.290e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.480e+00, tolerance: 2.290e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.139e+00, tolerance: 2.290e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.033e+00, tolerance: 2.290e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.026e-01, tolerance: 2.290e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.252e-01, tolerance: 2.290e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.132e-01, tolerance: 2.290e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.143e+00, tolerance: 2.290e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.144e+00, tolerance: 2.290e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.524e+00, tolerance: 2.290e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.706e+00, tolerance: 2.290e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.607e+00, tolerance: 2.290e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.533e+00, tolerance: 2.290e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.411e+00, tolerance: 2.290e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.328e+00, tolerance: 2.290e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.468e+00, tolerance: 2.290e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.849e+00, tolerance: 2.290e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.779e+00, tolerance: 2.290e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.558e+00, tolerance: 2.290e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.694e+00, tolerance: 2.290e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.121e+00, tolerance: 2.290e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.679e-02, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.968e-02, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.649e-02, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.794e-02, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.705e-02, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.630e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.466e-02, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.368e-02, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.104e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.294e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.082e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.144e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.083e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.587e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.600e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.473e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.137e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.113e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.314e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.000e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.985e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.234e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.036e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.219e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.580e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.475e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.449e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.125e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.968e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.686e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.044e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.295e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.493e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.836e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.087e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.328e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.624e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.691e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.375e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.497e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.592e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.575e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.732e-02, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.164e-02, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.026e-02, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.767e-02, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.916e-02, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.352e-02, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.717e-02, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.691e-02, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.222e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.048e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.187e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.316e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.830e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.530e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.966e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.989e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.861e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.055e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.322e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.479e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.654e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.209e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.756e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.323e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.307e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.163e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.051e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.099e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.011e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.059e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.038e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.036e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.120e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.149e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.312e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.619e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.888e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.250e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.050e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.119e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.130e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.317e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.660e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.831e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.778e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.513e-02, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.384e-02, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.235e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.583e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.242e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.020e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.004e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.873e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.518e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.264e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.508e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.156e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.055e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.128e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.895e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.218e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.701e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.149e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.989e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.196e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.157e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.565e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.643e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.355e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.506e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.480e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.227e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.087e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.234e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.221e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.197e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.090e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.479e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.801e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.784e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.667e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.535e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.544e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.862e-02, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.480e-02, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.568e-02, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.199e-02, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.238e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.204e-02, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.246e-02, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.503e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.468e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.745e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.892e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.824e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.254e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.608e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.233e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.687e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.355e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.274e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.095e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.794e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.562e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.095e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.399e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.424e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.544e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.609e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.778e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.598e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.492e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.518e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.733e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.739e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.661e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.847e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.164e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.414e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.436e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.005e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.171e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.915e-02, tolerance: 2.290e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.197e-02, tolerance: 2.290e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.940e-02, tolerance: 2.290e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.291e-02, tolerance: 2.290e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.531e-01, tolerance: 2.290e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.903e-02, tolerance: 2.290e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.106e-02, tolerance: 2.290e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.345e-02, tolerance: 2.290e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.342e-01, tolerance: 2.290e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.587e-01, tolerance: 2.290e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.736e-01, tolerance: 2.290e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.529e-01, tolerance: 2.290e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.263e-01, tolerance: 2.290e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.764e-01, tolerance: 2.290e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.215e-01, tolerance: 2.290e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.071e-01, tolerance: 2.290e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.338e-01, tolerance: 2.290e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.821e-01, tolerance: 2.290e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.618e-01, tolerance: 2.290e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.604e-01, tolerance: 2.290e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.473e-01, tolerance: 2.290e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.371e-01, tolerance: 2.290e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.599e-01, tolerance: 2.290e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.733e-01, tolerance: 2.290e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.182e-01, tolerance: 2.290e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.873e-01, tolerance: 2.290e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.997e-01, tolerance: 2.290e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.115e-01, tolerance: 2.290e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.916e-01, tolerance: 2.290e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.203e+00, tolerance: 2.290e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.083e+00, tolerance: 2.290e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.441e+00, tolerance: 2.290e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.648e+00, tolerance: 2.290e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.823e+00, tolerance: 2.290e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.447e+00, tolerance: 2.290e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.746e+00, tolerance: 2.290e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.966e+00, tolerance: 2.290e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.116e+00, tolerance: 2.290e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.114e+00, tolerance: 2.290e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.185e+00, tolerance: 2.290e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.121e+00, tolerance: 2.290e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.604e-02, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.722e-02, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.116e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.152e-02, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.052e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.790e-02, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.392e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.257e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.949e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.278e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.706e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.687e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.441e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.108e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.673e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.378e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.392e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.360e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.218e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.650e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.080e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.099e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.232e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.172e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.170e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.247e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.877e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.266e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.260e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.492e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.427e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.258e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.714e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.799e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.843e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.884e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.832e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.250e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.246e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.220e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.982e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.197e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.579e-02, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.483e-02, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.649e-02, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.029e-02, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.649e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.477e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.200e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.615e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.385e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.073e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.138e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.729e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.276e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.477e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.913e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.649e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.027e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.735e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.020e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.297e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.108e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.111e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.538e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.268e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.918e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.059e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.411e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.184e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.565e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.716e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.693e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.461e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.655e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.391e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.810e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.005e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.424e-02, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.563e-02, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.818e-02, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.077e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.396e-02, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.493e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.458e-02, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.424e-02, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.640e-02, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.307e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.343e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.106e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.872e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.166e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.938e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.861e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.218e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.527e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.729e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.937e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.851e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.881e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.160e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.197e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.486e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.305e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.234e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.081e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.110e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.028e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.223e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.477e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.661e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.842e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.867e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.275e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.367e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.629e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.847e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.207e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.142e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.853e-02, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.442e-02, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.837e-02, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.164e-02, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.323e-02, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.573e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.796e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.351e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.320e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.807e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.202e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.281e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.270e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.289e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.126e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.612e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.009e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.937e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.209e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.594e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.713e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.261e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.817e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.185e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.232e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.131e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.593e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.367e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.113e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.249e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.357e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.269e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.277e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.358e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.746e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.964e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.862e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.115e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.223e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.583e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.412e-02, tolerance: 2.290e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.270e-02, tolerance: 2.290e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.493e-02, tolerance: 2.290e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.348e-01, tolerance: 2.290e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.524e-01, tolerance: 2.290e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.435e-01, tolerance: 2.290e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.207e-01, tolerance: 2.290e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.789e-01, tolerance: 2.290e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.695e-01, tolerance: 2.290e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.538e-01, tolerance: 2.290e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.321e-01, tolerance: 2.290e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.034e-01, tolerance: 2.290e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.211e-01, tolerance: 2.290e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.668e-01, tolerance: 2.290e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.133e-01, tolerance: 2.290e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.766e-01, tolerance: 2.290e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.675e-01, tolerance: 2.290e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.969e-01, tolerance: 2.290e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.686e-01, tolerance: 2.290e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.718e-01, tolerance: 2.290e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.674e-01, tolerance: 2.290e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.911e-01, tolerance: 2.290e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.252e+00, tolerance: 2.290e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.417e+00, tolerance: 2.290e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.782e+00, tolerance: 2.290e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.027e+00, tolerance: 2.290e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.795e+00, tolerance: 2.290e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.622e+00, tolerance: 2.290e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.571e+00, tolerance: 2.290e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.521e+00, tolerance: 2.290e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.630e+00, tolerance: 2.290e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.668e+00, tolerance: 2.290e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.824e+00, tolerance: 2.290e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.962e+00, tolerance: 2.290e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.992e+00, tolerance: 2.290e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.159e+00, tolerance: 2.290e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.133e+00, tolerance: 2.290e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.237e+00, tolerance: 2.290e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.961e-02, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.253e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.063e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.522e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.582e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.977e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.492e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.201e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.433e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.852e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.945e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.155e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.620e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.408e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.867e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.072e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.879e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.642e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.689e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.989e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.283e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.456e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.477e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.098e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.409e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.710e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.102e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.465e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.837e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.255e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.018e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.529e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.469e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.611e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.621e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.809e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.665e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.512e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.306e-02, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.374e-02, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.298e-02, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.874e-02, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.850e-02, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.715e-02, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.293e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.608e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.294e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.483e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.221e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.693e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.340e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.806e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.894e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.649e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.722e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.307e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.470e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.778e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.232e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.537e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.171e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.480e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.415e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.445e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.584e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.994e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.189e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.226e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.089e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.285e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.432e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.597e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.263e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.457e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.092e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.329e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.689e-02, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.103e-02, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.863e-02, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.326e-02, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.092e-02, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.332e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.163e-02, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.082e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.985e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.025e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.078e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.398e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.841e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.075e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.035e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.903e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.238e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.038e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.107e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.033e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.104e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.208e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.287e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.468e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.654e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.705e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.819e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.621e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.465e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.942e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.100e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.241e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.515e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.484e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.692e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.817e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.981e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.760e-02, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.536e-02, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.526e-02, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.551e-02, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.046e-02, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.627e-02, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.853e-02, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.251e-02, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.747e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.264e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.228e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.088e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.501e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.231e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.784e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.892e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.242e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.574e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.039e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.008e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.084e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.309e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.103e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.727e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.888e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.097e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.390e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.830e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.020e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.338e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.481e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.787e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.668e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.110e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.905e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.157e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.254e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.413e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.610e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.470e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.348e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.512e-02, tolerance: 2.290e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.335e-02, tolerance: 2.290e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.534e-02, tolerance: 2.290e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.775e-02, tolerance: 2.290e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.358e-02, tolerance: 2.290e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.297e-01, tolerance: 2.290e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.592e-01, tolerance: 2.290e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.100e-01, tolerance: 2.290e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.130e-01, tolerance: 2.290e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.938e-01, tolerance: 2.290e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.211e-01, tolerance: 2.290e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.846e-01, tolerance: 2.290e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.341e-01, tolerance: 2.290e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.002e-01, tolerance: 2.290e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.509e-01, tolerance: 2.290e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.496e-01, tolerance: 2.290e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.754e-01, tolerance: 2.290e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.292e-01, tolerance: 2.290e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.540e-01, tolerance: 2.290e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.955e-01, tolerance: 2.290e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.545e-01, tolerance: 2.290e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.580e-01, tolerance: 2.290e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.318e-01, tolerance: 2.290e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.704e-01, tolerance: 2.290e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.802e-01, tolerance: 2.290e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.125e+00, tolerance: 2.290e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.362e+00, tolerance: 2.290e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.637e+00, tolerance: 2.290e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.771e+00, tolerance: 2.290e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.741e+00, tolerance: 2.290e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.261e+00, tolerance: 2.290e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.244e+00, tolerance: 2.290e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.249e+00, tolerance: 2.290e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.406e+00, tolerance: 2.290e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.587e+00, tolerance: 2.290e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.060e+00, tolerance: 2.290e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.111e+00, tolerance: 2.290e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.078e+00, tolerance: 2.290e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.524e+00, tolerance: 2.290e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.987e+00, tolerance: 2.290e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.111e+00, tolerance: 2.290e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.030e-02, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.214e-02, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.458e-02, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.060e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.510e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.738e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.942e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.703e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.535e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.697e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.807e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.770e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.823e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.818e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.481e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.624e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.929e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.250e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.250e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.244e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.696e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.118e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.527e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.783e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.007e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.068e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.863e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.390e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.502e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.403e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.969e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.519e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.279e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.771e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.799e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.354e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.785e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.282e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.174e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.125e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.133e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.438e-02, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.539e-02, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.474e-02, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.532e-02, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.458e-02, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.945e-02, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.091e-02, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.554e-02, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.829e-02, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.934e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.161e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.848e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.382e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.385e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.951e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.753e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.481e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.957e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.182e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.943e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.504e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.231e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.451e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.409e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.862e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.460e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.333e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.659e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.746e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.412e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.891e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.138e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.339e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.667e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.460e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.385e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.370e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.268e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.953e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.009e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.169e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.422e-02, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.709e-02, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.045e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.673e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.363e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.458e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.604e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.797e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.238e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.871e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.507e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.353e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.672e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.866e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.151e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.044e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.455e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.475e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.498e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.416e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.717e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.420e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.736e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.555e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.277e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.082e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.079e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.407e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.605e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.270e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.427e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.070e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.402e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.377e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.539e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.582e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.036e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.447e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.741e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.431e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.452e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.201e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.354e-02, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.145e-02, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.721e-02, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.444e-02, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.231e-02, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.824e-02, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.029e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.336e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.139e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.637e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.199e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.852e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.500e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.515e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.755e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.764e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.400e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.111e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.089e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.655e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.251e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.055e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.455e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.136e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.762e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.130e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.907e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.326e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.020e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.134e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.091e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.433e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.431e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.245e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.435e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.495e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.513e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.738e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.791e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.008e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.133e-02, tolerance: 2.290e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.161e-02, tolerance: 2.290e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.298e-02, tolerance: 2.290e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.343e-02, tolerance: 2.290e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.814e-02, tolerance: 2.290e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.468e-02, tolerance: 2.290e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.353e-02, tolerance: 2.290e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.153e-02, tolerance: 2.290e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.974e-02, tolerance: 2.290e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.823e-02, tolerance: 2.290e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.013e-01, tolerance: 2.290e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.017e-02, tolerance: 2.290e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.160e-01, tolerance: 2.290e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.029e-01, tolerance: 2.290e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.609e-02, tolerance: 2.290e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.692e-01, tolerance: 2.290e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.449e-01, tolerance: 2.290e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.016e-01, tolerance: 2.290e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.831e-01, tolerance: 2.290e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.390e-01, tolerance: 2.290e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.351e-01, tolerance: 2.290e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.697e-01, tolerance: 2.290e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.526e-01, tolerance: 2.290e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.430e-01, tolerance: 2.290e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.901e-01, tolerance: 2.290e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.373e-01, tolerance: 2.290e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.500e-01, tolerance: 2.290e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.201e+00, tolerance: 2.290e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.257e+00, tolerance: 2.290e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.566e+00, tolerance: 2.290e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.729e+00, tolerance: 2.290e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.908e+00, tolerance: 2.290e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.957e+00, tolerance: 2.290e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.947e+00, tolerance: 2.290e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.955e+00, tolerance: 2.290e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.073e+00, tolerance: 2.290e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.277e+00, tolerance: 2.290e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.145e+00, tolerance: 2.290e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.286e+00, tolerance: 2.290e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.553e+00, tolerance: 2.290e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.586e+00, tolerance: 2.290e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.605e+00, tolerance: 2.290e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.666e+00, tolerance: 2.290e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.659e+00, tolerance: 2.290e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.739e+00, tolerance: 2.290e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.762e+00, tolerance: 2.290e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.208e-02, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.110e-02, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.166e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.970e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.389e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.718e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.438e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.274e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.681e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.347e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.135e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.616e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.512e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.724e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.119e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.562e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.525e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.591e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.907e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.647e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.985e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.412e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.987e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.157e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.112e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.031e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.398e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.871e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.216e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.148e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.019e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.238e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.129e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.247e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.991e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.884e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.203e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.204e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.179e-02, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.292e-02, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.272e-02, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.524e-02, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.520e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.520e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.148e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.218e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.425e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.450e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.666e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.880e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.236e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.813e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.773e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.701e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.444e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.106e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.021e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.725e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.055e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.059e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.915e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.045e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.933e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.171e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.385e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.793e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.122e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.474e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.225e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.728e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.937e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.158e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.503e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.640e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.610e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.674e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.869e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.009e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.321e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.625e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.637e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.525e-02, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.362e-02, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.831e-02, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.545e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.312e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.235e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.089e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.413e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.035e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.138e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.348e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.118e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.913e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.758e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.799e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.019e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.636e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.575e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.758e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.377e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.315e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.068e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.197e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.492e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.758e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.987e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.123e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.784e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.307e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.583e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.701e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.980e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.256e-02, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.917e-02, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.812e-02, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.757e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.065e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.276e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.816e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.545e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.355e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.156e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.520e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.017e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.547e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.942e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.237e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.620e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.641e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.596e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.101e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.374e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.142e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.516e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.630e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.330e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.977e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.936e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.814e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.646e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.451e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.271e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.671e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.066e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.247e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.618e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.865e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.376e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.013e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.857e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.995e-02, tolerance: 2.290e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.986e-02, tolerance: 2.290e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.690e-02, tolerance: 2.290e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.904e-02, tolerance: 2.290e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.746e-02, tolerance: 2.290e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.476e-02, tolerance: 2.290e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.538e-01, tolerance: 2.290e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.590e-01, tolerance: 2.290e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.011e-01, tolerance: 2.290e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.434e-01, tolerance: 2.290e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.028e-01, tolerance: 2.290e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.681e-01, tolerance: 2.290e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.947e-01, tolerance: 2.290e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.506e-01, tolerance: 2.290e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.635e-01, tolerance: 2.290e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.040e-01, tolerance: 2.290e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.533e-01, tolerance: 2.290e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.328e-01, tolerance: 2.290e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.531e-01, tolerance: 2.290e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.999e-01, tolerance: 2.290e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.750e-01, tolerance: 2.290e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.462e-01, tolerance: 2.290e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.992e-01, tolerance: 2.290e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.079e-01, tolerance: 2.290e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.237e-01, tolerance: 2.290e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.473e-01, tolerance: 2.290e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.747e-01, tolerance: 2.290e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.247e-01, tolerance: 2.290e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.069e+00, tolerance: 2.290e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.233e-01, tolerance: 2.290e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.114e+00, tolerance: 2.290e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.115e+00, tolerance: 2.290e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.404e+00, tolerance: 2.290e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.906e+00, tolerance: 2.290e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.203e+00, tolerance: 2.290e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.181e+00, tolerance: 2.290e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.871e+00, tolerance: 2.290e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.745e+00, tolerance: 2.290e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.525e+00, tolerance: 2.290e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.564e+00, tolerance: 2.290e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.762e+00, tolerance: 2.290e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.807e+00, tolerance: 2.290e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.365e-02, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.202e-02, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.939e-02, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.212e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.152e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.251e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.326e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.966e-02, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.891e-02, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.078e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.602e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.495e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.319e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.562e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.257e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.820e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.008e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.007e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.523e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.533e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.060e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.671e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.128e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.367e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.006e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.339e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.437e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.407e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.569e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.591e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.734e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.696e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.147e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.061e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.670e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.101e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.155e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.244e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.410e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.677e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.954e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.504e-02, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.531e-02, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.711e-02, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.505e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.154e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.885e-02, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.887e-02, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.881e-02, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.525e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.715e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.612e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.261e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.356e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.727e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.969e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.671e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.234e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.353e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.083e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.029e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.936e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.591e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.215e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.621e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.322e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.189e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.197e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.149e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.277e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.494e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.811e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.655e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.590e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.970e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.096e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.134e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.053e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.967e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.833e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.988e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.934e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.974e-02, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.078e-02, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.441e-02, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.589e-02, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.228e-02, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.787e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.149e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.142e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.118e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.035e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.840e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.362e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.228e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.444e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.268e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.036e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.452e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.848e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.964e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.689e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.818e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.174e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.928e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.155e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.694e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.797e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.499e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.350e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.403e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.606e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.657e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.729e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.675e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.794e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.689e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.525e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.567e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.296e-02, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.450e-02, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.189e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.751e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.009e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.179e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.476e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.166e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.582e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.818e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.921e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.602e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.161e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.934e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.578e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.433e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.340e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.741e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.907e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.976e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.040e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.095e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.111e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.705e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.727e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.151e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.431e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.437e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.188e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.377e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.451e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.767e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.842e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.631e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.555e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.577e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.523e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.411e-02, tolerance: 2.290e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.116e-02, tolerance: 2.290e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.087e-02, tolerance: 2.290e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.386e-01, tolerance: 2.290e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.215e-01, tolerance: 2.290e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.778e-01, tolerance: 2.290e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.669e-01, tolerance: 2.290e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.016e-01, tolerance: 2.290e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.630e-01, tolerance: 2.290e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.450e-01, tolerance: 2.290e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.496e-01, tolerance: 2.290e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.797e-01, tolerance: 2.290e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.756e-01, tolerance: 2.290e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.713e-01, tolerance: 2.290e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.843e-01, tolerance: 2.290e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.921e-01, tolerance: 2.290e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.937e-01, tolerance: 2.290e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.702e-01, tolerance: 2.290e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.584e-01, tolerance: 2.290e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.262e-01, tolerance: 2.290e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.256e-01, tolerance: 2.290e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.494e-01, tolerance: 2.290e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.883e-01, tolerance: 2.290e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.986e-01, tolerance: 2.290e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.566e-01, tolerance: 2.290e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.088e-01, tolerance: 2.290e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.127e-01, tolerance: 2.290e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.039e-01, tolerance: 2.290e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.360e+00, tolerance: 2.290e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.603e+00, tolerance: 2.290e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.055e+00, tolerance: 2.290e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.617e+00, tolerance: 2.290e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.767e+00, tolerance: 2.290e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.025e+00, tolerance: 2.290e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.109e+00, tolerance: 2.290e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.263e+00, tolerance: 2.290e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.297e+00, tolerance: 2.290e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.487e+00, tolerance: 2.290e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.069e-02, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.156e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.462e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.502e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.560e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.004e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.996e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.626e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.041e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.497e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.381e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.515e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.480e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.534e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.630e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.870e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.646e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.639e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.958e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.528e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.319e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.761e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.308e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.783e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.065e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.107e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.993e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.046e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.125e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.283e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.448e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.600e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.580e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.521e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.618e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.631e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.531e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.802e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.533e-02, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.328e-02, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.417e-02, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.886e-02, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.578e-02, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.624e-02, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.753e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.376e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.666e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.648e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.580e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.885e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.623e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.554e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.323e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.596e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.769e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.492e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.615e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.713e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.843e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.929e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.610e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.390e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.024e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.546e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.099e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.952e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.139e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.160e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.632e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.976e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.106e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.333e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.562e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.717e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.970e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.983e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.707e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.822e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.779e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.134e-02, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.604e-02, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.320e-02, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.494e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.078e-02, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.760e-02, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.177e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.316e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.150e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.698e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.212e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.731e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.672e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.758e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.623e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.301e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.583e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.340e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.576e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.070e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.761e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.725e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.333e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.021e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.181e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.757e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.161e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.364e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.352e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.423e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.456e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.418e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.413e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.673e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.533e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.563e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.455e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.424e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.503e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.709e-02, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.548e-02, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.562e-02, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.503e-02, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.137e-02, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.131e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.112e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.300e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.928e-02, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.903e-02, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.015e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.858e-02, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.965e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.461e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.804e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.461e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.332e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.971e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.357e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.076e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.412e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.535e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.639e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.536e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.274e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.687e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.974e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.323e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.044e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.931e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.703e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.809e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.246e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.672e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.175e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.550e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.536e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.441e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.615e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.989e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.412e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.898e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.605e-02, tolerance: 2.290e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.019e-02, tolerance: 2.290e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.829e-02, tolerance: 2.290e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.581e-02, tolerance: 2.290e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.847e-02, tolerance: 2.290e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.419e-02, tolerance: 2.290e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.411e-01, tolerance: 2.290e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.174e-02, tolerance: 2.290e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.823e-01, tolerance: 2.290e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.561e-01, tolerance: 2.290e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.813e-01, tolerance: 2.290e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.304e-01, tolerance: 2.290e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.092e-01, tolerance: 2.290e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.001e-01, tolerance: 2.290e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.980e-01, tolerance: 2.290e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.098e-01, tolerance: 2.290e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.085e-01, tolerance: 2.290e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.781e-01, tolerance: 2.290e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.102e-01, tolerance: 2.290e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.212e-01, tolerance: 2.290e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.749e-01, tolerance: 2.290e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.109e-01, tolerance: 2.290e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.240e-01, tolerance: 2.290e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.875e-01, tolerance: 2.290e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.233e+00, tolerance: 2.290e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.597e+00, tolerance: 2.290e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.805e+00, tolerance: 2.290e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.568e+00, tolerance: 2.290e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.332e+00, tolerance: 2.290e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.403e+00, tolerance: 2.290e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.523e+00, tolerance: 2.290e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.445e+00, tolerance: 2.290e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.524e+00, tolerance: 2.290e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.498e+00, tolerance: 2.290e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.989e+00, tolerance: 2.290e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.466e+00, tolerance: 2.290e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.590e+00, tolerance: 2.290e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.624e+00, tolerance: 2.290e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.778e+00, tolerance: 2.290e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.889e+00, tolerance: 2.290e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.882e+00, tolerance: 2.290e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.155e-02, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.085e-02, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.758e-02, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.322e-02, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.869e-02, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.256e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.939e-02, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.767e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.273e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.546e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.886e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.552e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.652e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.636e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.941e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.671e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.233e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.041e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.913e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.350e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.435e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.250e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.197e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.048e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.397e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.218e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.183e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.231e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.033e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.350e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.175e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.433e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.972e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.252e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.802e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.239e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.253e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.076e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.948e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.713e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.391e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.048e-02, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.175e-02, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.700e-02, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.154e-02, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.380e-02, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.113e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.164e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.100e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.127e-02, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.043e-02, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.738e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.449e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.553e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.396e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.750e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.055e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.909e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.971e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.902e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.513e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.031e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.048e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.103e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.140e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.147e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.239e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.373e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.722e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.976e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.905e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.214e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.152e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.256e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.272e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.943e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.581e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.669e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.611e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.485e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.793e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.879e-02, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.794e-02, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.164e-02, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.459e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.644e-02, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.343e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.887e-02, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.994e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.474e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.008e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.919e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.841e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.869e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.893e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.145e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.395e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.271e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.009e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.844e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.723e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.074e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.556e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.170e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.225e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.059e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.324e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.406e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.305e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.327e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.084e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.836e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.457e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.054e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.264e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.615e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.047e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.776e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.144e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.695e-02, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.191e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.148e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.649e-02, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.161e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.051e-02, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.937e-02, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.100e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.055e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.661e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.844e-02, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.970e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.914e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.425e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.490e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.143e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.819e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.525e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.291e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.094e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.680e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.495e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.896e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.806e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.202e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.561e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.748e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.083e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.689e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.466e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.343e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.403e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.581e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.865e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.918e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.337e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.733e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.090e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.782e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.049e-02, tolerance: 2.290e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.401e-02, tolerance: 2.290e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.358e-02, tolerance: 2.290e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.032e-02, tolerance: 2.290e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.069e-01, tolerance: 2.290e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.966e-02, tolerance: 2.290e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.320e-01, tolerance: 2.290e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.329e-01, tolerance: 2.290e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.176e-01, tolerance: 2.290e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.668e-01, tolerance: 2.290e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.575e-01, tolerance: 2.290e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.759e-01, tolerance: 2.290e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.818e-01, tolerance: 2.290e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.374e-01, tolerance: 2.290e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.708e-01, tolerance: 2.290e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.811e-01, tolerance: 2.290e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.166e-01, tolerance: 2.290e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.923e-01, tolerance: 2.290e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.222e-01, tolerance: 2.290e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.762e-01, tolerance: 2.290e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.090e+00, tolerance: 2.290e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.121e+00, tolerance: 2.290e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.136e+00, tolerance: 2.290e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.119e+00, tolerance: 2.290e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.449e+00, tolerance: 2.290e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.183e+00, tolerance: 2.290e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.188e+00, tolerance: 2.290e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.258e+00, tolerance: 2.290e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.460e+00, tolerance: 2.290e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.657e+00, tolerance: 2.290e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.685e+00, tolerance: 2.290e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.899e+00, tolerance: 2.290e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.092e+00, tolerance: 2.290e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.142e+00, tolerance: 2.290e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.161e+00, tolerance: 2.290e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.123e+00, tolerance: 2.290e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.538e+00, tolerance: 2.290e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.560e+00, tolerance: 2.290e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.561e+00, tolerance: 2.290e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.804e+00, tolerance: 2.290e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.989e-02, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.531e-02, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.696e-02, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.465e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.654e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.610e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.600e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.185e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.356e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.768e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.050e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.769e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.898e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.408e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.448e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.578e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.685e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.754e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.696e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.949e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.910e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.353e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.645e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.023e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.564e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.762e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.014e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.156e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.527e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.012e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.006e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.035e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.570e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.597e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.742e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.700e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.947e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.777e-02, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.901e-02, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.458e-02, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.183e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.556e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.365e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.528e-02, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.159e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.964e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.104e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.997e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.831e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.883e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.306e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.006e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.552e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.027e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.442e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.031e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.461e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.878e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.279e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.099e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.363e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.323e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.301e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.519e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.441e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.579e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.544e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.414e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.475e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.320e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.477e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.651e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.778e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.596e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.519e-02, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.714e-02, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.105e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.232e-02, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.754e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.369e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.498e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.529e-02, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.581e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.290e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.715e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.556e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.060e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.380e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.184e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.870e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.100e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.535e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.900e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.047e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.939e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.361e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.901e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.107e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.141e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.035e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.195e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.232e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.169e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.353e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.583e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.571e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.449e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.300e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.351e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.434e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.548e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.585e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.549e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.820e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.959e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.065e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.373e-02, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.722e-02, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.864e-02, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.061e-02, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.221e-02, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.057e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.333e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.990e-02, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.232e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.016e-02, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.055e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.349e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.466e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.858e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.643e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.990e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.160e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.164e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.224e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.232e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.942e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.384e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.964e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.014e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.255e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.275e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.399e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.066e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.409e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.546e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.536e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.607e-01, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.192e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.229e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.262e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.559e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.739e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.603e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.677e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.763e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.921e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.035e+00, tolerance: 2.292e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    }
   ],
   "source": [
    "model = make_pipeline(StandardScaler(), LassoCV(cv=Cv_model)).fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "402b4353-a400-45cc-ba23-bddd8b9e5d4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1990080feb0>"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ymin, ymax =0, 1\n",
    "lasso = model[-1]\n",
    "plt.semilogx(lasso.alphas_, lasso.mse_path_, linestyle=\":\")\n",
    "plt.plot(\n",
    "    lasso.alphas_,\n",
    "    lasso.mse_path_.mean(axis=-1),\n",
    "    color=\"black\",\n",
    "    label=\"Average across the folds\",\n",
    "    linewidth=2,\n",
    ")\n",
    "plt.axvline(lasso.alpha_, linestyle=\"--\", color=\"black\", label=\"alpha: CV estimate\")\n",
    "\n",
    "plt.ylim(ymin, ymax)\n",
    "plt.xlabel(r\"$\\alpha$\")\n",
    "plt.ylabel(\"Mean square error\")\n",
    "plt.legend()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "5d8e3935-01a9-4adb-8939-18d9e9c2c150",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.014081051937973002"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lasso.alpha_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "0be9143b-967c-41fc-8e33-04f34afa9a5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "Cv_model= RepeatedStratifiedKFold(n_splits=5, n_repeats=10, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "d10f1531-da2b-4bb6-b83b-3558bdac2339",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.611e+01, tolerance: 2.865e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1146, 187)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lsvc =  Lasso(alpha=lasso.alpha_).fit(X, y)\n",
    "model = SelectFromModel(lsvc, prefit=True)\n",
    "X_new = model.transform(X)\n",
    "X_new.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "f7b74110-bf78-4a20-973b-7f81bf68a4a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>coef</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>MW</th>\n",
       "      <td>-0.000589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AMW</th>\n",
       "      <td>-0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sv</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Se</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sp</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>s34_relSize</th>\n",
       "      <td>-0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>s34_phSize</th>\n",
       "      <td>-0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>s34_phRelSize</th>\n",
       "      <td>-0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chiralMoment</th>\n",
       "      <td>-0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chiralPhMoment</th>\n",
       "      <td>-0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2248 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    coef\n",
       "MW             -0.000589\n",
       "AMW            -0.000000\n",
       "Sv              0.000000\n",
       "Se              0.000000\n",
       "Sp              0.000000\n",
       "...                  ...\n",
       "s34_relSize    -0.000000\n",
       "s34_phSize     -0.000000\n",
       "s34_phRelSize  -0.000000\n",
       "chiralMoment   -0.000000\n",
       "chiralPhMoment -0.000000\n",
       "\n",
       "[2248 rows x 1 columns]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lasso_coef=pd.DataFrame(lsvc.coef_)\n",
    "lasso_coef.index=X_NAomit_data.columns\n",
    "lasso_coef.columns=[\"coef\"]\n",
    "lasso_coef\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "013bbde3-8f0e-4b0f-9f7f-8ba774658777",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>coef</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>MW</th>\n",
       "      <td>-0.000589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max_conj_path</th>\n",
       "      <td>0.006244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>D/Dtr05</th>\n",
       "      <td>0.000787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>D/Dtr06</th>\n",
       "      <td>-0.000184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>D/Dtr08</th>\n",
       "      <td>0.000936</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   coef\n",
       "MW            -0.000589\n",
       "max_conj_path  0.006244\n",
       "D/Dtr05        0.000787\n",
       "D/Dtr06       -0.000184\n",
       "D/Dtr08        0.000936"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lasso_coef_last=lasso_coef[(lasso_coef[\"coef\"]>0)|(lasso_coef[\"coef\"]<0)]\n",
    "lasso_coef_last.to_csv(\"./Supplementary Data S6.csv\",sep=',')\n",
    "lasso_coef_last.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "c39feec4-a989-406f-b6a2-1c3428dc3b3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MW</th>\n",
       "      <th>max_conj_path</th>\n",
       "      <th>D/Dtr05</th>\n",
       "      <th>D/Dtr06</th>\n",
       "      <th>D/Dtr08</th>\n",
       "      <th>D/Dtr09</th>\n",
       "      <th>D/Dtr10</th>\n",
       "      <th>D/Dtr11</th>\n",
       "      <th>D/Dtr12</th>\n",
       "      <th>ZM1Kup</th>\n",
       "      <th>...</th>\n",
       "      <th>TPSA(Tot)</th>\n",
       "      <th>SAtot</th>\n",
       "      <th>SAdon</th>\n",
       "      <th>Vx</th>\n",
       "      <th>VvdwZAZ</th>\n",
       "      <th>MDEC-24</th>\n",
       "      <th>s3_size</th>\n",
       "      <th>s4_numRotBonds</th>\n",
       "      <th>s2_numAroBonds</th>\n",
       "      <th>s34_size</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OPTUM_LAB_ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3185712.0</th>\n",
       "      <td>536.72</td>\n",
       "      <td>9.0</td>\n",
       "      <td>262.170654</td>\n",
       "      <td>294.979398</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>603.695237</td>\n",
       "      <td>...</td>\n",
       "      <td>172.12</td>\n",
       "      <td>686.401741</td>\n",
       "      <td>83.805126</td>\n",
       "      <td>664.883721</td>\n",
       "      <td>484.15</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.5</td>\n",
       "      <td>5.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>31.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3532333.0</th>\n",
       "      <td>359.86</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>212.320330</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>111.199719</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>398.845717</td>\n",
       "      <td>...</td>\n",
       "      <td>98.98</td>\n",
       "      <td>417.373280</td>\n",
       "      <td>36.021501</td>\n",
       "      <td>414.252492</td>\n",
       "      <td>304.32</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16830460.0</th>\n",
       "      <td>472.41</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>471.074204</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>512.791152</td>\n",
       "      <td>...</td>\n",
       "      <td>70.59</td>\n",
       "      <td>565.665828</td>\n",
       "      <td>18.010751</td>\n",
       "      <td>555.830565</td>\n",
       "      <td>400.92</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3921421.0</th>\n",
       "      <td>468.59</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>541.435495</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>524.646510</td>\n",
       "      <td>...</td>\n",
       "      <td>81.54</td>\n",
       "      <td>637.982011</td>\n",
       "      <td>42.683343</td>\n",
       "      <td>603.936877</td>\n",
       "      <td>440.06</td>\n",
       "      <td>5.222984</td>\n",
       "      <td>9.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>31.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1314610.0</th>\n",
       "      <td>353.78</td>\n",
       "      <td>11.0</td>\n",
       "      <td>122.318827</td>\n",
       "      <td>151.087941</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>103.326195</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>461.033086</td>\n",
       "      <td>...</td>\n",
       "      <td>80.31</td>\n",
       "      <td>390.840292</td>\n",
       "      <td>18.010751</td>\n",
       "      <td>395.066445</td>\n",
       "      <td>286.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>664630.0</th>\n",
       "      <td>272.38</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>104.747025</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>89.373066</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>287.449055</td>\n",
       "      <td>...</td>\n",
       "      <td>53.17</td>\n",
       "      <td>392.110140</td>\n",
       "      <td>18.010751</td>\n",
       "      <td>366.245847</td>\n",
       "      <td>273.48</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3228536.0</th>\n",
       "      <td>395.47</td>\n",
       "      <td>10.0</td>\n",
       "      <td>239.404822</td>\n",
       "      <td>102.198910</td>\n",
       "      <td>120.588448</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>501.425648</td>\n",
       "      <td>...</td>\n",
       "      <td>114.60</td>\n",
       "      <td>458.127806</td>\n",
       "      <td>18.010751</td>\n",
       "      <td>458.455150</td>\n",
       "      <td>321.79</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>21.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>666815.0</th>\n",
       "      <td>397.48</td>\n",
       "      <td>8.0</td>\n",
       "      <td>60.907751</td>\n",
       "      <td>251.084340</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>116.929529</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>517.167699</td>\n",
       "      <td>...</td>\n",
       "      <td>91.36</td>\n",
       "      <td>491.721270</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>478.737542</td>\n",
       "      <td>352.36</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16197082.0</th>\n",
       "      <td>471.61</td>\n",
       "      <td>9.0</td>\n",
       "      <td>75.035536</td>\n",
       "      <td>447.085664</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>142.054326</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>506.549569</td>\n",
       "      <td>...</td>\n",
       "      <td>96.03</td>\n",
       "      <td>583.235156</td>\n",
       "      <td>60.694094</td>\n",
       "      <td>580.215947</td>\n",
       "      <td>420.55</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>11.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>23.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1519798.0</th>\n",
       "      <td>289.32</td>\n",
       "      <td>11.0</td>\n",
       "      <td>52.368748</td>\n",
       "      <td>158.410101</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>84.100142</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>369.961088</td>\n",
       "      <td>...</td>\n",
       "      <td>65.72</td>\n",
       "      <td>329.701033</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>341.578073</td>\n",
       "      <td>229.71</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1146 rows × 187 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  MW  max_conj_path     D/Dtr05     D/Dtr06     D/Dtr08  \\\n",
       "OPTUM_LAB_ID                                                              \n",
       "3185712.0     536.72            9.0  262.170654  294.979398    0.000000   \n",
       "3532333.0     359.86            8.0    0.000000  212.320330    0.000000   \n",
       "16830460.0    472.41           12.0    0.000000  471.074204    0.000000   \n",
       "3921421.0     468.59            6.0    0.000000  541.435495    0.000000   \n",
       "1314610.0     353.78           11.0  122.318827  151.087941    0.000000   \n",
       "...              ...            ...         ...         ...         ...   \n",
       "664630.0      272.38           10.0    0.000000  104.747025    0.000000   \n",
       "3228536.0     395.47           10.0  239.404822  102.198910  120.588448   \n",
       "666815.0      397.48            8.0   60.907751  251.084340    0.000000   \n",
       "16197082.0    471.61            9.0   75.035536  447.085664    0.000000   \n",
       "1519798.0     289.32           11.0   52.368748  158.410101    0.000000   \n",
       "\n",
       "                 D/Dtr09     D/Dtr10  D/Dtr11  D/Dtr12      ZM1Kup  ...  \\\n",
       "OPTUM_LAB_ID                                                        ...   \n",
       "3185712.0       0.000000    0.000000      0.0      0.0  603.695237  ...   \n",
       "3532333.0       0.000000  111.199719      0.0      0.0  398.845717  ...   \n",
       "16830460.0      0.000000    0.000000      0.0      0.0  512.791152  ...   \n",
       "3921421.0       0.000000    0.000000      0.0      0.0  524.646510  ...   \n",
       "1314610.0     103.326195    0.000000      0.0      0.0  461.033086  ...   \n",
       "...                  ...         ...      ...      ...         ...  ...   \n",
       "664630.0        0.000000   89.373066      0.0      0.0  287.449055  ...   \n",
       "3228536.0       0.000000    0.000000      0.0      0.0  501.425648  ...   \n",
       "666815.0      116.929529    0.000000      0.0      0.0  517.167699  ...   \n",
       "16197082.0    142.054326    0.000000      0.0      0.0  506.549569  ...   \n",
       "1519798.0       0.000000   84.100142      0.0      0.0  369.961088  ...   \n",
       "\n",
       "              TPSA(Tot)       SAtot      SAdon          Vx  VvdwZAZ   MDEC-24  \\\n",
       "OPTUM_LAB_ID                                                                    \n",
       "3185712.0        172.12  686.401741  83.805126  664.883721   484.15  0.000000   \n",
       "3532333.0         98.98  417.373280  36.021501  414.252492   304.32  0.000000   \n",
       "16830460.0        70.59  565.665828  18.010751  555.830565   400.92  0.000000   \n",
       "3921421.0         81.54  637.982011  42.683343  603.936877   440.06  5.222984   \n",
       "1314610.0         80.31  390.840292  18.010751  395.066445   286.00  0.000000   \n",
       "...                 ...         ...        ...         ...      ...       ...   \n",
       "664630.0          53.17  392.110140  18.010751  366.245847   273.48  0.000000   \n",
       "3228536.0        114.60  458.127806  18.010751  458.455150   321.79  0.000000   \n",
       "666815.0          91.36  491.721270   0.000000  478.737542   352.36  0.000000   \n",
       "16197082.0        96.03  583.235156  60.694094  580.215947   420.55  0.000000   \n",
       "1519798.0         65.72  329.701033   0.000000  341.578073   229.71  0.000000   \n",
       "\n",
       "              s3_size  s4_numRotBonds  s2_numAroBonds  s34_size  \n",
       "OPTUM_LAB_ID                                                     \n",
       "3185712.0         5.5             5.5             3.0      31.5  \n",
       "3532333.0         0.0             0.0             0.0       0.0  \n",
       "16830460.0        0.0             0.0             0.0       0.0  \n",
       "3921421.0         9.0             6.0             0.0      31.0  \n",
       "1314610.0         0.0             0.0             0.0       0.0  \n",
       "...               ...             ...             ...       ...  \n",
       "664630.0          0.0             0.0             0.0       0.0  \n",
       "3228536.0         9.0             2.0             6.0      21.0  \n",
       "666815.0          0.0             0.0             0.0       0.0  \n",
       "16197082.0       11.5             3.0             8.0      23.5  \n",
       "1519798.0         0.0             0.0             0.0       0.0  \n",
       "\n",
       "[1146 rows x 187 columns]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Lasso_data=X_NAomit_data[X_NAomit_data.columns[model.get_support()]]\n",
    "Lasso_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "afcca2a8-9ce0-4c49-88db-c3265e6374fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "Lasso_data.to_csv('./Lasso_data.csv',encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "c9c9a6da-b735-4689-897c-972cd30e5f64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MW</th>\n",
       "      <th>max_conj_path</th>\n",
       "      <th>D/Dtr05</th>\n",
       "      <th>D/Dtr06</th>\n",
       "      <th>D/Dtr08</th>\n",
       "      <th>D/Dtr09</th>\n",
       "      <th>D/Dtr10</th>\n",
       "      <th>D/Dtr11</th>\n",
       "      <th>D/Dtr12</th>\n",
       "      <th>ZM1Kup</th>\n",
       "      <th>...</th>\n",
       "      <th>TPSA(Tot)</th>\n",
       "      <th>SAtot</th>\n",
       "      <th>SAdon</th>\n",
       "      <th>Vx</th>\n",
       "      <th>VvdwZAZ</th>\n",
       "      <th>MDEC-24</th>\n",
       "      <th>s3_size</th>\n",
       "      <th>s4_numRotBonds</th>\n",
       "      <th>s2_numAroBonds</th>\n",
       "      <th>s34_size</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OPTUM_LAB_ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3185712.0</th>\n",
       "      <td>0.296685</td>\n",
       "      <td>0.321429</td>\n",
       "      <td>0.239260</td>\n",
       "      <td>0.146632</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.340758</td>\n",
       "      <td>...</td>\n",
       "      <td>0.408466</td>\n",
       "      <td>0.256010</td>\n",
       "      <td>0.163618</td>\n",
       "      <td>0.277083</td>\n",
       "      <td>0.273019</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.354839</td>\n",
       "      <td>0.115789</td>\n",
       "      <td>0.375</td>\n",
       "      <td>0.336898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3532333.0</th>\n",
       "      <td>0.145247</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.105543</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.136878</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.156849</td>\n",
       "      <td>...</td>\n",
       "      <td>0.194061</td>\n",
       "      <td>0.105590</td>\n",
       "      <td>0.070327</td>\n",
       "      <td>0.123581</td>\n",
       "      <td>0.122793</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16830460.0</th>\n",
       "      <td>0.241619</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.234167</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.259147</td>\n",
       "      <td>...</td>\n",
       "      <td>0.110838</td>\n",
       "      <td>0.188504</td>\n",
       "      <td>0.035164</td>\n",
       "      <td>0.210292</td>\n",
       "      <td>0.203490</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3921421.0</th>\n",
       "      <td>0.238348</td>\n",
       "      <td>0.214286</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.269143</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.269790</td>\n",
       "      <td>...</td>\n",
       "      <td>0.142937</td>\n",
       "      <td>0.228938</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.239755</td>\n",
       "      <td>0.236187</td>\n",
       "      <td>0.648396</td>\n",
       "      <td>0.580645</td>\n",
       "      <td>0.126316</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.331551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1314610.0</th>\n",
       "      <td>0.140041</td>\n",
       "      <td>0.392857</td>\n",
       "      <td>0.111629</td>\n",
       "      <td>0.075104</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.107116</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.212680</td>\n",
       "      <td>...</td>\n",
       "      <td>0.139331</td>\n",
       "      <td>0.090755</td>\n",
       "      <td>0.035164</td>\n",
       "      <td>0.111830</td>\n",
       "      <td>0.107488</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>664630.0</th>\n",
       "      <td>0.070342</td>\n",
       "      <td>0.357143</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.052069</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.110011</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.056840</td>\n",
       "      <td>...</td>\n",
       "      <td>0.059772</td>\n",
       "      <td>0.091465</td>\n",
       "      <td>0.035164</td>\n",
       "      <td>0.094179</td>\n",
       "      <td>0.097029</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3228536.0</th>\n",
       "      <td>0.175739</td>\n",
       "      <td>0.357143</td>\n",
       "      <td>0.218483</td>\n",
       "      <td>0.050802</td>\n",
       "      <td>0.306835</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.248943</td>\n",
       "      <td>...</td>\n",
       "      <td>0.239850</td>\n",
       "      <td>0.128377</td>\n",
       "      <td>0.035164</td>\n",
       "      <td>0.150653</td>\n",
       "      <td>0.137387</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.580645</td>\n",
       "      <td>0.042105</td>\n",
       "      <td>0.750</td>\n",
       "      <td>0.224599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>666815.0</th>\n",
       "      <td>0.177460</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.055585</td>\n",
       "      <td>0.124812</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.121219</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.263076</td>\n",
       "      <td>...</td>\n",
       "      <td>0.171723</td>\n",
       "      <td>0.147160</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.163075</td>\n",
       "      <td>0.162924</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16197082.0</th>\n",
       "      <td>0.240934</td>\n",
       "      <td>0.321429</td>\n",
       "      <td>0.068478</td>\n",
       "      <td>0.222242</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.147265</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.253543</td>\n",
       "      <td>...</td>\n",
       "      <td>0.185413</td>\n",
       "      <td>0.198327</td>\n",
       "      <td>0.118497</td>\n",
       "      <td>0.225227</td>\n",
       "      <td>0.219889</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.741935</td>\n",
       "      <td>0.063158</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.251337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1519798.0</th>\n",
       "      <td>0.084847</td>\n",
       "      <td>0.392857</td>\n",
       "      <td>0.047792</td>\n",
       "      <td>0.078744</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.103520</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.130917</td>\n",
       "      <td>...</td>\n",
       "      <td>0.096561</td>\n",
       "      <td>0.056570</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.079071</td>\n",
       "      <td>0.060465</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1146 rows × 187 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    MW  max_conj_path   D/Dtr05   D/Dtr06   D/Dtr08   D/Dtr09  \\\n",
       "OPTUM_LAB_ID                                                                    \n",
       "3185712.0     0.296685       0.321429  0.239260  0.146632  0.000000  0.000000   \n",
       "3532333.0     0.145247       0.285714  0.000000  0.105543  0.000000  0.000000   \n",
       "16830460.0    0.241619       0.428571  0.000000  0.234167  0.000000  0.000000   \n",
       "3921421.0     0.238348       0.214286  0.000000  0.269143  0.000000  0.000000   \n",
       "1314610.0     0.140041       0.392857  0.111629  0.075104  0.000000  0.107116   \n",
       "...                ...            ...       ...       ...       ...       ...   \n",
       "664630.0      0.070342       0.357143  0.000000  0.052069  0.000000  0.000000   \n",
       "3228536.0     0.175739       0.357143  0.218483  0.050802  0.306835  0.000000   \n",
       "666815.0      0.177460       0.285714  0.055585  0.124812  0.000000  0.121219   \n",
       "16197082.0    0.240934       0.321429  0.068478  0.222242  0.000000  0.147265   \n",
       "1519798.0     0.084847       0.392857  0.047792  0.078744  0.000000  0.000000   \n",
       "\n",
       "               D/Dtr10  D/Dtr11  D/Dtr12    ZM1Kup  ...  TPSA(Tot)     SAtot  \\\n",
       "OPTUM_LAB_ID                                        ...                        \n",
       "3185712.0     0.000000      0.0      0.0  0.340758  ...   0.408466  0.256010   \n",
       "3532333.0     0.136878      0.0      0.0  0.156849  ...   0.194061  0.105590   \n",
       "16830460.0    0.000000      0.0      0.0  0.259147  ...   0.110838  0.188504   \n",
       "3921421.0     0.000000      0.0      0.0  0.269790  ...   0.142937  0.228938   \n",
       "1314610.0     0.000000      0.0      0.0  0.212680  ...   0.139331  0.090755   \n",
       "...                ...      ...      ...       ...  ...        ...       ...   \n",
       "664630.0      0.110011      0.0      0.0  0.056840  ...   0.059772  0.091465   \n",
       "3228536.0     0.000000      0.0      0.0  0.248943  ...   0.239850  0.128377   \n",
       "666815.0      0.000000      0.0      0.0  0.263076  ...   0.171723  0.147160   \n",
       "16197082.0    0.000000      0.0      0.0  0.253543  ...   0.185413  0.198327   \n",
       "1519798.0     0.103520      0.0      0.0  0.130917  ...   0.096561  0.056570   \n",
       "\n",
       "                 SAdon        Vx   VvdwZAZ   MDEC-24   s3_size  \\\n",
       "OPTUM_LAB_ID                                                     \n",
       "3185712.0     0.163618  0.277083  0.273019  0.000000  0.354839   \n",
       "3532333.0     0.070327  0.123581  0.122793  0.000000  0.000000   \n",
       "16830460.0    0.035164  0.210292  0.203490  0.000000  0.000000   \n",
       "3921421.0     0.083333  0.239755  0.236187  0.648396  0.580645   \n",
       "1314610.0     0.035164  0.111830  0.107488  0.000000  0.000000   \n",
       "...                ...       ...       ...       ...       ...   \n",
       "664630.0      0.035164  0.094179  0.097029  0.000000  0.000000   \n",
       "3228536.0     0.035164  0.150653  0.137387  0.000000  0.580645   \n",
       "666815.0      0.000000  0.163075  0.162924  0.000000  0.000000   \n",
       "16197082.0    0.118497  0.225227  0.219889  0.000000  0.741935   \n",
       "1519798.0     0.000000  0.079071  0.060465  0.000000  0.000000   \n",
       "\n",
       "              s4_numRotBonds  s2_numAroBonds  s34_size  \n",
       "OPTUM_LAB_ID                                            \n",
       "3185712.0           0.115789           0.375  0.336898  \n",
       "3532333.0           0.000000           0.000  0.000000  \n",
       "16830460.0          0.000000           0.000  0.000000  \n",
       "3921421.0           0.126316           0.000  0.331551  \n",
       "1314610.0           0.000000           0.000  0.000000  \n",
       "...                      ...             ...       ...  \n",
       "664630.0            0.000000           0.000  0.000000  \n",
       "3228536.0           0.042105           0.750  0.224599  \n",
       "666815.0            0.000000           0.000  0.000000  \n",
       "16197082.0          0.063158           1.000  0.251337  \n",
       "1519798.0           0.000000           0.000  0.000000  \n",
       "\n",
       "[1146 rows x 187 columns]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Scale data\n",
    "Scaler = preprocessing.MinMaxScaler() #StandardScaler\n",
    "Transformer =Scaler.fit(Lasso_data)\n",
    "X_scaled_data=Transformer.transform(Lasso_data)\n",
    "X_scaled_data =pd.DataFrame(X_scaled_data)\n",
    "X_scaled_data.columns=Lasso_data.columns\n",
    "X_scaled_data.index=Raw_data.index\n",
    "\n",
    "joblib.dump(Transformer, './Lasso_Scaler_transformer.pkl')\n",
    "\n",
    "X_scaled_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "2c0643c9-e6ee-441f-a6e6-f8951935a04a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Model_results(Model_clf,X_test,y,Cv_model):\n",
    "    Model_scores= cross_validate(estimator=Model_clf, X=X_test, y=y, cv=Cv_model,scoring=( 'accuracy','f1','precision','recall','roc_auc'), return_train_score=True)\n",
    "    Model_score= cross_validate(estimator=Model_clf, X=X_test, y=y, cv=Cv_model,scoring=( 'accuracy','f1','precision','recall','roc_auc'), return_train_score=False)\n",
    "#Accuracy\n",
    "    Model_Accuracy_test_mean=Model_scores['test_accuracy'].mean()\n",
    "    Model_Accuracy_test_se=(Model_scores['test_accuracy'].std()/math.sqrt(len(Model_scores['test_accuracy']))) \n",
    "    Model_Accuracy_train_mean=Model_scores['train_accuracy'].mean()\n",
    "    Model_Accuracy_train_se=(Model_scores['train_accuracy'].std()/math.sqrt(len(Model_scores['train_accuracy']))) \n",
    "#f1\n",
    "    Model_f1_mean=Model_score['test_f1'].mean()\n",
    "    Model_f1_se=(Model_score['test_f1'].std()/math.sqrt(len(Model_score['test_f1']))) \n",
    "#precision\n",
    "    Model_precision_mean=Model_score['test_precision'].mean()\n",
    "    Model_precision_se=(Model_score['test_precision'].std()/math.sqrt(len(Model_score['test_precision']))) \n",
    "#recall\n",
    "    Model_recall_mean=Model_score['test_recall'].mean()\n",
    "    Model_recall_se=(Model_score['test_recall'].std()/math.sqrt(len(Model_score['test_recall']))) \n",
    "#roc_auc\n",
    "    Model_roc_auc_mean=Model_score['test_roc_auc'].mean()\n",
    "    Model_roc_auc_se=(Model_score['test_roc_auc'].std()/math.sqrt(len(Model_score['test_roc_auc']))) \n",
    "    Model = {'Mean':[Model_Accuracy_test_mean,Model_Accuracy_train_mean,Model_f1_mean,Model_precision_mean,Model_recall_mean,Model_roc_auc_mean],\n",
    "        'Se':[Model_Accuracy_test_se,Model_Accuracy_train_se,Model_f1_se,Model_precision_se,Model_recall_se,Model_roc_auc_se]}\n",
    "    Model = pd.DataFrame(Model, index=['Accuracy_test','Accuracy_train','F1 Score','Precision','Recall','Roc_auc']) # 这里设定了 index 个数要和列表长度一致\n",
    "    return Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "0e49d1bb-d5f4-4e7f-a620-a943c578fba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setting the KFold \n",
    "Cv_optuna= RepeatedStratifiedKFold(n_splits=5, n_repeats=10, random_state=0)\n",
    "Cv_model= RepeatedStratifiedKFold(n_splits=5, n_repeats=10, random_state=0)\n",
    "Cv_RFECV= RepeatedStratifiedKFold(n_splits=5, n_repeats=10, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "8b74394b-d874-4115-b66e-0bac0d514965",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data pre-processing of models\n",
    "X=np.array(X_scaled_data)\n",
    "y=Raw_data['Activity'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d026e47-e8b2-467a-a5a0-866a1888a801",
   "metadata": {},
   "source": [
    "## 1.1 DT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "e5dd9da6-318e-4a8f-8b6e-46380439376d",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf=DecisionTreeClassifier(random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "9d7e67d4-b288-4270-be5d-1598f117e05d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mean</th>\n",
       "      <th>Se</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Accuracy_test</th>\n",
       "      <td>0.619814</td>\n",
       "      <td>0.004582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Accuracy_train</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1 Score</th>\n",
       "      <td>0.619856</td>\n",
       "      <td>0.004555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Precision</th>\n",
       "      <td>0.620652</td>\n",
       "      <td>0.004963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recall</th>\n",
       "      <td>0.620423</td>\n",
       "      <td>0.005823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Roc_auc</th>\n",
       "      <td>0.619799</td>\n",
       "      <td>0.004582</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Mean        Se\n",
       "Accuracy_test   0.619814  0.004582\n",
       "Accuracy_train  1.000000  0.000000\n",
       "F1 Score        0.619856  0.004555\n",
       "Precision       0.620652  0.004963\n",
       "Recall          0.620423  0.005823\n",
       "Roc_auc         0.619799  0.004582"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Model1 （4175 descriptors）\n",
    "Model1_clf=clf\n",
    "#Model1\n",
    "Model1=Model_results(Model1_clf,X,y,Cv_model)\n",
    "Model1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "7bb0633b-59c6-4ad7-afb1-e241f713f990",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2024-11-14 21:22:25,566]\u001b[0m A new study created in memory with name: no-name-c3614020-9849-4dff-8280-b771b3bebc73\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 21:22:29,226]\u001b[0m Trial 0 finished with value: 0.6471258781089805 and parameters: {'max_depth': 4, 'max_features': 17, 'min_samples_split': 16}. Best is trial 0 with value: 0.6471258781089805.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 21:22:29,414]\u001b[0m Trial 1 finished with value: 0.6279289918359598 and parameters: {'max_depth': 4, 'max_features': 14, 'min_samples_split': 17}. Best is trial 0 with value: 0.6471258781089805.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 21:22:29,598]\u001b[0m Trial 2 finished with value: 0.634900322764382 and parameters: {'max_depth': 4, 'max_features': 19, 'min_samples_split': 25}. Best is trial 0 with value: 0.6471258781089805.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 21:22:29,783]\u001b[0m Trial 3 finished with value: 0.6305350294285172 and parameters: {'max_depth': 4, 'max_features': 18, 'min_samples_split': 14}. Best is trial 0 with value: 0.6471258781089805.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 21:22:29,967]\u001b[0m Trial 4 finished with value: 0.6341101196126827 and parameters: {'max_depth': 4, 'max_features': 20, 'min_samples_split': 3}. Best is trial 0 with value: 0.6471258781089805.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 21:22:30,152]\u001b[0m Trial 5 finished with value: 0.6215617998860832 and parameters: {'max_depth': 3, 'max_features': 10, 'min_samples_split': 21}. Best is trial 0 with value: 0.6471258781089805.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 21:22:30,355]\u001b[0m Trial 6 finished with value: 0.6411832162521359 and parameters: {'max_depth': 5, 'max_features': 19, 'min_samples_split': 25}. Best is trial 0 with value: 0.6471258781089805.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 21:22:30,536]\u001b[0m Trial 7 finished with value: 0.637167267894437 and parameters: {'max_depth': 5, 'max_features': 15, 'min_samples_split': 20}. Best is trial 0 with value: 0.6471258781089805.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 21:22:30,723]\u001b[0m Trial 8 finished with value: 0.64364192139738 and parameters: {'max_depth': 3, 'max_features': 17, 'min_samples_split': 5}. Best is trial 0 with value: 0.6471258781089805.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 21:22:30,895]\u001b[0m Trial 9 finished with value: 0.6411004366812227 and parameters: {'max_depth': 5, 'max_features': 15, 'min_samples_split': 11}. Best is trial 0 with value: 0.6471258781089805.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 21:22:31,066]\u001b[0m Trial 10 finished with value: 0.6346428707043857 and parameters: {'max_depth': 3, 'max_features': 12, 'min_samples_split': 9}. Best is trial 0 with value: 0.6471258781089805.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 21:22:31,236]\u001b[0m Trial 11 finished with value: 0.64364192139738 and parameters: {'max_depth': 3, 'max_features': 17, 'min_samples_split': 3}. Best is trial 0 with value: 0.6471258781089805.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 21:22:31,406]\u001b[0m Trial 12 finished with value: 0.64364192139738 and parameters: {'max_depth': 3, 'max_features': 17, 'min_samples_split': 9}. Best is trial 0 with value: 0.6471258781089805.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 21:22:31,574]\u001b[0m Trial 13 finished with value: 0.64364192139738 and parameters: {'max_depth': 3, 'max_features': 17, 'min_samples_split': 7}. Best is trial 0 with value: 0.6471258781089805.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 21:22:31,744]\u001b[0m Trial 14 finished with value: 0.6397926713499146 and parameters: {'max_depth': 4, 'max_features': 13, 'min_samples_split': 15}. Best is trial 0 with value: 0.6471258781089805.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 21:22:31,916]\u001b[0m Trial 15 finished with value: 0.6367366622365673 and parameters: {'max_depth': 3, 'max_features': 16, 'min_samples_split': 6}. Best is trial 0 with value: 0.6471258781089805.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 21:22:32,086]\u001b[0m Trial 16 finished with value: 0.6384773115625593 and parameters: {'max_depth': 5, 'max_features': 16, 'min_samples_split': 18}. Best is trial 0 with value: 0.6471258781089805.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 21:22:32,255]\u001b[0m Trial 17 finished with value: 0.6340243022593507 and parameters: {'max_depth': 4, 'max_features': 20, 'min_samples_split': 11}. Best is trial 0 with value: 0.6471258781089805.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 21:22:32,440]\u001b[0m Trial 18 finished with value: 0.6292303018796279 and parameters: {'max_depth': 4, 'max_features': 18, 'min_samples_split': 7}. Best is trial 0 with value: 0.6471258781089805.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 21:22:32,610]\u001b[0m Trial 19 finished with value: 0.6426664135181318 and parameters: {'max_depth': 3, 'max_features': 13, 'min_samples_split': 11}. Best is trial 0 with value: 0.6471258781089805.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 21:22:32,778]\u001b[0m Trial 20 finished with value: 0.6389128536168597 and parameters: {'max_depth': 5, 'max_features': 16, 'min_samples_split': 16}. Best is trial 0 with value: 0.6471258781089805.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 21:22:32,945]\u001b[0m Trial 21 finished with value: 0.64364192139738 and parameters: {'max_depth': 3, 'max_features': 17, 'min_samples_split': 8}. Best is trial 0 with value: 0.6471258781089805.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 21:22:33,114]\u001b[0m Trial 22 finished with value: 0.6339350674007974 and parameters: {'max_depth': 3, 'max_features': 18, 'min_samples_split': 13}. Best is trial 0 with value: 0.6471258781089805.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 21:22:33,285]\u001b[0m Trial 23 finished with value: 0.6341161951775204 and parameters: {'max_depth': 3, 'max_features': 15, 'min_samples_split': 9}. Best is trial 0 with value: 0.6471258781089805.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 21:22:33,467]\u001b[0m Trial 24 finished with value: 0.64364192139738 and parameters: {'max_depth': 3, 'max_features': 17, 'min_samples_split': 2}. Best is trial 0 with value: 0.6471258781089805.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 21:22:33,641]\u001b[0m Trial 25 finished with value: 0.6308889310803114 and parameters: {'max_depth': 3, 'max_features': 19, 'min_samples_split': 13}. Best is trial 0 with value: 0.6471258781089805.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 21:22:33,809]\u001b[0m Trial 26 finished with value: 0.6242532751091703 and parameters: {'max_depth': 4, 'max_features': 16, 'min_samples_split': 7}. Best is trial 0 with value: 0.6471258781089805.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 21:22:33,979]\u001b[0m Trial 27 finished with value: 0.6339350674007974 and parameters: {'max_depth': 3, 'max_features': 18, 'min_samples_split': 4}. Best is trial 0 with value: 0.6471258781089805.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 21:22:34,152]\u001b[0m Trial 28 finished with value: 0.6301036643250427 and parameters: {'max_depth': 4, 'max_features': 15, 'min_samples_split': 2}. Best is trial 0 with value: 0.6471258781089805.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 21:22:34,324]\u001b[0m Trial 29 finished with value: 0.6236616669831023 and parameters: {'max_depth': 3, 'max_features': 14, 'min_samples_split': 18}. Best is trial 0 with value: 0.6471258781089805.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 21:22:34,495]\u001b[0m Trial 30 finished with value: 0.6278412758686159 and parameters: {'max_depth': 4, 'max_features': 14, 'min_samples_split': 22}. Best is trial 0 with value: 0.6471258781089805.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 21:22:34,666]\u001b[0m Trial 31 finished with value: 0.64364192139738 and parameters: {'max_depth': 3, 'max_features': 17, 'min_samples_split': 5}. Best is trial 0 with value: 0.6471258781089805.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 21:22:34,838]\u001b[0m Trial 32 finished with value: 0.64364192139738 and parameters: {'max_depth': 3, 'max_features': 17, 'min_samples_split': 2}. Best is trial 0 with value: 0.6471258781089805.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 21:22:35,009]\u001b[0m Trial 33 finished with value: 0.6308889310803114 and parameters: {'max_depth': 3, 'max_features': 19, 'min_samples_split': 5}. Best is trial 0 with value: 0.6471258781089805.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 21:22:35,180]\u001b[0m Trial 34 finished with value: 0.6292303018796279 and parameters: {'max_depth': 4, 'max_features': 18, 'min_samples_split': 4}. Best is trial 0 with value: 0.6471258781089805.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 21:22:35,351]\u001b[0m Trial 35 finished with value: 0.6367366622365673 and parameters: {'max_depth': 3, 'max_features': 16, 'min_samples_split': 8}. Best is trial 0 with value: 0.6471258781089805.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 21:22:35,521]\u001b[0m Trial 36 finished with value: 0.6318465919878489 and parameters: {'max_depth': 4, 'max_features': 19, 'min_samples_split': 3}. Best is trial 0 with value: 0.6471258781089805.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 21:22:35,706]\u001b[0m Trial 37 finished with value: 0.6339350674007974 and parameters: {'max_depth': 3, 'max_features': 18, 'min_samples_split': 12}. Best is trial 0 with value: 0.6471258781089805.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 21:22:35,894]\u001b[0m Trial 38 finished with value: 0.6331509398139358 and parameters: {'max_depth': 4, 'max_features': 20, 'min_samples_split': 9}. Best is trial 0 with value: 0.6471258781089805.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 21:22:36,065]\u001b[0m Trial 39 finished with value: 0.6215617998860832 and parameters: {'max_depth': 3, 'max_features': 10, 'min_samples_split': 2}. Best is trial 0 with value: 0.6471258781089805.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 21:22:36,254]\u001b[0m Trial 40 finished with value: 0.6479100056958421 and parameters: {'max_depth': 5, 'max_features': 17, 'min_samples_split': 2}. Best is trial 40 with value: 0.6479100056958421.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 21:22:36,424]\u001b[0m Trial 41 finished with value: 0.6483501044237707 and parameters: {'max_depth': 5, 'max_features': 17, 'min_samples_split': 4}. Best is trial 41 with value: 0.6483501044237707.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 21:22:36,596]\u001b[0m Trial 42 finished with value: 0.6483501044237707 and parameters: {'max_depth': 5, 'max_features': 17, 'min_samples_split': 4}. Best is trial 41 with value: 0.6483501044237707.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 21:22:36,783]\u001b[0m Trial 43 finished with value: 0.6341150560091134 and parameters: {'max_depth': 5, 'max_features': 16, 'min_samples_split': 4}. Best is trial 41 with value: 0.6483501044237707.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 21:22:36,969]\u001b[0m Trial 44 finished with value: 0.637087905828745 and parameters: {'max_depth': 5, 'max_features': 18, 'min_samples_split': 3}. Best is trial 41 with value: 0.6483501044237707.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 21:22:37,156]\u001b[0m Trial 45 finished with value: 0.6470389215872413 and parameters: {'max_depth': 5, 'max_features': 17, 'min_samples_split': 5}. Best is trial 41 with value: 0.6483501044237707.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 21:22:37,327]\u001b[0m Trial 46 finished with value: 0.6407499525346497 and parameters: {'max_depth': 5, 'max_features': 15, 'min_samples_split': 6}. Best is trial 41 with value: 0.6483501044237707.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 21:22:37,499]\u001b[0m Trial 47 finished with value: 0.6391729637364724 and parameters: {'max_depth': 5, 'max_features': 19, 'min_samples_split': 20}. Best is trial 41 with value: 0.6483501044237707.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 21:22:37,671]\u001b[0m Trial 48 finished with value: 0.6394391494209227 and parameters: {'max_depth': 5, 'max_features': 17, 'min_samples_split': 15}. Best is trial 41 with value: 0.6483501044237707.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 21:22:37,856]\u001b[0m Trial 49 finished with value: 0.6381279665843934 and parameters: {'max_depth': 5, 'max_features': 16, 'min_samples_split': 17}. Best is trial 41 with value: 0.6483501044237707.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 21:22:38,029]\u001b[0m Trial 50 finished with value: 0.6396187583064363 and parameters: {'max_depth': 5, 'max_features': 11, 'min_samples_split': 6}. Best is trial 41 with value: 0.6483501044237707.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 21:22:38,200]\u001b[0m Trial 51 finished with value: 0.6486086956521739 and parameters: {'max_depth': 5, 'max_features': 17, 'min_samples_split': 3}. Best is trial 51 with value: 0.6486086956521739.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 21:22:38,399]\u001b[0m Trial 52 finished with value: 0.6369139927852667 and parameters: {'max_depth': 5, 'max_features': 18, 'min_samples_split': 4}. Best is trial 51 with value: 0.6486086956521739.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 21:22:38,570]\u001b[0m Trial 53 finished with value: 0.6470389215872413 and parameters: {'max_depth': 5, 'max_features': 17, 'min_samples_split': 5}. Best is trial 51 with value: 0.6486086956521739.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 21:22:38,757]\u001b[0m Trial 54 finished with value: 0.6339415226884374 and parameters: {'max_depth': 5, 'max_features': 16, 'min_samples_split': 3}. Best is trial 51 with value: 0.6486086956521739.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 21:22:38,931]\u001b[0m Trial 55 finished with value: 0.6470389215872413 and parameters: {'max_depth': 5, 'max_features': 17, 'min_samples_split': 5}. Best is trial 51 with value: 0.6486086956521739.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 21:22:39,118]\u001b[0m Trial 56 finished with value: 0.637087905828745 and parameters: {'max_depth': 5, 'max_features': 18, 'min_samples_split': 3}. Best is trial 51 with value: 0.6486086956521739.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 21:22:39,304]\u001b[0m Trial 57 finished with value: 0.6450313271311942 and parameters: {'max_depth': 5, 'max_features': 17, 'min_samples_split': 6}. Best is trial 51 with value: 0.6486086956521739.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 21:22:39,475]\u001b[0m Trial 58 finished with value: 0.6412732105562938 and parameters: {'max_depth': 5, 'max_features': 15, 'min_samples_split': 4}. Best is trial 51 with value: 0.6486086956521739.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 21:22:39,648]\u001b[0m Trial 59 finished with value: 0.6378712739700019 and parameters: {'max_depth': 5, 'max_features': 16, 'min_samples_split': 10}. Best is trial 51 with value: 0.6486086956521739.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 21:22:39,835]\u001b[0m Trial 60 finished with value: 0.634191760015189 and parameters: {'max_depth': 5, 'max_features': 19, 'min_samples_split': 15}. Best is trial 51 with value: 0.6486086956521739.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 21:22:40,006]\u001b[0m Trial 61 finished with value: 0.6479100056958421 and parameters: {'max_depth': 5, 'max_features': 17, 'min_samples_split': 2}. Best is trial 51 with value: 0.6486086956521739.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 21:22:40,179]\u001b[0m Trial 62 finished with value: 0.637087905828745 and parameters: {'max_depth': 5, 'max_features': 18, 'min_samples_split': 2}. Best is trial 51 with value: 0.6486086956521739.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 21:22:40,348]\u001b[0m Trial 63 finished with value: 0.6479100056958421 and parameters: {'max_depth': 5, 'max_features': 17, 'min_samples_split': 2}. Best is trial 51 with value: 0.6486086956521739.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 21:22:40,534]\u001b[0m Trial 64 finished with value: 0.6339415226884374 and parameters: {'max_depth': 5, 'max_features': 16, 'min_samples_split': 3}. Best is trial 51 with value: 0.6486086956521739.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 21:22:40,719]\u001b[0m Trial 65 finished with value: 0.6456392633377636 and parameters: {'max_depth': 4, 'max_features': 17, 'min_samples_split': 2}. Best is trial 51 with value: 0.6486086956521739.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 21:22:40,907]\u001b[0m Trial 66 finished with value: 0.6486086956521739 and parameters: {'max_depth': 5, 'max_features': 17, 'min_samples_split': 3}. Best is trial 51 with value: 0.6486086956521739.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 21:22:41,079]\u001b[0m Trial 67 finished with value: 0.637087905828745 and parameters: {'max_depth': 5, 'max_features': 18, 'min_samples_split': 3}. Best is trial 51 with value: 0.6486086956521739.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 21:22:41,266]\u001b[0m Trial 68 finished with value: 0.6483501044237707 and parameters: {'max_depth': 5, 'max_features': 17, 'min_samples_split': 4}. Best is trial 51 with value: 0.6486086956521739.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 21:22:41,452]\u001b[0m Trial 69 finished with value: 0.6341150560091134 and parameters: {'max_depth': 5, 'max_features': 16, 'min_samples_split': 4}. Best is trial 51 with value: 0.6486086956521739.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 21:22:41,638]\u001b[0m Trial 70 finished with value: 0.6355986329979114 and parameters: {'max_depth': 5, 'max_features': 18, 'min_samples_split': 7}. Best is trial 51 with value: 0.6486086956521739.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 21:22:41,824]\u001b[0m Trial 71 finished with value: 0.6479100056958421 and parameters: {'max_depth': 5, 'max_features': 17, 'min_samples_split': 2}. Best is trial 51 with value: 0.6486086956521739.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 21:22:42,024]\u001b[0m Trial 72 finished with value: 0.6486086956521739 and parameters: {'max_depth': 5, 'max_features': 17, 'min_samples_split': 3}. Best is trial 51 with value: 0.6486086956521739.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 21:22:42,212]\u001b[0m Trial 73 finished with value: 0.6341150560091134 and parameters: {'max_depth': 5, 'max_features': 16, 'min_samples_split': 4}. Best is trial 51 with value: 0.6486086956521739.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 21:22:42,400]\u001b[0m Trial 74 finished with value: 0.6483501044237707 and parameters: {'max_depth': 5, 'max_features': 17, 'min_samples_split': 4}. Best is trial 51 with value: 0.6486086956521739.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 21:22:42,586]\u001b[0m Trial 75 finished with value: 0.6450313271311942 and parameters: {'max_depth': 5, 'max_features': 17, 'min_samples_split': 6}. Best is trial 51 with value: 0.6486086956521739.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 21:22:42,772]\u001b[0m Trial 76 finished with value: 0.6326322384659199 and parameters: {'max_depth': 5, 'max_features': 16, 'min_samples_split': 5}. Best is trial 51 with value: 0.6486086956521739.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 21:22:42,941]\u001b[0m Trial 77 finished with value: 0.637087905828745 and parameters: {'max_depth': 5, 'max_features': 18, 'min_samples_split': 3}. Best is trial 51 with value: 0.6486086956521739.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 21:22:43,126]\u001b[0m Trial 78 finished with value: 0.6412732105562938 and parameters: {'max_depth': 5, 'max_features': 15, 'min_samples_split': 4}. Best is trial 51 with value: 0.6486086956521739.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 21:22:43,299]\u001b[0m Trial 79 finished with value: 0.6437174862350484 and parameters: {'max_depth': 5, 'max_features': 17, 'min_samples_split': 8}. Best is trial 51 with value: 0.6486086956521739.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 21:22:43,485]\u001b[0m Trial 80 finished with value: 0.6344678184925004 and parameters: {'max_depth': 5, 'max_features': 18, 'min_samples_split': 6}. Best is trial 51 with value: 0.6486086956521739.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 21:22:43,656]\u001b[0m Trial 81 finished with value: 0.6486086956521739 and parameters: {'max_depth': 5, 'max_features': 17, 'min_samples_split': 3}. Best is trial 51 with value: 0.6486086956521739.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 21:22:43,845]\u001b[0m Trial 82 finished with value: 0.6486086956521739 and parameters: {'max_depth': 5, 'max_features': 17, 'min_samples_split': 3}. Best is trial 51 with value: 0.6486086956521739.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 21:22:44,019]\u001b[0m Trial 83 finished with value: 0.6406599582304916 and parameters: {'max_depth': 5, 'max_features': 17, 'min_samples_split': 24}. Best is trial 51 with value: 0.6486086956521739.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 21:22:44,191]\u001b[0m Trial 84 finished with value: 0.6339415226884374 and parameters: {'max_depth': 5, 'max_features': 16, 'min_samples_split': 3}. Best is trial 51 with value: 0.6486086956521739.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 21:22:44,360]\u001b[0m Trial 85 finished with value: 0.6483501044237707 and parameters: {'max_depth': 5, 'max_features': 17, 'min_samples_split': 4}. Best is trial 51 with value: 0.6486086956521739.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 21:22:44,532]\u001b[0m Trial 86 finished with value: 0.6326322384659199 and parameters: {'max_depth': 5, 'max_features': 16, 'min_samples_split': 5}. Best is trial 51 with value: 0.6486086956521739.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 21:22:44,719]\u001b[0m Trial 87 finished with value: 0.6355986329979114 and parameters: {'max_depth': 5, 'max_features': 18, 'min_samples_split': 7}. Best is trial 51 with value: 0.6486086956521739.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 21:22:44,904]\u001b[0m Trial 88 finished with value: 0.6483501044237707 and parameters: {'max_depth': 5, 'max_features': 17, 'min_samples_split': 4}. Best is trial 51 with value: 0.6486086956521739.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 21:22:45,075]\u001b[0m Trial 89 finished with value: 0.6486086956521739 and parameters: {'max_depth': 5, 'max_features': 17, 'min_samples_split': 3}. Best is trial 51 with value: 0.6486086956521739.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 21:22:45,246]\u001b[0m Trial 90 finished with value: 0.637087905828745 and parameters: {'max_depth': 5, 'max_features': 18, 'min_samples_split': 3}. Best is trial 51 with value: 0.6486086956521739.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 21:22:45,418]\u001b[0m Trial 91 finished with value: 0.6470389215872413 and parameters: {'max_depth': 5, 'max_features': 17, 'min_samples_split': 5}. Best is trial 51 with value: 0.6486086956521739.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 21:22:45,588]\u001b[0m Trial 92 finished with value: 0.6486086956521739 and parameters: {'max_depth': 5, 'max_features': 17, 'min_samples_split': 3}. Best is trial 51 with value: 0.6486086956521739.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 21:22:45,760]\u001b[0m Trial 93 finished with value: 0.6486086956521739 and parameters: {'max_depth': 5, 'max_features': 17, 'min_samples_split': 3}. Best is trial 51 with value: 0.6486086956521739.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 21:22:45,933]\u001b[0m Trial 94 finished with value: 0.6339415226884374 and parameters: {'max_depth': 5, 'max_features': 16, 'min_samples_split': 3}. Best is trial 51 with value: 0.6486086956521739.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 21:22:46,104]\u001b[0m Trial 95 finished with value: 0.6479100056958421 and parameters: {'max_depth': 5, 'max_features': 17, 'min_samples_split': 2}. Best is trial 51 with value: 0.6486086956521739.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 21:22:46,275]\u001b[0m Trial 96 finished with value: 0.637087905828745 and parameters: {'max_depth': 5, 'max_features': 18, 'min_samples_split': 3}. Best is trial 51 with value: 0.6486086956521739.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 21:22:46,448]\u001b[0m Trial 97 finished with value: 0.6479100056958421 and parameters: {'max_depth': 5, 'max_features': 17, 'min_samples_split': 2}. Best is trial 51 with value: 0.6486086956521739.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 21:22:46,618]\u001b[0m Trial 98 finished with value: 0.6326322384659199 and parameters: {'max_depth': 5, 'max_features': 16, 'min_samples_split': 5}. Best is trial 51 with value: 0.6486086956521739.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 21:22:46,788]\u001b[0m Trial 99 finished with value: 0.637087905828745 and parameters: {'max_depth': 5, 'max_features': 18, 'min_samples_split': 3}. Best is trial 51 with value: 0.6486086956521739.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "#Tuning hyperparameters\n",
    "#Step 1. Define an objective function to be maximized.\n",
    "def objective(trial):\n",
    "    param = {\n",
    "        'max_depth': trial.suggest_int('max_depth',3,5,1),\n",
    "        'max_features' : trial.suggest_int(\"max_features\",10,20,1),\n",
    "        'min_samples_split':trial.suggest_int('min_samples_split',2,25,1)\n",
    "    }\n",
    "    model = DecisionTreeClassifier(**param,random_state=1)\n",
    "\n",
    " \n",
    "# Step 2: Scoring method:\n",
    "    score = model_selection.cross_val_score(model, X, y, n_jobs=12, scoring=\"accuracy\",cv=Cv_optuna)\n",
    "    accuracy = score.mean()\n",
    "    return accuracy\n",
    " \n",
    "# Step 3: Running it\n",
    "study = optuna.create_study(direction=\"maximize\",sampler=optuna.samplers.TPESampler(seed=0))\n",
    "study.optimize(objective, n_trials=100, show_progress_bar=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "28ac7c97-6c21-4117-add1-12a7be2e8f2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best parameters are : \n",
      "{'max_depth': 5, 'max_features': 17, 'min_samples_split': 3}\n"
     ]
    }
   ],
   "source": [
    "# Getting the best parameters:\n",
    "print(f\"The best parameters are : \\n{study.best_params}\")\n",
    "# Setting the best model\n",
    "clf =DecisionTreeClassifier(max_depth = study.best_params['max_depth']\n",
    "              ,max_features = study.best_params['max_features']\n",
    "              #,n_estimators = study.best_params['n_estimators']\n",
    "              #,learning_rate = study.best_params['learning_rate']\n",
    "              ,min_samples_split= study.best_params['min_samples_split']\n",
    "              ,random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "c0b71e00-d630-4d2b-b1d4-a79589e02288",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mean</th>\n",
       "      <th>Se</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Accuracy_test</th>\n",
       "      <td>0.648609</td>\n",
       "      <td>0.005099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Accuracy_train</th>\n",
       "      <td>0.756589</td>\n",
       "      <td>0.002231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1 Score</th>\n",
       "      <td>0.652491</td>\n",
       "      <td>0.006291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Precision</th>\n",
       "      <td>0.645749</td>\n",
       "      <td>0.005552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recall</th>\n",
       "      <td>0.663991</td>\n",
       "      <td>0.010066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Roc_auc</th>\n",
       "      <td>0.683640</td>\n",
       "      <td>0.005051</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Mean        Se\n",
       "Accuracy_test   0.648609  0.005099\n",
       "Accuracy_train  0.756589  0.002231\n",
       "F1 Score        0.652491  0.006291\n",
       "Precision       0.645749  0.005552\n",
       "Recall          0.663991  0.010066\n",
       "Roc_auc         0.683640  0.005051"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Model2\n",
    "Model2=Model_results(clf,X,y,Cv_model)\n",
    "Model2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "e4359628-316f-47c6-bdef-b9471932492e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th>Method</th>\n",
       "      <th colspan=\"4\" halign=\"left\">DT</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model</th>\n",
       "      <th colspan=\"2\" halign=\"left\">Model 1</th>\n",
       "      <th colspan=\"2\" halign=\"left\">Model 2</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Values</th>\n",
       "      <th>Mean</th>\n",
       "      <th>Se</th>\n",
       "      <th>Mean</th>\n",
       "      <th>Se</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Accuracy_test</th>\n",
       "      <td>0.619814</td>\n",
       "      <td>0.004582</td>\n",
       "      <td>0.648609</td>\n",
       "      <td>0.005099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Accuracy_train</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.756589</td>\n",
       "      <td>0.002231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1 Score</th>\n",
       "      <td>0.619856</td>\n",
       "      <td>0.004555</td>\n",
       "      <td>0.652491</td>\n",
       "      <td>0.006291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Precision</th>\n",
       "      <td>0.620652</td>\n",
       "      <td>0.004963</td>\n",
       "      <td>0.645749</td>\n",
       "      <td>0.005552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recall</th>\n",
       "      <td>0.620423</td>\n",
       "      <td>0.005823</td>\n",
       "      <td>0.663991</td>\n",
       "      <td>0.010066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Roc_auc</th>\n",
       "      <td>0.619799</td>\n",
       "      <td>0.004582</td>\n",
       "      <td>0.683640</td>\n",
       "      <td>0.005051</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Method                DT                              \n",
       "Model            Model 1             Model 2          \n",
       "Values              Mean        Se      Mean        Se\n",
       "Accuracy_test   0.619814  0.004582  0.648609  0.005099\n",
       "Accuracy_train  1.000000  0.000000  0.756589  0.002231\n",
       "F1 Score        0.619856  0.004555  0.652491  0.006291\n",
       "Precision       0.620652  0.004963  0.645749  0.005552\n",
       "Recall          0.620423  0.005823  0.663991  0.010066\n",
       "Roc_auc         0.619799  0.004582  0.683640  0.005051"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Saving the data of model performance\n",
    "Model_data=pd.concat([Model1,Model2],axis=1)\n",
    "Model_data.columns = [['DT']*4,['Model 1','Model 1', 'Model 2','Model 2'], ['Mean', 'Se', 'Mean', 'Se']]  \n",
    "Model_data.columns.names=['Method','Model','Values']\n",
    "Model_data.to_csv(\"./DT_model_lasso_data.csv\",sep=',')\n",
    "Model_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6047485d-89ab-471b-b393-08d893b317bc",
   "metadata": {},
   "source": [
    "## 1.2 LR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "7e67efc5-4154-43ea-ad89-57f6ba68ec1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf=LogisticRegression(solver='liblinear',random_state=0,dual=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "4e72f778-0bc0-4da2-b17d-d66357ab161c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mean</th>\n",
       "      <th>Se</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Accuracy_test</th>\n",
       "      <td>0.722692</td>\n",
       "      <td>0.004433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Accuracy_train</th>\n",
       "      <td>0.761933</td>\n",
       "      <td>0.001057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1 Score</th>\n",
       "      <td>0.726359</td>\n",
       "      <td>0.004481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Precision</th>\n",
       "      <td>0.717212</td>\n",
       "      <td>0.004715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recall</th>\n",
       "      <td>0.736783</td>\n",
       "      <td>0.005738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Roc_auc</th>\n",
       "      <td>0.794243</td>\n",
       "      <td>0.003870</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Mean        Se\n",
       "Accuracy_test   0.722692  0.004433\n",
       "Accuracy_train  0.761933  0.001057\n",
       "F1 Score        0.726359  0.004481\n",
       "Precision       0.717212  0.004715\n",
       "Recall          0.736783  0.005738\n",
       "Roc_auc         0.794243  0.003870"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Model1 \n",
    "Model1_clf=clf\n",
    "#Model1\n",
    "Model1=Model_results(Model1_clf,X,y,Cv_model)\n",
    "Model1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "b9338635-62a3-4fe9-912b-6acc77ef994a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2024-11-14 21:22:49,477]\u001b[0m A new study created in memory with name: no-name-7843e209-7761-4d81-89ca-c2b951e692c3\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 21:22:52,695]\u001b[0m Trial 0 finished with value: 0.7129158913992785 and parameters: {'logreg_c': 0.3177840006884068, 'l1_ratio': 0.7482920440979423, 'max_iter': 100}. Best is trial 0 with value: 0.7129158913992785.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 21:22:52,913]\u001b[0m Trial 1 finished with value: 0.7008699449401936 and parameters: {'logreg_c': 0.0651621545821569, 'l1_ratio': 0.23208030173540176, 'max_iter': 275}. Best is trial 0 with value: 0.7129158913992785.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 21:22:53,145]\u001b[0m Trial 2 finished with value: 0.6876050882855516 and parameters: {'logreg_c': 0.013108749615263334, 'l1_ratio': 0.411004654338743, 'max_iter': 854}. Best is trial 0 with value: 0.7129158913992785.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 21:22:53,409]\u001b[0m Trial 3 finished with value: 0.728454528194418 and parameters: {'logreg_c': 1.7096232052870346, 'l1_ratio': 0.4772750629629653, 'max_iter': 1402}. Best is trial 3 with value: 0.728454528194418.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 21:22:53,629]\u001b[0m Trial 4 finished with value: 0.6936290108220998 and parameters: {'logreg_c': 0.016854407828169382, 'l1_ratio': 0.8903056927518509, 'max_iter': 152}. Best is trial 3 with value: 0.728454528194418.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 21:22:53,941]\u001b[0m Trial 5 finished with value: 0.7478249477881147 and parameters: {'logreg_c': 10.539137268289434, 'l1_ratio': 0.4755743221304143, 'max_iter': 1162}. Best is trial 5 with value: 0.7478249477881147.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 21:22:54,141]\u001b[0m Trial 6 finished with value: 0.6568072906778052 and parameters: {'logreg_c': 0.006955392321661603, 'l1_ratio': 0.2782913401763909, 'max_iter': 1622}. Best is trial 5 with value: 0.7478249477881147.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 21:22:54,780]\u001b[0m Trial 7 finished with value: 0.7434528194418075 and parameters: {'logreg_c': 645.0144652189372, 'l1_ratio': 0.38208176034331853, 'max_iter': 1416}. Best is trial 5 with value: 0.7478249477881147.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 21:22:55,276]\u001b[0m Trial 8 finished with value: 0.7480778431744826 and parameters: {'logreg_c': 181.27374779133626, 'l1_ratio': 0.9051459971534626, 'max_iter': 261}. Best is trial 8 with value: 0.7480778431744826.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 21:22:55,494]\u001b[0m Trial 9 finished with value: 0.5283539016517942 and parameters: {'logreg_c': 0.001715255021408637, 'l1_ratio': 0.25284737760811204, 'max_iter': 1769}. Best is trial 8 with value: 0.7480778431744826.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 21:22:56,254]\u001b[0m Trial 10 finished with value: 0.744499335485096 and parameters: {'logreg_c': 909.7939268284556, 'l1_ratio': 0.9808743317423054, 'max_iter': 644}. Best is trial 8 with value: 0.7480778431744826.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 21:22:56,593]\u001b[0m Trial 11 finished with value: 0.7472124549079174 and parameters: {'logreg_c': 26.68235334285073, 'l1_ratio': 0.6357475149295672, 'max_iter': 1091}. Best is trial 8 with value: 0.7480778431744826.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 21:22:56,927]\u001b[0m Trial 12 finished with value: 0.7471258781089805 and parameters: {'logreg_c': 25.97004260307536, 'l1_ratio': 0.6275895804235085, 'max_iter': 550}. Best is trial 8 with value: 0.7480778431744826.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 21:22:57,272]\u001b[0m Trial 13 finished with value: 0.7473009303208659 and parameters: {'logreg_c': 23.367359201847155, 'l1_ratio': 0.76875396478504, 'max_iter': 1069}. Best is trial 8 with value: 0.7480778431744826.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 21:22:57,553]\u001b[0m Trial 14 finished with value: 0.7372644769318398 and parameters: {'logreg_c': 3.304075874015784, 'l1_ratio': 0.5568433483879746, 'max_iter': 1282}. Best is trial 8 with value: 0.7480778431744826.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 21:22:58,015]\u001b[0m Trial 15 finished with value: 0.7485137649515853 and parameters: {'logreg_c': 146.4182761953825, 'l1_ratio': 0.11342714523990888, 'max_iter': 693}. Best is trial 15 with value: 0.7485137649515853.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 21:22:58,777]\u001b[0m Trial 16 finished with value: 0.7482513764951587 and parameters: {'logreg_c': 156.41870478254816, 'l1_ratio': 0.10898590072384023, 'max_iter': 462}. Best is trial 15 with value: 0.7485137649515853.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 21:22:59,819]\u001b[0m Trial 17 finished with value: 0.7485141446743877 and parameters: {'logreg_c': 137.9871301885904, 'l1_ratio': 0.1021308409403022, 'max_iter': 579}. Best is trial 17 with value: 0.7485141446743877.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 21:23:00,759]\u001b[0m Trial 18 finished with value: 0.749735333206759 and parameters: {'logreg_c': 110.24741008209904, 'l1_ratio': 0.10021717673241526, 'max_iter': 834}. Best is trial 18 with value: 0.749735333206759.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 21:23:01,054]\u001b[0m Trial 19 finished with value: 0.7114307955192709 and parameters: {'logreg_c': 0.22845049071872373, 'l1_ratio': 0.17287534047600464, 'max_iter': 870}. Best is trial 18 with value: 0.749735333206759.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 21:23:01,487]\u001b[0m Trial 20 finished with value: 0.7440736662236569 and parameters: {'logreg_c': 5.878522766850031, 'l1_ratio': 0.32736117014315924, 'max_iter': 814}. Best is trial 18 with value: 0.749735333206759.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 21:23:02,335]\u001b[0m Trial 21 finished with value: 0.7483387127396999 and parameters: {'logreg_c': 134.2551259115093, 'l1_ratio': 0.1487300883736295, 'max_iter': 714}. Best is trial 18 with value: 0.749735333206759.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 21:23:03,075]\u001b[0m Trial 22 finished with value: 0.7493882665654072 and parameters: {'logreg_c': 73.9620227962533, 'l1_ratio': 0.1008095535435035, 'max_iter': 416}. Best is trial 18 with value: 0.749735333206759.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 21:23:03,769]\u001b[0m Trial 23 finished with value: 0.7489534839567117 and parameters: {'logreg_c': 64.36852818332991, 'l1_ratio': 0.21242058918782458, 'max_iter': 452}. Best is trial 18 with value: 0.749735333206759.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 21:23:04,462]\u001b[0m Trial 24 finished with value: 0.7495686348965256 and parameters: {'logreg_c': 39.38604600461043, 'l1_ratio': 0.19966597940702618, 'max_iter': 396}. Best is trial 18 with value: 0.749735333206759.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 21:23:05,814]\u001b[0m Trial 25 finished with value: 0.7438014049743686 and parameters: {'logreg_c': 613.6736281371216, 'l1_ratio': 0.30865993770827793, 'max_iter': 332}. Best is trial 18 with value: 0.749735333206759.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 21:23:06,107]\u001b[0m Trial 26 finished with value: 0.7161420163280806 and parameters: {'logreg_c': 0.532241332003281, 'l1_ratio': 0.1920192196824233, 'max_iter': 437}. Best is trial 18 with value: 0.749735333206759.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 21:23:06,554]\u001b[0m Trial 27 finished with value: 0.7467784317448263 and parameters: {'logreg_c': 8.412640650628198, 'l1_ratio': 0.3797391296196149, 'max_iter': 831}. Best is trial 18 with value: 0.749735333206759.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 21:23:07,117]\u001b[0m Trial 28 finished with value: 0.749131953673818 and parameters: {'logreg_c': 48.56596790114113, 'l1_ratio': 0.1761701280915972, 'max_iter': 963}. Best is trial 18 with value: 0.749735333206759.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 21:23:07,455]\u001b[0m Trial 29 finished with value: 0.7274064932599202 and parameters: {'logreg_c': 1.4786372976337825, 'l1_ratio': 0.2689145871114248, 'max_iter': 197}. Best is trial 18 with value: 0.749735333206759.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 21:23:08,524]\u001b[0m Trial 30 finished with value: 0.7450237326751471 and parameters: {'logreg_c': 355.73515228051855, 'l1_ratio': 0.16093584222435903, 'max_iter': 112}. Best is trial 18 with value: 0.749735333206759.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 21:23:09,116]\u001b[0m Trial 31 finished with value: 0.7486075564837669 and parameters: {'logreg_c': 32.97563864085463, 'l1_ratio': 0.1818682951551474, 'max_iter': 1011}. Best is trial 18 with value: 0.749735333206759.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 21:23:09,836]\u001b[0m Trial 32 finished with value: 0.7491273970001899 and parameters: {'logreg_c': 65.94567682961764, 'l1_ratio': 0.22659559877042562, 'max_iter': 347}. Best is trial 18 with value: 0.749735333206759.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 21:23:10,581]\u001b[0m Trial 33 finished with value: 0.7492170115815455 and parameters: {'logreg_c': 59.84916162186237, 'l1_ratio': 0.32715056655893526, 'max_iter': 907}. Best is trial 18 with value: 0.749735333206759.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 21:23:11,638]\u001b[0m Trial 34 finished with value: 0.7457209037402696 and parameters: {'logreg_c': 271.1014517951053, 'l1_ratio': 0.3336597358754543, 'max_iter': 1238}. Best is trial 18 with value: 0.749735333206759.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 21:23:12,111]\u001b[0m Trial 35 finished with value: 0.7476517941902411 and parameters: {'logreg_c': 12.040715416632654, 'l1_ratio': 0.47557881856657447, 'max_iter': 727}. Best is trial 18 with value: 0.749735333206759.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 21:23:12,500]\u001b[0m Trial 36 finished with value: 0.7385737611543575 and parameters: {'logreg_c': 3.552306151003997, 'l1_ratio': 0.23683085435732532, 'max_iter': 902}. Best is trial 18 with value: 0.749735333206759.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 21:23:12,764]\u001b[0m Trial 37 finished with value: 0.7094239605088285 and parameters: {'logreg_c': 0.15987250103783857, 'l1_ratio': 0.10025927887550398, 'max_iter': 587}. Best is trial 18 with value: 0.749735333206759.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 21:23:13,268]\u001b[0m Trial 38 finished with value: 0.747474843364344 and parameters: {'logreg_c': 15.75167614116776, 'l1_ratio': 0.4421099810280963, 'max_iter': 505}. Best is trial 18 with value: 0.749735333206759.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 21:23:13,994]\u001b[0m Trial 39 finished with value: 0.7490404404784508 and parameters: {'logreg_c': 65.07169840709791, 'l1_ratio': 0.2935238453736126, 'max_iter': 1564}. Best is trial 18 with value: 0.749735333206759.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 21:23:14,351]\u001b[0m Trial 40 finished with value: 0.7204218720334157 and parameters: {'logreg_c': 0.7762280673724565, 'l1_ratio': 0.35410872804910587, 'max_iter': 347}. Best is trial 18 with value: 0.749735333206759.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 21:23:15,041]\u001b[0m Trial 41 finished with value: 0.7490430985380673 and parameters: {'logreg_c': 51.147252534360035, 'l1_ratio': 0.1481081887735321, 'max_iter': 1022}. Best is trial 18 with value: 0.749735333206759.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 21:23:16,131]\u001b[0m Trial 42 finished with value: 0.7445874311752422 and parameters: {'logreg_c': 395.47797542737464, 'l1_ratio': 0.2108442300806621, 'max_iter': 947}. Best is trial 18 with value: 0.749735333206759.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 21:23:16,943]\u001b[0m Trial 43 finished with value: 0.7492997911524587 and parameters: {'logreg_c': 98.66700099032994, 'l1_ratio': 0.2576589086607993, 'max_iter': 1153}. Best is trial 18 with value: 0.749735333206759.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 21:23:17,814]\u001b[0m Trial 44 finished with value: 0.7498249477881147 and parameters: {'logreg_c': 84.23394476468694, 'l1_ratio': 0.2554449469098683, 'max_iter': 1388}. Best is trial 44 with value: 0.7498249477881147.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 21:23:19,587]\u001b[0m Trial 45 finished with value: 0.7438879817733056 and parameters: {'logreg_c': 975.8286797548943, 'l1_ratio': 0.2609663465225141, 'max_iter': 1996}. Best is trial 44 with value: 0.7498249477881147.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 21:23:20,614]\u001b[0m Trial 46 finished with value: 0.7456335674957281 and parameters: {'logreg_c': 269.11140431466623, 'l1_ratio': 0.42931013841302557, 'max_iter': 1403}. Best is trial 44 with value: 0.7498249477881147.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 21:23:21,533]\u001b[0m Trial 47 finished with value: 0.7490381621416367 and parameters: {'logreg_c': 100.95571320685202, 'l1_ratio': 0.5364181147495661, 'max_iter': 1496}. Best is trial 44 with value: 0.7498249477881147.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 21:23:22,142]\u001b[0m Trial 48 finished with value: 0.7464290867666604 and parameters: {'logreg_c': 19.273711619838, 'l1_ratio': 0.13879828080902634, 'max_iter': 1288}. Best is trial 44 with value: 0.7498249477881147.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 21:23:22,631]\u001b[0m Trial 49 finished with value: 0.7450332257452061 and parameters: {'logreg_c': 6.5712408363732475, 'l1_ratio': 0.2469783646375505, 'max_iter': 1689}. Best is trial 44 with value: 0.7498249477881147.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 21:23:22,923]\u001b[0m Trial 50 finished with value: 0.6979878488703245 and parameters: {'logreg_c': 0.023614953433099054, 'l1_ratio': 0.709203601402445, 'max_iter': 1146}. Best is trial 44 with value: 0.7498249477881147.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 21:23:23,512]\u001b[0m Trial 51 finished with value: 0.7485209796848301 and parameters: {'logreg_c': 31.71841231440523, 'l1_ratio': 0.3802370693198826, 'max_iter': 1229}. Best is trial 44 with value: 0.7498249477881147.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 21:23:24,305]\u001b[0m Trial 52 finished with value: 0.7497372318207709 and parameters: {'logreg_c': 91.7693940664344, 'l1_ratio': 0.1300188138132376, 'max_iter': 1342}. Best is trial 44 with value: 0.7498249477881147.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 21:23:25,562]\u001b[0m Trial 53 finished with value: 0.7466816024302259 and parameters: {'logreg_c': 219.63823210436914, 'l1_ratio': 0.13369432351226757, 'max_iter': 1313}. Best is trial 44 with value: 0.7498249477881147.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 21:23:26,530]\u001b[0m Trial 54 finished with value: 0.7493001708752611 and parameters: {'logreg_c': 99.27526593499566, 'l1_ratio': 0.21634621554127725, 'max_iter': 1130}. Best is trial 44 with value: 0.7498249477881147.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 21:23:28,200]\u001b[0m Trial 55 finished with value: 0.7440626542623885 and parameters: {'logreg_c': 550.9245260921905, 'l1_ratio': 0.19055139812948352, 'max_iter': 1372}. Best is trial 44 with value: 0.7498249477881147.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 21:23:29,036]\u001b[0m Trial 56 finished with value: 0.74982418834251 and parameters: {'logreg_c': 97.3876530854463, 'l1_ratio': 0.12594417628419063, 'max_iter': 1528}. Best is trial 44 with value: 0.7498249477881147.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 21:23:29,724]\u001b[0m Trial 57 finished with value: 0.749829504461743 and parameters: {'logreg_c': 40.67049068111694, 'l1_ratio': 0.1281031376809009, 'max_iter': 1766}. Best is trial 57 with value: 0.749829504461743.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 21:23:30,204]\u001b[0m Trial 58 finished with value: 0.7360440478450733 and parameters: {'logreg_c': 2.9994385981726124, 'l1_ratio': 0.129892596443916, 'max_iter': 1860}. Best is trial 57 with value: 0.749829504461743.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 21:23:30,827]\u001b[0m Trial 59 finished with value: 0.7479969622175813 and parameters: {'logreg_c': 30.768790895557824, 'l1_ratio': 0.16102751697907614, 'max_iter': 1503}. Best is trial 57 with value: 0.749829504461743.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 21:23:31,094]\u001b[0m Trial 60 finished with value: 0.5143949117144484 and parameters: {'logreg_c': 0.0014647914843692897, 'l1_ratio': 0.1976687026554126, 'max_iter': 1719}. Best is trial 57 with value: 0.749829504461743.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 21:23:32,284]\u001b[0m Trial 61 finished with value: 0.748688057717866 and parameters: {'logreg_c': 167.3983843095662, 'l1_ratio': 0.11924897583533323, 'max_iter': 1854}. Best is trial 57 with value: 0.749829504461743.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 21:23:32,781]\u001b[0m Trial 62 finished with value: 0.7475625593316879 and parameters: {'logreg_c': 13.716690140371071, 'l1_ratio': 0.10118980538898249, 'max_iter': 1581}. Best is trial 57 with value: 0.749829504461743.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 21:23:33,647]\u001b[0m Trial 63 finished with value: 0.7492124549079173 and parameters: {'logreg_c': 104.27070807359694, 'l1_ratio': 0.16299409304053883, 'max_iter': 256}. Best is trial 57 with value: 0.749829504461743.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 21:23:34,356]\u001b[0m Trial 64 finished with value: 0.749829504461743 and parameters: {'logreg_c': 40.219140520036206, 'l1_ratio': 0.13706883896287936, 'max_iter': 1449}. Best is trial 57 with value: 0.749829504461743.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 21:23:35,011]\u001b[0m Trial 65 finished with value: 0.7487822289728495 and parameters: {'logreg_c': 35.01289287758785, 'l1_ratio': 0.13613838439807208, 'max_iter': 1663}. Best is trial 57 with value: 0.749829504461743.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 21:23:35,616]\u001b[0m Trial 66 finished with value: 0.7467776722992217 and parameters: {'logreg_c': 19.787845112588826, 'l1_ratio': 0.1817728144257392, 'max_iter': 1480}. Best is trial 57 with value: 0.749829504461743.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 21:23:35,863]\u001b[0m Trial 67 finished with value: 0.588476931839757 and parameters: {'logreg_c': 0.003114708027338804, 'l1_ratio': 0.28704185025577933, 'max_iter': 1342}. Best is trial 57 with value: 0.749829504461743.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 21:23:37,219]\u001b[0m Trial 68 finished with value: 0.7445878108980444 and parameters: {'logreg_c': 443.6453221471282, 'l1_ratio': 0.21489780077564624, 'max_iter': 1435}. Best is trial 57 with value: 0.749829504461743.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 21:23:37,720]\u001b[0m Trial 69 finished with value: 0.7479126637554585 and parameters: {'logreg_c': 9.362413748446661, 'l1_ratio': 0.15629462222493878, 'max_iter': 1608}. Best is trial 57 with value: 0.749829504461743.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 21:23:38,831]\u001b[0m Trial 70 finished with value: 0.7460702487184355 and parameters: {'logreg_c': 257.4035972535498, 'l1_ratio': 0.8620627555293229, 'max_iter': 1760}. Best is trial 57 with value: 0.749829504461743.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 21:23:39,549]\u001b[0m Trial 71 finished with value: 0.7489572811847351 and parameters: {'logreg_c': 42.220605680192726, 'l1_ratio': 0.12166714614527144, 'max_iter': 1531}. Best is trial 57 with value: 0.749829504461743.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 21:23:40,531]\u001b[0m Trial 72 finished with value: 0.7497372318207709 and parameters: {'logreg_c': 93.07248582424027, 'l1_ratio': 0.10519103253531392, 'max_iter': 1220}. Best is trial 57 with value: 0.749829504461743.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 21:23:41,526]\u001b[0m Trial 73 finished with value: 0.7485145243971901 and parameters: {'logreg_c': 177.4359783488376, 'l1_ratio': 0.17216939059250896, 'max_iter': 1204}. Best is trial 57 with value: 0.749829504461743.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 21:23:42,287]\u001b[0m Trial 74 finished with value: 0.7497376115435732 and parameters: {'logreg_c': 83.11368130439577, 'l1_ratio': 0.1415823387488192, 'max_iter': 1447}. Best is trial 57 with value: 0.749829504461743.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 21:23:43,052]\u001b[0m Trial 75 finished with value: 0.7496498955762294 and parameters: {'logreg_c': 81.58004406639151, 'l1_ratio': 0.13104672161566014, 'max_iter': 1379}. Best is trial 57 with value: 0.749829504461743.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 21:23:43,986]\u001b[0m Trial 76 finished with value: 0.7482513764951584 and parameters: {'logreg_c': 131.04317160508452, 'l1_ratio': 0.2374988802270042, 'max_iter': 1444}. Best is trial 57 with value: 0.749829504461743.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 21:23:44,720]\u001b[0m Trial 77 finished with value: 0.7490446174292765 and parameters: {'logreg_c': 48.45198671033242, 'l1_ratio': 0.1524341548060329, 'max_iter': 1639}. Best is trial 57 with value: 0.749829504461743.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 21:23:45,385]\u001b[0m Trial 78 finished with value: 0.7473009303208659 and parameters: {'logreg_c': 23.1448988533989, 'l1_ratio': 0.12275307683324485, 'max_iter': 1250}. Best is trial 57 with value: 0.749829504461743.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 21:23:46,282]\u001b[0m Trial 79 finished with value: 0.7484268084298462 and parameters: {'logreg_c': 140.1494473387295, 'l1_ratio': 0.19181857206710654, 'max_iter': 1101}. Best is trial 57 with value: 0.749829504461743.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 21:23:47,352]\u001b[0m Trial 80 finished with value: 0.7445866717296374 and parameters: {'logreg_c': 373.3974381674279, 'l1_ratio': 0.10364685293526792, 'max_iter': 1333}. Best is trial 57 with value: 0.749829504461743.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 21:23:48,186]\u001b[0m Trial 81 finished with value: 0.749125498386178 and parameters: {'logreg_c': 101.4578420824522, 'l1_ratio': 0.1385817369293406, 'max_iter': 1364}. Best is trial 57 with value: 0.749829504461743.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 21:23:49,122]\u001b[0m Trial 82 finished with value: 0.7495633187772924 and parameters: {'logreg_c': 71.95563149699021, 'l1_ratio': 0.12318272655296243, 'max_iter': 1193}. Best is trial 57 with value: 0.749829504461743.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 21:23:50,033]\u001b[0m Trial 83 finished with value: 0.7493882665654072 and parameters: {'logreg_c': 73.9866405067812, 'l1_ratio': 0.16863642868306467, 'max_iter': 1447}. Best is trial 57 with value: 0.749829504461743.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 21:23:51,200]\u001b[0m Trial 84 finished with value: 0.7462437820391113 and parameters: {'logreg_c': 248.9076710269619, 'l1_ratio': 0.1490968427139701, 'max_iter': 1280}. Best is trial 57 with value: 0.749829504461743.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 21:23:51,898]\u001b[0m Trial 85 finished with value: 0.7490446174292765 and parameters: {'logreg_c': 48.06958713627818, 'l1_ratio': 0.10286987585808077, 'max_iter': 1392}. Best is trial 57 with value: 0.749829504461743.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 21:23:53,788]\u001b[0m Trial 86 finished with value: 0.7436267324852858 and parameters: {'logreg_c': 697.3366681130506, 'l1_ratio': 0.20344264285419772, 'max_iter': 1467}. Best is trial 57 with value: 0.749829504461743.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 21:23:54,743]\u001b[0m Trial 87 finished with value: 0.7499996202771976 and parameters: {'logreg_c': 85.4545028000233, 'l1_ratio': 0.528440706950595, 'max_iter': 1528}. Best is trial 87 with value: 0.7499996202771976.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 21:23:55,419]\u001b[0m Trial 88 finished with value: 0.7471251186633759 and parameters: {'logreg_c': 26.972646191213347, 'l1_ratio': 0.6769686022062825, 'max_iter': 1825}. Best is trial 87 with value: 0.7499996202771976.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 21:23:56,374]\u001b[0m Trial 89 finished with value: 0.7477284981963166 and parameters: {'logreg_c': 197.81663778353962, 'l1_ratio': 0.8082423816139115, 'max_iter': 1566}. Best is trial 87 with value: 0.7499996202771976.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 21:23:57,296]\u001b[0m Trial 90 finished with value: 0.7488619707613442 and parameters: {'logreg_c': 128.01817345990105, 'l1_ratio': 0.5352972754747769, 'max_iter': 1050}. Best is trial 87 with value: 0.7499996202771976.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 21:23:58,168]\u001b[0m Trial 91 finished with value: 0.7497372318207708 and parameters: {'logreg_c': 80.79654173129092, 'l1_ratio': 0.23289020412782888, 'max_iter': 1532}. Best is trial 87 with value: 0.7499996202771976.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 21:23:58,935]\u001b[0m Trial 92 finished with value: 0.7492173913043478 and parameters: {'logreg_c': 53.329131157858036, 'l1_ratio': 0.5947556869588314, 'max_iter': 1538}. Best is trial 87 with value: 0.7499996202771976.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 21:23:59,531]\u001b[0m Trial 93 finished with value: 0.7472132143535218 and parameters: {'logreg_c': 17.096070494391554, 'l1_ratio': 0.23039051295952895, 'max_iter': 1606}. Best is trial 87 with value: 0.7499996202771976.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 21:24:00,739]\u001b[0m Trial 94 finished with value: 0.7456335674957282 and parameters: {'logreg_c': 312.4624985212137, 'l1_ratio': 0.2739642894355833, 'max_iter': 1730}. Best is trial 87 with value: 0.7499996202771976.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 21:24:01,564]\u001b[0m Trial 95 finished with value: 0.7496502752990317 and parameters: {'logreg_c': 89.40873894628874, 'l1_ratio': 0.30959991820634425, 'max_iter': 1953}. Best is trial 87 with value: 0.7499996202771976.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 21:24:02,169]\u001b[0m Trial 96 finished with value: 0.7494794000379721 and parameters: {'logreg_c': 36.669008043821435, 'l1_ratio': 0.1791577049507426, 'max_iter': 1518}. Best is trial 87 with value: 0.7499996202771976.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 21:24:03,296]\u001b[0m Trial 97 finished with value: 0.7477284981963167 and parameters: {'logreg_c': 186.03847658202858, 'l1_ratio': 0.1545149158260225, 'max_iter': 768}. Best is trial 87 with value: 0.7499996202771976.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 21:24:04,150]\u001b[0m Trial 98 finished with value: 0.7499992405543953 and parameters: {'logreg_c': 77.34676202519437, 'l1_ratio': 0.22274385358173032, 'max_iter': 1412}. Best is trial 87 with value: 0.7499996202771976.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 21:24:04,914]\u001b[0m Trial 99 finished with value: 0.7492170115815455 and parameters: {'logreg_c': 57.812209327806414, 'l1_ratio': 0.49840938824045733, 'max_iter': 1415}. Best is trial 87 with value: 0.7499996202771976.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "#Tuning hyperparameters\n",
    "#Step 1. Define an objective function to be maximized.\n",
    "def objective(trial):\n",
    "    logreg_c = trial.suggest_float(\"logreg_c\", 1e-3,  1e3, log=True)\n",
    "    l1_ratio = trial.suggest_float(\"l1_ratio\",0.1,1,log=False) \n",
    "    #penalty = trial.suggest_categorical(\"penalty\",['l1','l2'])\n",
    "    max_iter = trial.suggest_int(\"max_iter\", 100,2000)\n",
    "    model =LogisticRegression(C=logreg_c,\n",
    "                              max_iter=max_iter,\n",
    "                              l1_ratio=l1_ratio,\n",
    "                              solver='liblinear',random_state=1)\n",
    "    \n",
    "# Step 2: Scoring method:\n",
    "    score = model_selection.cross_val_score(model, X, y, n_jobs=8, scoring=\"accuracy\",cv=Cv_optuna)\n",
    "    accuracy = score.mean()\n",
    "    return accuracy\n",
    "\n",
    "# Step 3: Running it\n",
    "study = optuna.create_study(direction=\"maximize\",sampler=optuna.samplers.TPESampler(seed=1))\n",
    "study.optimize(objective, n_trials=100, show_progress_bar=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "cd09afa2-c7ae-4f28-acb3-9a0c06e89504",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best parameters are : \n",
      "{'logreg_c': 85.4545028000233, 'l1_ratio': 0.528440706950595, 'max_iter': 1528}\n"
     ]
    }
   ],
   "source": [
    "# Getting the best parameters:\n",
    "print(f\"The best parameters are : \\n{study.best_params}\")\n",
    "# Setting the best model\n",
    "clf=LogisticRegression(C=study.best_params['logreg_c'],\n",
    "                              max_iter=study.best_params['max_iter'],\n",
    "                              l1_ratio=study.best_params['l1_ratio'],\n",
    "                              solver='liblinear',\n",
    "                              random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "18f98263-5b44-4a58-ad76-bd2288347abf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mean</th>\n",
       "      <th>Se</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Accuracy_test</th>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.003570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Accuracy_train</th>\n",
       "      <td>0.820921</td>\n",
       "      <td>0.001116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1 Score</th>\n",
       "      <td>0.751578</td>\n",
       "      <td>0.003448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Precision</th>\n",
       "      <td>0.748110</td>\n",
       "      <td>0.004700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recall</th>\n",
       "      <td>0.756522</td>\n",
       "      <td>0.004848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Roc_auc</th>\n",
       "      <td>0.813838</td>\n",
       "      <td>0.002911</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Mean        Se\n",
       "Accuracy_test   0.750000  0.003570\n",
       "Accuracy_train  0.820921  0.001116\n",
       "F1 Score        0.751578  0.003448\n",
       "Precision       0.748110  0.004700\n",
       "Recall          0.756522  0.004848\n",
       "Roc_auc         0.813838  0.002911"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Model2\n",
    "Model2=Model_results(clf,X,y,Cv_model)\n",
    "Model2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "0eba0a05-824b-4da4-8a16-535220341d36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th>Method</th>\n",
       "      <th colspan=\"4\" halign=\"left\">LR</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model</th>\n",
       "      <th colspan=\"2\" halign=\"left\">Model 1</th>\n",
       "      <th colspan=\"2\" halign=\"left\">Model 2</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Values</th>\n",
       "      <th>Mean</th>\n",
       "      <th>Se</th>\n",
       "      <th>Mean</th>\n",
       "      <th>Se</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Accuracy_test</th>\n",
       "      <td>0.722692</td>\n",
       "      <td>0.004433</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.003570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Accuracy_train</th>\n",
       "      <td>0.761933</td>\n",
       "      <td>0.001057</td>\n",
       "      <td>0.820921</td>\n",
       "      <td>0.001116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1 Score</th>\n",
       "      <td>0.726359</td>\n",
       "      <td>0.004481</td>\n",
       "      <td>0.751578</td>\n",
       "      <td>0.003448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Precision</th>\n",
       "      <td>0.717212</td>\n",
       "      <td>0.004715</td>\n",
       "      <td>0.748110</td>\n",
       "      <td>0.004700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recall</th>\n",
       "      <td>0.736783</td>\n",
       "      <td>0.005738</td>\n",
       "      <td>0.756522</td>\n",
       "      <td>0.004848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Roc_auc</th>\n",
       "      <td>0.794243</td>\n",
       "      <td>0.003870</td>\n",
       "      <td>0.813838</td>\n",
       "      <td>0.002911</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Method                LR                              \n",
       "Model            Model 1             Model 2          \n",
       "Values              Mean        Se      Mean        Se\n",
       "Accuracy_test   0.722692  0.004433  0.750000  0.003570\n",
       "Accuracy_train  0.761933  0.001057  0.820921  0.001116\n",
       "F1 Score        0.726359  0.004481  0.751578  0.003448\n",
       "Precision       0.717212  0.004715  0.748110  0.004700\n",
       "Recall          0.736783  0.005738  0.756522  0.004848\n",
       "Roc_auc         0.794243  0.003870  0.813838  0.002911"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Saving the data of model performance\n",
    "Model_data=pd.concat([Model1,Model2],axis=1)\n",
    "Model_data.columns = [['LR']*4,['Model 1','Model 1', 'Model 2','Model 2'], ['Mean', 'Se', 'Mean', 'Se']]  \n",
    "Model_data.columns.names=['Method','Model','Values']\n",
    "Model_data.to_csv(\"./LR_model_lasso_data.csv\",sep=',')\n",
    "Model_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0844c7c8-f6b1-410a-b253-879aedd14e57",
   "metadata": {},
   "source": [
    "## 1.3 RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "d9c4731c-bbfe-47eb-bb7f-7d8b2909ea2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf=RandomForestClassifier(random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "ffdd2f35-ec29-4ef8-8309-6a84646f4539",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mean</th>\n",
       "      <th>Se</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Accuracy_test</th>\n",
       "      <td>0.705591</td>\n",
       "      <td>0.003320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Accuracy_train</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1 Score</th>\n",
       "      <td>0.706152</td>\n",
       "      <td>0.003557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Precision</th>\n",
       "      <td>0.705308</td>\n",
       "      <td>0.003888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recall</th>\n",
       "      <td>0.708526</td>\n",
       "      <td>0.005622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Roc_auc</th>\n",
       "      <td>0.773311</td>\n",
       "      <td>0.003423</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Mean        Se\n",
       "Accuracy_test   0.705591  0.003320\n",
       "Accuracy_train  1.000000  0.000000\n",
       "F1 Score        0.706152  0.003557\n",
       "Precision       0.705308  0.003888\n",
       "Recall          0.708526  0.005622\n",
       "Roc_auc         0.773311  0.003423"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Model1 （4175 descriptors）\n",
    "Model1_clf=clf\n",
    "#Model1\n",
    "Model1=Model_results(Model1_clf,X,y,Cv_model)\n",
    "Model1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "6f4b6d2b-6cf0-4f44-8bd5-02b5d1377add",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2024-11-14 21:25:15,394]\u001b[0m A new study created in memory with name: no-name-f210d30a-6e61-429d-9d84-9973a9ccd6e8\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 21:25:25,674]\u001b[0m Trial 0 finished with value: 0.49825327510917033 and parameters: {'n_estimators': 594, 'max_depth': 16, 'max_features': 20, 'min_impurity_decrease': 2.724415914984484}. Best is trial 0 with value: 0.49825327510917033.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 21:25:33,596]\u001b[0m Trial 1 finished with value: 0.49825327510917033 and parameters: {'n_estimators': 481, 'max_depth': 15, 'max_features': 16, 'min_impurity_decrease': 4.4588650039103985}. Best is trial 0 with value: 0.49825327510917033.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 21:25:51,010]\u001b[0m Trial 2 finished with value: 0.49825327510917033 and parameters: {'n_estimators': 968, 'max_depth': 11, 'max_features': 25, 'min_impurity_decrease': 2.644474598764522}. Best is trial 0 with value: 0.49825327510917033.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 21:25:59,801]\u001b[0m Trial 3 finished with value: 0.49825327510917033 and parameters: {'n_estimators': 611, 'max_depth': 19, 'max_features': 6, 'min_impurity_decrease': 0.43564649850770354}. Best is trial 0 with value: 0.49825327510917033.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 21:26:02,213]\u001b[0m Trial 4 finished with value: 0.5 and parameters: {'n_estimators': 118, 'max_depth': 18, 'max_features': 25, 'min_impurity_decrease': 4.3500607412340955}. Best is trial 4 with value: 0.5.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 21:26:17,827]\u001b[0m Trial 5 finished with value: 0.49825327510917033 and parameters: {'n_estimators': 981, 'max_depth': 17, 'max_features': 16, 'min_impurity_decrease': 3.902645881432277}. Best is trial 4 with value: 0.5.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 21:26:21,035]\u001b[0m Trial 6 finished with value: 0.5 and parameters: {'n_estimators': 206, 'max_depth': 15, 'max_features': 8, 'min_impurity_decrease': 4.7233445852479194}. Best is trial 4 with value: 0.5.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 21:26:29,952]\u001b[0m Trial 7 finished with value: 0.49825327510917033 and parameters: {'n_estimators': 570, 'max_depth': 11, 'max_features': 11, 'min_impurity_decrease': 3.871168447171083}. Best is trial 4 with value: 0.5.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 21:26:37,380]\u001b[0m Trial 8 finished with value: 0.49825327510917033 and parameters: {'n_estimators': 510, 'max_depth': 14, 'max_features': 5, 'min_impurity_decrease': 3.0881774853793855}. Best is trial 4 with value: 0.5.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 21:26:49,608]\u001b[0m Trial 9 finished with value: 0.49825327510917033 and parameters: {'n_estimators': 651, 'max_depth': 14, 'max_features': 29, 'min_impurity_decrease': 3.409101495517417}. Best is trial 4 with value: 0.5.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 21:26:51,766]\u001b[0m Trial 10 finished with value: 0.5 and parameters: {'n_estimators': 118, 'max_depth': 7, 'max_features': 23, 'min_impurity_decrease': 1.5925189256906216}. Best is trial 4 with value: 0.5.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 21:26:54,116]\u001b[0m Trial 11 finished with value: 0.5 and parameters: {'n_estimators': 124, 'max_depth': 20, 'max_features': 12, 'min_impurity_decrease': 4.92344269588344}. Best is trial 4 with value: 0.5.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 21:27:00,145]\u001b[0m Trial 12 finished with value: 0.5 and parameters: {'n_estimators': 324, 'max_depth': 18, 'max_features': 29, 'min_impurity_decrease': 4.902627126552196}. Best is trial 4 with value: 0.5.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 21:27:05,026]\u001b[0m Trial 13 finished with value: 0.5 and parameters: {'n_estimators': 287, 'max_depth': 6, 'max_features': 10, 'min_impurity_decrease': 1.623183405239199}. Best is trial 4 with value: 0.5.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 21:27:09,798]\u001b[0m Trial 14 finished with value: 0.5 and parameters: {'n_estimators': 253, 'max_depth': 11, 'max_features': 21, 'min_impurity_decrease': 4.1293377417421695}. Best is trial 4 with value: 0.5.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 21:27:17,143]\u001b[0m Trial 15 finished with value: 0.49825327510917033 and parameters: {'n_estimators': 381, 'max_depth': 17, 'max_features': 26, 'min_impurity_decrease': 2.0049935735461806}. Best is trial 4 with value: 0.5.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 21:27:20,842]\u001b[0m Trial 16 finished with value: 0.5 and parameters: {'n_estimators': 213, 'max_depth': 13, 'max_features': 18, 'min_impurity_decrease': 3.4814210246729473}. Best is trial 4 with value: 0.5.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 21:27:35,555]\u001b[0m Trial 17 finished with value: 0.49825327510917033 and parameters: {'n_estimators': 807, 'max_depth': 9, 'max_features': 21, 'min_impurity_decrease': 3.5908341056521604}. Best is trial 4 with value: 0.5.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 21:27:41,082]\u001b[0m Trial 18 finished with value: 0.5 and parameters: {'n_estimators': 345, 'max_depth': 5, 'max_features': 13, 'min_impurity_decrease': 1.0196866701694638}. Best is trial 4 with value: 0.5.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 21:27:47,513]\u001b[0m Trial 19 finished with value: 0.49825327510917033 and parameters: {'n_estimators': 398, 'max_depth': 5, 'max_features': 14, 'min_impurity_decrease': 0.09108304911137066}. Best is trial 4 with value: 0.5.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 21:27:50,826]\u001b[0m Trial 20 finished with value: 0.5 and parameters: {'n_estimators': 190, 'max_depth': 13, 'max_features': 18, 'min_impurity_decrease': 3.1134039841340018}. Best is trial 4 with value: 0.5.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 21:27:52,833]\u001b[0m Trial 21 finished with value: 0.5 and parameters: {'n_estimators': 101, 'max_depth': 7, 'max_features': 22, 'min_impurity_decrease': 1.2447055641537923}. Best is trial 4 with value: 0.5.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 21:27:59,423]\u001b[0m Trial 22 finished with value: 0.49825327510917033 and parameters: {'n_estimators': 391, 'max_depth': 9, 'max_features': 19, 'min_impurity_decrease': 0.9525958151106366}. Best is trial 4 with value: 0.5.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 21:28:02,998]\u001b[0m Trial 23 finished with value: 0.5 and parameters: {'n_estimators': 193, 'max_depth': 20, 'max_features': 13, 'min_impurity_decrease': 2.0493906988532697}. Best is trial 4 with value: 0.5.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 21:28:05,107]\u001b[0m Trial 24 finished with value: 0.5 and parameters: {'n_estimators': 117, 'max_depth': 8, 'max_features': 16, 'min_impurity_decrease': 2.2203080509173434}. Best is trial 4 with value: 0.5.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 21:28:10,881]\u001b[0m Trial 25 finished with value: 0.5 and parameters: {'n_estimators': 304, 'max_depth': 13, 'max_features': 29, 'min_impurity_decrease': 1.1267235203934949}. Best is trial 4 with value: 0.5.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 21:28:19,057]\u001b[0m Trial 26 finished with value: 0.49825327510917033 and parameters: {'n_estimators': 463, 'max_depth': 20, 'max_features': 27, 'min_impurity_decrease': 1.613719481790231}. Best is trial 4 with value: 0.5.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 21:28:23,711]\u001b[0m Trial 27 finished with value: 0.5 and parameters: {'n_estimators': 293, 'max_depth': 11, 'max_features': 9, 'min_impurity_decrease': 0.5821102032088267}. Best is trial 4 with value: 0.5.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 21:28:28,019]\u001b[0m Trial 28 finished with value: 0.5 and parameters: {'n_estimators': 275, 'max_depth': 8, 'max_features': 10, 'min_impurity_decrease': 2.215425474858536}. Best is trial 4 with value: 0.5.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 21:28:40,345]\u001b[0m Trial 29 finished with value: 0.49825327510917033 and parameters: {'n_estimators': 690, 'max_depth': 10, 'max_features': 23, 'min_impurity_decrease': 2.34897383584667}. Best is trial 4 with value: 0.5.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 21:28:44,065]\u001b[0m Trial 30 finished with value: 0.5 and parameters: {'n_estimators': 209, 'max_depth': 12, 'max_features': 19, 'min_impurity_decrease': 3.125351702860808}. Best is trial 4 with value: 0.5.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 21:28:48,310]\u001b[0m Trial 31 finished with value: 0.5 and parameters: {'n_estimators': 228, 'max_depth': 12, 'max_features': 21, 'min_impurity_decrease': 2.9745045516118473}. Best is trial 4 with value: 0.5.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 21:28:52,046]\u001b[0m Trial 32 finished with value: 0.5 and parameters: {'n_estimators': 203, 'max_depth': 12, 'max_features': 19, 'min_impurity_decrease': 3.004645436646335}. Best is trial 4 with value: 0.5.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 21:28:56,416]\u001b[0m Trial 33 finished with value: 0.5 and parameters: {'n_estimators': 287, 'max_depth': 10, 'max_features': 9, 'min_impurity_decrease': 2.620552315533587}. Best is trial 4 with value: 0.5.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 21:29:00,619]\u001b[0m Trial 34 finished with value: 0.5 and parameters: {'n_estimators': 251, 'max_depth': 12, 'max_features': 17, 'min_impurity_decrease': 2.883546750375743}. Best is trial 4 with value: 0.5.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 21:29:03,137]\u001b[0m Trial 35 finished with value: 0.5 and parameters: {'n_estimators': 148, 'max_depth': 7, 'max_features': 16, 'min_impurity_decrease': 2.6109336059538366}. Best is trial 4 with value: 0.5.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 21:29:06,121]\u001b[0m Trial 36 finished with value: 0.5 and parameters: {'n_estimators': 170, 'max_depth': 15, 'max_features': 23, 'min_impurity_decrease': 0.942432634130236}. Best is trial 4 with value: 0.5.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 21:29:11,694]\u001b[0m Trial 37 finished with value: 0.5 and parameters: {'n_estimators': 359, 'max_depth': 10, 'max_features': 14, 'min_impurity_decrease': 2.7354493877147523}. Best is trial 4 with value: 0.5.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 21:29:17,986]\u001b[0m Trial 38 finished with value: 0.49825327510917033 and parameters: {'n_estimators': 435, 'max_depth': 5, 'max_features': 7, 'min_impurity_decrease': 2.651766057933213}. Best is trial 4 with value: 0.5.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 21:29:24,439]\u001b[0m Trial 39 finished with value: 0.5 and parameters: {'n_estimators': 338, 'max_depth': 18, 'max_features': 30, 'min_impurity_decrease': 0.5734664533003649}. Best is trial 4 with value: 0.5.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 21:29:38,419]\u001b[0m Trial 40 finished with value: 0.49825327510917033 and parameters: {'n_estimators': 911, 'max_depth': 18, 'max_features': 7, 'min_impurity_decrease': 0.5711650830675976}. Best is trial 4 with value: 0.5.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 21:29:41,508]\u001b[0m Trial 41 finished with value: 0.5 and parameters: {'n_estimators': 165, 'max_depth': 7, 'max_features': 15, 'min_impurity_decrease': 2.1927467040026247}. Best is trial 4 with value: 0.5.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 21:29:44,433]\u001b[0m Trial 42 finished with value: 0.5 and parameters: {'n_estimators': 169, 'max_depth': 14, 'max_features': 12, 'min_impurity_decrease': 1.967133687872711}. Best is trial 4 with value: 0.5.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 21:29:46,479]\u001b[0m Trial 43 finished with value: 0.5 and parameters: {'n_estimators': 107, 'max_depth': 7, 'max_features': 15, 'min_impurity_decrease': 1.30308091730776}. Best is trial 4 with value: 0.5.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 21:29:56,409]\u001b[0m Trial 44 finished with value: 0.49825327510917033 and parameters: {'n_estimators': 523, 'max_depth': 8, 'max_features': 27, 'min_impurity_decrease': 1.2437448523584442}. Best is trial 4 with value: 0.5.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 21:30:01,297]\u001b[0m Trial 45 finished with value: 0.6383971900512626 and parameters: {'n_estimators': 290, 'max_depth': 9, 'max_features': 5, 'min_impurity_decrease': 0.02220319837191198}. Best is trial 45 with value: 0.6383971900512626.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 21:30:06,279]\u001b[0m Trial 46 finished with value: 0.6299320296183786 and parameters: {'n_estimators': 297, 'max_depth': 9, 'max_features': 5, 'min_impurity_decrease': 0.029767475130423444}. Best is trial 45 with value: 0.6383971900512626.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 21:30:12,539]\u001b[0m Trial 47 finished with value: 0.49825327510917033 and parameters: {'n_estimators': 421, 'max_depth': 9, 'max_features': 5, 'min_impurity_decrease': 0.10429383643081136}. Best is trial 45 with value: 0.6383971900512626.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 21:30:16,696]\u001b[0m Trial 48 finished with value: 0.5 and parameters: {'n_estimators': 252, 'max_depth': 10, 'max_features': 6, 'min_impurity_decrease': 3.763781936042235}. Best is trial 45 with value: 0.6383971900512626.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 21:30:21,529]\u001b[0m Trial 49 finished with value: 0.5 and parameters: {'n_estimators': 308, 'max_depth': 11, 'max_features': 7, 'min_impurity_decrease': 0.32166511622624316}. Best is trial 45 with value: 0.6383971900512626.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 21:30:29,383]\u001b[0m Trial 50 finished with value: 0.49825327510917033 and parameters: {'n_estimators': 492, 'max_depth': 8, 'max_features': 6, 'min_impurity_decrease': 0.2727932882690923}. Best is trial 45 with value: 0.6383971900512626.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 21:30:32,862]\u001b[0m Trial 51 finished with value: 0.5 and parameters: {'n_estimators': 188, 'max_depth': 13, 'max_features': 24, 'min_impurity_decrease': 0.767187272465516}. Best is trial 45 with value: 0.6383971900512626.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 21:30:37,735]\u001b[0m Trial 52 finished with value: 0.5 and parameters: {'n_estimators': 291, 'max_depth': 9, 'max_features': 9, 'min_impurity_decrease': 0.4993774674250687}. Best is trial 45 with value: 0.6383971900512626.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 21:30:39,913]\u001b[0m Trial 53 finished with value: 0.5 and parameters: {'n_estimators': 124, 'max_depth': 6, 'max_features': 8, 'min_impurity_decrease': 1.4444975453865474}. Best is trial 45 with value: 0.6383971900512626.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 21:30:42,402]\u001b[0m Trial 54 finished with value: 0.5 and parameters: {'n_estimators': 147, 'max_depth': 6, 'max_features': 17, 'min_impurity_decrease': 1.941449729569013}. Best is trial 45 with value: 0.6383971900512626.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 21:30:46,779]\u001b[0m Trial 55 finished with value: 0.5 and parameters: {'n_estimators': 258, 'max_depth': 8, 'max_features': 10, 'min_impurity_decrease': 0.7796422645456925}. Best is trial 45 with value: 0.6383971900512626.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 21:30:50,558]\u001b[0m Trial 56 finished with value: 0.5 and parameters: {'n_estimators': 237, 'max_depth': 6, 'max_features': 5, 'min_impurity_decrease': 0.19356282461981283}. Best is trial 45 with value: 0.6383971900512626.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 21:30:54,864]\u001b[0m Trial 57 finished with value: 0.5 and parameters: {'n_estimators': 241, 'max_depth': 8, 'max_features': 11, 'min_impurity_decrease': 3.272419424321475}. Best is trial 45 with value: 0.6383971900512626.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 21:30:58,596]\u001b[0m Trial 58 finished with value: 0.5 and parameters: {'n_estimators': 228, 'max_depth': 14, 'max_features': 5, 'min_impurity_decrease': 0.08476480802220127}. Best is trial 45 with value: 0.6383971900512626.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 21:31:03,948]\u001b[0m Trial 59 finished with value: 0.6357767229922157 and parameters: {'n_estimators': 321, 'max_depth': 16, 'max_features': 6, 'min_impurity_decrease': 0.03996434588599508}. Best is trial 45 with value: 0.6383971900512626.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 21:31:12,771]\u001b[0m Trial 60 finished with value: 0.49825327510917033 and parameters: {'n_estimators': 595, 'max_depth': 16, 'max_features': 6, 'min_impurity_decrease': 0.315470014512259}. Best is trial 45 with value: 0.6383971900512626.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 21:31:17,801]\u001b[0m Trial 61 finished with value: 0.5 and parameters: {'n_estimators': 311, 'max_depth': 19, 'max_features': 13, 'min_impurity_decrease': 1.7988999344100705}. Best is trial 45 with value: 0.6383971900512626.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 21:31:24,350]\u001b[0m Trial 62 finished with value: 0.5 and parameters: {'n_estimators': 367, 'max_depth': 12, 'max_features': 21, 'min_impurity_decrease': 2.8714962293875876}. Best is trial 45 with value: 0.6383971900512626.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 21:31:29,714]\u001b[0m Trial 63 finished with value: 0.5 and parameters: {'n_estimators': 311, 'max_depth': 19, 'max_features': 8, 'min_impurity_decrease': 2.517427682364428}. Best is trial 45 with value: 0.6383971900512626.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 21:31:35,673]\u001b[0m Trial 64 finished with value: 0.5 and parameters: {'n_estimators': 363, 'max_depth': 12, 'max_features': 8, 'min_impurity_decrease': 2.8953960612415117}. Best is trial 45 with value: 0.6383971900512626.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 21:31:41,035]\u001b[0m Trial 65 finished with value: 0.5 and parameters: {'n_estimators': 331, 'max_depth': 16, 'max_features': 9, 'min_impurity_decrease': 2.5655664917906367}. Best is trial 45 with value: 0.6383971900512626.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 21:31:46,910]\u001b[0m Trial 66 finished with value: 0.49825327510917033 and parameters: {'n_estimators': 393, 'max_depth': 10, 'max_features': 6, 'min_impurity_decrease': 3.496988821360553}. Best is trial 45 with value: 0.6383971900512626.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 21:31:53,618]\u001b[0m Trial 67 finished with value: 0.49825327510917033 and parameters: {'n_estimators': 445, 'max_depth': 11, 'max_features': 8, 'min_impurity_decrease': 1.3835930782885124}. Best is trial 45 with value: 0.6383971900512626.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 21:31:58,368]\u001b[0m Trial 68 finished with value: 0.5 and parameters: {'n_estimators': 285, 'max_depth': 15, 'max_features': 10, 'min_impurity_decrease': 0.3571868132311483}. Best is trial 45 with value: 0.6383971900512626.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 21:32:01,285]\u001b[0m Trial 69 finished with value: 0.5 and parameters: {'n_estimators': 149, 'max_depth': 9, 'max_features': 19, 'min_impurity_decrease': 2.3805703521247445}. Best is trial 45 with value: 0.6383971900512626.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 21:32:05,659]\u001b[0m Trial 70 finished with value: 0.5 and parameters: {'n_estimators': 275, 'max_depth': 15, 'max_features': 11, 'min_impurity_decrease': 0.3781562560785817}. Best is trial 45 with value: 0.6383971900512626.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 21:32:08,488]\u001b[0m Trial 71 finished with value: 0.5 and parameters: {'n_estimators': 139, 'max_depth': 17, 'max_features': 20, 'min_impurity_decrease': 2.403763127584775}. Best is trial 45 with value: 0.6383971900512626.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 21:32:12,912]\u001b[0m Trial 72 finished with value: 0.5 and parameters: {'n_estimators': 263, 'max_depth': 15, 'max_features': 17, 'min_impurity_decrease': 0.7821829321678324}. Best is trial 45 with value: 0.6383971900512626.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 21:32:15,806]\u001b[0m Trial 73 finished with value: 0.5 and parameters: {'n_estimators': 167, 'max_depth': 16, 'max_features': 16, 'min_impurity_decrease': 2.7808456384179534}. Best is trial 45 with value: 0.6383971900512626.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 21:32:21,323]\u001b[0m Trial 74 finished with value: 0.5 and parameters: {'n_estimators': 341, 'max_depth': 18, 'max_features': 15, 'min_impurity_decrease': 0.6488837297479209}. Best is trial 45 with value: 0.6383971900512626.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 21:32:30,433]\u001b[0m Trial 75 finished with value: 0.7066455287640022 and parameters: {'n_estimators': 167, 'max_depth': 16, 'max_features': 30, 'min_impurity_decrease': 0.003462083435323105}. Best is trial 75 with value: 0.7066455287640022.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 21:32:37,313]\u001b[0m Trial 76 finished with value: 0.6363888361496108 and parameters: {'n_estimators': 336, 'max_depth': 18, 'max_features': 30, 'min_impurity_decrease': 0.054808805153401946}. Best is trial 75 with value: 0.7066455287640022.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 21:32:42,740]\u001b[0m Trial 77 finished with value: 0.6539316498955763 and parameters: {'n_estimators': 221, 'max_depth': 12, 'max_features': 26, 'min_impurity_decrease': 0.022882458270589545}. Best is trial 75 with value: 0.7066455287640022.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 21:32:48,572]\u001b[0m Trial 78 finished with value: 0.6524476931839758 and parameters: {'n_estimators': 215, 'max_depth': 17, 'max_features': 28, 'min_impurity_decrease': 0.02384709333335347}. Best is trial 75 with value: 0.7066455287640022.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 21:33:06,249]\u001b[0m Trial 79 finished with value: 0.6457277387507119 and parameters: {'n_estimators': 718, 'max_depth': 17, 'max_features': 28, 'min_impurity_decrease': 0.028198310179880448}. Best is trial 75 with value: 0.7066455287640022.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 21:33:38,919]\u001b[0m Trial 80 finished with value: 0.7057676096449592 and parameters: {'n_estimators': 708, 'max_depth': 17, 'max_features': 28, 'min_impurity_decrease': 0.005533671061814217}. Best is trial 75 with value: 0.7066455287640022.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 21:34:09,748]\u001b[0m Trial 81 finished with value: 0.7040216441997341 and parameters: {'n_estimators': 720, 'max_depth': 17, 'max_features': 28, 'min_impurity_decrease': 0.006607969743210391}. Best is trial 75 with value: 0.7066455287640022.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 21:34:23,105]\u001b[0m Trial 82 finished with value: 0.49825327510917033 and parameters: {'n_estimators': 721, 'max_depth': 17, 'max_features': 28, 'min_impurity_decrease': 0.18929894248795162}. Best is trial 75 with value: 0.7066455287640022.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 21:34:37,896]\u001b[0m Trial 83 finished with value: 0.49825327510917033 and parameters: {'n_estimators': 815, 'max_depth': 17, 'max_features': 30, 'min_impurity_decrease': 0.18034883340143384}. Best is trial 75 with value: 0.7066455287640022.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 21:35:09,203]\u001b[0m Trial 84 finished with value: 0.7089113347256502 and parameters: {'n_estimators': 645, 'max_depth': 17, 'max_features': 28, 'min_impurity_decrease': 0.0041110388969605935}. Best is trial 84 with value: 0.7089113347256502.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 21:35:33,714]\u001b[0m Trial 85 finished with value: 0.7083865578127967 and parameters: {'n_estimators': 641, 'max_depth': 17, 'max_features': 26, 'min_impurity_decrease': 0.003862987077758777}. Best is trial 84 with value: 0.7089113347256502.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 21:35:39,743]\u001b[0m Trial 86 finished with value: 0.49825327510917033 and parameters: {'n_estimators': 661, 'max_depth': 17, 'max_features': 28, 'min_impurity_decrease': 0.43182223219208943}. Best is trial 84 with value: 0.7089113347256502.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 21:35:46,529]\u001b[0m Trial 87 finished with value: 0.49825327510917033 and parameters: {'n_estimators': 765, 'max_depth': 18, 'max_features': 26, 'min_impurity_decrease': 0.2185737234071846}. Best is trial 84 with value: 0.7089113347256502.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 21:35:52,389]\u001b[0m Trial 88 finished with value: 0.49825327510917033 and parameters: {'n_estimators': 641, 'max_depth': 16, 'max_features': 28, 'min_impurity_decrease': 0.46673971191765473}. Best is trial 84 with value: 0.7089113347256502.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 21:36:14,681]\u001b[0m Trial 89 finished with value: 0.6938989937345736 and parameters: {'n_estimators': 736, 'max_depth': 19, 'max_features': 26, 'min_impurity_decrease': 0.011976896700169236}. Best is trial 84 with value: 0.7089113347256502.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 21:36:27,768]\u001b[0m Trial 90 finished with value: 0.49825327510917033 and parameters: {'n_estimators': 727, 'max_depth': 19, 'max_features': 26, 'min_impurity_decrease': 0.6659435855533804}. Best is trial 84 with value: 0.7089113347256502.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 21:36:38,569]\u001b[0m Trial 91 finished with value: 0.49825327510917033 and parameters: {'n_estimators': 566, 'max_depth': 17, 'max_features': 25, 'min_impurity_decrease': 0.15446035328695168}. Best is trial 84 with value: 0.7089113347256502.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 21:36:56,967]\u001b[0m Trial 92 finished with value: 0.639880007594456 and parameters: {'n_estimators': 783, 'max_depth': 17, 'max_features': 29, 'min_impurity_decrease': 0.04173177108529587}. Best is trial 84 with value: 0.7089113347256502.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 21:37:12,520]\u001b[0m Trial 93 finished with value: 0.49825327510917033 and parameters: {'n_estimators': 815, 'max_depth': 19, 'max_features': 29, 'min_impurity_decrease': 0.27029127780162476}. Best is trial 84 with value: 0.7089113347256502.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 21:37:31,266]\u001b[0m Trial 94 finished with value: 0.6448551357509018 and parameters: {'n_estimators': 780, 'max_depth': 17, 'max_features': 27, 'min_impurity_decrease': 0.02875815137901709}. Best is trial 84 with value: 0.7089113347256502.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 21:38:06,380]\u001b[0m Trial 95 finished with value: 0.7050689196886272 and parameters: {'n_estimators': 852, 'max_depth': 18, 'max_features': 27, 'min_impurity_decrease': 0.006066869343950478}. Best is trial 84 with value: 0.7089113347256502.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 21:38:17,874]\u001b[0m Trial 96 finished with value: 0.49825327510917033 and parameters: {'n_estimators': 635, 'max_depth': 18, 'max_features': 25, 'min_impurity_decrease': 0.4405243259627828}. Best is trial 84 with value: 0.7089113347256502.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 21:38:33,401]\u001b[0m Trial 97 finished with value: 0.49825327510917033 and parameters: {'n_estimators': 880, 'max_depth': 20, 'max_features': 27, 'min_impurity_decrease': 0.2580984613194701}. Best is trial 84 with value: 0.7089113347256502.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 21:39:09,873]\u001b[0m Trial 98 finished with value: 0.7097812796658439 and parameters: {'n_estimators': 696, 'max_depth': 18, 'max_features': 24, 'min_impurity_decrease': 0.0005877694670980782}. Best is trial 98 with value: 0.7097812796658439.\u001b[0m\n",
      "\u001b[32m[I 2024-11-14 21:39:22,751]\u001b[0m Trial 99 finished with value: 0.49825327510917033 and parameters: {'n_estimators': 673, 'max_depth': 19, 'max_features': 24, 'min_impurity_decrease': 0.1504139306846975}. Best is trial 98 with value: 0.7097812796658439.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "#Tuning hyperparameters\n",
    "#Step 1. Define an objective function to be maximized.\n",
    "def objective(trial):\n",
    "    n_estimators = trial.suggest_int(\"n_estimators\",100,1000,1) \n",
    "    max_depth = trial.suggest_int(\"max_depth\",5,20,1)\n",
    "    max_features = trial.suggest_int(\"max_features\",5,30,1)\n",
    "    min_impurity_decrease = trial.suggest_float(\"min_impurity_decrease\",0,5,log=False) \n",
    "    model = RandomForestClassifier(n_estimators = n_estimators\n",
    "              ,max_depth = max_depth\n",
    "              ,max_features = max_features\n",
    "              ,min_impurity_decrease = min_impurity_decrease\n",
    "              ,random_state=1\n",
    "              ,verbose=False\n",
    "              ,n_jobs=8)\n",
    "\n",
    "# Step 2: Scoring method:\n",
    "    score = model_selection.cross_val_score(model, X, y, n_jobs=8, scoring=\"accuracy\",cv=Cv_optuna)\n",
    "    accuracy = score.mean()\n",
    "    return accuracy\n",
    " \n",
    "# Step 3: Running it\n",
    "study = optuna.create_study(direction=\"maximize\",sampler=optuna.samplers.TPESampler(seed=0))\n",
    "study.optimize(objective, n_trials=100, show_progress_bar=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "3ea7fc26-11ae-497b-ab4a-949cd12a43a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best parameters are : \n",
      "{'n_estimators': 696, 'max_depth': 18, 'max_features': 24, 'min_impurity_decrease': 0.0005877694670980782}\n"
     ]
    }
   ],
   "source": [
    "# Getting the best parameters:\n",
    "print(f\"The best parameters are : \\n{study.best_params}\")\n",
    "# Setting the best model\n",
    "clf=RandomForestClassifier(n_estimators = study.best_params['n_estimators']\n",
    "              ,max_depth = study.best_params['max_depth']\n",
    "              ,max_features = study.best_params['max_features']\n",
    "              ,min_impurity_decrease = study.best_params['min_impurity_decrease']\n",
    "              ,random_state=0\n",
    "              ,verbose=False\n",
    "              ,n_jobs=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "90cca67e-3df8-43ff-8b96-2c9bec87ee43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mean</th>\n",
       "      <th>Se</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Accuracy_test</th>\n",
       "      <td>0.714666</td>\n",
       "      <td>0.003311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Accuracy_train</th>\n",
       "      <td>0.999891</td>\n",
       "      <td>0.000046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1 Score</th>\n",
       "      <td>0.716444</td>\n",
       "      <td>0.003666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Precision</th>\n",
       "      <td>0.712319</td>\n",
       "      <td>0.003811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recall</th>\n",
       "      <td>0.722307</td>\n",
       "      <td>0.005999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Roc_auc</th>\n",
       "      <td>0.783051</td>\n",
       "      <td>0.003676</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Mean        Se\n",
       "Accuracy_test   0.714666  0.003311\n",
       "Accuracy_train  0.999891  0.000046\n",
       "F1 Score        0.716444  0.003666\n",
       "Precision       0.712319  0.003811\n",
       "Recall          0.722307  0.005999\n",
       "Roc_auc         0.783051  0.003676"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Model2\n",
    "Model2=Model_results(clf,X,y,Cv_model)\n",
    "Model2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "346eea08-6a51-48fc-bfcd-1a8d913649a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th>Method</th>\n",
       "      <th colspan=\"4\" halign=\"left\">RF</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model</th>\n",
       "      <th colspan=\"2\" halign=\"left\">Model 1</th>\n",
       "      <th colspan=\"2\" halign=\"left\">Model 2</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Values</th>\n",
       "      <th>Mean</th>\n",
       "      <th>Se</th>\n",
       "      <th>Mean</th>\n",
       "      <th>Se</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Accuracy_test</th>\n",
       "      <td>0.705591</td>\n",
       "      <td>0.003320</td>\n",
       "      <td>0.714666</td>\n",
       "      <td>0.003311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Accuracy_train</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.999891</td>\n",
       "      <td>0.000046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1 Score</th>\n",
       "      <td>0.706152</td>\n",
       "      <td>0.003557</td>\n",
       "      <td>0.716444</td>\n",
       "      <td>0.003666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Precision</th>\n",
       "      <td>0.705308</td>\n",
       "      <td>0.003888</td>\n",
       "      <td>0.712319</td>\n",
       "      <td>0.003811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recall</th>\n",
       "      <td>0.708526</td>\n",
       "      <td>0.005622</td>\n",
       "      <td>0.722307</td>\n",
       "      <td>0.005999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Roc_auc</th>\n",
       "      <td>0.773311</td>\n",
       "      <td>0.003423</td>\n",
       "      <td>0.783051</td>\n",
       "      <td>0.003676</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Method                RF                              \n",
       "Model            Model 1             Model 2          \n",
       "Values              Mean        Se      Mean        Se\n",
       "Accuracy_test   0.705591  0.003320  0.714666  0.003311\n",
       "Accuracy_train  1.000000  0.000000  0.999891  0.000046\n",
       "F1 Score        0.706152  0.003557  0.716444  0.003666\n",
       "Precision       0.705308  0.003888  0.712319  0.003811\n",
       "Recall          0.708526  0.005622  0.722307  0.005999\n",
       "Roc_auc         0.773311  0.003423  0.783051  0.003676"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Saving the data of model performance\n",
    "Model_data=pd.concat([Model1,Model2],axis=1)\n",
    "Model_data.columns = [['RF']*4,['Model 1','Model 1', 'Model 2','Model 2'], ['Mean', 'Se', 'Mean', 'Se']]  \n",
    "Model_data.columns.names=['Method','Model','Values']\n",
    "Model_data.to_csv(\"./RF_model_lasso_data.csv\",sep=',')\n",
    "Model_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "115be659-b066-4abf-85ac-59fccd101ad4",
   "metadata": {},
   "source": [
    "## 1.4 XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "3ff2324c-d316-43ae-96dc-e58f404273a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf=xgb.XGBClassifier(random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "03979633-d8bb-44e7-a9d7-b7050c4c32c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mean</th>\n",
       "      <th>Se</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Accuracy_test</th>\n",
       "      <td>0.714049</td>\n",
       "      <td>0.003174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Accuracy_train</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1 Score</th>\n",
       "      <td>0.716252</td>\n",
       "      <td>0.003368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Precision</th>\n",
       "      <td>0.711574</td>\n",
       "      <td>0.003907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recall</th>\n",
       "      <td>0.723031</td>\n",
       "      <td>0.006039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Roc_auc</th>\n",
       "      <td>0.778745</td>\n",
       "      <td>0.003458</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Mean        Se\n",
       "Accuracy_test   0.714049  0.003174\n",
       "Accuracy_train  1.000000  0.000000\n",
       "F1 Score        0.716252  0.003368\n",
       "Precision       0.711574  0.003907\n",
       "Recall          0.723031  0.006039\n",
       "Roc_auc         0.778745  0.003458"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Model1 \n",
    "Model1_clf=clf\n",
    "#Model1\n",
    "Model1=Model_results(Model1_clf,X,y,Cv_model)\n",
    "Model1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "c6e5e42b-3688-4c6f-aa87-cf0fe5b1ff05",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2024-11-14 21:41:09,125]\u001b[0m A new study created in memory with name: no-name-ac9d0e0b-963e-4e81-9d8e-39369665282c\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_85072\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_85072\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-11-14 21:41:30,880]\u001b[0m Trial 0 finished with value: 0.7170153787734955 and parameters: {'lambda': 0.15676677195506075, 'alpha': 0.7257005721594281, 'colsample_bytree': 0.7, 'subsample': 0.7000000000000001, 'learning_rate': 0.0801, 'n_estimators': 664}. Best is trial 0 with value: 0.7170153787734955.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_85072\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_85072\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-11-14 21:41:48,679]\u001b[0m Trial 1 finished with value: 0.7157922916271121 and parameters: {'lambda': 0.0562793204741517, 'alpha': 3.6905577292137624, 'colsample_bytree': 1.0, 'subsample': 0.6000000000000001, 'learning_rate': 0.1551, 'n_estimators': 552}. Best is trial 0 with value: 0.7170153787734955.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_85072\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_85072\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-11-14 21:42:43,968]\u001b[0m Trial 2 finished with value: 0.6924997152078981 and parameters: {'lambda': 0.18714500686240676, 'alpha': 5.039489598671215, 'colsample_bytree': 0.3, 'subsample': 0.4, 'learning_rate': 0.0001, 'n_estimators': 841}. Best is trial 0 with value: 0.7170153787734955.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_85072\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_85072\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-11-14 21:44:04,958]\u001b[0m Trial 3 finished with value: 0.7222525156635656 and parameters: {'lambda': 1.2960656597279736, 'alpha': 3.0202896401586674, 'colsample_bytree': 1.0, 'subsample': 0.9, 'learning_rate': 0.0901, 'n_estimators': 792}. Best is trial 3 with value: 0.7222525156635656.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_85072\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_85072\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-11-14 21:44:36,709]\u001b[0m Trial 4 finished with value: 0.7174524397190051 and parameters: {'lambda': 0.0029723346443356552, 'alpha': 0.3628140404024381, 'colsample_bytree': 0.4, 'subsample': 1.0, 'learning_rate': 0.10010000000000001, 'n_estimators': 444}. Best is trial 3 with value: 0.7222525156635656.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_85072\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_85072\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-11-14 21:46:11,677]\u001b[0m Trial 5 finished with value: 0.7075952154926903 and parameters: {'lambda': 0.011434638743472197, 'alpha': 1.2500712230836255, 'colsample_bytree': 0.6000000000000001, 'subsample': 0.7000000000000001, 'learning_rate': 0.0001, 'n_estimators': 637}. Best is trial 3 with value: 0.7222525156635656.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_85072\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_85072\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-11-14 21:47:30,230]\u001b[0m Trial 6 finished with value: 0.7218162141636606 and parameters: {'lambda': 0.2807908107885728, 'alpha': 0.2935864364395359, 'colsample_bytree': 1.0, 'subsample': 0.8, 'learning_rate': 0.07010000000000001, 'n_estimators': 465}. Best is trial 3 with value: 0.7222525156635656.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_85072\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_85072\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-11-14 21:48:00,715]\u001b[0m Trial 7 finished with value: 0.7192010632238467 and parameters: {'lambda': 0.6173405204074314, 'alpha': 0.0017414134181586202, 'colsample_bytree': 0.8, 'subsample': 0.8, 'learning_rate': 0.040100000000000004, 'n_estimators': 172}. Best is trial 3 with value: 0.7222525156635656.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_85072\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_85072\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-11-14 21:48:19,009]\u001b[0m Trial 8 finished with value: 0.7108137459654453 and parameters: {'lambda': 0.01826894228153233, 'alpha': 0.028499883436971588, 'colsample_bytree': 0.7, 'subsample': 0.7000000000000001, 'learning_rate': 0.1951, 'n_estimators': 147}. Best is trial 3 with value: 0.7222525156635656.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_85072\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_85072\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-11-14 21:48:54,937]\u001b[0m Trial 9 finished with value: 0.7154478830453768 and parameters: {'lambda': 0.006847105576684045, 'alpha': 0.004418125737902547, 'colsample_bytree': 0.8, 'subsample': 0.5, 'learning_rate': 0.0901, 'n_estimators': 282}. Best is trial 3 with value: 0.7222525156635656.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_85072\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_85072\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-11-14 21:50:36,257]\u001b[0m Trial 10 finished with value: 0.718855135750902 and parameters: {'lambda': 6.8179090749657245, 'alpha': 0.05930570259610594, 'colsample_bytree': 0.5, 'subsample': 1.0, 'learning_rate': 0.1301, 'n_estimators': 987}. Best is trial 3 with value: 0.7222525156635656.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_85072\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_85072\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-11-14 21:52:03,441]\u001b[0m Trial 11 finished with value: 0.7231247389405734 and parameters: {'lambda': 1.9073794982580998, 'alpha': 0.19733730083782078, 'colsample_bytree': 1.0, 'subsample': 0.9, 'learning_rate': 0.0551, 'n_estimators': 410}. Best is trial 11 with value: 0.7231247389405734.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_85072\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_85072\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-11-14 21:54:24,263]\u001b[0m Trial 12 finished with value: 0.7239111448642491 and parameters: {'lambda': 2.5678455391010973, 'alpha': 0.013018672297928333, 'colsample_bytree': 0.9000000000000001, 'subsample': 0.9, 'learning_rate': 0.040100000000000004, 'n_estimators': 822}. Best is trial 12 with value: 0.7239111448642491.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_85072\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_85072\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-11-14 21:55:30,758]\u001b[0m Trial 13 finished with value: 0.7224306056578698 and parameters: {'lambda': 6.1962979052601455, 'alpha': 0.016605414256086717, 'colsample_bytree': 0.9000000000000001, 'subsample': 0.9, 'learning_rate': 0.040100000000000004, 'n_estimators': 320}. Best is trial 12 with value: 0.7239111448642491.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_85072\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_85072\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-11-14 21:58:12,665]\u001b[0m Trial 14 finished with value: 0.7221708752610594 and parameters: {'lambda': 2.130338839554029, 'alpha': 0.010215573929742533, 'colsample_bytree': 0.9000000000000001, 'subsample': 0.9, 'learning_rate': 0.040100000000000004, 'n_estimators': 999}. Best is trial 12 with value: 0.7239111448642491.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_85072\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_85072\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-11-14 22:00:29,395]\u001b[0m Trial 15 finished with value: 0.7246933738370989 and parameters: {'lambda': 2.049705593462595, 'alpha': 0.09088576434269839, 'colsample_bytree': 0.9000000000000001, 'subsample': 0.8, 'learning_rate': 0.0551, 'n_estimators': 800}. Best is trial 15 with value: 0.7246933738370989.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_85072\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_85072\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-11-14 22:02:58,168]\u001b[0m Trial 16 finished with value: 0.7234775014239605 and parameters: {'lambda': 8.180940591372398, 'alpha': 0.0992386037553163, 'colsample_bytree': 0.8, 'subsample': 0.8, 'learning_rate': 0.0201, 'n_estimators': 821}. Best is trial 15 with value: 0.7246933738370989.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_85072\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_85072\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-11-14 22:04:12,467]\u001b[0m Trial 17 finished with value: 0.7175337003987089 and parameters: {'lambda': 0.0010007385532741766, 'alpha': 0.004791330764793538, 'colsample_bytree': 0.9000000000000001, 'subsample': 0.6000000000000001, 'learning_rate': 0.1201, 'n_estimators': 713}. Best is trial 15 with value: 0.7246933738370989.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_85072\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_85072\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-11-14 22:06:00,847]\u001b[0m Trial 18 finished with value: 0.7188513385228784 and parameters: {'lambda': 0.05914448947463636, 'alpha': 0.056690819443767936, 'colsample_bytree': 0.6000000000000001, 'subsample': 1.0, 'learning_rate': 0.0601, 'n_estimators': 884}. Best is trial 15 with value: 0.7246933738370989.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_85072\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_85072\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-11-14 22:08:31,947]\u001b[0m Trial 19 finished with value: 0.7230404404784507 and parameters: {'lambda': 0.7860483671343276, 'alpha': 0.027739224719767277, 'colsample_bytree': 0.8, 'subsample': 0.8, 'learning_rate': 0.0201, 'n_estimators': 906}. Best is trial 15 with value: 0.7246933738370989.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_85072\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_85072\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-11-14 22:09:52,868]\u001b[0m Trial 20 finished with value: 0.7232147332447313 and parameters: {'lambda': 2.5132520362548596, 'alpha': 0.0013872638792760748, 'colsample_bytree': 0.9000000000000001, 'subsample': 0.6000000000000001, 'learning_rate': 0.11510000000000001, 'n_estimators': 574}. Best is trial 15 with value: 0.7246933738370989.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_85072\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_85072\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-11-14 22:12:31,139]\u001b[0m Trial 21 finished with value: 0.7231262578317827 and parameters: {'lambda': 8.837449158774847, 'alpha': 0.09308613689694932, 'colsample_bytree': 0.8, 'subsample': 0.8, 'learning_rate': 0.0201, 'n_estimators': 755}. Best is trial 15 with value: 0.7246933738370989.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_85072\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_85072\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-11-14 22:14:40,085]\u001b[0m Trial 22 finished with value: 0.7215599012720714 and parameters: {'lambda': 4.914321871662103, 'alpha': 0.1746311044100552, 'colsample_bytree': 0.7, 'subsample': 0.8, 'learning_rate': 0.0201, 'n_estimators': 817}. Best is trial 15 with value: 0.7246933738370989.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_85072\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_85072\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-11-14 22:16:35,756]\u001b[0m Trial 23 finished with value: 0.721820011391684 and parameters: {'lambda': 0.3867564363477971, 'alpha': 0.006567229851571051, 'colsample_bytree': 0.9000000000000001, 'subsample': 0.9, 'learning_rate': 0.0551, 'n_estimators': 919}. Best is trial 15 with value: 0.7246933738370989.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_85072\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_85072\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-11-14 22:18:26,235]\u001b[0m Trial 24 finished with value: 0.7237383709891777 and parameters: {'lambda': 4.078860411949103, 'alpha': 0.060000045848698606, 'colsample_bytree': 0.8, 'subsample': 0.7000000000000001, 'learning_rate': 0.0301, 'n_estimators': 700}. Best is trial 15 with value: 0.7246933738370989.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_85072\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_85072\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-11-14 22:20:23,148]\u001b[0m Trial 25 finished with value: 0.724610973988988 and parameters: {'lambda': 3.3703321956906827, 'alpha': 0.027585582977643373, 'colsample_bytree': 0.9000000000000001, 'subsample': 0.7000000000000001, 'learning_rate': 0.035100000000000006, 'n_estimators': 699}. Best is trial 15 with value: 0.7246933738370989.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_85072\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_85072\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-11-14 22:22:03,119]\u001b[0m Trial 26 finished with value: 0.7213829504461742 and parameters: {'lambda': 1.0911594261463873, 'alpha': 0.023853119726216142, 'colsample_bytree': 0.9000000000000001, 'subsample': 0.7000000000000001, 'learning_rate': 0.0651, 'n_estimators': 623}. Best is trial 15 with value: 0.7246933738370989.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_85072\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_85072\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-11-14 22:24:16,911]\u001b[0m Trial 27 finished with value: 0.722428707043858 and parameters: {'lambda': 3.5025290233356734, 'alpha': 0.003233911476877331, 'colsample_bytree': 1.0, 'subsample': 0.5, 'learning_rate': 0.0451, 'n_estimators': 757}. Best is trial 15 with value: 0.7246933738370989.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_85072\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_85072\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-11-14 22:26:09,824]\u001b[0m Trial 28 finished with value: 0.6981727738750712 and parameters: {'lambda': 0.5933499630989603, 'alpha': 0.014358837305384347, 'colsample_bytree': 0.7, 'subsample': 0.9, 'learning_rate': 0.0001, 'n_estimators': 599}. Best is trial 15 with value: 0.7246933738370989.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_85072\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_85072\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-11-14 22:27:26,325]\u001b[0m Trial 29 finished with value: 0.7224241503702298 and parameters: {'lambda': 0.14251827071187584, 'alpha': 0.7297885974341038, 'colsample_bytree': 0.7, 'subsample': 0.6000000000000001, 'learning_rate': 0.0751, 'n_estimators': 721}. Best is trial 15 with value: 0.7246933738370989.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_85072\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_85072\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-11-14 22:28:32,514]\u001b[0m Trial 30 finished with value: 0.720068729827226 and parameters: {'lambda': 1.2677134560187653, 'alpha': 0.0087141312667876, 'colsample_bytree': 0.6000000000000001, 'subsample': 0.7000000000000001, 'learning_rate': 0.0801, 'n_estimators': 666}. Best is trial 15 with value: 0.7246933738370989.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_85072\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_85072\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-11-14 22:30:22,158]\u001b[0m Trial 31 finished with value: 0.7230370229732296 and parameters: {'lambda': 3.2043675194389114, 'alpha': 0.05281634610384797, 'colsample_bytree': 0.8, 'subsample': 0.7000000000000001, 'learning_rate': 0.0301, 'n_estimators': 685}. Best is trial 15 with value: 0.7246933738370989.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_85072\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_85072\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-11-14 22:32:04,421]\u001b[0m Trial 32 finished with value: 0.7251311942282135 and parameters: {'lambda': 4.378343078622679, 'alpha': 0.041061182203621385, 'colsample_bytree': 0.9000000000000001, 'subsample': 0.8, 'learning_rate': 0.0301, 'n_estimators': 526}. Best is trial 32 with value: 0.7251311942282135.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_85072\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_85072\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-11-14 22:32:17,803]\u001b[0m Trial 33 finished with value: 0.7123914942092273 and parameters: {'lambda': 1.6303772793386635, 'alpha': 0.034042392940360704, 'colsample_bytree': 1.0, 'subsample': 0.8, 'learning_rate': 0.050100000000000006, 'n_estimators': 54}. Best is trial 32 with value: 0.7251311942282135.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_85072\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_85072\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-11-14 22:33:39,165]\u001b[0m Trial 34 finished with value: 0.7219886083159295 and parameters: {'lambda': 0.3682676372054322, 'alpha': 0.1565071783335395, 'colsample_bytree': 0.9000000000000001, 'subsample': 0.8, 'learning_rate': 0.0101, 'n_estimators': 527}. Best is trial 32 with value: 0.7251311942282135.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_85072\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_85072\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-11-14 22:35:34,503]\u001b[0m Trial 35 finished with value: 0.7174531991646098 and parameters: {'lambda': 3.11096899111118, 'alpha': 0.01411521991190153, 'colsample_bytree': 1.0, 'subsample': 1.0, 'learning_rate': 0.0301, 'n_estimators': 501}. Best is trial 32 with value: 0.7251311942282135.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_85072\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_85072\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-11-14 22:37:03,361]\u001b[0m Trial 36 finished with value: 0.7205965445224985 and parameters: {'lambda': 9.958589587498123, 'alpha': 0.5590608107494122, 'colsample_bytree': 0.3, 'subsample': 0.9, 'learning_rate': 0.0101, 'n_estimators': 873}. Best is trial 32 with value: 0.7251311942282135.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_85072\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_85072\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-11-14 22:38:03,239]\u001b[0m Trial 37 finished with value: 0.7223428896905258 and parameters: {'lambda': 0.7803051110438222, 'alpha': 8.861629685772476, 'colsample_bytree': 0.9000000000000001, 'subsample': 0.8, 'learning_rate': 0.0951, 'n_estimators': 783}. Best is trial 32 with value: 0.7251311942282135.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_85072\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_85072\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-11-14 22:38:29,025]\u001b[0m Trial 38 finished with value: 0.7102973229542435 and parameters: {'lambda': 0.09951913673562154, 'alpha': 0.0025164247483631225, 'colsample_bytree': 0.4, 'subsample': 0.4, 'learning_rate': 0.0651, 'n_estimators': 382}. Best is trial 32 with value: 0.7251311942282135.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_85072\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_85072\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-11-14 22:39:46,381]\u001b[0m Trial 39 finished with value: 0.7165767989367761 and parameters: {'lambda': 4.673936123889524, 'alpha': 1.6519698923047048, 'colsample_bytree': 1.0, 'subsample': 0.9, 'learning_rate': 0.1601, 'n_estimators': 640}. Best is trial 32 with value: 0.7251311942282135.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_85072\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_85072\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-11-14 22:41:53,808]\u001b[0m Trial 40 finished with value: 0.7236514144674389 and parameters: {'lambda': 1.158730241610988, 'alpha': 0.04134651336818216, 'colsample_bytree': 0.9000000000000001, 'subsample': 0.7000000000000001, 'learning_rate': 0.035100000000000006, 'n_estimators': 940}. Best is trial 32 with value: 0.7251311942282135.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_85072\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_85072\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-11-14 22:43:47,301]\u001b[0m Trial 41 finished with value: 0.7239126637554587 and parameters: {'lambda': 4.264857847452955, 'alpha': 0.08252418328353617, 'colsample_bytree': 0.8, 'subsample': 0.7000000000000001, 'learning_rate': 0.0301, 'n_estimators': 715}. Best is trial 32 with value: 0.7251311942282135.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_85072\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_85072\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-11-14 22:46:06,087]\u001b[0m Trial 42 finished with value: 0.7268782988418454 and parameters: {'lambda': 2.264172034463285, 'alpha': 0.10772009242905159, 'colsample_bytree': 0.8, 'subsample': 0.6000000000000001, 'learning_rate': 0.0101, 'n_estimators': 845}. Best is trial 42 with value: 0.7268782988418454.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_85072\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_85072\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-11-14 22:48:25,279]\u001b[0m Trial 43 finished with value: 0.7243485855325611 and parameters: {'lambda': 5.295684190398493, 'alpha': 0.11573606005577143, 'colsample_bytree': 0.8, 'subsample': 0.6000000000000001, 'learning_rate': 0.0101, 'n_estimators': 854}. Best is trial 42 with value: 0.7268782988418454.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_85072\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_85072\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-11-14 22:50:31,905]\u001b[0m Trial 44 finished with value: 0.7212082779570912 and parameters: {'lambda': 1.8234843801517775, 'alpha': 0.34247279668876185, 'colsample_bytree': 0.7, 'subsample': 0.6000000000000001, 'learning_rate': 0.0051, 'n_estimators': 958}. Best is trial 42 with value: 0.7268782988418454.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_85072\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_85072\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-11-14 22:51:09,815]\u001b[0m Trial 45 finished with value: 0.7219062084678184 and parameters: {'lambda': 0.02336072642852878, 'alpha': 0.13830361549785766, 'colsample_bytree': 0.8, 'subsample': 0.5, 'learning_rate': 0.0101, 'n_estimators': 849}. Best is trial 42 with value: 0.7268782988418454.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_85072\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_85072\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-11-14 22:52:46,793]\u001b[0m Trial 46 finished with value: 0.726093411809379 and parameters: {'lambda': 5.800297748740936, 'alpha': 0.2653032720403588, 'colsample_bytree': 0.8, 'subsample': 0.6000000000000001, 'learning_rate': 0.0201, 'n_estimators': 762}. Best is trial 42 with value: 0.7268782988418454.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_85072\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_85072\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-11-14 22:54:59,298]\u001b[0m Trial 47 finished with value: 0.7241742927662805 and parameters: {'lambda': 2.4273620456052574, 'alpha': 0.23513672667862692, 'colsample_bytree': 0.9000000000000001, 'subsample': 0.5, 'learning_rate': 0.0201, 'n_estimators': 779}. Best is trial 42 with value: 0.7268782988418454.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_85072\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_85072\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-11-14 22:56:32,166]\u001b[0m Trial 48 finished with value: 0.7247829884184546 and parameters: {'lambda': 6.91853616332799, 'alpha': 0.46010388976269, 'colsample_bytree': 1.0, 'subsample': 0.6000000000000001, 'learning_rate': 0.0451, 'n_estimators': 468}. Best is trial 42 with value: 0.7268782988418454.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_85072\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_85072\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-11-14 22:57:41,954]\u001b[0m Trial 49 finished with value: 0.7267047655211697 and parameters: {'lambda': 6.904861696204474, 'alpha': 0.45080700730357953, 'colsample_bytree': 1.0, 'subsample': 0.6000000000000001, 'learning_rate': 0.0451, 'n_estimators': 346}. Best is trial 42 with value: 0.7268782988418454.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_85072\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_85072\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-11-14 22:58:30,681]\u001b[0m Trial 50 finished with value: 0.7196354661097399 and parameters: {'lambda': 6.739460239484707, 'alpha': 0.535944409857974, 'colsample_bytree': 1.0, 'subsample': 0.5, 'learning_rate': 0.08510000000000001, 'n_estimators': 286}. Best is trial 42 with value: 0.7268782988418454.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_85072\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_85072\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-11-14 22:59:54,602]\u001b[0m Trial 51 finished with value: 0.7246979305107273 and parameters: {'lambda': 9.919691075983597, 'alpha': 1.0047145866905993, 'colsample_bytree': 1.0, 'subsample': 0.6000000000000001, 'learning_rate': 0.0601, 'n_estimators': 399}. Best is trial 42 with value: 0.7268782988418454.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_85072\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_85072\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-11-14 23:00:54,741]\u001b[0m Trial 52 finished with value: 0.7258302639073476 and parameters: {'lambda': 9.876797738699967, 'alpha': 0.9487398478768829, 'colsample_bytree': 1.0, 'subsample': 0.6000000000000001, 'learning_rate': 0.050100000000000006, 'n_estimators': 354}. Best is trial 42 with value: 0.7268782988418454.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_85072\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_85072\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-11-14 23:01:49,575]\u001b[0m Trial 53 finished with value: 0.7236472375166129 and parameters: {'lambda': 5.897959495893311, 'alpha': 2.0478377056502715, 'colsample_bytree': 1.0, 'subsample': 0.6000000000000001, 'learning_rate': 0.0451, 'n_estimators': 331}. Best is trial 42 with value: 0.7268782988418454.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_85072\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_85072\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-11-14 23:03:01,957]\u001b[0m Trial 54 finished with value: 0.7230362635276247 and parameters: {'lambda': 6.856379715061063, 'alpha': 0.4484570962382324, 'colsample_bytree': 1.0, 'subsample': 0.6000000000000001, 'learning_rate': 0.050100000000000006, 'n_estimators': 456}. Best is trial 42 with value: 0.7268782988418454.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_85072\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_85072\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-11-14 23:03:38,335]\u001b[0m Trial 55 finished with value: 0.7200668312132145 and parameters: {'lambda': 6.844031716604315, 'alpha': 0.2719087685286023, 'colsample_bytree': 1.0, 'subsample': 0.6000000000000001, 'learning_rate': 0.0251, 'n_estimators': 213}. Best is trial 42 with value: 0.7268782988418454.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_85072\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_85072\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-11-14 23:04:32,404]\u001b[0m Trial 56 finished with value: 0.6942437820391114 and parameters: {'lambda': 4.729668345488162, 'alpha': 0.8063162651518481, 'colsample_bytree': 1.0, 'subsample': 0.5, 'learning_rate': 0.0001, 'n_estimators': 353}. Best is trial 42 with value: 0.7268782988418454.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_85072\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_85072\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-11-14 23:05:23,686]\u001b[0m Trial 57 finished with value: 0.7227753939624074 and parameters: {'lambda': 9.402588205945964, 'alpha': 2.2751572367876207, 'colsample_bytree': 0.9000000000000001, 'subsample': 0.5, 'learning_rate': 0.1051, 'n_estimators': 433}. Best is trial 42 with value: 0.7268782988418454.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_85072\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_85072\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-11-14 23:05:59,413]\u001b[0m Trial 58 finished with value: 0.7195485095880008 and parameters: {'lambda': 0.004059966036700435, 'alpha': 1.0319934291110497, 'colsample_bytree': 1.0, 'subsample': 0.6000000000000001, 'learning_rate': 0.015099999999999999, 'n_estimators': 200}. Best is trial 42 with value: 0.7268782988418454.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_85072\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_85072\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-11-14 23:06:39,728]\u001b[0m Trial 59 finished with value: 0.7240877159673438 and parameters: {'lambda': 2.7534510201426623, 'alpha': 4.314459660202597, 'colsample_bytree': 1.0, 'subsample': 0.6000000000000001, 'learning_rate': 0.0451, 'n_estimators': 267}. Best is trial 42 with value: 0.7268782988418454.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_85072\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_85072\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-11-14 23:07:09,832]\u001b[0m Trial 60 finished with value: 0.7166637554585151 and parameters: {'lambda': 1.7366095566630815, 'alpha': 0.40889116865902775, 'colsample_bytree': 0.5, 'subsample': 0.5, 'learning_rate': 0.1401, 'n_estimators': 478}. Best is trial 42 with value: 0.7268782988418454.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_85072\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_85072\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-11-14 23:08:10,950]\u001b[0m Trial 61 finished with value: 0.7264408581735331 and parameters: {'lambda': 9.66414550479923, 'alpha': 1.1767347276664417, 'colsample_bytree': 1.0, 'subsample': 0.6000000000000001, 'learning_rate': 0.0601, 'n_estimators': 400}. Best is trial 42 with value: 0.7268782988418454.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_85072\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_85072\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-11-14 23:09:09,347]\u001b[0m Trial 62 finished with value: 0.7222544142775772 and parameters: {'lambda': 7.17028417414659, 'alpha': 1.1318731819804877, 'colsample_bytree': 0.9000000000000001, 'subsample': 0.6000000000000001, 'learning_rate': 0.07010000000000001, 'n_estimators': 423}. Best is trial 42 with value: 0.7268782988418454.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_85072\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_85072\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-11-14 23:10:07,623]\u001b[0m Trial 63 finished with value: 0.7246971710651227 and parameters: {'lambda': 4.304548293341669, 'alpha': 0.23908081644447637, 'colsample_bytree': 1.0, 'subsample': 0.6000000000000001, 'learning_rate': 0.035100000000000006, 'n_estimators': 372}. Best is trial 42 with value: 0.7268782988418454.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_85072\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_85072\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-11-14 23:11:33,452]\u001b[0m Trial 64 finished with value: 0.7246971710651224 and parameters: {'lambda': 5.754241685299205, 'alpha': 1.5081456800603261, 'colsample_bytree': 1.0, 'subsample': 0.7000000000000001, 'learning_rate': 0.050100000000000006, 'n_estimators': 559}. Best is trial 42 with value: 0.7268782988418454.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_85072\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_85072\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-11-14 23:12:15,933]\u001b[0m Trial 65 finished with value: 0.7249618378583633 and parameters: {'lambda': 7.437848463216224, 'alpha': 0.6552012501925356, 'colsample_bytree': 0.9000000000000001, 'subsample': 0.6000000000000001, 'learning_rate': 0.040100000000000004, 'n_estimators': 301}. Best is trial 42 with value: 0.7268782988418454.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_85072\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_85072\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-11-14 23:12:52,890]\u001b[0m Trial 66 finished with value: 0.7220786026200874 and parameters: {'lambda': 3.536292389857035, 'alpha': 2.7062886154511565, 'colsample_bytree': 0.9000000000000001, 'subsample': 0.7000000000000001, 'learning_rate': 0.0601, 'n_estimators': 250}. Best is trial 42 with value: 0.7268782988418454.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_85072\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_85072\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-11-14 23:13:21,679]\u001b[0m Trial 67 finished with value: 0.7117824188342512 and parameters: {'lambda': 8.126540171062734, 'alpha': 0.6530744584442927, 'colsample_bytree': 0.8, 'subsample': 0.4, 'learning_rate': 0.1951, 'n_estimators': 307}. Best is trial 42 with value: 0.7268782988418454.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_85072\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_85072\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-11-14 23:13:37,445]\u001b[0m Trial 68 finished with value: 0.7184131384089614 and parameters: {'lambda': 2.2744969439192397, 'alpha': 0.3137876081256344, 'colsample_bytree': 0.6000000000000001, 'subsample': 0.6000000000000001, 'learning_rate': 0.040100000000000004, 'n_estimators': 142}. Best is trial 42 with value: 0.7268782988418454.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_85072\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_85072\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-11-14 23:14:22,850]\u001b[0m Trial 69 finished with value: 0.7214645908486804 and parameters: {'lambda': 9.921146665667003, 'alpha': 0.17728581582113204, 'colsample_bytree': 0.9000000000000001, 'subsample': 0.5, 'learning_rate': 0.0251, 'n_estimators': 346}. Best is trial 42 with value: 0.7268782988418454.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_85072\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_85072\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-11-14 23:14:59,016]\u001b[0m Trial 70 finished with value: 0.7185859122840327 and parameters: {'lambda': 3.8735428374699077, 'alpha': 0.07420124503406293, 'colsample_bytree': 0.9000000000000001, 'subsample': 0.7000000000000001, 'learning_rate': 0.015099999999999999, 'n_estimators': 236}. Best is trial 42 with value: 0.7268782988418454.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_85072\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_85072\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-11-14 23:16:11,025]\u001b[0m Trial 71 finished with value: 0.7275758496297704 and parameters: {'lambda': 6.128228577813985, 'alpha': 0.8593310293548012, 'colsample_bytree': 1.0, 'subsample': 0.6000000000000001, 'learning_rate': 0.040100000000000004, 'n_estimators': 480}. Best is trial 71 with value: 0.7275758496297704.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_85072\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_85072\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-11-14 23:17:00,109]\u001b[0m Trial 72 finished with value: 0.7217296373647237 and parameters: {'lambda': 5.714089341544364, 'alpha': 0.9183024343385972, 'colsample_bytree': 1.0, 'subsample': 0.6000000000000001, 'learning_rate': 0.0251, 'n_estimators': 312}. Best is trial 71 with value: 0.7275758496297704.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_85072\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_85072\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-11-14 23:18:12,262]\u001b[0m Trial 73 finished with value: 0.7239157015378772 and parameters: {'lambda': 2.9110051104160237, 'alpha': 1.4226943593564523, 'colsample_bytree': 0.9000000000000001, 'subsample': 0.6000000000000001, 'learning_rate': 0.035100000000000006, 'n_estimators': 529}. Best is trial 71 with value: 0.7275758496297704.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_85072\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_85072\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-11-14 23:19:08,407]\u001b[0m Trial 74 finished with value: 0.7234733244731346 and parameters: {'lambda': 5.189935029461615, 'alpha': 0.6278590590632901, 'colsample_bytree': 1.0, 'subsample': 0.6000000000000001, 'learning_rate': 0.0751, 'n_estimators': 381}. Best is trial 71 with value: 0.7275758496297704.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_85072\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_85072\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-11-14 23:20:02,506]\u001b[0m Trial 75 finished with value: 0.7227791911904311 and parameters: {'lambda': 1.51531544457469, 'alpha': 0.020817027791247236, 'colsample_bytree': 0.7, 'subsample': 0.6000000000000001, 'learning_rate': 0.0551, 'n_estimators': 487}. Best is trial 71 with value: 0.7275758496297704.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_85072\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_85072\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-11-14 23:21:03,405]\u001b[0m Trial 76 finished with value: 0.7219054490222138 and parameters: {'lambda': 0.0011273296147167535, 'alpha': 1.832697643178514, 'colsample_bytree': 0.9000000000000001, 'subsample': 0.7000000000000001, 'learning_rate': 0.040100000000000004, 'n_estimators': 403}. Best is trial 71 with value: 0.7275758496297704.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_85072\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_85072\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-11-14 23:22:01,616]\u001b[0m Trial 77 finished with value: 0.722778052022024 and parameters: {'lambda': 8.161885178398984, 'alpha': 0.12395195610709389, 'colsample_bytree': 0.8, 'subsample': 0.5, 'learning_rate': 0.0251, 'n_estimators': 503}. Best is trial 71 with value: 0.7275758496297704.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_85072\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_85072\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-11-14 23:23:09,942]\u001b[0m Trial 78 finished with value: 0.7228661477121702 and parameters: {'lambda': 4.570330062294089, 'alpha': 1.2599395794705317, 'colsample_bytree': 1.0, 'subsample': 0.6000000000000001, 'learning_rate': 0.015099999999999999, 'n_estimators': 434}. Best is trial 71 with value: 0.7275758496297704.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_85072\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_85072\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-11-14 23:23:48,902]\u001b[0m Trial 79 finished with value: 0.7199855705335106 and parameters: {'lambda': 0.8712942090840389, 'alpha': 0.0431952539892993, 'colsample_bytree': 0.9000000000000001, 'subsample': 0.5, 'learning_rate': 0.0651, 'n_estimators': 358}. Best is trial 71 with value: 0.7275758496297704.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_85072\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_85072\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-11-14 23:24:52,739]\u001b[0m Trial 80 finished with value: 0.7213776343269415 and parameters: {'lambda': 0.028784882649652125, 'alpha': 0.7878284986601933, 'colsample_bytree': 0.8, 'subsample': 0.7000000000000001, 'learning_rate': 0.050100000000000006, 'n_estimators': 582}. Best is trial 71 with value: 0.7275758496297704.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_85072\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_85072\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-11-14 23:26:01,009]\u001b[0m Trial 81 finished with value: 0.7242608695652174 and parameters: {'lambda': 7.557799811256208, 'alpha': 0.5360280366438459, 'colsample_bytree': 1.0, 'subsample': 0.6000000000000001, 'learning_rate': 0.0451, 'n_estimators': 464}. Best is trial 71 with value: 0.7275758496297704.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_85072\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_85072\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-11-14 23:27:01,727]\u001b[0m Trial 82 finished with value: 0.7284488323523827 and parameters: {'lambda': 6.052425424222589, 'alpha': 0.40529624769915296, 'colsample_bytree': 1.0, 'subsample': 0.6000000000000001, 'learning_rate': 0.035100000000000006, 'n_estimators': 405}. Best is trial 82 with value: 0.7284488323523827.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_85072\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_85072\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-11-14 23:28:02,569]\u001b[0m Trial 83 finished with value: 0.7244355420543005 and parameters: {'lambda': 3.6125785679333906, 'alpha': 0.22073106744868856, 'colsample_bytree': 1.0, 'subsample': 0.6000000000000001, 'learning_rate': 0.0301, 'n_estimators': 410}. Best is trial 82 with value: 0.7284488323523827.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_85072\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_85072\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-11-14 23:28:56,124]\u001b[0m Trial 84 finished with value: 0.7125673058667172 and parameters: {'lambda': 5.1465018235840265, 'alpha': 0.4362770364311124, 'colsample_bytree': 1.0, 'subsample': 0.6000000000000001, 'learning_rate': 0.0051, 'n_estimators': 339}. Best is trial 82 with value: 0.7284488323523827.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_85072\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_85072\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-11-14 23:29:37,054]\u001b[0m Trial 85 finished with value: 0.7232151129675337 and parameters: {'lambda': 2.7656371151927996, 'alpha': 0.3489756098880735, 'colsample_bytree': 0.9000000000000001, 'subsample': 0.6000000000000001, 'learning_rate': 0.035100000000000006, 'n_estimators': 295}. Best is trial 82 with value: 0.7284488323523827.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_85072\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_85072\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-11-14 23:31:28,164]\u001b[0m Trial 86 finished with value: 0.7248741218910194 and parameters: {'lambda': 8.304777224162606, 'alpha': 0.28238709202790596, 'colsample_bytree': 1.0, 'subsample': 0.6000000000000001, 'learning_rate': 0.0201, 'n_estimators': 743}. Best is trial 82 with value: 0.7284488323523827.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_85072\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_85072\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-11-14 23:33:20,685]\u001b[0m Trial 87 finished with value: 0.7230404404784507 and parameters: {'lambda': 0.2282149403771052, 'alpha': 0.8264139502859875, 'colsample_bytree': 1.0, 'subsample': 0.7000000000000001, 'learning_rate': 0.040100000000000004, 'n_estimators': 888}. Best is trial 82 with value: 0.7284488323523827.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_85072\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_85072\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-11-14 23:34:15,877]\u001b[0m Trial 88 finished with value: 0.7199832921966964 and parameters: {'lambda': 2.1068314233431824, 'alpha': 0.1841166141559588, 'colsample_bytree': 0.9000000000000001, 'subsample': 0.6000000000000001, 'learning_rate': 0.0551, 'n_estimators': 379}. Best is trial 82 with value: 0.7284488323523827.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_85072\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_85072\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-11-14 23:35:15,434]\u001b[0m Trial 89 finished with value: 0.7159715207898235 and parameters: {'lambda': 6.257613321289273, 'alpha': 0.07002921680225392, 'colsample_bytree': 1.0, 'subsample': 0.5, 'learning_rate': 0.1851, 'n_estimators': 531}. Best is trial 82 with value: 0.7284488323523827.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_85072\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_85072\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-11-14 23:36:28,702]\u001b[0m Trial 90 finished with value: 0.7170161382191 and parameters: {'lambda': 4.183066163227069, 'alpha': 0.3719926313527911, 'colsample_bytree': 0.8, 'subsample': 0.7000000000000001, 'learning_rate': 0.0051, 'n_estimators': 445}. Best is trial 82 with value: 0.7284488323523827.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_85072\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_85072\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-11-14 23:38:16,068]\u001b[0m Trial 91 finished with value: 0.7283595974938296 and parameters: {'lambda': 7.822860038604355, 'alpha': 0.2807156987082255, 'colsample_bytree': 1.0, 'subsample': 0.6000000000000001, 'learning_rate': 0.0301, 'n_estimators': 743}. Best is trial 82 with value: 0.7284488323523827.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_85072\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_85072\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-11-14 23:39:05,183]\u001b[0m Trial 92 finished with value: 0.7233875071198025 and parameters: {'lambda': 5.92092388804609, 'alpha': 0.6455896559119132, 'colsample_bytree': 1.0, 'subsample': 0.6000000000000001, 'learning_rate': 0.0301, 'n_estimators': 323}. Best is trial 82 with value: 0.7284488323523827.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_85072\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_85072\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-11-14 23:40:24,849]\u001b[0m Trial 93 finished with value: 0.7258306436301502 and parameters: {'lambda': 9.888414077001197, 'alpha': 0.10471951122695748, 'colsample_bytree': 1.0, 'subsample': 0.6000000000000001, 'learning_rate': 0.035100000000000006, 'n_estimators': 612}. Best is trial 82 with value: 0.7284488323523827.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_85072\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_85072\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-11-14 23:40:57,159]\u001b[0m Trial 94 finished with value: 0.7258306436301499 and parameters: {'lambda': 9.516870605087336, 'alpha': 0.10678247885972188, 'colsample_bytree': 1.0, 'subsample': 0.6000000000000001, 'learning_rate': 0.0251, 'n_estimators': 639}. Best is trial 82 with value: 0.7284488323523827.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_85072\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_85072\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-11-14 23:41:29,588]\u001b[0m Trial 95 finished with value: 0.721991266375546 and parameters: {'lambda': 9.627636657940453, 'alpha': 0.12056886000322102, 'colsample_bytree': 1.0, 'subsample': 0.6000000000000001, 'learning_rate': 0.015099999999999999, 'n_estimators': 606}. Best is trial 82 with value: 0.7284488323523827.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_85072\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_85072\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-11-14 23:42:02,485]\u001b[0m Trial 96 finished with value: 0.7262692234668691 and parameters: {'lambda': 8.359345462624608, 'alpha': 0.09864722677447235, 'colsample_bytree': 1.0, 'subsample': 0.6000000000000001, 'learning_rate': 0.0251, 'n_estimators': 642}. Best is trial 82 with value: 0.7284488323523827.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_85072\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_85072\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-11-14 23:42:35,905]\u001b[0m Trial 97 finished with value: 0.723212075185115 and parameters: {'lambda': 7.965717440200889, 'alpha': 0.11008722609534785, 'colsample_bytree': 1.0, 'subsample': 0.6000000000000001, 'learning_rate': 0.0251, 'n_estimators': 658}. Best is trial 82 with value: 0.7284488323523827.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_85072\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_85072\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-11-14 23:42:59,225]\u001b[0m Trial 98 finished with value: 0.7240007594456047 and parameters: {'lambda': 3.253077587229872, 'alpha': 0.15220293760990036, 'colsample_bytree': 0.6000000000000001, 'subsample': 0.6000000000000001, 'learning_rate': 0.0201, 'n_estimators': 670}. Best is trial 82 with value: 0.7284488323523827.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_85072\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_85072\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-11-14 23:43:26,708]\u001b[0m Trial 99 finished with value: 0.722512246060376 and parameters: {'lambda': 6.142690752561295, 'alpha': 0.0941333982257041, 'colsample_bytree': 1.0, 'subsample': 0.5, 'learning_rate': 0.035100000000000006, 'n_estimators': 630}. Best is trial 82 with value: 0.7284488323523827.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "#Tuning hyperparameters\n",
    "#Step 1. Define an objective function to be maximized.\n",
    "def objective(trial):\n",
    "    param = {\n",
    "        'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
    "        'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
    "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.3,1.0,step=0.1),\n",
    "        'subsample': trial.suggest_float('subsample', 0.4, 1.0, step=0.1),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.0001, 0.2, step=0.005),\n",
    "        'n_estimators': trial.suggest_int(\"n_estimators\",50,1000,1)\n",
    "        #'min_child_weight': trial.suggest_int('min_child_weight', 1, 300),\n",
    "    }\n",
    "    model = xgb.XGBClassifier(**param,random_state=1,n_jobs=8)\n",
    "\n",
    " \n",
    "# Step 2: Scoring method:\n",
    "    score = model_selection.cross_val_score(model, X, y, n_jobs=8, scoring=\"accuracy\",cv=Cv_optuna)\n",
    "    accuracy = score.mean()\n",
    "    return accuracy\n",
    "\n",
    "# Step 3: Running it\n",
    "study = optuna.create_study(direction=\"maximize\",sampler=optuna.samplers.TPESampler(seed=0))\n",
    "study.optimize(objective, n_trials=100, show_progress_bar=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "b2be4542-3f0e-438f-8e41-c67d96410fab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best parameters are : \n",
      "{'lambda': 6.052425424222589, 'alpha': 0.40529624769915296, 'colsample_bytree': 1.0, 'subsample': 0.6000000000000001, 'learning_rate': 0.035100000000000006, 'n_estimators': 405}\n"
     ]
    }
   ],
   "source": [
    "# Getting the best parameters:\n",
    "print(f\"The best parameters are : \\n{study.best_params}\")\n",
    "# Setting the best model\n",
    "clf=xgb.XGBClassifier(alpha = study.best_params['alpha']\n",
    "              ,colsample_bytree = study.best_params['colsample_bytree']\n",
    "              ,subsample = study.best_params['subsample']\n",
    "              ,n_estimators = study.best_params['n_estimators']\n",
    "              ,learning_rate= study.best_params['learning_rate'], n_jobs=8\n",
    "              ,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "d0687ace-1f1a-44a0-9329-fc50b681ff53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mean</th>\n",
       "      <th>Se</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Accuracy_test</th>\n",
       "      <td>0.721818</td>\n",
       "      <td>0.003827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Accuracy_train</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1 Score</th>\n",
       "      <td>0.724838</td>\n",
       "      <td>0.004087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Precision</th>\n",
       "      <td>0.717326</td>\n",
       "      <td>0.004230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recall</th>\n",
       "      <td>0.733998</td>\n",
       "      <td>0.006064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Roc_auc</th>\n",
       "      <td>0.793690</td>\n",
       "      <td>0.003490</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Mean        Se\n",
       "Accuracy_test   0.721818  0.003827\n",
       "Accuracy_train  1.000000  0.000000\n",
       "F1 Score        0.724838  0.004087\n",
       "Precision       0.717326  0.004230\n",
       "Recall          0.733998  0.006064\n",
       "Roc_auc         0.793690  0.003490"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Model2\n",
    "Model2=Model_results(clf,X,y,Cv_model)\n",
    "Model2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "0bb46026-eb5e-4693-8e81-0a0a2ed16564",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th>Method</th>\n",
       "      <th colspan=\"4\" halign=\"left\">XGB</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model</th>\n",
       "      <th colspan=\"2\" halign=\"left\">Model 1</th>\n",
       "      <th colspan=\"2\" halign=\"left\">Model 2</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Values</th>\n",
       "      <th>Mean</th>\n",
       "      <th>Se</th>\n",
       "      <th>Mean</th>\n",
       "      <th>Se</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Accuracy_test</th>\n",
       "      <td>0.714049</td>\n",
       "      <td>0.003174</td>\n",
       "      <td>0.721818</td>\n",
       "      <td>0.003827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Accuracy_train</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1 Score</th>\n",
       "      <td>0.716252</td>\n",
       "      <td>0.003368</td>\n",
       "      <td>0.724838</td>\n",
       "      <td>0.004087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Precision</th>\n",
       "      <td>0.711574</td>\n",
       "      <td>0.003907</td>\n",
       "      <td>0.717326</td>\n",
       "      <td>0.004230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recall</th>\n",
       "      <td>0.723031</td>\n",
       "      <td>0.006039</td>\n",
       "      <td>0.733998</td>\n",
       "      <td>0.006064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Roc_auc</th>\n",
       "      <td>0.778745</td>\n",
       "      <td>0.003458</td>\n",
       "      <td>0.793690</td>\n",
       "      <td>0.003490</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Method               XGB                              \n",
       "Model            Model 1             Model 2          \n",
       "Values              Mean        Se      Mean        Se\n",
       "Accuracy_test   0.714049  0.003174  0.721818  0.003827\n",
       "Accuracy_train  1.000000  0.000000  1.000000  0.000000\n",
       "F1 Score        0.716252  0.003368  0.724838  0.004087\n",
       "Precision       0.711574  0.003907  0.717326  0.004230\n",
       "Recall          0.723031  0.006039  0.733998  0.006064\n",
       "Roc_auc         0.778745  0.003458  0.793690  0.003490"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Saving the data of model performance\n",
    "Model_data=pd.concat([Model1,Model2],axis=1)\n",
    "Model_data.columns = [['XGB']*4,['Model 1','Model 1', 'Model 2','Model 2'], ['Mean', 'Se', 'Mean', 'Se']]  \n",
    "Model_data.columns.names=['Method','Model','Values']\n",
    "Model_data.to_csv(\"./XGB_model_lasso_data.csv\",sep=',')\n",
    "Model_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "208fbfd4-b156-43fb-b7b8-5f38ee0e24ef",
   "metadata": {},
   "source": [
    "# 2. MLREM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45019f5e-5468-4d1b-a4de-8b8c86e33654",
   "metadata": {},
   "outputs": [],
   "source": [
    "col_data= pd.read_csv(\"./Results/MLREM_col.csv\",header=0,index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6d91ba6-9049-4060-818a-8cf59d7a47b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "MRLEM_data=X_NAomit_data[col_data.index]\n",
    "MRLEM_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d8bf42e-2223-4c7b-9bd2-7c2787032802",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scale data\n",
    "Scaler = preprocessing.MinMaxScaler() #StandardScaler\n",
    "Transformer =Scaler.fit(MRLEM_data)\n",
    "X_scaled_data=Transformer.transform(MRLEM_data)\n",
    "X_scaled_data =pd.DataFrame(X_scaled_data)\n",
    "X_scaled_data.columns=MRLEM_data.columns\n",
    "X_scaled_data.index=Raw_data.index\n",
    "X_scaled_data.to_csv(\"./Original data/MRLEM_data_X_scaled_data.csv\",sep=',',header=1,index=1)\n",
    "joblib.dump(Transformer, './Models/MRLEM_data_Scaler_transformer.pkl')\n",
    "\n",
    "X_scaled_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "c5eb8b75-76bc-4fcb-aad5-6762048df1c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Model_results(Model_clf,X_test,y,Cv_model):\n",
    "    Model_scores= cross_validate(estimator=Model_clf, X=X_test, y=y, cv=Cv_model,scoring=( 'accuracy','f1','precision','recall','roc_auc'), return_train_score=True)\n",
    "    Model_score= cross_validate(estimator=Model_clf, X=X_test, y=y, cv=Cv_model,scoring=( 'accuracy','f1','precision','recall','roc_auc'), return_train_score=False)\n",
    "#Accuracy\n",
    "    Model_Accuracy_test_mean=Model_scores['test_accuracy'].mean()\n",
    "    Model_Accuracy_test_se=(Model_scores['test_accuracy'].std()/math.sqrt(len(Model_scores['test_accuracy']))) \n",
    "    Model_Accuracy_train_mean=Model_scores['train_accuracy'].mean()\n",
    "    Model_Accuracy_train_se=(Model_scores['train_accuracy'].std()/math.sqrt(len(Model_scores['train_accuracy']))) \n",
    "#f1\n",
    "    Model_f1_mean=Model_score['test_f1'].mean()\n",
    "    Model_f1_se=(Model_score['test_f1'].std()/math.sqrt(len(Model_score['test_f1']))) \n",
    "#precision\n",
    "    Model_precision_mean=Model_score['test_precision'].mean()\n",
    "    Model_precision_se=(Model_score['test_precision'].std()/math.sqrt(len(Model_score['test_precision']))) \n",
    "#recall\n",
    "    Model_recall_mean=Model_score['test_recall'].mean()\n",
    "    Model_recall_se=(Model_score['test_recall'].std()/math.sqrt(len(Model_score['test_recall']))) \n",
    "#roc_auc\n",
    "    Model_roc_auc_mean=Model_score['test_roc_auc'].mean()\n",
    "    Model_roc_auc_se=(Model_score['test_roc_auc'].std()/math.sqrt(len(Model_score['test_roc_auc']))) \n",
    "    Model = {'Mean':[Model_Accuracy_test_mean,Model_Accuracy_train_mean,Model_f1_mean,Model_precision_mean,Model_recall_mean,Model_roc_auc_mean],\n",
    "        'Se':[Model_Accuracy_test_se,Model_Accuracy_train_se,Model_f1_se,Model_precision_se,Model_recall_se,Model_roc_auc_se]}\n",
    "    Model = pd.DataFrame(Model, index=['Accuracy_test','Accuracy_train','F1 Score','Precision','Recall','Roc_auc'])\n",
    "    return Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "43024221-dcb1-4c20-a862-8ba15cc4978a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setting the KFold \n",
    "Cv_optuna= RepeatedStratifiedKFold(n_splits=5, n_repeats=10, random_state=0)\n",
    "Cv_model= RepeatedStratifiedKFold(n_splits=5, n_repeats=10, random_state=0)\n",
    "Cv_RFECV= RepeatedStratifiedKFold(n_splits=5, n_repeats=10, random_state=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "ef2d9106-5c7e-4daa-89d3-1c228a5ac78a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data pre-processing of models\n",
    "X=np.array(X_scaled_data)\n",
    "y=Raw_data['Hydrogel-forming ability'].values\n",
    "clf=LogisticRegression(solver='liblinear',random_state=0,dual=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48b68d6d-1a1e-439b-aee8-42486486d23e",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 2.1 DT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "74f1bf04-5bde-4d51-bc10-aee4e7d2c583",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf=DecisionTreeClassifier(random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "7c30897c-633f-4a53-96c3-a415fd50308c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mean</th>\n",
       "      <th>Se</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Accuracy_test</th>\n",
       "      <td>0.629333</td>\n",
       "      <td>0.015032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Accuracy_train</th>\n",
       "      <td>0.729981</td>\n",
       "      <td>0.004700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1 Score</th>\n",
       "      <td>0.697627</td>\n",
       "      <td>0.013235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Precision</th>\n",
       "      <td>0.620752</td>\n",
       "      <td>0.011961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recall</th>\n",
       "      <td>0.811071</td>\n",
       "      <td>0.020893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Roc_auc</th>\n",
       "      <td>0.664796</td>\n",
       "      <td>0.020543</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Mean        Se\n",
       "Accuracy_test   0.629333  0.015032\n",
       "Accuracy_train  0.729981  0.004700\n",
       "F1 Score        0.697627  0.013235\n",
       "Precision       0.620752  0.011961\n",
       "Recall          0.811071  0.020893\n",
       "Roc_auc         0.664796  0.020543"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Model1 \n",
    "Model1_clf=clf\n",
    "#Model1\n",
    "Model1=Model_results(Model1_clf,X,y,Cv_model)\n",
    "Model1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "f86a6975-0d73-46e6-9ba4-c3c488b2a565",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2024-01-12 01:29:56,212]\u001b[0m A new study created in memory with name: no-name-6a0b1671-0ec2-4905-98f9-69d2f7e33654\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:29:57,476]\u001b[0m Trial 0 finished with value: 0.6312380952380953 and parameters: {'max_depth': 4, 'max_features': 17, 'min_samples_split': 16}. Best is trial 0 with value: 0.6312380952380953.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:29:57,505]\u001b[0m Trial 1 finished with value: 0.5926666666666667 and parameters: {'max_depth': 4, 'max_features': 14, 'min_samples_split': 17}. Best is trial 0 with value: 0.6312380952380953.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:29:57,530]\u001b[0m Trial 2 finished with value: 0.6375238095238095 and parameters: {'max_depth': 4, 'max_features': 19, 'min_samples_split': 25}. Best is trial 2 with value: 0.6375238095238095.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:29:57,554]\u001b[0m Trial 3 finished with value: 0.6208571428571428 and parameters: {'max_depth': 4, 'max_features': 18, 'min_samples_split': 14}. Best is trial 2 with value: 0.6375238095238095.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:29:57,579]\u001b[0m Trial 4 finished with value: 0.6296190476190476 and parameters: {'max_depth': 4, 'max_features': 20, 'min_samples_split': 3}. Best is trial 2 with value: 0.6375238095238095.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:29:57,600]\u001b[0m Trial 5 finished with value: 0.6120952380952381 and parameters: {'max_depth': 3, 'max_features': 10, 'min_samples_split': 21}. Best is trial 2 with value: 0.6375238095238095.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:29:57,624]\u001b[0m Trial 6 finished with value: 0.6318095238095238 and parameters: {'max_depth': 5, 'max_features': 19, 'min_samples_split': 25}. Best is trial 2 with value: 0.6375238095238095.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:29:57,646]\u001b[0m Trial 7 finished with value: 0.5998095238095238 and parameters: {'max_depth': 5, 'max_features': 15, 'min_samples_split': 20}. Best is trial 2 with value: 0.6375238095238095.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:29:57,666]\u001b[0m Trial 8 finished with value: 0.6439999999999999 and parameters: {'max_depth': 3, 'max_features': 17, 'min_samples_split': 5}. Best is trial 8 with value: 0.6439999999999999.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:29:57,689]\u001b[0m Trial 9 finished with value: 0.6057142857142856 and parameters: {'max_depth': 5, 'max_features': 15, 'min_samples_split': 11}. Best is trial 8 with value: 0.6439999999999999.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:29:57,714]\u001b[0m Trial 10 finished with value: 0.601047619047619 and parameters: {'max_depth': 3, 'max_features': 12, 'min_samples_split': 2}. Best is trial 8 with value: 0.6439999999999999.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:29:57,739]\u001b[0m Trial 11 finished with value: 0.6411428571428571 and parameters: {'max_depth': 3, 'max_features': 17, 'min_samples_split': 8}. Best is trial 8 with value: 0.6439999999999999.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:29:57,765]\u001b[0m Trial 12 finished with value: 0.6411428571428571 and parameters: {'max_depth': 3, 'max_features': 17, 'min_samples_split': 9}. Best is trial 8 with value: 0.6439999999999999.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:29:57,789]\u001b[0m Trial 13 finished with value: 0.6411428571428571 and parameters: {'max_depth': 3, 'max_features': 17, 'min_samples_split': 7}. Best is trial 8 with value: 0.6439999999999999.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:29:57,813]\u001b[0m Trial 14 finished with value: 0.6280952380952382 and parameters: {'max_depth': 3, 'max_features': 13, 'min_samples_split': 6}. Best is trial 8 with value: 0.6439999999999999.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:29:57,838]\u001b[0m Trial 15 finished with value: 0.64 and parameters: {'max_depth': 3, 'max_features': 16, 'min_samples_split': 5}. Best is trial 8 with value: 0.6439999999999999.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:29:57,862]\u001b[0m Trial 16 finished with value: 0.64 and parameters: {'max_depth': 3, 'max_features': 16, 'min_samples_split': 10}. Best is trial 8 with value: 0.6439999999999999.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:29:57,887]\u001b[0m Trial 17 finished with value: 0.6042857142857144 and parameters: {'max_depth': 3, 'max_features': 20, 'min_samples_split': 6}. Best is trial 8 with value: 0.6439999999999999.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:29:57,914]\u001b[0m Trial 18 finished with value: 0.6207619047619047 and parameters: {'max_depth': 4, 'max_features': 18, 'min_samples_split': 12}. Best is trial 8 with value: 0.6439999999999999.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:29:57,939]\u001b[0m Trial 19 finished with value: 0.6295238095238096 and parameters: {'max_depth': 3, 'max_features': 13, 'min_samples_split': 4}. Best is trial 8 with value: 0.6439999999999999.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:29:57,964]\u001b[0m Trial 20 finished with value: 0.6385714285714286 and parameters: {'max_depth': 3, 'max_features': 16, 'min_samples_split': 7}. Best is trial 8 with value: 0.6439999999999999.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:29:57,989]\u001b[0m Trial 21 finished with value: 0.6411428571428571 and parameters: {'max_depth': 3, 'max_features': 17, 'min_samples_split': 9}. Best is trial 8 with value: 0.6439999999999999.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:29:58,013]\u001b[0m Trial 22 finished with value: 0.6111428571428571 and parameters: {'max_depth': 3, 'max_features': 18, 'min_samples_split': 13}. Best is trial 8 with value: 0.6439999999999999.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:29:58,038]\u001b[0m Trial 23 finished with value: 0.6411428571428571 and parameters: {'max_depth': 3, 'max_features': 17, 'min_samples_split': 8}. Best is trial 8 with value: 0.6439999999999999.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:29:58,063]\u001b[0m Trial 24 finished with value: 0.6253333333333333 and parameters: {'max_depth': 3, 'max_features': 19, 'min_samples_split': 9}. Best is trial 8 with value: 0.6439999999999999.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:29:58,088]\u001b[0m Trial 25 finished with value: 0.6405714285714285 and parameters: {'max_depth': 4, 'max_features': 16, 'min_samples_split': 10}. Best is trial 8 with value: 0.6439999999999999.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:29:58,114]\u001b[0m Trial 26 finished with value: 0.6097142857142858 and parameters: {'max_depth': 3, 'max_features': 14, 'min_samples_split': 4}. Best is trial 8 with value: 0.6439999999999999.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:29:58,137]\u001b[0m Trial 27 finished with value: 0.6129523809523809 and parameters: {'max_depth': 3, 'max_features': 15, 'min_samples_split': 6}. Best is trial 8 with value: 0.6439999999999999.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:29:58,163]\u001b[0m Trial 28 finished with value: 0.6222857142857143 and parameters: {'max_depth': 4, 'max_features': 18, 'min_samples_split': 7}. Best is trial 8 with value: 0.6439999999999999.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:29:58,187]\u001b[0m Trial 29 finished with value: 0.6396190476190476 and parameters: {'max_depth': 4, 'max_features': 17, 'min_samples_split': 14}. Best is trial 8 with value: 0.6439999999999999.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:29:58,212]\u001b[0m Trial 30 finished with value: 0.6363809523809524 and parameters: {'max_depth': 3, 'max_features': 19, 'min_samples_split': 16}. Best is trial 8 with value: 0.6439999999999999.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:29:58,237]\u001b[0m Trial 31 finished with value: 0.6411428571428571 and parameters: {'max_depth': 3, 'max_features': 17, 'min_samples_split': 8}. Best is trial 8 with value: 0.6439999999999999.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:29:58,260]\u001b[0m Trial 32 finished with value: 0.6385714285714286 and parameters: {'max_depth': 3, 'max_features': 16, 'min_samples_split': 9}. Best is trial 8 with value: 0.6439999999999999.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:29:58,285]\u001b[0m Trial 33 finished with value: 0.624 and parameters: {'max_depth': 3, 'max_features': 18, 'min_samples_split': 2}. Best is trial 8 with value: 0.6439999999999999.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:29:58,312]\u001b[0m Trial 34 finished with value: 0.6411428571428571 and parameters: {'max_depth': 3, 'max_features': 17, 'min_samples_split': 11}. Best is trial 8 with value: 0.6439999999999999.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:29:58,335]\u001b[0m Trial 35 finished with value: 0.614 and parameters: {'max_depth': 4, 'max_features': 15, 'min_samples_split': 4}. Best is trial 8 with value: 0.6439999999999999.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:29:58,360]\u001b[0m Trial 36 finished with value: 0.6111428571428571 and parameters: {'max_depth': 3, 'max_features': 18, 'min_samples_split': 12}. Best is trial 8 with value: 0.6439999999999999.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:29:58,386]\u001b[0m Trial 37 finished with value: 0.6011428571428571 and parameters: {'max_depth': 4, 'max_features': 14, 'min_samples_split': 7}. Best is trial 8 with value: 0.6439999999999999.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:29:58,413]\u001b[0m Trial 38 finished with value: 0.6281904761904762 and parameters: {'max_depth': 3, 'max_features': 19, 'min_samples_split': 5}. Best is trial 8 with value: 0.6439999999999999.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:29:58,439]\u001b[0m Trial 39 finished with value: 0.6067619047619047 and parameters: {'max_depth': 4, 'max_features': 10, 'min_samples_split': 16}. Best is trial 8 with value: 0.6439999999999999.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:29:58,466]\u001b[0m Trial 40 finished with value: 0.6393333333333333 and parameters: {'max_depth': 5, 'max_features': 16, 'min_samples_split': 11}. Best is trial 8 with value: 0.6439999999999999.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:29:58,491]\u001b[0m Trial 41 finished with value: 0.6411428571428571 and parameters: {'max_depth': 3, 'max_features': 17, 'min_samples_split': 9}. Best is trial 8 with value: 0.6439999999999999.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:29:58,519]\u001b[0m Trial 42 finished with value: 0.6368571428571428 and parameters: {'max_depth': 3, 'max_features': 17, 'min_samples_split': 14}. Best is trial 8 with value: 0.6439999999999999.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:29:58,545]\u001b[0m Trial 43 finished with value: 0.6411428571428571 and parameters: {'max_depth': 3, 'max_features': 17, 'min_samples_split': 8}. Best is trial 8 with value: 0.6439999999999999.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:29:58,570]\u001b[0m Trial 44 finished with value: 0.614 and parameters: {'max_depth': 3, 'max_features': 18, 'min_samples_split': 10}. Best is trial 8 with value: 0.6439999999999999.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:29:58,597]\u001b[0m Trial 45 finished with value: 0.6411428571428571 and parameters: {'max_depth': 3, 'max_features': 17, 'min_samples_split': 8}. Best is trial 8 with value: 0.6439999999999999.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:29:58,624]\u001b[0m Trial 46 finished with value: 0.6056190476190477 and parameters: {'max_depth': 3, 'max_features': 20, 'min_samples_split': 5}. Best is trial 8 with value: 0.6439999999999999.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:29:58,651]\u001b[0m Trial 47 finished with value: 0.64 and parameters: {'max_depth': 3, 'max_features': 16, 'min_samples_split': 3}. Best is trial 8 with value: 0.6439999999999999.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:29:58,678]\u001b[0m Trial 48 finished with value: 0.6143809523809524 and parameters: {'max_depth': 3, 'max_features': 15, 'min_samples_split': 8}. Best is trial 8 with value: 0.6439999999999999.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:29:58,704]\u001b[0m Trial 49 finished with value: 0.6180952380952381 and parameters: {'max_depth': 3, 'max_features': 18, 'min_samples_split': 21}. Best is trial 8 with value: 0.6439999999999999.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:29:58,729]\u001b[0m Trial 50 finished with value: 0.6406666666666666 and parameters: {'max_depth': 3, 'max_features': 11, 'min_samples_split': 3}. Best is trial 8 with value: 0.6439999999999999.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:29:58,758]\u001b[0m Trial 51 finished with value: 0.6411428571428571 and parameters: {'max_depth': 3, 'max_features': 17, 'min_samples_split': 11}. Best is trial 8 with value: 0.6439999999999999.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:29:58,785]\u001b[0m Trial 52 finished with value: 0.6411428571428571 and parameters: {'max_depth': 3, 'max_features': 17, 'min_samples_split': 11}. Best is trial 8 with value: 0.6439999999999999.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:29:58,811]\u001b[0m Trial 53 finished with value: 0.6371428571428572 and parameters: {'max_depth': 3, 'max_features': 16, 'min_samples_split': 12}. Best is trial 8 with value: 0.6439999999999999.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:29:58,838]\u001b[0m Trial 54 finished with value: 0.6425714285714286 and parameters: {'max_depth': 3, 'max_features': 17, 'min_samples_split': 6}. Best is trial 8 with value: 0.6439999999999999.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:29:58,863]\u001b[0m Trial 55 finished with value: 0.6211428571428571 and parameters: {'max_depth': 3, 'max_features': 18, 'min_samples_split': 6}. Best is trial 8 with value: 0.6439999999999999.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:29:58,888]\u001b[0m Trial 56 finished with value: 0.6375238095238095 and parameters: {'max_depth': 3, 'max_features': 19, 'min_samples_split': 24}. Best is trial 8 with value: 0.6439999999999999.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:29:58,915]\u001b[0m Trial 57 finished with value: 0.6422857142857145 and parameters: {'max_depth': 5, 'max_features': 16, 'min_samples_split': 7}. Best is trial 8 with value: 0.6439999999999999.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:29:58,941]\u001b[0m Trial 58 finished with value: 0.6604761904761905 and parameters: {'max_depth': 5, 'max_features': 16, 'min_samples_split': 5}. Best is trial 58 with value: 0.6604761904761905.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:29:58,966]\u001b[0m Trial 59 finished with value: 0.6406666666666666 and parameters: {'max_depth': 5, 'max_features': 15, 'min_samples_split': 6}. Best is trial 58 with value: 0.6604761904761905.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:29:58,992]\u001b[0m Trial 60 finished with value: 0.6604761904761905 and parameters: {'max_depth': 5, 'max_features': 16, 'min_samples_split': 5}. Best is trial 58 with value: 0.6604761904761905.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:29:59,017]\u001b[0m Trial 61 finished with value: 0.6604761904761905 and parameters: {'max_depth': 5, 'max_features': 16, 'min_samples_split': 5}. Best is trial 58 with value: 0.6604761904761905.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:29:59,044]\u001b[0m Trial 62 finished with value: 0.647904761904762 and parameters: {'max_depth': 5, 'max_features': 14, 'min_samples_split': 3}. Best is trial 58 with value: 0.6604761904761905.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:29:59,073]\u001b[0m Trial 63 finished with value: 0.6742857142857143 and parameters: {'max_depth': 5, 'max_features': 13, 'min_samples_split': 2}. Best is trial 63 with value: 0.6742857142857143.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:29:59,099]\u001b[0m Trial 64 finished with value: 0.6520952380952381 and parameters: {'max_depth': 5, 'max_features': 14, 'min_samples_split': 2}. Best is trial 63 with value: 0.6742857142857143.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:29:59,125]\u001b[0m Trial 65 finished with value: 0.6742857142857143 and parameters: {'max_depth': 5, 'max_features': 13, 'min_samples_split': 2}. Best is trial 63 with value: 0.6742857142857143.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:29:59,151]\u001b[0m Trial 66 finished with value: 0.68 and parameters: {'max_depth': 5, 'max_features': 13, 'min_samples_split': 3}. Best is trial 66 with value: 0.68.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:29:59,176]\u001b[0m Trial 67 finished with value: 0.6742857142857143 and parameters: {'max_depth': 5, 'max_features': 13, 'min_samples_split': 2}. Best is trial 66 with value: 0.68.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:29:59,201]\u001b[0m Trial 68 finished with value: 0.6742857142857143 and parameters: {'max_depth': 5, 'max_features': 13, 'min_samples_split': 2}. Best is trial 66 with value: 0.68.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:29:59,226]\u001b[0m Trial 69 finished with value: 0.6742857142857143 and parameters: {'max_depth': 5, 'max_features': 13, 'min_samples_split': 2}. Best is trial 66 with value: 0.68.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:29:59,252]\u001b[0m Trial 70 finished with value: 0.6742857142857143 and parameters: {'max_depth': 5, 'max_features': 13, 'min_samples_split': 2}. Best is trial 66 with value: 0.68.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:29:59,278]\u001b[0m Trial 71 finished with value: 0.6742857142857143 and parameters: {'max_depth': 5, 'max_features': 13, 'min_samples_split': 2}. Best is trial 66 with value: 0.68.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:29:59,302]\u001b[0m Trial 72 finished with value: 0.6742857142857143 and parameters: {'max_depth': 5, 'max_features': 13, 'min_samples_split': 2}. Best is trial 66 with value: 0.68.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:29:59,328]\u001b[0m Trial 73 finished with value: 0.6690476190476191 and parameters: {'max_depth': 5, 'max_features': 12, 'min_samples_split': 3}. Best is trial 66 with value: 0.68.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:29:59,355]\u001b[0m Trial 74 finished with value: 0.6761904761904762 and parameters: {'max_depth': 5, 'max_features': 12, 'min_samples_split': 2}. Best is trial 66 with value: 0.68.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:29:59,380]\u001b[0m Trial 75 finished with value: 0.6676190476190478 and parameters: {'max_depth': 5, 'max_features': 12, 'min_samples_split': 4}. Best is trial 66 with value: 0.68.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:29:59,416]\u001b[0m Trial 76 finished with value: 0.6742857142857143 and parameters: {'max_depth': 5, 'max_features': 13, 'min_samples_split': 2}. Best is trial 66 with value: 0.68.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:29:59,444]\u001b[0m Trial 77 finished with value: 0.6690476190476191 and parameters: {'max_depth': 5, 'max_features': 12, 'min_samples_split': 3}. Best is trial 66 with value: 0.68.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:29:59,471]\u001b[0m Trial 78 finished with value: 0.6451428571428572 and parameters: {'max_depth': 5, 'max_features': 11, 'min_samples_split': 4}. Best is trial 66 with value: 0.68.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:29:59,496]\u001b[0m Trial 79 finished with value: 0.6742857142857143 and parameters: {'max_depth': 5, 'max_features': 13, 'min_samples_split': 2}. Best is trial 66 with value: 0.68.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:29:59,522]\u001b[0m Trial 80 finished with value: 0.6676190476190478 and parameters: {'max_depth': 5, 'max_features': 12, 'min_samples_split': 4}. Best is trial 66 with value: 0.68.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:29:59,548]\u001b[0m Trial 81 finished with value: 0.6742857142857143 and parameters: {'max_depth': 5, 'max_features': 13, 'min_samples_split': 2}. Best is trial 66 with value: 0.68.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:29:59,573]\u001b[0m Trial 82 finished with value: 0.68 and parameters: {'max_depth': 5, 'max_features': 13, 'min_samples_split': 3}. Best is trial 66 with value: 0.68.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:29:59,599]\u001b[0m Trial 83 finished with value: 0.647904761904762 and parameters: {'max_depth': 5, 'max_features': 14, 'min_samples_split': 3}. Best is trial 66 with value: 0.68.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:29:59,624]\u001b[0m Trial 84 finished with value: 0.6478095238095238 and parameters: {'max_depth': 5, 'max_features': 11, 'min_samples_split': 3}. Best is trial 66 with value: 0.68.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:29:59,649]\u001b[0m Trial 85 finished with value: 0.6759999999999999 and parameters: {'max_depth': 5, 'max_features': 13, 'min_samples_split': 4}. Best is trial 66 with value: 0.68.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:29:59,675]\u001b[0m Trial 86 finished with value: 0.6676190476190478 and parameters: {'max_depth': 5, 'max_features': 12, 'min_samples_split': 4}. Best is trial 66 with value: 0.68.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:29:59,701]\u001b[0m Trial 87 finished with value: 0.6337142857142858 and parameters: {'max_depth': 5, 'max_features': 12, 'min_samples_split': 18}. Best is trial 66 with value: 0.68.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:29:59,729]\u001b[0m Trial 88 finished with value: 0.68 and parameters: {'max_depth': 5, 'max_features': 13, 'min_samples_split': 3}. Best is trial 66 with value: 0.68.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:29:59,758]\u001b[0m Trial 89 finished with value: 0.647904761904762 and parameters: {'max_depth': 5, 'max_features': 14, 'min_samples_split': 3}. Best is trial 66 with value: 0.68.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:29:59,784]\u001b[0m Trial 90 finished with value: 0.68 and parameters: {'max_depth': 5, 'max_features': 13, 'min_samples_split': 3}. Best is trial 66 with value: 0.68.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:29:59,809]\u001b[0m Trial 91 finished with value: 0.6759999999999999 and parameters: {'max_depth': 5, 'max_features': 13, 'min_samples_split': 4}. Best is trial 66 with value: 0.68.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:29:59,836]\u001b[0m Trial 92 finished with value: 0.6759999999999999 and parameters: {'max_depth': 5, 'max_features': 13, 'min_samples_split': 4}. Best is trial 66 with value: 0.68.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:29:59,862]\u001b[0m Trial 93 finished with value: 0.6759999999999999 and parameters: {'max_depth': 5, 'max_features': 13, 'min_samples_split': 4}. Best is trial 66 with value: 0.68.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:29:59,889]\u001b[0m Trial 94 finished with value: 0.6379047619047619 and parameters: {'max_depth': 5, 'max_features': 14, 'min_samples_split': 4}. Best is trial 66 with value: 0.68.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:29:59,915]\u001b[0m Trial 95 finished with value: 0.6676190476190478 and parameters: {'max_depth': 5, 'max_features': 12, 'min_samples_split': 4}. Best is trial 66 with value: 0.68.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:29:59,942]\u001b[0m Trial 96 finished with value: 0.68 and parameters: {'max_depth': 5, 'max_features': 13, 'min_samples_split': 3}. Best is trial 66 with value: 0.68.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:29:59,968]\u001b[0m Trial 97 finished with value: 0.6421904761904762 and parameters: {'max_depth': 5, 'max_features': 14, 'min_samples_split': 5}. Best is trial 66 with value: 0.68.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:29:59,993]\u001b[0m Trial 98 finished with value: 0.6634285714285714 and parameters: {'max_depth': 5, 'max_features': 12, 'min_samples_split': 5}. Best is trial 66 with value: 0.68.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:30:00,019]\u001b[0m Trial 99 finished with value: 0.6478095238095238 and parameters: {'max_depth': 5, 'max_features': 11, 'min_samples_split': 3}. Best is trial 66 with value: 0.68.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "#Tuning hyperparameters\n",
    "#Step 1. Define an objective function to be maximized.\n",
    "def objective(trial):\n",
    "    param = {\n",
    "        'max_depth': trial.suggest_int('max_depth',3,5,1),\n",
    "        'max_features' : trial.suggest_int(\"max_features\",10,20,1),\n",
    "        'min_samples_split':trial.suggest_int('min_samples_split',2,25,1)\n",
    "    }\n",
    "    model = DecisionTreeClassifier(**param,random_state=1)\n",
    "\n",
    " \n",
    "# Step 2: Scoring method:\n",
    "    score = model_selection.cross_val_score(model, X, y, n_jobs=8, scoring=\"accuracy\",cv=Cv_optuna)\n",
    "    accuracy = score.mean()\n",
    "    return accuracy\n",
    " \n",
    "# Step 3: Running it\n",
    "study = optuna.create_study(direction=\"maximize\",sampler=optuna.samplers.TPESampler(seed=0))\n",
    "study.optimize(objective, n_trials=100, show_progress_bar=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "6ec0811a-1713-4b39-b21f-cb09e9594c4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best parameters are : \n",
      "{'max_depth': 5, 'max_features': 13, 'min_samples_split': 3}\n"
     ]
    }
   ],
   "source": [
    "# Getting the best parameters:\n",
    "print(f\"The best parameters are : \\n{study.best_params}\")\n",
    "# Setting the best model\n",
    "clf =DecisionTreeClassifier(max_depth = study.best_params['max_depth']\n",
    "              ,max_features = study.best_params['max_features']\n",
    "              #,n_estimators = study.best_params['n_estimators']\n",
    "              #,learning_rate = study.best_params['learning_rate']\n",
    "              ,min_samples_split= study.best_params['min_samples_split']\n",
    "              ,random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "9d1899f3-a5c0-4f3d-8fb2-176c72ea4a4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mean</th>\n",
       "      <th>Se</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Accuracy_test</th>\n",
       "      <td>0.680000</td>\n",
       "      <td>0.012329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Accuracy_train</th>\n",
       "      <td>0.925345</td>\n",
       "      <td>0.005584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1 Score</th>\n",
       "      <td>0.706865</td>\n",
       "      <td>0.012092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Precision</th>\n",
       "      <td>0.698240</td>\n",
       "      <td>0.013460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recall</th>\n",
       "      <td>0.735714</td>\n",
       "      <td>0.020076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Roc_auc</th>\n",
       "      <td>0.690561</td>\n",
       "      <td>0.015281</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Mean        Se\n",
       "Accuracy_test   0.680000  0.012329\n",
       "Accuracy_train  0.925345  0.005584\n",
       "F1 Score        0.706865  0.012092\n",
       "Precision       0.698240  0.013460\n",
       "Recall          0.735714  0.020076\n",
       "Roc_auc         0.690561  0.015281"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Model2\n",
    "Model2=Model_results(clf,X,y,Cv_model)\n",
    "Model2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "390c5554-ccf3-490e-9e3e-7d53299bb3bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th>Method</th>\n",
       "      <th colspan=\"4\" halign=\"left\">DT</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model</th>\n",
       "      <th colspan=\"2\" halign=\"left\">Model 1</th>\n",
       "      <th colspan=\"2\" halign=\"left\">Model 2</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Values</th>\n",
       "      <th>Mean</th>\n",
       "      <th>Se</th>\n",
       "      <th>Mean</th>\n",
       "      <th>Se</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Accuracy_test</th>\n",
       "      <td>0.629333</td>\n",
       "      <td>0.015032</td>\n",
       "      <td>0.680000</td>\n",
       "      <td>0.012329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Accuracy_train</th>\n",
       "      <td>0.729981</td>\n",
       "      <td>0.004700</td>\n",
       "      <td>0.925345</td>\n",
       "      <td>0.005584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1 Score</th>\n",
       "      <td>0.697627</td>\n",
       "      <td>0.013235</td>\n",
       "      <td>0.706865</td>\n",
       "      <td>0.012092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Precision</th>\n",
       "      <td>0.620752</td>\n",
       "      <td>0.011961</td>\n",
       "      <td>0.698240</td>\n",
       "      <td>0.013460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recall</th>\n",
       "      <td>0.811071</td>\n",
       "      <td>0.020893</td>\n",
       "      <td>0.735714</td>\n",
       "      <td>0.020076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Roc_auc</th>\n",
       "      <td>0.664796</td>\n",
       "      <td>0.020543</td>\n",
       "      <td>0.690561</td>\n",
       "      <td>0.015281</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Method                DT                              \n",
       "Model            Model 1             Model 2          \n",
       "Values              Mean        Se      Mean        Se\n",
       "Accuracy_test   0.629333  0.015032  0.680000  0.012329\n",
       "Accuracy_train  0.729981  0.004700  0.925345  0.005584\n",
       "F1 Score        0.697627  0.013235  0.706865  0.012092\n",
       "Precision       0.620752  0.011961  0.698240  0.013460\n",
       "Recall          0.811071  0.020893  0.735714  0.020076\n",
       "Roc_auc         0.664796  0.020543  0.690561  0.015281"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Saving the data of model performance\n",
    "Model_data=pd.concat([Model1,Model2],axis=1)\n",
    "Model_data.columns = [['DT']*4,['Model 1','Model 1', 'Model 2','Model 2'], ['Mean', 'Se', 'Mean', 'Se']]  \n",
    "Model_data.columns.names=['Method','Model','Values']\n",
    "Model_data.to_csv(\"./Results/DT_model_mlrem_data.csv\",sep=',')\n",
    "Model_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff716df6-f48a-4890-819b-cca04c92e57c",
   "metadata": {},
   "source": [
    "## 2.2 LR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "96eeb954-8032-43c2-afb2-e47f675b2d15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mean</th>\n",
       "      <th>Se</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Accuracy_test</th>\n",
       "      <td>0.680000</td>\n",
       "      <td>0.012329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Accuracy_train</th>\n",
       "      <td>0.925345</td>\n",
       "      <td>0.005584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1 Score</th>\n",
       "      <td>0.706865</td>\n",
       "      <td>0.012092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Precision</th>\n",
       "      <td>0.698240</td>\n",
       "      <td>0.013460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recall</th>\n",
       "      <td>0.735714</td>\n",
       "      <td>0.020076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Roc_auc</th>\n",
       "      <td>0.690561</td>\n",
       "      <td>0.015281</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Mean        Se\n",
       "Accuracy_test   0.680000  0.012329\n",
       "Accuracy_train  0.925345  0.005584\n",
       "F1 Score        0.706865  0.012092\n",
       "Precision       0.698240  0.013460\n",
       "Recall          0.735714  0.020076\n",
       "Roc_auc         0.690561  0.015281"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Model1\n",
    "Model1_clf=clf\n",
    "#Model1\n",
    "Model1=Model_results(Model1_clf,X,y,Cv_model)\n",
    "Model1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "662dc3e0-7ca9-41f6-ad45-99db640a18b8",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2024-01-12 01:33:46,194]\u001b[0m A new study created in memory with name: no-name-e4ba7b5b-b8fd-4929-82c3-50137ca4832b\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:33:46,218]\u001b[0m Trial 0 finished with value: 0.6096190476190476 and parameters: {'logreg_c': 0.3177840006884068, 'l1_ratio': 0.7482920440979423, 'max_iter': 100}. Best is trial 0 with value: 0.6096190476190476.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:33:46,239]\u001b[0m Trial 1 finished with value: 0.6195238095238095 and parameters: {'logreg_c': 0.0651621545821569, 'l1_ratio': 0.23208030173540176, 'max_iter': 275}. Best is trial 1 with value: 0.6195238095238095.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:33:46,262]\u001b[0m Trial 2 finished with value: 0.570095238095238 and parameters: {'logreg_c': 0.013108749615263334, 'l1_ratio': 0.411004654338743, 'max_iter': 854}. Best is trial 1 with value: 0.6195238095238095.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:33:46,284]\u001b[0m Trial 3 finished with value: 0.6294285714285714 and parameters: {'logreg_c': 1.7096232052870346, 'l1_ratio': 0.4772750629629653, 'max_iter': 1402}. Best is trial 3 with value: 0.6294285714285714.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:33:46,305]\u001b[0m Trial 4 finished with value: 0.574095238095238 and parameters: {'logreg_c': 0.016854407828169382, 'l1_ratio': 0.8903056927518509, 'max_iter': 152}. Best is trial 3 with value: 0.6294285714285714.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:33:46,328]\u001b[0m Trial 5 finished with value: 0.6167619047619047 and parameters: {'logreg_c': 10.539137268289434, 'l1_ratio': 0.4755743221304143, 'max_iter': 1162}. Best is trial 3 with value: 0.6294285714285714.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:33:46,351]\u001b[0m Trial 6 finished with value: 0.5672380952380952 and parameters: {'logreg_c': 0.006955392321661603, 'l1_ratio': 0.2782913401763909, 'max_iter': 1622}. Best is trial 3 with value: 0.6294285714285714.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:33:46,373]\u001b[0m Trial 7 finished with value: 0.6282857142857143 and parameters: {'logreg_c': 645.0144652189372, 'l1_ratio': 0.38208176034331853, 'max_iter': 1416}. Best is trial 3 with value: 0.6294285714285714.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:33:46,397]\u001b[0m Trial 8 finished with value: 0.6093333333333334 and parameters: {'logreg_c': 181.27374779133626, 'l1_ratio': 0.9051459971534626, 'max_iter': 261}. Best is trial 3 with value: 0.6294285714285714.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:33:46,418]\u001b[0m Trial 9 finished with value: 0.5601904761904761 and parameters: {'logreg_c': 0.001715255021408637, 'l1_ratio': 0.25284737760811204, 'max_iter': 1769}. Best is trial 3 with value: 0.6294285714285714.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:33:46,444]\u001b[0m Trial 10 finished with value: 0.6153333333333333 and parameters: {'logreg_c': 9.589685409552947, 'l1_ratio': 0.6553689413187243, 'max_iter': 845}. Best is trial 3 with value: 0.6294285714285714.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:33:46,469]\u001b[0m Trial 11 finished with value: 0.6268571428571428 and parameters: {'logreg_c': 843.2126062012233, 'l1_ratio': 0.5380831473609496, 'max_iter': 1376}. Best is trial 3 with value: 0.6294285714285714.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:33:46,493]\u001b[0m Trial 12 finished with value: 0.6167619047619047 and parameters: {'logreg_c': 7.624466107886496, 'l1_ratio': 0.378272352651409, 'max_iter': 1494}. Best is trial 3 with value: 0.6294285714285714.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:33:46,518]\u001b[0m Trial 13 finished with value: 0.6162857142857143 and parameters: {'logreg_c': 51.786339691986214, 'l1_ratio': 0.6316370562712422, 'max_iter': 1128}. Best is trial 3 with value: 0.6294285714285714.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:33:46,543]\u001b[0m Trial 14 finished with value: 0.627904761904762 and parameters: {'logreg_c': 0.8529452363532304, 'l1_ratio': 0.13738672304214128, 'max_iter': 1780}. Best is trial 3 with value: 0.6294285714285714.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:33:46,570]\u001b[0m Trial 15 finished with value: 0.6281904761904762 and parameters: {'logreg_c': 763.5588094994378, 'l1_ratio': 0.3689322680983461, 'max_iter': 1971}. Best is trial 3 with value: 0.6294285714285714.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:33:46,596]\u001b[0m Trial 16 finished with value: 0.6195238095238096 and parameters: {'logreg_c': 0.13707192890174966, 'l1_ratio': 0.5845266407991517, 'max_iter': 1309}. Best is trial 3 with value: 0.6294285714285714.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:33:46,623]\u001b[0m Trial 17 finished with value: 0.6120000000000001 and parameters: {'logreg_c': 76.37303329769077, 'l1_ratio': 0.7683639981317943, 'max_iter': 716}. Best is trial 3 with value: 0.6294285714285714.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:33:46,649]\u001b[0m Trial 18 finished with value: 0.6252380952380953 and parameters: {'logreg_c': 2.932001936719566, 'l1_ratio': 0.10084185856253824, 'max_iter': 553}. Best is trial 3 with value: 0.6294285714285714.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:33:46,674]\u001b[0m Trial 19 finished with value: 0.6307619047619046 and parameters: {'logreg_c': 1.3160447446956969, 'l1_ratio': 0.4671561613242705, 'max_iter': 1312}. Best is trial 19 with value: 0.6307619047619046.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:33:46,701]\u001b[0m Trial 20 finished with value: 0.6293333333333333 and parameters: {'logreg_c': 1.4651691779773963, 'l1_ratio': 0.4935134748265029, 'max_iter': 983}. Best is trial 19 with value: 0.6307619047619046.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:33:46,725]\u001b[0m Trial 21 finished with value: 0.6237142857142858 and parameters: {'logreg_c': 0.8287025892084571, 'l1_ratio': 0.5199862466969595, 'max_iter': 1054}. Best is trial 19 with value: 0.6307619047619046.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:33:46,751]\u001b[0m Trial 22 finished with value: 0.6238095238095238 and parameters: {'logreg_c': 3.1654611271505058, 'l1_ratio': 0.4597028916076701, 'max_iter': 1266}. Best is trial 19 with value: 0.6307619047619046.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:33:46,777]\u001b[0m Trial 23 finished with value: 0.6166666666666667 and parameters: {'logreg_c': 0.1535200845989714, 'l1_ratio': 0.6782814588832947, 'max_iter': 981}. Best is trial 19 with value: 0.6307619047619046.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:33:46,803]\u001b[0m Trial 24 finished with value: 0.6294285714285714 and parameters: {'logreg_c': 1.8873063599506599, 'l1_ratio': 0.326102166138698, 'max_iter': 1522}. Best is trial 19 with value: 0.6307619047619046.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:33:46,827]\u001b[0m Trial 25 finished with value: 0.6180952380952381 and parameters: {'logreg_c': 0.41516225975438653, 'l1_ratio': 0.2979284535359352, 'max_iter': 1547}. Best is trial 19 with value: 0.6307619047619046.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:33:46,853]\u001b[0m Trial 26 finished with value: 0.6191428571428571 and parameters: {'logreg_c': 17.953162228525414, 'l1_ratio': 0.31727555023219167, 'max_iter': 1687}. Best is trial 19 with value: 0.6307619047619046.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:33:46,878]\u001b[0m Trial 27 finished with value: 0.6266666666666666 and parameters: {'logreg_c': 2.602409837373429, 'l1_ratio': 0.19868034857393024, 'max_iter': 1919}. Best is trial 19 with value: 0.6307619047619046.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:33:46,905]\u001b[0m Trial 28 finished with value: 0.6195238095238095 and parameters: {'logreg_c': 0.07229078967635784, 'l1_ratio': 0.42868388614084174, 'max_iter': 1511}. Best is trial 19 with value: 0.6307619047619046.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:33:46,931]\u001b[0m Trial 29 finished with value: 0.6194285714285716 and parameters: {'logreg_c': 0.3860177138367054, 'l1_ratio': 0.8158505713189557, 'max_iter': 1211}. Best is trial 19 with value: 0.6307619047619046.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:33:46,956]\u001b[0m Trial 30 finished with value: 0.6168571428571429 and parameters: {'logreg_c': 4.8505444157280655, 'l1_ratio': 0.989090737470458, 'max_iter': 1389}. Best is trial 19 with value: 0.6307619047619046.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:33:46,984]\u001b[0m Trial 31 finished with value: 0.6293333333333334 and parameters: {'logreg_c': 1.2065391735314397, 'l1_ratio': 0.4963584342131737, 'max_iter': 1011}. Best is trial 19 with value: 0.6307619047619046.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:33:47,011]\u001b[0m Trial 32 finished with value: 0.6162857142857143 and parameters: {'logreg_c': 28.72272514710678, 'l1_ratio': 0.581199409657952, 'max_iter': 582}. Best is trial 19 with value: 0.6307619047619046.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:33:47,038]\u001b[0m Trial 33 finished with value: 0.6293333333333333 and parameters: {'logreg_c': 1.3696220900607625, 'l1_ratio': 0.42558482659301816, 'max_iter': 1297}. Best is trial 19 with value: 0.6307619047619046.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:33:47,063]\u001b[0m Trial 34 finished with value: 0.6067619047619047 and parameters: {'logreg_c': 0.2875637249472787, 'l1_ratio': 0.3482207466346646, 'max_iter': 1109}. Best is trial 19 with value: 0.6307619047619046.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:33:47,088]\u001b[0m Trial 35 finished with value: 0.6009523809523809 and parameters: {'logreg_c': 0.03576221722627603, 'l1_ratio': 0.5765441371212959, 'max_iter': 870}. Best is trial 19 with value: 0.6307619047619046.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:33:47,116]\u001b[0m Trial 36 finished with value: 0.6209523809523809 and parameters: {'logreg_c': 0.6626791637945557, 'l1_ratio': 0.20185400717777569, 'max_iter': 1676}. Best is trial 19 with value: 0.6307619047619046.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:33:47,140]\u001b[0m Trial 37 finished with value: 0.6294285714285714 and parameters: {'logreg_c': 1.9120072183363928, 'l1_ratio': 0.4733809188346099, 'max_iter': 1467}. Best is trial 19 with value: 0.6307619047619046.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:33:47,165]\u001b[0m Trial 38 finished with value: 0.6177142857142858 and parameters: {'logreg_c': 19.34210830669201, 'l1_ratio': 0.44990617999528343, 'max_iter': 1557}. Best is trial 19 with value: 0.6307619047619046.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:33:47,192]\u001b[0m Trial 39 finished with value: 0.6139047619047618 and parameters: {'logreg_c': 0.22059945415572177, 'l1_ratio': 0.3267785933880323, 'max_iter': 1424}. Best is trial 19 with value: 0.6307619047619046.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:33:47,219]\u001b[0m Trial 40 finished with value: 0.6139047619047618 and parameters: {'logreg_c': 5.702688279032213, 'l1_ratio': 0.706870700092175, 'max_iter': 1216}. Best is trial 19 with value: 0.6307619047619046.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:33:47,247]\u001b[0m Trial 41 finished with value: 0.6307619047619047 and parameters: {'logreg_c': 2.1083445203193767, 'l1_ratio': 0.5013573618384977, 'max_iter': 1814}. Best is trial 41 with value: 0.6307619047619047.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:33:47,273]\u001b[0m Trial 42 finished with value: 0.6294285714285714 and parameters: {'logreg_c': 1.8778046360697456, 'l1_ratio': 0.39812276354777576, 'max_iter': 1899}. Best is trial 41 with value: 0.6307619047619047.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:33:47,308]\u001b[0m Trial 43 finished with value: 0.6196190476190475 and parameters: {'logreg_c': 4.005595097886426, 'l1_ratio': 0.40683807642605113, 'max_iter': 1851}. Best is trial 41 with value: 0.6307619047619047.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:33:47,335]\u001b[0m Trial 44 finished with value: 0.6153333333333333 and parameters: {'logreg_c': 10.51995398501394, 'l1_ratio': 0.5242462748652383, 'max_iter': 1635}. Best is trial 41 with value: 0.6307619047619047.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:33:47,361]\u001b[0m Trial 45 finished with value: 0.6166666666666667 and parameters: {'logreg_c': 0.43649305773415953, 'l1_ratio': 0.62669435281089, 'max_iter': 1803}. Best is trial 41 with value: 0.6307619047619047.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:33:47,387]\u001b[0m Trial 46 finished with value: 0.6195238095238095 and parameters: {'logreg_c': 0.07187646725784044, 'l1_ratio': 0.281967448657918, 'max_iter': 1917}. Best is trial 41 with value: 0.6307619047619047.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:33:47,414]\u001b[0m Trial 47 finished with value: 0.627904761904762 and parameters: {'logreg_c': 2.0310237754182316, 'l1_ratio': 0.39414395429506727, 'max_iter': 1726}. Best is trial 41 with value: 0.6307619047619047.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:33:47,441]\u001b[0m Trial 48 finished with value: 0.620952380952381 and parameters: {'logreg_c': 0.6082079556285477, 'l1_ratio': 0.5660058818783812, 'max_iter': 1618}. Best is trial 41 with value: 0.6307619047619047.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:33:47,466]\u001b[0m Trial 49 finished with value: 0.6108571428571429 and parameters: {'logreg_c': 240.59569344033093, 'l1_ratio': 0.24451803344912826, 'max_iter': 1985}. Best is trial 41 with value: 0.6307619047619047.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:33:47,492]\u001b[0m Trial 50 finished with value: 0.5643809523809523 and parameters: {'logreg_c': 0.003166482546125131, 'l1_ratio': 0.4598078240788601, 'max_iter': 1365}. Best is trial 41 with value: 0.6307619047619047.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:33:47,518]\u001b[0m Trial 51 finished with value: 0.6167619047619047 and parameters: {'logreg_c': 7.943065063340901, 'l1_ratio': 0.3551537545361903, 'max_iter': 1474}. Best is trial 41 with value: 0.6307619047619047.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:33:47,545]\u001b[0m Trial 52 finished with value: 0.6294285714285714 and parameters: {'logreg_c': 1.8518389019522237, 'l1_ratio': 0.49224974644280434, 'max_iter': 1844}. Best is trial 41 with value: 0.6307619047619047.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:33:47,571]\u001b[0m Trial 53 finished with value: 0.627904761904762 and parameters: {'logreg_c': 1.3572714107165977, 'l1_ratio': 0.49277895678099476, 'max_iter': 1458}. Best is trial 41 with value: 0.6307619047619047.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:33:47,598]\u001b[0m Trial 54 finished with value: 0.6210476190476191 and parameters: {'logreg_c': 3.7115076962149858, 'l1_ratio': 0.6102000361609092, 'max_iter': 1590}. Best is trial 41 with value: 0.6307619047619047.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:33:47,625]\u001b[0m Trial 55 finished with value: 0.6264761904761904 and parameters: {'logreg_c': 0.8911994905571492, 'l1_ratio': 0.3993140649769618, 'max_iter': 1883}. Best is trial 41 with value: 0.6307619047619047.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:33:47,651]\u001b[0m Trial 56 finished with value: 0.6294285714285714 and parameters: {'logreg_c': 2.2506604255090674, 'l1_ratio': 0.5420213510321465, 'max_iter': 1719}. Best is trial 41 with value: 0.6307619047619047.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:33:47,678]\u001b[0m Trial 57 finished with value: 0.6191428571428571 and parameters: {'logreg_c': 19.197800367683012, 'l1_ratio': 0.4652438210429772, 'max_iter': 1762}. Best is trial 41 with value: 0.6307619047619047.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:33:47,705]\u001b[0m Trial 58 finished with value: 0.6195238095238096 and parameters: {'logreg_c': 0.17391612699617703, 'l1_ratio': 0.5464710550797393, 'max_iter': 1365}. Best is trial 41 with value: 0.6307619047619047.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:33:47,730]\u001b[0m Trial 59 finished with value: 0.613904761904762 and parameters: {'logreg_c': 6.575270743844423, 'l1_ratio': 0.5466415698694522, 'max_iter': 1686}. Best is trial 41 with value: 0.6307619047619047.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:33:47,758]\u001b[0m Trial 60 finished with value: 0.6163809523809525 and parameters: {'logreg_c': 54.54049186437329, 'l1_ratio': 0.4325278919043865, 'max_iter': 1996}. Best is trial 41 with value: 0.6307619047619047.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:33:47,784]\u001b[0m Trial 61 finished with value: 0.6307619047619047 and parameters: {'logreg_c': 2.096362271932597, 'l1_ratio': 0.5160078527964562, 'max_iter': 1556}. Best is trial 41 with value: 0.6307619047619047.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:33:47,811]\u001b[0m Trial 62 finished with value: 0.6266666666666666 and parameters: {'logreg_c': 2.538893199184801, 'l1_ratio': 0.504806699044337, 'max_iter': 1744}. Best is trial 41 with value: 0.6307619047619047.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:33:47,838]\u001b[0m Trial 63 finished with value: 0.6308571428571428 and parameters: {'logreg_c': 1.6491171164828378, 'l1_ratio': 0.37983614680640526, 'max_iter': 1831}. Best is trial 63 with value: 0.6308571428571428.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:33:47,865]\u001b[0m Trial 64 finished with value: 0.6207619047619048 and parameters: {'logreg_c': 0.5680946103743453, 'l1_ratio': 0.6124516385720995, 'max_iter': 1804}. Best is trial 63 with value: 0.6308571428571428.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:33:47,891]\u001b[0m Trial 65 finished with value: 0.6194285714285714 and parameters: {'logreg_c': 12.835933863876129, 'l1_ratio': 0.3307896654069705, 'max_iter': 1545}. Best is trial 63 with value: 0.6308571428571428.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:33:47,916]\u001b[0m Trial 66 finished with value: 0.6167619047619047 and parameters: {'logreg_c': 4.284809135627299, 'l1_ratio': 0.49198373373937326, 'max_iter': 1318}. Best is trial 63 with value: 0.6308571428571428.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:33:47,944]\u001b[0m Trial 67 finished with value: 0.6307619047619047 and parameters: {'logreg_c': 0.9489377554918126, 'l1_ratio': 0.37627684812340034, 'max_iter': 1225}. Best is trial 63 with value: 0.6308571428571428.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:33:47,968]\u001b[0m Trial 68 finished with value: 0.6292380952380953 and parameters: {'logreg_c': 1.0538708885678392, 'l1_ratio': 0.6781276320502876, 'max_iter': 1209}. Best is trial 63 with value: 0.6308571428571428.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:33:47,993]\u001b[0m Trial 69 finished with value: 0.6067619047619047 and parameters: {'logreg_c': 0.29155306833483985, 'l1_ratio': 0.36263117743566936, 'max_iter': 1660}. Best is trial 63 with value: 0.6308571428571428.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:33:48,018]\u001b[0m Trial 70 finished with value: 0.6251428571428571 and parameters: {'logreg_c': 0.8333203040302765, 'l1_ratio': 0.43197726798313846, 'max_iter': 1169}. Best is trial 63 with value: 0.6308571428571428.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:33:48,045]\u001b[0m Trial 71 finished with value: 0.6224761904761905 and parameters: {'logreg_c': 3.2825957984619203, 'l1_ratio': 0.52930545567372, 'max_iter': 1902}. Best is trial 63 with value: 0.6308571428571428.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:33:48,071]\u001b[0m Trial 72 finished with value: 0.6294285714285714 and parameters: {'logreg_c': 1.707563442346071, 'l1_ratio': 0.2692265008939825, 'max_iter': 1804}. Best is trial 63 with value: 0.6308571428571428.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:33:48,098]\u001b[0m Trial 73 finished with value: 0.627904761904762 and parameters: {'logreg_c': 1.244565542128993, 'l1_ratio': 0.22628313375302067, 'max_iter': 1283}. Best is trial 63 with value: 0.6308571428571428.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:33:48,124]\u001b[0m Trial 74 finished with value: 0.617904761904762 and parameters: {'logreg_c': 0.5423233219501331, 'l1_ratio': 0.37441966805804505, 'max_iter': 1429}. Best is trial 63 with value: 0.6308571428571428.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:33:48,150]\u001b[0m Trial 75 finished with value: 0.6238095238095238 and parameters: {'logreg_c': 2.6428530082211377, 'l1_ratio': 0.2853040906189891, 'max_iter': 1736}. Best is trial 63 with value: 0.6308571428571428.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:33:48,175]\u001b[0m Trial 76 finished with value: 0.6209523809523809 and parameters: {'logreg_c': 0.10939627711828923, 'l1_ratio': 0.4735312789321377, 'max_iter': 1846}. Best is trial 63 with value: 0.6308571428571428.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:33:48,201]\u001b[0m Trial 77 finished with value: 0.6264761904761904 and parameters: {'logreg_c': 0.8745518604877525, 'l1_ratio': 0.442590140651025, 'max_iter': 1078}. Best is trial 63 with value: 0.6308571428571428.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:33:48,227]\u001b[0m Trial 78 finished with value: 0.6154285714285713 and parameters: {'logreg_c': 5.330321809025692, 'l1_ratio': 0.4137370416803211, 'max_iter': 1943}. Best is trial 63 with value: 0.6308571428571428.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:33:48,254]\u001b[0m Trial 79 finished with value: 0.6321904761904762 and parameters: {'logreg_c': 1.5684558195868687, 'l1_ratio': 0.51063148634346, 'max_iter': 1863}. Best is trial 79 with value: 0.6321904761904762.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:33:48,280]\u001b[0m Trial 80 finished with value: 0.6194285714285716 and parameters: {'logreg_c': 0.37976816840820854, 'l1_ratio': 0.34025799616210806, 'max_iter': 1579}. Best is trial 79 with value: 0.6321904761904762.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:33:48,304]\u001b[0m Trial 81 finished with value: 0.6308571428571428 and parameters: {'logreg_c': 1.5835184104709785, 'l1_ratio': 0.5016015552438089, 'max_iter': 1871}. Best is trial 79 with value: 0.6321904761904762.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:33:48,327]\u001b[0m Trial 82 finished with value: 0.6308571428571428 and parameters: {'logreg_c': 1.6594874201724938, 'l1_ratio': 0.3063290111973975, 'max_iter': 1960}. Best is trial 79 with value: 0.6321904761904762.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:33:48,352]\u001b[0m Trial 83 finished with value: 0.6307619047619046 and parameters: {'logreg_c': 1.343979148614231, 'l1_ratio': 0.5176219420701993, 'max_iter': 1967}. Best is trial 79 with value: 0.6321904761904762.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:33:48,376]\u001b[0m Trial 84 finished with value: 0.6223809523809524 and parameters: {'logreg_c': 0.7187697779331849, 'l1_ratio': 0.5672396458148798, 'max_iter': 1939}. Best is trial 79 with value: 0.6321904761904762.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:33:48,402]\u001b[0m Trial 85 finished with value: 0.6293333333333334 and parameters: {'logreg_c': 1.2029830464414577, 'l1_ratio': 0.5185295899090988, 'max_iter': 1859}. Best is trial 79 with value: 0.6321904761904762.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:33:48,427]\u001b[0m Trial 86 finished with value: 0.6266666666666666 and parameters: {'logreg_c': 2.9061910777908393, 'l1_ratio': 0.3132992841051993, 'max_iter': 1949}. Best is trial 79 with value: 0.6321904761904762.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:33:48,450]\u001b[0m Trial 87 finished with value: 0.6096190476190476 and parameters: {'logreg_c': 0.2725593715364528, 'l1_ratio': 0.3860887328318272, 'max_iter': 1796}. Best is trial 79 with value: 0.6321904761904762.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:33:48,475]\u001b[0m Trial 88 finished with value: 0.6165714285714287 and parameters: {'logreg_c': 0.4912865251268892, 'l1_ratio': 0.5945013797755109, 'max_iter': 2000}. Best is trial 79 with value: 0.6321904761904762.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:33:48,499]\u001b[0m Trial 89 finished with value: 0.6153333333333333 and parameters: {'logreg_c': 8.240833064906228, 'l1_ratio': 0.5139563256443173, 'max_iter': 162}. Best is trial 79 with value: 0.6321904761904762.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:33:48,523]\u001b[0m Trial 90 finished with value: 0.6307619047619047 and parameters: {'logreg_c': 1.4731369609639198, 'l1_ratio': 0.4554672724433561, 'max_iter': 1883}. Best is trial 79 with value: 0.6321904761904762.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:33:48,546]\u001b[0m Trial 91 finished with value: 0.627904761904762 and parameters: {'logreg_c': 1.2362306827283187, 'l1_ratio': 0.45224194854848165, 'max_iter': 1869}. Best is trial 79 with value: 0.6321904761904762.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:33:48,572]\u001b[0m Trial 92 finished with value: 0.628 and parameters: {'logreg_c': 1.8218108234980488, 'l1_ratio': 0.47339867982647943, 'max_iter': 1823}. Best is trial 79 with value: 0.6321904761904762.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:33:48,595]\u001b[0m Trial 93 finished with value: 0.6167619047619047 and parameters: {'logreg_c': 4.271962308570505, 'l1_ratio': 0.5609556013046808, 'max_iter': 1914}. Best is trial 79 with value: 0.6321904761904762.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:33:48,618]\u001b[0m Trial 94 finished with value: 0.6307619047619047 and parameters: {'logreg_c': 0.9774627856036887, 'l1_ratio': 0.42302130014987804, 'max_iter': 1700}. Best is trial 79 with value: 0.6321904761904762.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:33:48,643]\u001b[0m Trial 95 finished with value: 0.6222857142857143 and parameters: {'logreg_c': 0.8082919920657609, 'l1_ratio': 0.41564559443826843, 'max_iter': 1765}. Best is trial 79 with value: 0.6321904761904762.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:33:48,667]\u001b[0m Trial 96 finished with value: 0.6308571428571428 and parameters: {'logreg_c': 1.576347619069216, 'l1_ratio': 0.37665937232889934, 'max_iter': 1705}. Best is trial 79 with value: 0.6321904761904762.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:33:48,691]\u001b[0m Trial 97 finished with value: 0.6252380952380953 and parameters: {'logreg_c': 3.119735317205072, 'l1_ratio': 0.3724348739191003, 'max_iter': 1701}. Best is trial 79 with value: 0.6321904761904762.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:33:48,715]\u001b[0m Trial 98 finished with value: 0.613904761904762 and parameters: {'logreg_c': 6.204154164274675, 'l1_ratio': 0.3480031298152046, 'max_iter': 1631}. Best is trial 79 with value: 0.6321904761904762.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:33:48,739]\u001b[0m Trial 99 finished with value: 0.6195238095238096 and parameters: {'logreg_c': 0.6240590821298014, 'l1_ratio': 0.39483273607916664, 'max_iter': 1765}. Best is trial 79 with value: 0.6321904761904762.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "#Tuning hyperparameters\n",
    "#Step 1. Define an objective function to be maximized.\n",
    "def objective(trial):\n",
    "    logreg_c = trial.suggest_float(\"logreg_c\", 1e-3,  1e3, log=True)\n",
    "    l1_ratio = trial.suggest_float(\"l1_ratio\",0.1,1,log=False) \n",
    "    #penalty = trial.suggest_categorical(\"penalty\",['l1','l2'])\n",
    "    max_iter = trial.suggest_int(\"max_iter\", 100,2000)\n",
    "    model =LogisticRegression(C=logreg_c,\n",
    "                              max_iter=max_iter,\n",
    "                              l1_ratio=l1_ratio,\n",
    "                              solver='liblinear',random_state=1)\n",
    "    \n",
    "# Step 2: Scoring method:\n",
    "    score = model_selection.cross_val_score(model, X, y, n_jobs=8, scoring=\"accuracy\",cv=Cv_optuna)\n",
    "    accuracy = score.mean()\n",
    "    return accuracy\n",
    "\n",
    "# Step 3: Running it\n",
    "study = optuna.create_study(direction=\"maximize\",sampler=optuna.samplers.TPESampler(seed=1))\n",
    "study.optimize(objective, n_trials=100, show_progress_bar=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "36a76651-b007-4715-a58f-8776deab4b8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best parameters are : \n",
      "{'logreg_c': 1.5684558195868687, 'l1_ratio': 0.51063148634346, 'max_iter': 1863}\n"
     ]
    }
   ],
   "source": [
    "# Getting the best parameters:\n",
    "print(f\"The best parameters are : \\n{study.best_params}\")\n",
    "# Setting the best model\n",
    "clf=LogisticRegression(C=study.best_params['logreg_c'],\n",
    "                              max_iter=study.best_params['max_iter'],\n",
    "                              l1_ratio=study.best_params['l1_ratio'],\n",
    "                              solver='liblinear',\n",
    "                              random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "b3ae0d1b-badc-4865-802b-396e3ee1b6cf",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mean</th>\n",
       "      <th>Se</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Accuracy_test</th>\n",
       "      <td>0.632190</td>\n",
       "      <td>0.014648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Accuracy_train</th>\n",
       "      <td>0.735909</td>\n",
       "      <td>0.004541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1 Score</th>\n",
       "      <td>0.694496</td>\n",
       "      <td>0.013341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Precision</th>\n",
       "      <td>0.627650</td>\n",
       "      <td>0.012121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recall</th>\n",
       "      <td>0.794643</td>\n",
       "      <td>0.021058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Roc_auc</th>\n",
       "      <td>0.673325</td>\n",
       "      <td>0.020325</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Mean        Se\n",
       "Accuracy_test   0.632190  0.014648\n",
       "Accuracy_train  0.735909  0.004541\n",
       "F1 Score        0.694496  0.013341\n",
       "Precision       0.627650  0.012121\n",
       "Recall          0.794643  0.021058\n",
       "Roc_auc         0.673325  0.020325"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Model2\n",
    "Model2=Model_results(clf,X,y,Cv_model)\n",
    "Model2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "a5007e9c-21fb-4007-bc2e-d5875dabe240",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th>Method</th>\n",
       "      <th colspan=\"4\" halign=\"left\">LR</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model</th>\n",
       "      <th colspan=\"2\" halign=\"left\">Model 1</th>\n",
       "      <th colspan=\"2\" halign=\"left\">Model 2</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Values</th>\n",
       "      <th>Mean</th>\n",
       "      <th>Se</th>\n",
       "      <th>Mean</th>\n",
       "      <th>Se</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Accuracy_test</th>\n",
       "      <td>0.680000</td>\n",
       "      <td>0.012329</td>\n",
       "      <td>0.632190</td>\n",
       "      <td>0.014648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Accuracy_train</th>\n",
       "      <td>0.925345</td>\n",
       "      <td>0.005584</td>\n",
       "      <td>0.735909</td>\n",
       "      <td>0.004541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1 Score</th>\n",
       "      <td>0.706865</td>\n",
       "      <td>0.012092</td>\n",
       "      <td>0.694496</td>\n",
       "      <td>0.013341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Precision</th>\n",
       "      <td>0.698240</td>\n",
       "      <td>0.013460</td>\n",
       "      <td>0.627650</td>\n",
       "      <td>0.012121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recall</th>\n",
       "      <td>0.735714</td>\n",
       "      <td>0.020076</td>\n",
       "      <td>0.794643</td>\n",
       "      <td>0.021058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Roc_auc</th>\n",
       "      <td>0.690561</td>\n",
       "      <td>0.015281</td>\n",
       "      <td>0.673325</td>\n",
       "      <td>0.020325</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Method                LR                              \n",
       "Model            Model 1             Model 2          \n",
       "Values              Mean        Se      Mean        Se\n",
       "Accuracy_test   0.680000  0.012329  0.632190  0.014648\n",
       "Accuracy_train  0.925345  0.005584  0.735909  0.004541\n",
       "F1 Score        0.706865  0.012092  0.694496  0.013341\n",
       "Precision       0.698240  0.013460  0.627650  0.012121\n",
       "Recall          0.735714  0.020076  0.794643  0.021058\n",
       "Roc_auc         0.690561  0.015281  0.673325  0.020325"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Saving the data of model performance\n",
    "Model_data=pd.concat([Model1,Model2],axis=1)\n",
    "Model_data.columns = [['LR']*4,['Model 1','Model 1', 'Model 2','Model 2'], ['Mean', 'Se', 'Mean', 'Se']]  \n",
    "Model_data.columns.names=['Method','Model','Values']\n",
    "Model_data.to_csv(\"./Results/LR_model_mlrem_data.csv\",sep=',')\n",
    "Model_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "892cd0c1-3914-4d08-a63a-550ffd5f60fb",
   "metadata": {},
   "source": [
    "## 2.3 RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "570a3fc5-5ce1-4bd8-a18a-b9209126a44e",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf=RandomForestClassifier(random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "4448a0ec-3f59-45ad-be0b-3713b3c0072b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mean</th>\n",
       "      <th>Se</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Accuracy_test</th>\n",
       "      <td>0.676381</td>\n",
       "      <td>0.014691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Accuracy_train</th>\n",
       "      <td>0.978164</td>\n",
       "      <td>0.001539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1 Score</th>\n",
       "      <td>0.711877</td>\n",
       "      <td>0.013423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Precision</th>\n",
       "      <td>0.688878</td>\n",
       "      <td>0.014746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recall</th>\n",
       "      <td>0.757857</td>\n",
       "      <td>0.020561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Roc_auc</th>\n",
       "      <td>0.756424</td>\n",
       "      <td>0.017012</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Mean        Se\n",
       "Accuracy_test   0.676381  0.014691\n",
       "Accuracy_train  0.978164  0.001539\n",
       "F1 Score        0.711877  0.013423\n",
       "Precision       0.688878  0.014746\n",
       "Recall          0.757857  0.020561\n",
       "Roc_auc         0.756424  0.017012"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Model1\n",
    "Model1_clf=clf\n",
    "#Model1\n",
    "Model1=Model_results(Model1_clf,X,y,Cv_model)\n",
    "Model1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "d0f9ce84-3537-484b-9862-bf7cefca94b8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2024-01-12 01:35:16,075]\u001b[0m A new study created in memory with name: no-name-0e368382-34a5-42fd-91ba-b1b1a0a8e3bf\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:35:19,314]\u001b[0m Trial 0 finished with value: 0.5352380952380952 and parameters: {'n_estimators': 594, 'max_depth': 16, 'max_features': 20, 'min_impurity_decrease': 2.724415914984484}. Best is trial 0 with value: 0.5352380952380952.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:35:21,908]\u001b[0m Trial 1 finished with value: 0.5352380952380952 and parameters: {'n_estimators': 481, 'max_depth': 15, 'max_features': 16, 'min_impurity_decrease': 4.4588650039103985}. Best is trial 0 with value: 0.5352380952380952.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:35:27,120]\u001b[0m Trial 2 finished with value: 0.5352380952380952 and parameters: {'n_estimators': 968, 'max_depth': 11, 'max_features': 25, 'min_impurity_decrease': 2.644474598764522}. Best is trial 0 with value: 0.5352380952380952.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:35:30,335]\u001b[0m Trial 3 finished with value: 0.5352380952380952 and parameters: {'n_estimators': 611, 'max_depth': 19, 'max_features': 6, 'min_impurity_decrease': 0.43564649850770354}. Best is trial 0 with value: 0.5352380952380952.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:35:31,006]\u001b[0m Trial 4 finished with value: 0.5352380952380952 and parameters: {'n_estimators': 118, 'max_depth': 18, 'max_features': 25, 'min_impurity_decrease': 4.3500607412340955}. Best is trial 0 with value: 0.5352380952380952.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:35:36,134]\u001b[0m Trial 5 finished with value: 0.5352380952380952 and parameters: {'n_estimators': 981, 'max_depth': 17, 'max_features': 16, 'min_impurity_decrease': 3.902645881432277}. Best is trial 0 with value: 0.5352380952380952.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:35:37,261]\u001b[0m Trial 6 finished with value: 0.5352380952380952 and parameters: {'n_estimators': 206, 'max_depth': 15, 'max_features': 8, 'min_impurity_decrease': 4.7233445852479194}. Best is trial 0 with value: 0.5352380952380952.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:35:40,255]\u001b[0m Trial 7 finished with value: 0.5352380952380952 and parameters: {'n_estimators': 570, 'max_depth': 11, 'max_features': 11, 'min_impurity_decrease': 3.871168447171083}. Best is trial 0 with value: 0.5352380952380952.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:35:42,854]\u001b[0m Trial 8 finished with value: 0.5352380952380952 and parameters: {'n_estimators': 510, 'max_depth': 14, 'max_features': 5, 'min_impurity_decrease': 3.0881774853793855}. Best is trial 0 with value: 0.5352380952380952.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:35:46,294]\u001b[0m Trial 9 finished with value: 0.5352380952380952 and parameters: {'n_estimators': 651, 'max_depth': 14, 'max_features': 29, 'min_impurity_decrease': 3.409101495517417}. Best is trial 0 with value: 0.5352380952380952.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:35:50,414]\u001b[0m Trial 10 finished with value: 0.5352380952380952 and parameters: {'n_estimators': 790, 'max_depth': 7, 'max_features': 21, 'min_impurity_decrease': 1.5046577569438309}. Best is trial 0 with value: 0.5352380952380952.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:35:52,562]\u001b[0m Trial 11 finished with value: 0.5352380952380952 and parameters: {'n_estimators': 397, 'max_depth': 20, 'max_features': 16, 'min_impurity_decrease': 1.9887909510549393}. Best is trial 0 with value: 0.5352380952380952.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:35:54,439]\u001b[0m Trial 12 finished with value: 0.5352380952380952 and parameters: {'n_estimators': 353, 'max_depth': 16, 'max_features': 20, 'min_impurity_decrease': 0.7029374955194359}. Best is trial 0 with value: 0.5352380952380952.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:35:56,713]\u001b[0m Trial 13 finished with value: 0.5352380952380952 and parameters: {'n_estimators': 411, 'max_depth': 12, 'max_features': 12, 'min_impurity_decrease': 4.931175650908394}. Best is trial 0 with value: 0.5352380952380952.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:36:00,636]\u001b[0m Trial 14 finished with value: 0.5352380952380952 and parameters: {'n_estimators': 743, 'max_depth': 7, 'max_features': 19, 'min_impurity_decrease': 1.5253121430442067}. Best is trial 0 with value: 0.5352380952380952.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:36:04,681]\u001b[0m Trial 15 finished with value: 0.5352380952380952 and parameters: {'n_estimators': 757, 'max_depth': 13, 'max_features': 12, 'min_impurity_decrease': 2.668111844473928}. Best is trial 0 with value: 0.5352380952380952.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:36:06,269]\u001b[0m Trial 16 finished with value: 0.5352380952380952 and parameters: {'n_estimators': 286, 'max_depth': 9, 'max_features': 24, 'min_impurity_decrease': 3.4814210246729473}. Best is trial 0 with value: 0.5352380952380952.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:36:10,648]\u001b[0m Trial 17 finished with value: 0.5352380952380952 and parameters: {'n_estimators': 807, 'max_depth': 5, 'max_features': 19, 'min_impurity_decrease': 1.4307627258174422}. Best is trial 0 with value: 0.5352380952380952.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:36:14,484]\u001b[0m Trial 18 finished with value: 0.5352380952380952 and parameters: {'n_estimators': 714, 'max_depth': 13, 'max_features': 12, 'min_impurity_decrease': 2.574069984147719}. Best is trial 0 with value: 0.5352380952380952.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:36:16,040]\u001b[0m Trial 19 finished with value: 0.5352380952380952 and parameters: {'n_estimators': 291, 'max_depth': 8, 'max_features': 24, 'min_impurity_decrease': 3.3144569973486893}. Best is trial 0 with value: 0.5352380952380952.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:36:20,679]\u001b[0m Trial 20 finished with value: 0.5352380952380952 and parameters: {'n_estimators': 871, 'max_depth': 5, 'max_features': 29, 'min_impurity_decrease': 1.0528796896599464}. Best is trial 0 with value: 0.5352380952380952.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:36:24,313]\u001b[0m Trial 21 finished with value: 0.5352380952380952 and parameters: {'n_estimators': 670, 'max_depth': 10, 'max_features': 14, 'min_impurity_decrease': 2.1272690676619246}. Best is trial 0 with value: 0.5352380952380952.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:36:27,036]\u001b[0m Trial 22 finished with value: 0.5352380952380952 and parameters: {'n_estimators': 502, 'max_depth': 9, 'max_features': 23, 'min_impurity_decrease': 3.0212243946132653}. Best is trial 0 with value: 0.5352380952380952.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:36:31,734]\u001b[0m Trial 23 finished with value: 0.5352380952380952 and parameters: {'n_estimators': 871, 'max_depth': 6, 'max_features': 30, 'min_impurity_decrease': 0.8924229302747374}. Best is trial 0 with value: 0.5352380952380952.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:36:35,612]\u001b[0m Trial 24 finished with value: 0.5352380952380952 and parameters: {'n_estimators': 673, 'max_depth': 11, 'max_features': 28, 'min_impurity_decrease': 2.183958261339378}. Best is trial 0 with value: 0.5352380952380952.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:36:41,146]\u001b[0m Trial 25 finished with value: 0.5352380952380952 and parameters: {'n_estimators': 548, 'max_depth': 9, 'max_features': 22, 'min_impurity_decrease': 2.0762642939740097}. Best is trial 0 with value: 0.5352380952380952.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:36:51,062]\u001b[0m Trial 26 finished with value: 0.6323809523809524 and parameters: {'n_estimators': 859, 'max_depth': 7, 'max_features': 27, 'min_impurity_decrease': 0.05016303754931206}. Best is trial 26 with value: 0.6323809523809524.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:37:01,691]\u001b[0m Trial 27 finished with value: 0.672 and parameters: {'n_estimators': 889, 'max_depth': 6, 'max_features': 27, 'min_impurity_decrease': 0.008573433661244079}. Best is trial 27 with value: 0.672.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:37:11,727]\u001b[0m Trial 28 finished with value: 0.6322857142857143 and parameters: {'n_estimators': 901, 'max_depth': 7, 'max_features': 27, 'min_impurity_decrease': 0.04449057244021093}. Best is trial 27 with value: 0.672.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:37:22,093]\u001b[0m Trial 29 finished with value: 0.6254285714285714 and parameters: {'n_estimators': 918, 'max_depth': 7, 'max_features': 27, 'min_impurity_decrease': 0.06568686852538762}. Best is trial 27 with value: 0.672.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:37:30,555]\u001b[0m Trial 30 finished with value: 0.5352380952380952 and parameters: {'n_estimators': 855, 'max_depth': 6, 'max_features': 26, 'min_impurity_decrease': 0.3179551086113602}. Best is trial 27 with value: 0.672.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:37:38,485]\u001b[0m Trial 31 finished with value: 0.597047619047619 and parameters: {'n_estimators': 937, 'max_depth': 7, 'max_features': 27, 'min_impurity_decrease': 0.18490386200494244}. Best is trial 27 with value: 0.672.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:37:46,299]\u001b[0m Trial 32 finished with value: 0.6747619047619048 and parameters: {'n_estimators': 913, 'max_depth': 8, 'max_features': 27, 'min_impurity_decrease': 0.004905793398417582}. Best is trial 32 with value: 0.6747619047619048.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:37:56,619]\u001b[0m Trial 33 finished with value: 0.6761904761904762 and parameters: {'n_estimators': 917, 'max_depth': 6, 'max_features': 30, 'min_impurity_decrease': 0.0020653183224317627}. Best is trial 33 with value: 0.6761904761904762.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:38:05,942]\u001b[0m Trial 34 finished with value: 0.5352380952380952 and parameters: {'n_estimators': 989, 'max_depth': 5, 'max_features': 29, 'min_impurity_decrease': 0.6299600959488392}. Best is trial 33 with value: 0.6761904761904762.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:38:13,475]\u001b[0m Trial 35 finished with value: 0.5352380952380952 and parameters: {'n_estimators': 815, 'max_depth': 8, 'max_features': 30, 'min_impurity_decrease': 0.4674586648441808}. Best is trial 33 with value: 0.6761904761904762.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:38:23,053]\u001b[0m Trial 36 finished with value: 0.5352380952380952 and parameters: {'n_estimators': 961, 'max_depth': 6, 'max_features': 25, 'min_impurity_decrease': 1.1357603095945366}. Best is trial 33 with value: 0.6761904761904762.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:38:31,082]\u001b[0m Trial 37 finished with value: 0.5352380952380952 and parameters: {'n_estimators': 840, 'max_depth': 8, 'max_features': 26, 'min_impurity_decrease': 0.4114799952729883}. Best is trial 33 with value: 0.6761904761904762.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:38:40,979]\u001b[0m Trial 38 finished with value: 0.5352380952380952 and parameters: {'n_estimators': 998, 'max_depth': 10, 'max_features': 23, 'min_impurity_decrease': 0.7115028745023322}. Best is trial 33 with value: 0.6761904761904762.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:38:51,024]\u001b[0m Trial 39 finished with value: 0.6297142857142857 and parameters: {'n_estimators': 903, 'max_depth': 6, 'max_features': 28, 'min_impurity_decrease': 0.06208220513260173}. Best is trial 33 with value: 0.6761904761904762.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:38:58,675]\u001b[0m Trial 40 finished with value: 0.5352380952380952 and parameters: {'n_estimators': 758, 'max_depth': 5, 'max_features': 25, 'min_impurity_decrease': 1.2530333907876288}. Best is trial 33 with value: 0.6761904761904762.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:39:08,515]\u001b[0m Trial 41 finished with value: 0.6322857142857143 and parameters: {'n_estimators': 907, 'max_depth': 8, 'max_features': 27, 'min_impurity_decrease': 0.05286677087361633}. Best is trial 33 with value: 0.6761904761904762.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:39:17,698]\u001b[0m Trial 42 finished with value: 0.5352380952380952 and parameters: {'n_estimators': 942, 'max_depth': 8, 'max_features': 30, 'min_impurity_decrease': 0.5113387488083093}. Best is trial 33 with value: 0.6761904761904762.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:39:26,348]\u001b[0m Trial 43 finished with value: 0.5421904761904762 and parameters: {'n_estimators': 888, 'max_depth': 10, 'max_features': 28, 'min_impurity_decrease': 0.22488874368369016}. Best is trial 33 with value: 0.6761904761904762.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:39:34,856]\u001b[0m Trial 44 finished with value: 0.5352380952380952 and parameters: {'n_estimators': 829, 'max_depth': 6, 'max_features': 26, 'min_impurity_decrease': 0.9284394996974525}. Best is trial 33 with value: 0.6761904761904762.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:39:45,663]\u001b[0m Trial 45 finished with value: 0.6718095238095237 and parameters: {'n_estimators': 948, 'max_depth': 9, 'max_features': 28, 'min_impurity_decrease': 0.0222031983719142}. Best is trial 33 with value: 0.6761904761904762.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:39:55,567]\u001b[0m Trial 46 finished with value: 0.5352380952380952 and parameters: {'n_estimators': 949, 'max_depth': 9, 'max_features': 29, 'min_impurity_decrease': 0.3420653743587697}. Best is trial 33 with value: 0.6761904761904762.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:40:02,772]\u001b[0m Trial 47 finished with value: 0.5352380952380952 and parameters: {'n_estimators': 785, 'max_depth': 7, 'max_features': 9, 'min_impurity_decrease': 0.6816047837540026}. Best is trial 33 with value: 0.6761904761904762.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:40:08,909]\u001b[0m Trial 48 finished with value: 0.5352380952380952 and parameters: {'n_estimators': 622, 'max_depth': 6, 'max_features': 24, 'min_impurity_decrease': 0.8511767213202808}. Best is trial 33 with value: 0.6761904761904762.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:40:09,968]\u001b[0m Trial 49 finished with value: 0.5309523809523808 and parameters: {'n_estimators': 107, 'max_depth': 10, 'max_features': 21, 'min_impurity_decrease': 0.26320721389361473}. Best is trial 33 with value: 0.6761904761904762.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:40:17,265]\u001b[0m Trial 50 finished with value: 0.5352380952380952 and parameters: {'n_estimators': 708, 'max_depth': 12, 'max_features': 28, 'min_impurity_decrease': 1.8082382735708258}. Best is trial 33 with value: 0.6761904761904762.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:40:28,042]\u001b[0m Trial 51 finished with value: 0.676095238095238 and parameters: {'n_estimators': 962, 'max_depth': 7, 'max_features': 27, 'min_impurity_decrease': 0.02106459317315383}. Best is trial 33 with value: 0.6761904761904762.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:40:37,749]\u001b[0m Trial 52 finished with value: 0.5352380952380952 and parameters: {'n_estimators': 955, 'max_depth': 7, 'max_features': 26, 'min_impurity_decrease': 0.49937746742507}. Best is trial 33 with value: 0.6761904761904762.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:40:47,221]\u001b[0m Trial 53 finished with value: 0.5323809523809523 and parameters: {'n_estimators': 989, 'max_depth': 5, 'max_features': 30, 'min_impurity_decrease': 0.24933984959020736}. Best is trial 33 with value: 0.6761904761904762.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:40:57,354]\u001b[0m Trial 54 finished with value: 0.671904761904762 and parameters: {'n_estimators': 850, 'max_depth': 8, 'max_features': 29, 'min_impurity_decrease': 0.00020460322913867096}. Best is trial 33 with value: 0.6761904761904762.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:41:06,231]\u001b[0m Trial 55 finished with value: 0.5352380952380952 and parameters: {'n_estimators': 926, 'max_depth': 8, 'max_features': 29, 'min_impurity_decrease': 0.5829495913183985}. Best is trial 33 with value: 0.6761904761904762.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:41:13,996]\u001b[0m Trial 56 finished with value: 0.5352380952380952 and parameters: {'n_estimators': 807, 'max_depth': 9, 'max_features': 25, 'min_impurity_decrease': 4.063447563238093}. Best is trial 33 with value: 0.6761904761904762.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:41:24,402]\u001b[0m Trial 57 finished with value: 0.6761904761904762 and parameters: {'n_estimators': 880, 'max_depth': 11, 'max_features': 28, 'min_impurity_decrease': 0.007051219363487071}. Best is trial 33 with value: 0.6761904761904762.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:41:26,100]\u001b[0m Trial 58 finished with value: 0.5352380952380952 and parameters: {'n_estimators': 167, 'max_depth': 11, 'max_features': 29, 'min_impurity_decrease': 0.798147610103549}. Best is trial 33 with value: 0.6761904761904762.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:41:33,758]\u001b[0m Trial 59 finished with value: 0.5352380952380952 and parameters: {'n_estimators': 770, 'max_depth': 18, 'max_features': 30, 'min_impurity_decrease': 0.382341636539112}. Best is trial 33 with value: 0.6761904761904762.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:41:41,537]\u001b[0m Trial 60 finished with value: 0.5309523809523808 and parameters: {'n_estimators': 843, 'max_depth': 16, 'max_features': 17, 'min_impurity_decrease': 0.2654469511283595}. Best is trial 33 with value: 0.6761904761904762.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:41:52,032]\u001b[0m Trial 61 finished with value: 0.6776190476190476 and parameters: {'n_estimators': 879, 'max_depth': 9, 'max_features': 28, 'min_impurity_decrease': 0.008123194334826785}. Best is trial 61 with value: 0.6776190476190476.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:42:01,231]\u001b[0m Trial 62 finished with value: 0.5956190476190477 and parameters: {'n_estimators': 876, 'max_depth': 12, 'max_features': 28, 'min_impurity_decrease': 0.18049512848250882}. Best is trial 61 with value: 0.6776190476190476.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:42:09,726]\u001b[0m Trial 63 finished with value: 0.5352380952380952 and parameters: {'n_estimators': 889, 'max_depth': 8, 'max_features': 26, 'min_impurity_decrease': 0.5086713670369812}. Best is trial 61 with value: 0.6776190476190476.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:42:16,982]\u001b[0m Trial 64 finished with value: 0.5983809523809525 and parameters: {'n_estimators': 736, 'max_depth': 14, 'max_features': 23, 'min_impurity_decrease': 0.17773926474715257}. Best is trial 61 with value: 0.6776190476190476.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:42:26,203]\u001b[0m Trial 65 finished with value: 0.5352380952380952 and parameters: {'n_estimators': 969, 'max_depth': 10, 'max_features': 29, 'min_impurity_decrease': 0.33631758132430556}. Best is trial 61 with value: 0.6776190476190476.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:42:35,065]\u001b[0m Trial 66 finished with value: 0.6165714285714285 and parameters: {'n_estimators': 925, 'max_depth': 11, 'max_features': 27, 'min_impurity_decrease': 0.1425798717417805}. Best is trial 61 with value: 0.6776190476190476.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:42:44,003]\u001b[0m Trial 67 finished with value: 0.5352380952380952 and parameters: {'n_estimators': 862, 'max_depth': 6, 'max_features': 24, 'min_impurity_decrease': 2.868193262665083}. Best is trial 61 with value: 0.6776190476190476.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:42:51,348]\u001b[0m Trial 68 finished with value: 0.5352380952380952 and parameters: {'n_estimators': 797, 'max_depth': 9, 'max_features': 25, 'min_impurity_decrease': 0.994325851568861}. Best is trial 61 with value: 0.6776190476190476.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:43:00,977]\u001b[0m Trial 69 finished with value: 0.6535238095238095 and parameters: {'n_estimators': 828, 'max_depth': 7, 'max_features': 30, 'min_impurity_decrease': 0.031484934359399815}. Best is trial 61 with value: 0.6776190476190476.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:43:09,542]\u001b[0m Trial 70 finished with value: 0.5352380952380952 and parameters: {'n_estimators': 974, 'max_depth': 8, 'max_features': 15, 'min_impurity_decrease': 0.634550934357082}. Best is trial 61 with value: 0.6776190476190476.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:43:19,004]\u001b[0m Trial 71 finished with value: 0.5352380952380952 and parameters: {'n_estimators': 931, 'max_depth': 9, 'max_features': 28, 'min_impurity_decrease': 0.38649297888281287}. Best is trial 61 with value: 0.6776190476190476.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:43:29,212]\u001b[0m Trial 72 finished with value: 0.6577142857142857 and parameters: {'n_estimators': 899, 'max_depth': 9, 'max_features': 28, 'min_impurity_decrease': 0.030118637469662382}. Best is trial 61 with value: 0.6776190476190476.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:43:40,472]\u001b[0m Trial 73 finished with value: 0.6464761904761906 and parameters: {'n_estimators': 997, 'max_depth': 8, 'max_features': 27, 'min_impurity_decrease': 0.03301911564319314}. Best is trial 61 with value: 0.6776190476190476.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:43:49,058]\u001b[0m Trial 74 finished with value: 0.5832380952380952 and parameters: {'n_estimators': 869, 'max_depth': 7, 'max_features': 29, 'min_impurity_decrease': 0.19804900719497173}. Best is trial 61 with value: 0.6776190476190476.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:44:00,411]\u001b[0m Trial 75 finished with value: 0.6733333333333333 and parameters: {'n_estimators': 960, 'max_depth': 11, 'max_features': 27, 'min_impurity_decrease': 0.0033010724541531968}. Best is trial 61 with value: 0.6776190476190476.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:44:09,453]\u001b[0m Trial 76 finished with value: 0.5352380952380952 and parameters: {'n_estimators': 913, 'max_depth': 11, 'max_features': 26, 'min_impurity_decrease': 0.42939915296424785}. Best is trial 61 with value: 0.6776190476190476.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:44:18,106]\u001b[0m Trial 77 finished with value: 0.5941904761904763 and parameters: {'n_estimators': 841, 'max_depth': 13, 'max_features': 27, 'min_impurity_decrease': 0.16676348958431253}. Best is trial 61 with value: 0.6776190476190476.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:44:22,894]\u001b[0m Trial 78 finished with value: 0.5352380952380952 and parameters: {'n_estimators': 457, 'max_depth': 6, 'max_features': 29, 'min_impurity_decrease': 0.7933694921818996}. Best is trial 61 with value: 0.6776190476190476.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:44:31,918]\u001b[0m Trial 79 finished with value: 0.5352380952380952 and parameters: {'n_estimators': 965, 'max_depth': 12, 'max_features': 26, 'min_impurity_decrease': 0.5862286818332793}. Best is trial 61 with value: 0.6776190476190476.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:44:40,745]\u001b[0m Trial 80 finished with value: 0.5352380952380952 and parameters: {'n_estimators': 894, 'max_depth': 10, 'max_features': 30, 'min_impurity_decrease': 0.3144294030115981}. Best is trial 61 with value: 0.6776190476190476.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:44:51,308]\u001b[0m Trial 81 finished with value: 0.6733333333333335 and parameters: {'n_estimators': 934, 'max_depth': 10, 'max_features': 28, 'min_impurity_decrease': 0.006323452295319941}. Best is trial 61 with value: 0.6776190476190476.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:45:00,829]\u001b[0m Trial 82 finished with value: 0.6165714285714285 and parameters: {'n_estimators': 927, 'max_depth': 10, 'max_features': 28, 'min_impurity_decrease': 0.14545468932474404}. Best is trial 61 with value: 0.6776190476190476.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:45:10,329]\u001b[0m Trial 83 finished with value: 0.5352380952380952 and parameters: {'n_estimators': 975, 'max_depth': 5, 'max_features': 27, 'min_impurity_decrease': 0.33087900745123566}. Best is trial 61 with value: 0.6776190476190476.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:45:19,087]\u001b[0m Trial 84 finished with value: 0.5352380952380952 and parameters: {'n_estimators': 874, 'max_depth': 10, 'max_features': 28, 'min_impurity_decrease': 2.387601930957447}. Best is trial 61 with value: 0.6776190476190476.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:45:29,929]\u001b[0m Trial 85 finished with value: 0.6748571428571429 and parameters: {'n_estimators': 952, 'max_depth': 11, 'max_features': 25, 'min_impurity_decrease': 0.0007392099609671288}. Best is trial 61 with value: 0.6776190476190476.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:45:39,247]\u001b[0m Trial 86 finished with value: 0.5352380952380952 and parameters: {'n_estimators': 947, 'max_depth': 11, 'max_features': 26, 'min_impurity_decrease': 0.48146683809049023}. Best is trial 61 with value: 0.6776190476190476.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:45:47,789]\u001b[0m Trial 87 finished with value: 0.6207619047619047 and parameters: {'n_estimators': 915, 'max_depth': 13, 'max_features': 24, 'min_impurity_decrease': 0.13757031221334323}. Best is trial 61 with value: 0.6776190476190476.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:45:58,181]\u001b[0m Trial 88 finished with value: 0.5352380952380952 and parameters: {'n_estimators': 998, 'max_depth': 12, 'max_features': 25, 'min_impurity_decrease': 0.30676748165353357}. Best is trial 61 with value: 0.6776190476190476.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:46:07,313]\u001b[0m Trial 89 finished with value: 0.5352380952380952 and parameters: {'n_estimators': 956, 'max_depth': 11, 'max_features': 27, 'min_impurity_decrease': 4.576798205075603}. Best is trial 61 with value: 0.6776190476190476.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:46:10,360]\u001b[0m Trial 90 finished with value: 0.620952380952381 and parameters: {'n_estimators': 289, 'max_depth': 12, 'max_features': 7, 'min_impurity_decrease': 0.1288307028354426}. Best is trial 61 with value: 0.6776190476190476.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:46:20,365]\u001b[0m Trial 91 finished with value: 0.6761904761904762 and parameters: {'n_estimators': 852, 'max_depth': 7, 'max_features': 29, 'min_impurity_decrease': 0.007725264887275658}. Best is trial 61 with value: 0.6776190476190476.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:46:29,221]\u001b[0m Trial 92 finished with value: 0.5295238095238095 and parameters: {'n_estimators': 889, 'max_depth': 11, 'max_features': 30, 'min_impurity_decrease': 0.2520599220602134}. Best is trial 61 with value: 0.6776190476190476.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:46:38,312]\u001b[0m Trial 93 finished with value: 0.6732380952380952 and parameters: {'n_estimators': 822, 'max_depth': 7, 'max_features': 29, 'min_impurity_decrease': 0.02259369678524981}. Best is trial 61 with value: 0.6776190476190476.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:46:42,912]\u001b[0m Trial 94 finished with value: 0.617904761904762 and parameters: {'n_estimators': 812, 'max_depth': 7, 'max_features': 29, 'min_impurity_decrease': 0.14831488771027054}. Best is trial 61 with value: 0.6776190476190476.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:46:48,995]\u001b[0m Trial 95 finished with value: 0.6761904761904762 and parameters: {'n_estimators': 940, 'max_depth': 7, 'max_features': 28, 'min_impurity_decrease': 0.005823654890190223}. Best is trial 61 with value: 0.6776190476190476.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:46:54,400]\u001b[0m Trial 96 finished with value: 0.5352380952380952 and parameters: {'n_estimators': 938, 'max_depth': 9, 'max_features': 28, 'min_impurity_decrease': 0.4235083475944678}. Best is trial 61 with value: 0.6776190476190476.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:46:59,625]\u001b[0m Trial 97 finished with value: 0.5352380952380952 and parameters: {'n_estimators': 978, 'max_depth': 10, 'max_features': 27, 'min_impurity_decrease': 0.5367328068166792}. Best is trial 61 with value: 0.6776190476190476.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:47:05,409]\u001b[0m Trial 98 finished with value: 0.6733333333333335 and parameters: {'n_estimators': 919, 'max_depth': 8, 'max_features': 30, 'min_impurity_decrease': 0.0005874942435908203}. Best is trial 61 with value: 0.6776190476190476.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:47:10,306]\u001b[0m Trial 99 finished with value: 0.5352380952380952 and parameters: {'n_estimators': 909, 'max_depth': 8, 'max_features': 30, 'min_impurity_decrease': 0.719689906318086}. Best is trial 61 with value: 0.6776190476190476.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "#Tuning hyperparameters\n",
    "#Step 1. Define an objective function to be maximized.\n",
    "def objective(trial):\n",
    "    n_estimators = trial.suggest_int(\"n_estimators\",100,1000,1) \n",
    "    max_depth = trial.suggest_int(\"max_depth\",5,20,1)\n",
    "    max_features = trial.suggest_int(\"max_features\",5,30,1)\n",
    "    min_impurity_decrease = trial.suggest_float(\"min_impurity_decrease\",0,5,log=False) \n",
    "    model = RandomForestClassifier(n_estimators = n_estimators\n",
    "              ,max_depth = max_depth\n",
    "              ,max_features = max_features\n",
    "              ,min_impurity_decrease = min_impurity_decrease\n",
    "              ,random_state=1\n",
    "              ,verbose=False\n",
    "              ,n_jobs=8)\n",
    "\n",
    "# Step 2: Scoring method:\n",
    "    score = model_selection.cross_val_score(model, X, y, n_jobs=8, scoring=\"accuracy\",cv=Cv_optuna)\n",
    "    accuracy = score.mean()\n",
    "    return accuracy\n",
    " \n",
    "# Step 3: Running it\n",
    "study = optuna.create_study(direction=\"maximize\",sampler=optuna.samplers.TPESampler(seed=0))\n",
    "study.optimize(objective, n_trials=100, show_progress_bar=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "9b88d250-7567-4062-b7d5-0a9638d732c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best parameters are : \n",
      "{'n_estimators': 879, 'max_depth': 9, 'max_features': 28, 'min_impurity_decrease': 0.008123194334826785}\n"
     ]
    }
   ],
   "source": [
    "# Getting the best parameters:\n",
    "print(f\"The best parameters are : \\n{study.best_params}\")\n",
    "# Setting the best model\n",
    "clf=RandomForestClassifier(n_estimators = study.best_params['n_estimators']\n",
    "              ,max_depth = study.best_params['max_depth']\n",
    "              ,max_features = study.best_params['max_features']\n",
    "              ,min_impurity_decrease = study.best_params['min_impurity_decrease']\n",
    "              ,random_state=0\n",
    "              ,verbose=False\n",
    "              ,n_jobs=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "a4281260-9ed3-4ed2-93c1-ed1888b7625f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mean</th>\n",
       "      <th>Se</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Accuracy_test</th>\n",
       "      <td>0.670571</td>\n",
       "      <td>0.013460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Accuracy_train</th>\n",
       "      <td>0.974643</td>\n",
       "      <td>0.001874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1 Score</th>\n",
       "      <td>0.703054</td>\n",
       "      <td>0.013994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Precision</th>\n",
       "      <td>0.681364</td>\n",
       "      <td>0.014131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recall</th>\n",
       "      <td>0.749643</td>\n",
       "      <td>0.022551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Roc_auc</th>\n",
       "      <td>0.752985</td>\n",
       "      <td>0.015938</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Mean        Se\n",
       "Accuracy_test   0.670571  0.013460\n",
       "Accuracy_train  0.974643  0.001874\n",
       "F1 Score        0.703054  0.013994\n",
       "Precision       0.681364  0.014131\n",
       "Recall          0.749643  0.022551\n",
       "Roc_auc         0.752985  0.015938"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Model2\n",
    "Model2=Model_results(clf,X,y,Cv_model)\n",
    "Model2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "c06b82a5-a8ce-4b80-b011-d93c0ab3a6cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th>Method</th>\n",
       "      <th colspan=\"4\" halign=\"left\">RF</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model</th>\n",
       "      <th colspan=\"2\" halign=\"left\">Model 1</th>\n",
       "      <th colspan=\"2\" halign=\"left\">Model 2</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Values</th>\n",
       "      <th>Mean</th>\n",
       "      <th>Se</th>\n",
       "      <th>Mean</th>\n",
       "      <th>Se</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Accuracy_test</th>\n",
       "      <td>0.676381</td>\n",
       "      <td>0.014691</td>\n",
       "      <td>0.670571</td>\n",
       "      <td>0.013460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Accuracy_train</th>\n",
       "      <td>0.978164</td>\n",
       "      <td>0.001539</td>\n",
       "      <td>0.974643</td>\n",
       "      <td>0.001874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1 Score</th>\n",
       "      <td>0.711877</td>\n",
       "      <td>0.013423</td>\n",
       "      <td>0.703054</td>\n",
       "      <td>0.013994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Precision</th>\n",
       "      <td>0.688878</td>\n",
       "      <td>0.014746</td>\n",
       "      <td>0.681364</td>\n",
       "      <td>0.014131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recall</th>\n",
       "      <td>0.757857</td>\n",
       "      <td>0.020561</td>\n",
       "      <td>0.749643</td>\n",
       "      <td>0.022551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Roc_auc</th>\n",
       "      <td>0.756424</td>\n",
       "      <td>0.017012</td>\n",
       "      <td>0.752985</td>\n",
       "      <td>0.015938</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Method                RF                              \n",
       "Model            Model 1             Model 2          \n",
       "Values              Mean        Se      Mean        Se\n",
       "Accuracy_test   0.676381  0.014691  0.670571  0.013460\n",
       "Accuracy_train  0.978164  0.001539  0.974643  0.001874\n",
       "F1 Score        0.711877  0.013423  0.703054  0.013994\n",
       "Precision       0.688878  0.014746  0.681364  0.014131\n",
       "Recall          0.757857  0.020561  0.749643  0.022551\n",
       "Roc_auc         0.756424  0.017012  0.752985  0.015938"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Saving the data of model performance\n",
    "Model_data=pd.concat([Model1,Model2],axis=1)\n",
    "Model_data.columns = [['RF']*4,['Model 1','Model 1', 'Model 2','Model 2'], ['Mean', 'Se', 'Mean', 'Se']]  \n",
    "Model_data.columns.names=['Method','Model','Values']\n",
    "Model_data.to_csv(\"./Results/RF_model_mlrem_data.csv\",sep=',')\n",
    "Model_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de27d5ec-8039-4cfd-8629-ad30d87ca90f",
   "metadata": {},
   "source": [
    "## 2.4 XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "19aa8297-4182-4dac-8857-008a9ad45f1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf=xgb.XGBClassifier(random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "66336653-640b-407f-8c25-80c9e29b3651",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mean</th>\n",
       "      <th>Se</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Accuracy_test</th>\n",
       "      <td>0.662476</td>\n",
       "      <td>0.016918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Accuracy_train</th>\n",
       "      <td>0.978164</td>\n",
       "      <td>0.001539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1 Score</th>\n",
       "      <td>0.693483</td>\n",
       "      <td>0.017356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Precision</th>\n",
       "      <td>0.671509</td>\n",
       "      <td>0.015551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recall</th>\n",
       "      <td>0.737143</td>\n",
       "      <td>0.025112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Roc_auc</th>\n",
       "      <td>0.749660</td>\n",
       "      <td>0.017686</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Mean        Se\n",
       "Accuracy_test   0.662476  0.016918\n",
       "Accuracy_train  0.978164  0.001539\n",
       "F1 Score        0.693483  0.017356\n",
       "Precision       0.671509  0.015551\n",
       "Recall          0.737143  0.025112\n",
       "Roc_auc         0.749660  0.017686"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Model1 \n",
    "Model1_clf=clf\n",
    "#Model1\n",
    "Model1=Model_results(Model1_clf,X,y,Cv_model)\n",
    "Model1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "2184b863-0c03-4641-8e98-2b00c0fd5878",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2024-01-12 01:49:39,219]\u001b[0m A new study created in memory with name: no-name-9bfd5a88-8b2a-4996-844c-9f159bf96100\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-01-12 01:49:44,945]\u001b[0m Trial 0 finished with value: 0.6608571428571429 and parameters: {'lambda': 0.15676677195506075, 'alpha': 0.7257005721594281, 'colsample_bytree': 0.7, 'subsample': 0.7000000000000001, 'learning_rate': 0.0801, 'n_estimators': 664}. Best is trial 0 with value: 0.6608571428571429.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-01-12 01:49:47,925]\u001b[0m Trial 1 finished with value: 0.6323809523809524 and parameters: {'lambda': 0.0562793204741517, 'alpha': 3.6905577292137624, 'colsample_bytree': 1.0, 'subsample': 0.6000000000000001, 'learning_rate': 0.1551, 'n_estimators': 552}. Best is trial 0 with value: 0.6608571428571429.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-01-12 01:49:51,796]\u001b[0m Trial 2 finished with value: 0.5408571428571428 and parameters: {'lambda': 0.18714500686240676, 'alpha': 5.039489598671215, 'colsample_bytree': 0.3, 'subsample': 0.4, 'learning_rate': 0.0001, 'n_estimators': 841}. Best is trial 0 with value: 0.6608571428571429.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-01-12 01:49:56,159]\u001b[0m Trial 3 finished with value: 0.6392380952380953 and parameters: {'lambda': 1.2960656597279736, 'alpha': 3.0202896401586674, 'colsample_bytree': 1.0, 'subsample': 0.9, 'learning_rate': 0.0901, 'n_estimators': 792}. Best is trial 0 with value: 0.6608571428571429.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-01-12 01:49:59,349]\u001b[0m Trial 4 finished with value: 0.6553333333333334 and parameters: {'lambda': 0.0029723346443356552, 'alpha': 0.3628140404024381, 'colsample_bytree': 0.4, 'subsample': 1.0, 'learning_rate': 0.10010000000000001, 'n_estimators': 444}. Best is trial 0 with value: 0.6608571428571429.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-01-12 01:50:06,638]\u001b[0m Trial 5 finished with value: 0.638 and parameters: {'lambda': 0.011434638743472197, 'alpha': 1.2500712230836255, 'colsample_bytree': 0.6000000000000001, 'subsample': 0.7000000000000001, 'learning_rate': 0.0001, 'n_estimators': 637}. Best is trial 0 with value: 0.6608571428571429.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-01-12 01:50:10,699]\u001b[0m Trial 6 finished with value: 0.6510476190476191 and parameters: {'lambda': 0.2807908107885728, 'alpha': 0.2935864364395359, 'colsample_bytree': 1.0, 'subsample': 0.8, 'learning_rate': 0.07010000000000001, 'n_estimators': 465}. Best is trial 0 with value: 0.6608571428571429.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-01-12 01:50:12,762]\u001b[0m Trial 7 finished with value: 0.6508571428571429 and parameters: {'lambda': 0.6173405204074314, 'alpha': 0.0017414134181586202, 'colsample_bytree': 0.8, 'subsample': 0.8, 'learning_rate': 0.040100000000000004, 'n_estimators': 172}. Best is trial 0 with value: 0.6608571428571429.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-01-12 01:50:13,989]\u001b[0m Trial 8 finished with value: 0.6779047619047618 and parameters: {'lambda': 0.01826894228153233, 'alpha': 0.028499883436971588, 'colsample_bytree': 0.7, 'subsample': 0.7000000000000001, 'learning_rate': 0.1951, 'n_estimators': 147}. Best is trial 8 with value: 0.6779047619047618.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-01-12 01:50:16,120]\u001b[0m Trial 9 finished with value: 0.667904761904762 and parameters: {'lambda': 0.006847105576684045, 'alpha': 0.004418125737902547, 'colsample_bytree': 0.8, 'subsample': 0.5, 'learning_rate': 0.0901, 'n_estimators': 282}. Best is trial 8 with value: 0.6779047619047618.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-01-12 01:50:16,755]\u001b[0m Trial 10 finished with value: 0.6451428571428572 and parameters: {'lambda': 5.790132527437195, 'alpha': 0.025043968115100592, 'colsample_bytree': 0.5, 'subsample': 0.5, 'learning_rate': 0.1901, 'n_estimators': 57}. Best is trial 8 with value: 0.6779047619047618.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-01-12 01:50:18,686]\u001b[0m Trial 11 finished with value: 0.6690476190476192 and parameters: {'lambda': 0.017123553109627314, 'alpha': 0.013676263870483537, 'colsample_bytree': 0.8, 'subsample': 0.5, 'learning_rate': 0.14509999999999998, 'n_estimators': 277}. Best is trial 8 with value: 0.6779047619047618.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-01-12 01:50:20,734]\u001b[0m Trial 12 finished with value: 0.6763809523809523 and parameters: {'lambda': 0.02491353701899208, 'alpha': 0.023063141329483616, 'colsample_bytree': 0.8, 'subsample': 0.4, 'learning_rate': 0.15009999999999998, 'n_estimators': 319}. Best is trial 8 with value: 0.6779047619047618.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-01-12 01:50:22,688]\u001b[0m Trial 13 finished with value: 0.662 and parameters: {'lambda': 0.04474111800996658, 'alpha': 0.038990832725213885, 'colsample_bytree': 0.6000000000000001, 'subsample': 0.4, 'learning_rate': 0.1951, 'n_estimators': 316}. Best is trial 8 with value: 0.6779047619047618.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-01-12 01:50:23,622]\u001b[0m Trial 14 finished with value: 0.6509523809523808 and parameters: {'lambda': 0.0012140452982167488, 'alpha': 0.06910620324453418, 'colsample_bytree': 0.7, 'subsample': 0.6000000000000001, 'learning_rate': 0.1551, 'n_estimators': 94}. Best is trial 8 with value: 0.6779047619047618.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-01-12 01:50:25,465]\u001b[0m Trial 15 finished with value: 0.6680000000000001 and parameters: {'lambda': 0.027126643489253296, 'alpha': 0.0045017087887461935, 'colsample_bytree': 0.9000000000000001, 'subsample': 1.0, 'learning_rate': 0.1301, 'n_estimators': 204}. Best is trial 8 with value: 0.6779047619047618.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-01-12 01:50:27,896]\u001b[0m Trial 16 finished with value: 0.6703809523809525 and parameters: {'lambda': 0.004818440651909064, 'alpha': 0.16888877355169551, 'colsample_bytree': 0.5, 'subsample': 0.6000000000000001, 'learning_rate': 0.1751, 'n_estimators': 358}. Best is trial 8 with value: 0.6779047619047618.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-01-12 01:50:29,534]\u001b[0m Trial 17 finished with value: 0.6649523809523811 and parameters: {'lambda': 0.0010007385532741818, 'alpha': 0.009646273191219181, 'colsample_bytree': 0.9000000000000001, 'subsample': 0.8, 'learning_rate': 0.1201, 'n_estimators': 181}. Best is trial 8 with value: 0.6779047619047618.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-01-12 01:50:31,793]\u001b[0m Trial 18 finished with value: 0.6763809523809524 and parameters: {'lambda': 0.061634227943790754, 'alpha': 0.07305295568841107, 'colsample_bytree': 0.7, 'subsample': 0.4, 'learning_rate': 0.1701, 'n_estimators': 367}. Best is trial 8 with value: 0.6779047619047618.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-01-12 01:50:36,908]\u001b[0m Trial 19 finished with value: 0.6748571428571429 and parameters: {'lambda': 0.08189216606299816, 'alpha': 0.09137793328553549, 'colsample_bytree': 0.5, 'subsample': 0.6000000000000001, 'learning_rate': 0.1751, 'n_estimators': 930}. Best is trial 8 with value: 0.6779047619047618.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-01-12 01:50:40,298]\u001b[0m Trial 20 finished with value: 0.6764761904761906 and parameters: {'lambda': 1.6767154928982846, 'alpha': 0.0016483661900255071, 'colsample_bytree': 0.7, 'subsample': 0.9, 'learning_rate': 0.1751, 'n_estimators': 429}. Best is trial 8 with value: 0.6779047619047618.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-01-12 01:50:44,316]\u001b[0m Trial 21 finished with value: 0.6525714285714286 and parameters: {'lambda': 7.401604059812908, 'alpha': 0.0010968075467978052, 'colsample_bytree': 0.7, 'subsample': 0.9, 'learning_rate': 0.18009999999999998, 'n_estimators': 421}. Best is trial 8 with value: 0.6779047619047618.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-01-12 01:50:48,618]\u001b[0m Trial 22 finished with value: 0.6694285714285715 and parameters: {'lambda': 2.0928422583512405, 'alpha': 0.0036652235601470915, 'colsample_bytree': 0.6000000000000001, 'subsample': 0.9, 'learning_rate': 0.1701, 'n_estimators': 558}. Best is trial 8 with value: 0.6779047619047618.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-01-12 01:50:51,373]\u001b[0m Trial 23 finished with value: 0.6751428571428572 and parameters: {'lambda': 0.6439279076937869, 'alpha': 0.04386602055339343, 'colsample_bytree': 0.7, 'subsample': 0.7000000000000001, 'learning_rate': 0.1951, 'n_estimators': 391}. Best is trial 8 with value: 0.6779047619047618.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-01-12 01:50:54,900]\u001b[0m Trial 24 finished with value: 0.6764761904761905 and parameters: {'lambda': 0.3883136303907193, 'alpha': 0.010049953917114773, 'colsample_bytree': 0.6000000000000001, 'subsample': 0.8, 'learning_rate': 0.1301, 'n_estimators': 496}. Best is trial 8 with value: 0.6779047619047618.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-01-12 01:50:59,980]\u001b[0m Trial 25 finished with value: 0.6653333333333333 and parameters: {'lambda': 2.7802503139996473, 'alpha': 0.008337657822509066, 'colsample_bytree': 0.6000000000000001, 'subsample': 0.8, 'learning_rate': 0.1301, 'n_estimators': 656}. Best is trial 8 with value: 0.6779047619047618.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-01-12 01:51:05,250]\u001b[0m Trial 26 finished with value: 0.6790476190476192 and parameters: {'lambda': 0.5989769734564016, 'alpha': 0.001754204354028918, 'colsample_bytree': 0.4, 'subsample': 0.9, 'learning_rate': 0.11510000000000001, 'n_estimators': 725}. Best is trial 26 with value: 0.6790476190476192.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-01-12 01:51:12,244]\u001b[0m Trial 27 finished with value: 0.6693333333333336 and parameters: {'lambda': 1.2518838419016274, 'alpha': 0.002084110757581769, 'colsample_bytree': 0.4, 'subsample': 0.9, 'learning_rate': 0.0451, 'n_estimators': 779}. Best is trial 26 with value: 0.6790476190476192.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-01-12 01:51:21,465]\u001b[0m Trial 28 finished with value: 0.6609523809523811 and parameters: {'lambda': 4.723187635059192, 'alpha': 0.002467585771750723, 'colsample_bytree': 0.3, 'subsample': 1.0, 'learning_rate': 0.050100000000000006, 'n_estimators': 916}. Best is trial 26 with value: 0.6790476190476192.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-01-12 01:51:26,158]\u001b[0m Trial 29 finished with value: 0.6861904761904764 and parameters: {'lambda': 0.1357530766063751, 'alpha': 0.00604912334356112, 'colsample_bytree': 0.4, 'subsample': 0.7000000000000001, 'learning_rate': 0.11510000000000001, 'n_estimators': 740}. Best is trial 29 with value: 0.6861904761904764.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-01-12 01:51:30,752]\u001b[0m Trial 30 finished with value: 0.6750476190476192 and parameters: {'lambda': 0.18092199214591256, 'alpha': 0.0010057216538091605, 'colsample_bytree': 0.4, 'subsample': 0.7000000000000001, 'learning_rate': 0.1101, 'n_estimators': 709}. Best is trial 29 with value: 0.6861904761904764.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-01-12 01:51:35,311]\u001b[0m Trial 31 finished with value: 0.6751428571428572 and parameters: {'lambda': 0.11119277519798368, 'alpha': 0.006118149756823851, 'colsample_bytree': 0.5, 'subsample': 0.7000000000000001, 'learning_rate': 0.11510000000000001, 'n_estimators': 723}. Best is trial 29 with value: 0.6861904761904764.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-01-12 01:51:40,257]\u001b[0m Trial 32 finished with value: 0.6821904761904765 and parameters: {'lambda': 0.6301118583785598, 'alpha': 0.01900920382279658, 'colsample_bytree': 0.4, 'subsample': 0.9, 'learning_rate': 0.0651, 'n_estimators': 591}. Best is trial 29 with value: 0.6861904761904764.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-01-12 01:51:45,058]\u001b[0m Trial 33 finished with value: 0.6763809523809524 and parameters: {'lambda': 0.6999320996994477, 'alpha': 0.016156842125445648, 'colsample_bytree': 0.3, 'subsample': 0.7000000000000001, 'learning_rate': 0.0601, 'n_estimators': 588}. Best is trial 29 with value: 0.6861904761904764.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-01-12 01:51:52,041]\u001b[0m Trial 34 finished with value: 0.674952380952381 and parameters: {'lambda': 0.3527627967271589, 'alpha': 0.030241715405447074, 'colsample_bytree': 0.4, 'subsample': 0.8, 'learning_rate': 0.0751, 'n_estimators': 991}. Best is trial 29 with value: 0.6861904761904764.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-01-12 01:51:59,408]\u001b[0m Trial 35 finished with value: 0.6609523809523811 and parameters: {'lambda': 0.14364941444825624, 'alpha': 0.017627889213148507, 'colsample_bytree': 0.3, 'subsample': 0.6000000000000001, 'learning_rate': 0.0201, 'n_estimators': 836}. Best is trial 29 with value: 0.6861904761904764.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-01-12 01:52:04,321]\u001b[0m Trial 36 finished with value: 0.6680000000000001 and parameters: {'lambda': 1.0360787933743876, 'alpha': 0.006610100039382611, 'colsample_bytree': 0.4, 'subsample': 1.0, 'learning_rate': 0.10010000000000001, 'n_estimators': 590}. Best is trial 29 with value: 0.6861904761904764.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-01-12 01:52:07,614]\u001b[0m Trial 37 finished with value: 0.5927619047619048 and parameters: {'lambda': 0.24008342239429287, 'alpha': 8.861629685772453, 'colsample_bytree': 0.5, 'subsample': 0.7000000000000001, 'learning_rate': 0.08510000000000001, 'n_estimators': 730}. Best is trial 29 with value: 0.6861904761904764.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-01-12 01:52:14,227]\u001b[0m Trial 38 finished with value: 0.6707619047619049 and parameters: {'lambda': 0.037769804089962805, 'alpha': 0.17532934883981124, 'colsample_bytree': 0.4, 'subsample': 0.9, 'learning_rate': 0.0201, 'n_estimators': 622}. Best is trial 29 with value: 0.6861904761904764.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-01-12 01:52:17,939]\u001b[0m Trial 39 finished with value: 0.677904761904762 and parameters: {'lambda': 0.08654988469845346, 'alpha': 0.0033305961239733462, 'colsample_bytree': 0.3, 'subsample': 0.8, 'learning_rate': 0.1401, 'n_estimators': 535}. Best is trial 29 with value: 0.6861904761904764.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-01-12 01:52:22,157]\u001b[0m Trial 40 finished with value: 0.667904761904762 and parameters: {'lambda': 0.4364559577785702, 'alpha': 0.002986127875870649, 'colsample_bytree': 0.3, 'subsample': 0.8, 'learning_rate': 0.1051, 'n_estimators': 529}. Best is trial 29 with value: 0.6861904761904764.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-01-12 01:52:26,780]\u001b[0m Trial 41 finished with value: 0.6820952380952382 and parameters: {'lambda': 0.012041246302698917, 'alpha': 0.005755556753698326, 'colsample_bytree': 0.3, 'subsample': 0.9, 'learning_rate': 0.1401, 'n_estimators': 679}. Best is trial 29 with value: 0.6861904761904764.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-01-12 01:52:30,094]\u001b[0m Trial 42 finished with value: 0.6821904761904761 and parameters: {'lambda': 0.00976530253589791, 'alpha': 0.004521658633426094, 'colsample_bytree': 0.3, 'subsample': 0.9, 'learning_rate': 0.1401, 'n_estimators': 692}. Best is trial 29 with value: 0.6861904761904764.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-01-12 01:52:31,968]\u001b[0m Trial 43 finished with value: 0.6820952380952382 and parameters: {'lambda': 0.009533938648370993, 'alpha': 0.005142380479852608, 'colsample_bytree': 0.4, 'subsample': 0.9, 'learning_rate': 0.1201, 'n_estimators': 779}. Best is trial 29 with value: 0.6861904761904764.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-01-12 01:52:34,015]\u001b[0m Trial 44 finished with value: 0.701714285714286 and parameters: {'lambda': 0.008556178294461857, 'alpha': 0.00559859295117001, 'colsample_bytree': 0.3, 'subsample': 1.0, 'learning_rate': 0.1601, 'n_estimators': 792}. Best is trial 44 with value: 0.701714285714286.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-01-12 01:52:35,874]\u001b[0m Trial 45 finished with value: 0.7003809523809525 and parameters: {'lambda': 0.002736395942107596, 'alpha': 0.010967284413723879, 'colsample_bytree': 0.3, 'subsample': 1.0, 'learning_rate': 0.1601, 'n_estimators': 687}. Best is trial 44 with value: 0.701714285714286.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-01-12 01:52:38,163]\u001b[0m Trial 46 finished with value: 0.6960952380952382 and parameters: {'lambda': 0.0028166231869091456, 'alpha': 0.009994188044722196, 'colsample_bytree': 0.3, 'subsample': 1.0, 'learning_rate': 0.1651, 'n_estimators': 830}. Best is trial 44 with value: 0.701714285714286.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-01-12 01:52:40,457]\u001b[0m Trial 47 finished with value: 0.6947619047619049 and parameters: {'lambda': 0.0019027548784550043, 'alpha': 0.012393652417147363, 'colsample_bytree': 0.3, 'subsample': 1.0, 'learning_rate': 0.0651, 'n_estimators': 836}. Best is trial 44 with value: 0.701714285714286.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-01-12 01:52:42,704]\u001b[0m Trial 48 finished with value: 0.6960952380952381 and parameters: {'lambda': 0.0024183815673537484, 'alpha': 0.011729643522042612, 'colsample_bytree': 0.3, 'subsample': 1.0, 'learning_rate': 0.1851, 'n_estimators': 846}. Best is trial 44 with value: 0.701714285714286.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-01-12 01:52:44,291]\u001b[0m Trial 49 finished with value: 0.6551428571428572 and parameters: {'lambda': 0.0019408046467350051, 'alpha': 1.0433113847404174, 'colsample_bytree': 0.3, 'subsample': 1.0, 'learning_rate': 0.1851, 'n_estimators': 854}. Best is trial 44 with value: 0.701714285714286.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-01-12 01:52:46,542]\u001b[0m Trial 50 finished with value: 0.7002857142857144 and parameters: {'lambda': 0.0033591891295767654, 'alpha': 0.01382541664678391, 'colsample_bytree': 0.3, 'subsample': 1.0, 'learning_rate': 0.1601, 'n_estimators': 874}. Best is trial 44 with value: 0.701714285714286.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-01-12 01:52:48,705]\u001b[0m Trial 51 finished with value: 0.7017142857142857 and parameters: {'lambda': 0.0034229051056133657, 'alpha': 0.012871271791450633, 'colsample_bytree': 0.3, 'subsample': 1.0, 'learning_rate': 0.1601, 'n_estimators': 866}. Best is trial 44 with value: 0.701714285714286.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-01-12 01:52:51,053]\u001b[0m Trial 52 finished with value: 0.7001904761904763 and parameters: {'lambda': 0.004225220871455537, 'alpha': 0.011370294688030805, 'colsample_bytree': 0.3, 'subsample': 1.0, 'learning_rate': 0.1601, 'n_estimators': 890}. Best is trial 44 with value: 0.701714285714286.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-01-12 01:52:53,527]\u001b[0m Trial 53 finished with value: 0.6960000000000002 and parameters: {'lambda': 0.004103597114144333, 'alpha': 0.04967022533268807, 'colsample_bytree': 0.3, 'subsample': 1.0, 'learning_rate': 0.1601, 'n_estimators': 920}. Best is trial 44 with value: 0.701714285714286.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-01-12 01:52:55,907]\u001b[0m Trial 54 finished with value: 0.7031428571428572 and parameters: {'lambda': 0.004043834319918063, 'alpha': 0.029633425764158693, 'colsample_bytree': 0.3, 'subsample': 1.0, 'learning_rate': 0.1601, 'n_estimators': 894}. Best is trial 54 with value: 0.7031428571428572.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-01-12 01:52:58,610]\u001b[0m Trial 55 finished with value: 0.6975238095238098 and parameters: {'lambda': 0.004980224075064425, 'alpha': 0.03510787695470061, 'colsample_bytree': 0.3, 'subsample': 1.0, 'learning_rate': 0.1551, 'n_estimators': 995}. Best is trial 54 with value: 0.7031428571428572.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-01-12 01:53:00,935]\u001b[0m Trial 56 finished with value: 0.7102857142857144 and parameters: {'lambda': 0.0013221304985698086, 'alpha': 0.02305461805888264, 'colsample_bytree': 0.3, 'subsample': 1.0, 'learning_rate': 0.15009999999999998, 'n_estimators': 884}. Best is trial 56 with value: 0.7102857142857144.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-01-12 01:53:03,490]\u001b[0m Trial 57 finished with value: 0.6793333333333333 and parameters: {'lambda': 0.0012446922418356734, 'alpha': 0.022077479688830965, 'colsample_bytree': 0.4, 'subsample': 1.0, 'learning_rate': 0.15009999999999998, 'n_estimators': 962}. Best is trial 56 with value: 0.7102857142857144.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-01-12 01:53:05,883]\u001b[0m Trial 58 finished with value: 0.6791428571428573 and parameters: {'lambda': 0.006622004577595627, 'alpha': 0.1431496104944084, 'colsample_bytree': 0.3, 'subsample': 1.0, 'learning_rate': 0.1651, 'n_estimators': 885}. Best is trial 56 with value: 0.7102857142857144.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-01-12 01:53:08,000]\u001b[0m Trial 59 finished with value: 0.6751428571428572 and parameters: {'lambda': 0.0014168536815106854, 'alpha': 0.02621704841078774, 'colsample_bytree': 0.5, 'subsample': 1.0, 'learning_rate': 0.15009999999999998, 'n_estimators': 803}. Best is trial 56 with value: 0.7102857142857144.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-01-12 01:53:10,527]\u001b[0m Trial 60 finished with value: 0.677904761904762 and parameters: {'lambda': 0.003453061915516729, 'alpha': 0.06591221885128822, 'colsample_bytree': 0.4, 'subsample': 1.0, 'learning_rate': 0.1701, 'n_estimators': 955}. Best is trial 56 with value: 0.7102857142857144.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-01-12 01:53:12,750]\u001b[0m Trial 61 finished with value: 0.6932380952380953 and parameters: {'lambda': 0.006241233717411143, 'alpha': 0.008377211507259008, 'colsample_bytree': 0.3, 'subsample': 1.0, 'learning_rate': 0.1601, 'n_estimators': 885}. Best is trial 56 with value: 0.7102857142857144.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-01-12 01:53:15,123]\u001b[0m Trial 62 finished with value: 0.7001904761904763 and parameters: {'lambda': 0.00199673319822298, 'alpha': 0.01284143905578283, 'colsample_bytree': 0.3, 'subsample': 1.0, 'learning_rate': 0.1601, 'n_estimators': 875}. Best is trial 56 with value: 0.7102857142857144.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-01-12 01:53:17,298]\u001b[0m Trial 63 finished with value: 0.6935238095238097 and parameters: {'lambda': 0.0018104838952691495, 'alpha': 0.014581416070468362, 'colsample_bytree': 0.3, 'subsample': 1.0, 'learning_rate': 0.18009999999999998, 'n_estimators': 804}. Best is trial 56 with value: 0.7102857142857144.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-01-12 01:53:19,428]\u001b[0m Trial 64 finished with value: 0.7004761904761907 and parameters: {'lambda': 0.0024756254478756406, 'alpha': 0.052568127938742146, 'colsample_bytree': 0.3, 'subsample': 1.0, 'learning_rate': 0.14509999999999998, 'n_estimators': 764}. Best is trial 56 with value: 0.7102857142857144.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-01-12 01:53:21,329]\u001b[0m Trial 65 finished with value: 0.6792380952380952 and parameters: {'lambda': 0.0028689485895962183, 'alpha': 0.04629073394230276, 'colsample_bytree': 0.9000000000000001, 'subsample': 0.9, 'learning_rate': 0.1351, 'n_estimators': 765}. Best is trial 56 with value: 0.7102857142857144.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-01-12 01:53:22,970]\u001b[0m Trial 66 finished with value: 0.6595238095238096 and parameters: {'lambda': 0.001014578900194637, 'alpha': 0.36043897298369987, 'colsample_bytree': 0.4, 'subsample': 1.0, 'learning_rate': 0.14509999999999998, 'n_estimators': 761}. Best is trial 56 with value: 0.7102857142857144.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-01-12 01:53:25,064]\u001b[0m Trial 67 finished with value: 0.6751428571428572 and parameters: {'lambda': 0.01737522874540943, 'alpha': 0.05780931059819181, 'colsample_bytree': 1.0, 'subsample': 0.9, 'learning_rate': 0.15009999999999998, 'n_estimators': 815}. Best is trial 56 with value: 0.7102857142857144.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-01-12 01:53:27,445]\u001b[0m Trial 68 finished with value: 0.6863809523809524 and parameters: {'lambda': 0.0015222664201042758, 'alpha': 0.11020953113272494, 'colsample_bytree': 0.3, 'subsample': 1.0, 'learning_rate': 0.1301, 'n_estimators': 936}. Best is trial 56 with value: 0.7102857142857144.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-01-12 01:53:29,694]\u001b[0m Trial 69 finished with value: 0.6778095238095238 and parameters: {'lambda': 0.003426341240967464, 'alpha': 0.03256146187092011, 'colsample_bytree': 0.4, 'subsample': 1.0, 'learning_rate': 0.1751, 'n_estimators': 866}. Best is trial 56 with value: 0.7102857142857144.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-01-12 01:53:31,832]\u001b[0m Trial 70 finished with value: 0.6820952380952382 and parameters: {'lambda': 0.005384501751833538, 'alpha': 0.022922639033061288, 'colsample_bytree': 0.4, 'subsample': 0.9, 'learning_rate': 0.14509999999999998, 'n_estimators': 905}. Best is trial 56 with value: 0.7102857142857144.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-01-12 01:53:34,361]\u001b[0m Trial 71 finished with value: 0.6932380952380954 and parameters: {'lambda': 0.0038325905699101567, 'alpha': 0.02051598231771764, 'colsample_bytree': 0.3, 'subsample': 1.0, 'learning_rate': 0.1651, 'n_estimators': 965}. Best is trial 56 with value: 0.7102857142857144.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-01-12 01:53:36,703]\u001b[0m Trial 72 finished with value: 0.7002857142857144 and parameters: {'lambda': 0.0024577069483295065, 'alpha': 0.007109582478627625, 'colsample_bytree': 0.3, 'subsample': 1.0, 'learning_rate': 0.1551, 'n_estimators': 896}. Best is trial 56 with value: 0.7102857142857144.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-01-12 01:53:38,713]\u001b[0m Trial 73 finished with value: 0.6973333333333335 and parameters: {'lambda': 0.0024282570038449054, 'alpha': 0.08294927790166803, 'colsample_bytree': 0.3, 'subsample': 1.0, 'learning_rate': 0.1551, 'n_estimators': 752}. Best is trial 56 with value: 0.7102857142857144.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-01-12 01:53:40,765]\u001b[0m Trial 74 finished with value: 0.6973333333333335 and parameters: {'lambda': 0.008296731719590096, 'alpha': 0.0073542298983549645, 'colsample_bytree': 0.3, 'subsample': 1.0, 'learning_rate': 0.1701, 'n_estimators': 787}. Best is trial 56 with value: 0.7102857142857144.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-01-12 01:53:42,888]\u001b[0m Trial 75 finished with value: 0.678952380952381 and parameters: {'lambda': 0.013459544298683093, 'alpha': 0.01606555197132388, 'colsample_bytree': 0.3, 'subsample': 0.5, 'learning_rate': 0.1251, 'n_estimators': 938}. Best is trial 56 with value: 0.7102857142857144.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-01-12 01:53:45,243]\u001b[0m Trial 76 finished with value: 0.6835238095238096 and parameters: {'lambda': 0.002432929541319386, 'alpha': 0.03867844669314933, 'colsample_bytree': 0.4, 'subsample': 1.0, 'learning_rate': 0.1551, 'n_estimators': 905}. Best is trial 56 with value: 0.7102857142857144.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-01-12 01:53:46,786]\u001b[0m Trial 77 finished with value: 0.6908571428571428 and parameters: {'lambda': 0.0014775448337385007, 'alpha': 0.008379965030471833, 'colsample_bytree': 0.3, 'subsample': 0.9, 'learning_rate': 0.1901, 'n_estimators': 647}. Best is trial 56 with value: 0.7102857142857144.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-01-12 01:53:48,713]\u001b[0m Trial 78 finished with value: 0.6807619047619049 and parameters: {'lambda': 0.006701372418938602, 'alpha': 0.004045620666985065, 'colsample_bytree': 0.4, 'subsample': 0.9, 'learning_rate': 0.14509999999999998, 'n_estimators': 820}. Best is trial 56 with value: 0.7102857142857144.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-01-12 01:53:50,849]\u001b[0m Trial 79 finished with value: 0.6876190476190479 and parameters: {'lambda': 0.003127746609011728, 'alpha': 0.025715495289677936, 'colsample_bytree': 0.3, 'subsample': 1.0, 'learning_rate': 0.18009999999999998, 'n_estimators': 858}. Best is trial 56 with value: 0.7102857142857144.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-01-12 01:53:52,896]\u001b[0m Trial 80 finished with value: 0.6960952380952383 and parameters: {'lambda': 0.0011720575701298413, 'alpha': 0.016807260672059614, 'colsample_bytree': 0.3, 'subsample': 1.0, 'learning_rate': 0.1651, 'n_estimators': 797}. Best is trial 56 with value: 0.7102857142857144.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-01-12 01:53:55,044]\u001b[0m Trial 81 finished with value: 0.7044761904761907 and parameters: {'lambda': 0.0020203854446397642, 'alpha': 0.013357193776383159, 'colsample_bytree': 0.3, 'subsample': 1.0, 'learning_rate': 0.1601, 'n_estimators': 877}. Best is trial 56 with value: 0.7102857142857144.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-01-12 01:53:57,400]\u001b[0m Trial 82 finished with value: 0.698857142857143 and parameters: {'lambda': 0.005019268124724571, 'alpha': 0.009246692653937827, 'colsample_bytree': 0.3, 'subsample': 1.0, 'learning_rate': 0.1701, 'n_estimators': 903}. Best is trial 56 with value: 0.7102857142857144.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-01-12 01:53:59,710]\u001b[0m Trial 83 finished with value: 0.6962857142857143 and parameters: {'lambda': 0.002471192899337615, 'alpha': 0.014195787739054177, 'colsample_bytree': 0.3, 'subsample': 1.0, 'learning_rate': 0.1351, 'n_estimators': 863}. Best is trial 56 with value: 0.7102857142857144.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-01-12 01:54:01,031]\u001b[0m Trial 84 finished with value: 0.6265714285714286 and parameters: {'lambda': 0.0020518609785551635, 'alpha': 2.3474089145676693, 'colsample_bytree': 0.3, 'subsample': 1.0, 'learning_rate': 0.1551, 'n_estimators': 709}. Best is trial 56 with value: 0.7102857142857144.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-01-12 01:54:03,502]\u001b[0m Trial 85 finished with value: 0.6877142857142857 and parameters: {'lambda': 0.0016715687766010845, 'alpha': 0.007252154293450322, 'colsample_bytree': 0.4, 'subsample': 1.0, 'learning_rate': 0.1401, 'n_estimators': 973}. Best is trial 56 with value: 0.7102857142857144.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-01-12 01:54:05,680]\u001b[0m Trial 86 finished with value: 0.6807619047619048 and parameters: {'lambda': 0.004042017054172613, 'alpha': 0.019549267963618795, 'colsample_bytree': 0.3, 'subsample': 0.9, 'learning_rate': 0.15009999999999998, 'n_estimators': 938}. Best is trial 56 with value: 0.7102857142857144.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-01-12 01:54:07,852]\u001b[0m Trial 87 finished with value: 0.7031428571428572 and parameters: {'lambda': 0.023473634497896897, 'alpha': 0.005636601005747783, 'colsample_bytree': 0.3, 'subsample': 1.0, 'learning_rate': 0.1601, 'n_estimators': 848}. Best is trial 56 with value: 0.7102857142857144.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-01-12 01:54:10,073]\u001b[0m Trial 88 finished with value: 0.6862857142857144 and parameters: {'lambda': 0.03357853084274716, 'alpha': 0.004764047018815245, 'colsample_bytree': 0.4, 'subsample': 1.0, 'learning_rate': 0.1751, 'n_estimators': 843}. Best is trial 56 with value: 0.7102857142857144.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-01-12 01:54:12,340]\u001b[0m Trial 89 finished with value: 0.7031428571428572 and parameters: {'lambda': 0.00851847070190272, 'alpha': 0.010913691529586302, 'colsample_bytree': 0.3, 'subsample': 1.0, 'learning_rate': 0.1651, 'n_estimators': 816}. Best is trial 56 with value: 0.7102857142857144.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-01-12 01:54:14,158]\u001b[0m Trial 90 finished with value: 0.6907619047619049 and parameters: {'lambda': 0.026298523095546197, 'alpha': 0.002337637077580732, 'colsample_bytree': 0.3, 'subsample': 0.9, 'learning_rate': 0.18009999999999998, 'n_estimators': 767}. Best is trial 56 with value: 0.7102857142857144.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-01-12 01:54:16,189]\u001b[0m Trial 91 finished with value: 0.6889523809523811 and parameters: {'lambda': 0.007679646889123362, 'alpha': 0.003095610150491639, 'colsample_bytree': 0.3, 'subsample': 1.0, 'learning_rate': 0.1651, 'n_estimators': 817}. Best is trial 56 with value: 0.7102857142857144.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-01-12 01:54:18,346]\u001b[0m Trial 92 finished with value: 0.698857142857143 and parameters: {'lambda': 0.019627147648464925, 'alpha': 0.010308846754474606, 'colsample_bytree': 0.3, 'subsample': 1.0, 'learning_rate': 0.14509999999999998, 'n_estimators': 789}. Best is trial 56 with value: 0.7102857142857144.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-01-12 01:54:20,399]\u001b[0m Trial 93 finished with value: 0.6989523809523811 and parameters: {'lambda': 0.012104952676441646, 'alpha': 0.03039331547668624, 'colsample_bytree': 0.3, 'subsample': 1.0, 'learning_rate': 0.1601, 'n_estimators': 742}. Best is trial 56 with value: 0.7102857142857144.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-01-12 01:54:21,764]\u001b[0m Trial 94 finished with value: 0.7060000000000001 and parameters: {'lambda': 0.005758744911796952, 'alpha': 0.00592458636159379, 'colsample_bytree': 0.3, 'subsample': 1.0, 'learning_rate': 0.1551, 'n_estimators': 489}. Best is trial 56 with value: 0.7102857142857144.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-01-12 01:54:23,361]\u001b[0m Trial 95 finished with value: 0.7003809523809525 and parameters: {'lambda': 0.05944768953566761, 'alpha': 0.00537721962184014, 'colsample_bytree': 0.3, 'subsample': 1.0, 'learning_rate': 0.15009999999999998, 'n_estimators': 559}. Best is trial 56 with value: 0.7102857142857144.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-01-12 01:54:24,709]\u001b[0m Trial 96 finished with value: 0.6947619047619048 and parameters: {'lambda': 0.04615810486191638, 'alpha': 0.005041871944751029, 'colsample_bytree': 0.3, 'subsample': 1.0, 'learning_rate': 0.15009999999999998, 'n_estimators': 482}. Best is trial 56 with value: 0.7102857142857144.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-01-12 01:54:25,993]\u001b[0m Trial 97 finished with value: 0.6821904761904762 and parameters: {'lambda': 0.009891164357898056, 'alpha': 0.0036417886687594215, 'colsample_bytree': 0.4, 'subsample': 1.0, 'learning_rate': 0.1701, 'n_estimators': 462}. Best is trial 56 with value: 0.7102857142857144.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-01-12 01:54:28,093]\u001b[0m Trial 98 finished with value: 0.6793333333333336 and parameters: {'lambda': 0.07346609827384647, 'alpha': 0.0017648041937854684, 'colsample_bytree': 0.3, 'subsample': 0.9, 'learning_rate': 0.1351, 'n_estimators': 557}. Best is trial 56 with value: 0.7102857142857144.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-01-12 01:54:32,881]\u001b[0m Trial 99 finished with value: 0.6862857142857142 and parameters: {'lambda': 0.005843712147701568, 'alpha': 0.010227730927162207, 'colsample_bytree': 0.4, 'subsample': 1.0, 'learning_rate': 0.1651, 'n_estimators': 681}. Best is trial 56 with value: 0.7102857142857144.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "#Tuning hyperparameters\n",
    "#Step 1. Define an objective function to be maximized.\n",
    "def objective(trial):\n",
    "    param = {\n",
    "        'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
    "        'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
    "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.3,1.0,step=0.1),\n",
    "        'subsample': trial.suggest_float('subsample', 0.4, 1.0, step=0.1),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.0001, 0.2, step=0.005),\n",
    "        'n_estimators': trial.suggest_int(\"n_estimators\",50,1000,1)\n",
    "        #'min_child_weight': trial.suggest_int('min_child_weight', 1, 300),\n",
    "    }\n",
    "    model = xgb.XGBClassifier(**param,random_state=1,n_jobs=8)\n",
    "\n",
    " \n",
    "# Step 2: Scoring method:\n",
    "    score = model_selection.cross_val_score(model, X, y, n_jobs=8, scoring=\"accuracy\",cv=Cv_optuna)\n",
    "    accuracy = score.mean()\n",
    "    return accuracy\n",
    "\n",
    "# Step 3: Running it\n",
    "study = optuna.create_study(direction=\"maximize\",sampler=optuna.samplers.TPESampler(seed=0))\n",
    "study.optimize(objective, n_trials=100, show_progress_bar=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "61fd4c6f-d6af-4f71-8f40-73e5cb7f1a34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best parameters are : \n",
      "{'lambda': 0.0013221304985698086, 'alpha': 0.02305461805888264, 'colsample_bytree': 0.3, 'subsample': 1.0, 'learning_rate': 0.15009999999999998, 'n_estimators': 884}\n"
     ]
    }
   ],
   "source": [
    "# Getting the best parameters:\n",
    "print(f\"The best parameters are : \\n{study.best_params}\")\n",
    "# Setting the best model\n",
    "clf=xgb.XGBClassifier(alpha = study.best_params['alpha']\n",
    "              ,colsample_bytree = study.best_params['colsample_bytree']\n",
    "              ,subsample = study.best_params['subsample']\n",
    "              ,n_estimators = study.best_params['n_estimators']\n",
    "              ,learning_rate= study.best_params['learning_rate'], n_jobs=8\n",
    "              ,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "4b5d7bd3-660b-42d3-9546-2633863cc8ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mean</th>\n",
       "      <th>Se</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Accuracy_test</th>\n",
       "      <td>0.682000</td>\n",
       "      <td>0.015467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Accuracy_train</th>\n",
       "      <td>0.978164</td>\n",
       "      <td>0.001539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1 Score</th>\n",
       "      <td>0.710276</td>\n",
       "      <td>0.015000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Precision</th>\n",
       "      <td>0.693874</td>\n",
       "      <td>0.013624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recall</th>\n",
       "      <td>0.748214</td>\n",
       "      <td>0.023279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Roc_auc</th>\n",
       "      <td>0.752117</td>\n",
       "      <td>0.018448</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Mean        Se\n",
       "Accuracy_test   0.682000  0.015467\n",
       "Accuracy_train  0.978164  0.001539\n",
       "F1 Score        0.710276  0.015000\n",
       "Precision       0.693874  0.013624\n",
       "Recall          0.748214  0.023279\n",
       "Roc_auc         0.752117  0.018448"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Model2=Model_results(clf,X,y,Cv_model)\n",
    "Model2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "a8261ab4-67a6-445c-8d21-feddad6b3796",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th>Method</th>\n",
       "      <th colspan=\"4\" halign=\"left\">XGB</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model</th>\n",
       "      <th colspan=\"2\" halign=\"left\">Model 1</th>\n",
       "      <th colspan=\"2\" halign=\"left\">Model 2</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Values</th>\n",
       "      <th>Mean</th>\n",
       "      <th>Se</th>\n",
       "      <th>Mean</th>\n",
       "      <th>Se</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Accuracy_test</th>\n",
       "      <td>0.662476</td>\n",
       "      <td>0.016918</td>\n",
       "      <td>0.682000</td>\n",
       "      <td>0.015467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Accuracy_train</th>\n",
       "      <td>0.978164</td>\n",
       "      <td>0.001539</td>\n",
       "      <td>0.978164</td>\n",
       "      <td>0.001539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1 Score</th>\n",
       "      <td>0.693483</td>\n",
       "      <td>0.017356</td>\n",
       "      <td>0.710276</td>\n",
       "      <td>0.015000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Precision</th>\n",
       "      <td>0.671509</td>\n",
       "      <td>0.015551</td>\n",
       "      <td>0.693874</td>\n",
       "      <td>0.013624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recall</th>\n",
       "      <td>0.737143</td>\n",
       "      <td>0.025112</td>\n",
       "      <td>0.748214</td>\n",
       "      <td>0.023279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Roc_auc</th>\n",
       "      <td>0.749660</td>\n",
       "      <td>0.017686</td>\n",
       "      <td>0.752117</td>\n",
       "      <td>0.018448</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Method               XGB                              \n",
       "Model            Model 1             Model 2          \n",
       "Values              Mean        Se      Mean        Se\n",
       "Accuracy_test   0.662476  0.016918  0.682000  0.015467\n",
       "Accuracy_train  0.978164  0.001539  0.978164  0.001539\n",
       "F1 Score        0.693483  0.017356  0.710276  0.015000\n",
       "Precision       0.671509  0.015551  0.693874  0.013624\n",
       "Recall          0.737143  0.025112  0.748214  0.023279\n",
       "Roc_auc         0.749660  0.017686  0.752117  0.018448"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Saving the data of model performance\n",
    "Model_data=pd.concat([Model1,Model2],axis=1)\n",
    "Model_data.columns = [['XGB']*4,['Model 1','Model 1', 'Model 2','Model 2'], ['Mean', 'Se', 'Mean', 'Se']]  \n",
    "Model_data.columns.names=['Method','Model','Values']\n",
    "Model_data.to_csv(\"./Results/XGB_model_mlrem_data.csv\",sep=',')\n",
    "Model_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec50adff-12d7-4284-a740-a33a46351d03",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hydrogel",
   "language": "python",
   "name": "hydrogel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
