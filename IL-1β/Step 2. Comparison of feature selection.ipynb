{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "50559d19-ab40-4880-bae7-44a3dbe180a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Others\n",
    "import random\n",
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "from pandas import Series\n",
    "import numpy as np\n",
    "import math\n",
    "import os\n",
    "import warnings\n",
    "import optuna\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "70ff5d38-60c9-476d-a509-9e1419bea2b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing packages\n",
    "#Sklearn\n",
    "from sklearn import model_selection, linear_model\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.feature_selection import RFECV,SelectFromModel\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV,RandomizedSearchCV,RepeatedStratifiedKFold,cross_validate\n",
    "from sklearn.metrics import accuracy_score,precision_score,recall_score,f1_score,auc,roc_auc_score,roc_curve,classification_report\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.linear_model import Ridge, LinearRegression, Lasso\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a6baca9e-4a5b-4e5f-9cd3-2db48c543dc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LassoCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bc75945b-ce4f-4650-8380-f7bfb5ff1b51",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"C:/Users/A/Desktop/Bioactive/IL-1β\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "12865361-291e-449c-8ca4-53ed95b92f16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1134, 3964)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MW</th>\n",
       "      <th>AMW</th>\n",
       "      <th>Sv</th>\n",
       "      <th>Se</th>\n",
       "      <th>Sp</th>\n",
       "      <th>Si</th>\n",
       "      <th>Mv</th>\n",
       "      <th>Me</th>\n",
       "      <th>Mp</th>\n",
       "      <th>Mi</th>\n",
       "      <th>...</th>\n",
       "      <th>s1_numAroBonds</th>\n",
       "      <th>s2_numAroBonds</th>\n",
       "      <th>s3_numAroBonds</th>\n",
       "      <th>s4_numAroBonds</th>\n",
       "      <th>s34_size</th>\n",
       "      <th>s34_relSize</th>\n",
       "      <th>s34_phSize</th>\n",
       "      <th>s34_phRelSize</th>\n",
       "      <th>chiralMoment</th>\n",
       "      <th>chiralPhMoment</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OPTUM_LAB_ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>53300413.0</th>\n",
       "      <td>704.02</td>\n",
       "      <td>6.518704</td>\n",
       "      <td>63.0926</td>\n",
       "      <td>107.4464</td>\n",
       "      <td>67.5519</td>\n",
       "      <td>122.5431</td>\n",
       "      <td>0.584191</td>\n",
       "      <td>0.994874</td>\n",
       "      <td>0.625481</td>\n",
       "      <td>1.134658</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>46.75</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>10.625</td>\n",
       "      <td>0.208333</td>\n",
       "      <td>50.709541</td>\n",
       "      <td>12.001003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49795501.0</th>\n",
       "      <td>373.47</td>\n",
       "      <td>7.322941</td>\n",
       "      <td>31.3867</td>\n",
       "      <td>51.5196</td>\n",
       "      <td>32.6935</td>\n",
       "      <td>58.0300</td>\n",
       "      <td>0.615425</td>\n",
       "      <td>1.010188</td>\n",
       "      <td>0.641049</td>\n",
       "      <td>1.137843</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>23.50</td>\n",
       "      <td>0.870370</td>\n",
       "      <td>6.000</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>21.400935</td>\n",
       "      <td>6.633250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9551212.0</th>\n",
       "      <td>487.74</td>\n",
       "      <td>6.869577</td>\n",
       "      <td>41.8673</td>\n",
       "      <td>70.7049</td>\n",
       "      <td>45.2221</td>\n",
       "      <td>80.6829</td>\n",
       "      <td>0.589680</td>\n",
       "      <td>0.995844</td>\n",
       "      <td>0.636931</td>\n",
       "      <td>1.136379</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53300217.0</th>\n",
       "      <td>515.47</td>\n",
       "      <td>8.182063</td>\n",
       "      <td>40.9322</td>\n",
       "      <td>63.5306</td>\n",
       "      <td>43.2048</td>\n",
       "      <td>70.5350</td>\n",
       "      <td>0.649717</td>\n",
       "      <td>1.008422</td>\n",
       "      <td>0.685790</td>\n",
       "      <td>1.119603</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>25.50</td>\n",
       "      <td>0.728571</td>\n",
       "      <td>4.000</td>\n",
       "      <td>0.114286</td>\n",
       "      <td>20.296826</td>\n",
       "      <td>3.602880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1254489.0</th>\n",
       "      <td>477.98</td>\n",
       "      <td>8.241034</td>\n",
       "      <td>38.5457</td>\n",
       "      <td>58.6579</td>\n",
       "      <td>40.0684</td>\n",
       "      <td>64.8437</td>\n",
       "      <td>0.664581</td>\n",
       "      <td>1.011343</td>\n",
       "      <td>0.690834</td>\n",
       "      <td>1.117995</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 3964 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  MW       AMW       Sv        Se       Sp        Si  \\\n",
       "OPTUM_LAB_ID                                                           \n",
       "53300413.0    704.02  6.518704  63.0926  107.4464  67.5519  122.5431   \n",
       "49795501.0    373.47  7.322941  31.3867   51.5196  32.6935   58.0300   \n",
       "9551212.0     487.74  6.869577  41.8673   70.7049  45.2221   80.6829   \n",
       "53300217.0    515.47  8.182063  40.9322   63.5306  43.2048   70.5350   \n",
       "1254489.0     477.98  8.241034  38.5457   58.6579  40.0684   64.8437   \n",
       "\n",
       "                    Mv        Me        Mp        Mi  ...  s1_numAroBonds  \\\n",
       "OPTUM_LAB_ID                                          ...                   \n",
       "53300413.0    0.584191  0.994874  0.625481  1.134658  ...             0.0   \n",
       "49795501.0    0.615425  1.010188  0.641049  1.137843  ...             0.0   \n",
       "9551212.0     0.589680  0.995844  0.636931  1.136379  ...             0.0   \n",
       "53300217.0    0.649717  1.008422  0.685790  1.119603  ...             0.0   \n",
       "1254489.0     0.664581  1.011343  0.690834  1.117995  ...             0.0   \n",
       "\n",
       "              s2_numAroBonds  s3_numAroBonds  s4_numAroBonds  s34_size  \\\n",
       "OPTUM_LAB_ID                                                             \n",
       "53300413.0               0.0             6.0             6.0     46.75   \n",
       "49795501.0               0.0             5.0             6.0     23.50   \n",
       "9551212.0                0.0             0.0             0.0      0.00   \n",
       "53300217.0               0.0             6.0             6.0     25.50   \n",
       "1254489.0                0.0             0.0             0.0      0.00   \n",
       "\n",
       "              s34_relSize  s34_phSize  s34_phRelSize  chiralMoment  \\\n",
       "OPTUM_LAB_ID                                                         \n",
       "53300413.0       0.916667      10.625       0.208333     50.709541   \n",
       "49795501.0       0.870370       6.000       0.222222     21.400935   \n",
       "9551212.0        0.000000       0.000       0.000000      0.000000   \n",
       "53300217.0       0.728571       4.000       0.114286     20.296826   \n",
       "1254489.0        0.000000       0.000       0.000000      0.000000   \n",
       "\n",
       "              chiralPhMoment  \n",
       "OPTUM_LAB_ID                  \n",
       "53300413.0         12.001003  \n",
       "49795501.0          6.633250  \n",
       "9551212.0           0.000000  \n",
       "53300217.0          3.602880  \n",
       "1254489.0           0.000000  \n",
       "\n",
       "[5 rows x 3964 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Reading the data\n",
    "ML_data= pd.read_csv(\"./ML_data.csv\",header=0,index_col=0)\n",
    "X_NAomit_data= pd.read_csv(\"./X_NAomit_data.csv\",header=0,index_col=0)\n",
    "Raw_data = pd.read_csv('./data_psm.csv',index_col=0)\n",
    "\n",
    "#original data(descriptors= 4175）\n",
    "print(X_NAomit_data.shape)\n",
    "X_NAomit_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a68cc910-dca6-4b63-ae90-8fac100e1ac6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MW</th>\n",
       "      <th>AMW</th>\n",
       "      <th>Sv</th>\n",
       "      <th>Se</th>\n",
       "      <th>Sp</th>\n",
       "      <th>Si</th>\n",
       "      <th>Mv</th>\n",
       "      <th>Me</th>\n",
       "      <th>Mp</th>\n",
       "      <th>Mi</th>\n",
       "      <th>...</th>\n",
       "      <th>s1_numAroBonds</th>\n",
       "      <th>s2_numAroBonds</th>\n",
       "      <th>s3_numAroBonds</th>\n",
       "      <th>s4_numAroBonds</th>\n",
       "      <th>s34_size</th>\n",
       "      <th>s34_relSize</th>\n",
       "      <th>s34_phSize</th>\n",
       "      <th>s34_phRelSize</th>\n",
       "      <th>chiralMoment</th>\n",
       "      <th>chiralPhMoment</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OPTUM_LAB_ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>53300413.0</th>\n",
       "      <td>704.02</td>\n",
       "      <td>6.518704</td>\n",
       "      <td>63.0926</td>\n",
       "      <td>107.4464</td>\n",
       "      <td>67.5519</td>\n",
       "      <td>122.5431</td>\n",
       "      <td>0.584191</td>\n",
       "      <td>0.994874</td>\n",
       "      <td>0.625481</td>\n",
       "      <td>1.134658</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>46.750000</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>10.625000</td>\n",
       "      <td>0.208333</td>\n",
       "      <td>50.709541</td>\n",
       "      <td>12.001003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49795501.0</th>\n",
       "      <td>373.47</td>\n",
       "      <td>7.322941</td>\n",
       "      <td>31.3867</td>\n",
       "      <td>51.5196</td>\n",
       "      <td>32.6935</td>\n",
       "      <td>58.0300</td>\n",
       "      <td>0.615425</td>\n",
       "      <td>1.010188</td>\n",
       "      <td>0.641049</td>\n",
       "      <td>1.137843</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>23.500000</td>\n",
       "      <td>0.870370</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>21.400935</td>\n",
       "      <td>6.633250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9551212.0</th>\n",
       "      <td>487.74</td>\n",
       "      <td>6.869577</td>\n",
       "      <td>41.8673</td>\n",
       "      <td>70.7049</td>\n",
       "      <td>45.2221</td>\n",
       "      <td>80.6829</td>\n",
       "      <td>0.589680</td>\n",
       "      <td>0.995844</td>\n",
       "      <td>0.636931</td>\n",
       "      <td>1.136379</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53300217.0</th>\n",
       "      <td>515.47</td>\n",
       "      <td>8.182063</td>\n",
       "      <td>40.9322</td>\n",
       "      <td>63.5306</td>\n",
       "      <td>43.2048</td>\n",
       "      <td>70.5350</td>\n",
       "      <td>0.649717</td>\n",
       "      <td>1.008422</td>\n",
       "      <td>0.685790</td>\n",
       "      <td>1.119603</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>25.500000</td>\n",
       "      <td>0.728571</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.114286</td>\n",
       "      <td>20.296826</td>\n",
       "      <td>3.602880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1254489.0</th>\n",
       "      <td>477.98</td>\n",
       "      <td>8.241034</td>\n",
       "      <td>38.5457</td>\n",
       "      <td>58.6579</td>\n",
       "      <td>40.0684</td>\n",
       "      <td>64.8437</td>\n",
       "      <td>0.664581</td>\n",
       "      <td>1.011343</td>\n",
       "      <td>0.690834</td>\n",
       "      <td>1.117995</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53382587.0</th>\n",
       "      <td>306.35</td>\n",
       "      <td>7.658750</td>\n",
       "      <td>24.8312</td>\n",
       "      <td>40.9089</td>\n",
       "      <td>25.3751</td>\n",
       "      <td>45.3652</td>\n",
       "      <td>0.620780</td>\n",
       "      <td>1.022722</td>\n",
       "      <td>0.634378</td>\n",
       "      <td>1.134130</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>0.772727</td>\n",
       "      <td>5.666667</td>\n",
       "      <td>0.257576</td>\n",
       "      <td>14.965511</td>\n",
       "      <td>5.130768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53301482.0</th>\n",
       "      <td>559.66</td>\n",
       "      <td>7.882535</td>\n",
       "      <td>47.4866</td>\n",
       "      <td>71.4287</td>\n",
       "      <td>49.1878</td>\n",
       "      <td>78.9395</td>\n",
       "      <td>0.668825</td>\n",
       "      <td>1.006038</td>\n",
       "      <td>0.692786</td>\n",
       "      <td>1.111824</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>34.500000</td>\n",
       "      <td>0.821429</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>0.190476</td>\n",
       "      <td>39.408121</td>\n",
       "      <td>9.797959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53301383.0</th>\n",
       "      <td>298.40</td>\n",
       "      <td>7.852632</td>\n",
       "      <td>23.3035</td>\n",
       "      <td>38.6580</td>\n",
       "      <td>24.5683</td>\n",
       "      <td>43.0758</td>\n",
       "      <td>0.613250</td>\n",
       "      <td>1.017316</td>\n",
       "      <td>0.646534</td>\n",
       "      <td>1.133574</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>5.500000</td>\n",
       "      <td>0.275000</td>\n",
       "      <td>22.053235</td>\n",
       "      <td>7.123106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53301632.0</th>\n",
       "      <td>499.57</td>\n",
       "      <td>8.057581</td>\n",
       "      <td>40.9490</td>\n",
       "      <td>62.9815</td>\n",
       "      <td>41.9150</td>\n",
       "      <td>69.6905</td>\n",
       "      <td>0.660468</td>\n",
       "      <td>1.015831</td>\n",
       "      <td>0.676048</td>\n",
       "      <td>1.124040</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>0.810811</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>0.270270</td>\n",
       "      <td>25.455844</td>\n",
       "      <td>10.392305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53301556.0</th>\n",
       "      <td>508.69</td>\n",
       "      <td>7.480735</td>\n",
       "      <td>42.7059</td>\n",
       "      <td>68.1705</td>\n",
       "      <td>45.3526</td>\n",
       "      <td>76.1916</td>\n",
       "      <td>0.628028</td>\n",
       "      <td>1.002507</td>\n",
       "      <td>0.666950</td>\n",
       "      <td>1.120465</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>31.333333</td>\n",
       "      <td>0.870370</td>\n",
       "      <td>6.333333</td>\n",
       "      <td>0.175926</td>\n",
       "      <td>40.126995</td>\n",
       "      <td>9.090127</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1134 rows × 3964 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  MW       AMW       Sv        Se       Sp        Si  \\\n",
       "OPTUM_LAB_ID                                                           \n",
       "53300413.0    704.02  6.518704  63.0926  107.4464  67.5519  122.5431   \n",
       "49795501.0    373.47  7.322941  31.3867   51.5196  32.6935   58.0300   \n",
       "9551212.0     487.74  6.869577  41.8673   70.7049  45.2221   80.6829   \n",
       "53300217.0    515.47  8.182063  40.9322   63.5306  43.2048   70.5350   \n",
       "1254489.0     477.98  8.241034  38.5457   58.6579  40.0684   64.8437   \n",
       "...              ...       ...      ...       ...      ...       ...   \n",
       "53382587.0    306.35  7.658750  24.8312   40.9089  25.3751   45.3652   \n",
       "53301482.0    559.66  7.882535  47.4866   71.4287  49.1878   78.9395   \n",
       "53301383.0    298.40  7.852632  23.3035   38.6580  24.5683   43.0758   \n",
       "53301632.0    499.57  8.057581  40.9490   62.9815  41.9150   69.6905   \n",
       "53301556.0    508.69  7.480735  42.7059   68.1705  45.3526   76.1916   \n",
       "\n",
       "                    Mv        Me        Mp        Mi  ...  s1_numAroBonds  \\\n",
       "OPTUM_LAB_ID                                          ...                   \n",
       "53300413.0    0.584191  0.994874  0.625481  1.134658  ...             0.0   \n",
       "49795501.0    0.615425  1.010188  0.641049  1.137843  ...             0.0   \n",
       "9551212.0     0.589680  0.995844  0.636931  1.136379  ...             0.0   \n",
       "53300217.0    0.649717  1.008422  0.685790  1.119603  ...             0.0   \n",
       "1254489.0     0.664581  1.011343  0.690834  1.117995  ...             0.0   \n",
       "...                ...       ...       ...       ...  ...             ...   \n",
       "53382587.0    0.620780  1.022722  0.634378  1.134130  ...             0.0   \n",
       "53301482.0    0.668825  1.006038  0.692786  1.111824  ...             0.0   \n",
       "53301383.0    0.613250  1.017316  0.646534  1.133574  ...             0.0   \n",
       "53301632.0    0.660468  1.015831  0.676048  1.124040  ...             0.0   \n",
       "53301556.0    0.628028  1.002507  0.666950  1.120465  ...             0.0   \n",
       "\n",
       "              s2_numAroBonds  s3_numAroBonds  s4_numAroBonds   s34_size  \\\n",
       "OPTUM_LAB_ID                                                              \n",
       "53300413.0               0.0             6.0             6.0  46.750000   \n",
       "49795501.0               0.0             5.0             6.0  23.500000   \n",
       "9551212.0                0.0             0.0             0.0   0.000000   \n",
       "53300217.0               0.0             6.0             6.0  25.500000   \n",
       "1254489.0                0.0             0.0             0.0   0.000000   \n",
       "...                      ...             ...             ...        ...   \n",
       "53382587.0               0.0             2.0             6.0  17.000000   \n",
       "53301482.0               6.0             5.0            18.0  34.500000   \n",
       "53301383.0               0.0             1.0             4.0  18.000000   \n",
       "53301632.0               6.0             6.0            11.0  30.000000   \n",
       "53301556.0               2.0             4.0            12.0  31.333333   \n",
       "\n",
       "              s34_relSize  s34_phSize  s34_phRelSize  chiralMoment  \\\n",
       "OPTUM_LAB_ID                                                         \n",
       "53300413.0       0.916667   10.625000       0.208333     50.709541   \n",
       "49795501.0       0.870370    6.000000       0.222222     21.400935   \n",
       "9551212.0        0.000000    0.000000       0.000000      0.000000   \n",
       "53300217.0       0.728571    4.000000       0.114286     20.296826   \n",
       "1254489.0        0.000000    0.000000       0.000000      0.000000   \n",
       "...                   ...         ...            ...           ...   \n",
       "53382587.0       0.772727    5.666667       0.257576     14.965511   \n",
       "53301482.0       0.821429    8.000000       0.190476     39.408121   \n",
       "53301383.0       0.900000    5.500000       0.275000     22.053235   \n",
       "53301632.0       0.810811   10.000000       0.270270     25.455844   \n",
       "53301556.0       0.870370    6.333333       0.175926     40.126995   \n",
       "\n",
       "              chiralPhMoment  \n",
       "OPTUM_LAB_ID                  \n",
       "53300413.0         12.001003  \n",
       "49795501.0          6.633250  \n",
       "9551212.0           0.000000  \n",
       "53300217.0          3.602880  \n",
       "1254489.0           0.000000  \n",
       "...                      ...  \n",
       "53382587.0          5.130768  \n",
       "53301482.0          9.797959  \n",
       "53301383.0          7.123106  \n",
       "53301632.0         10.392305  \n",
       "53301556.0          9.090127  \n",
       "\n",
       "[1134 rows x 3964 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_NAomit_data= pd.read_csv(\"./X_NAomit_data.csv\",header=0,index_col=0)\n",
    "X_NAomit_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e1c89e32-9d35-4229-a7fd-6dc4bc6e3b4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "col_data= pd.read_csv(\"./X_NAomit_data.csv\",header=0,index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c075c2f5-c839-4ab6-8f1d-ee4e808c3238",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MW</th>\n",
       "      <th>AMW</th>\n",
       "      <th>Sv</th>\n",
       "      <th>Se</th>\n",
       "      <th>Sp</th>\n",
       "      <th>Si</th>\n",
       "      <th>Mv</th>\n",
       "      <th>Me</th>\n",
       "      <th>Mp</th>\n",
       "      <th>Mi</th>\n",
       "      <th>...</th>\n",
       "      <th>s1_numAroBonds</th>\n",
       "      <th>s2_numAroBonds</th>\n",
       "      <th>s3_numAroBonds</th>\n",
       "      <th>s4_numAroBonds</th>\n",
       "      <th>s34_size</th>\n",
       "      <th>s34_relSize</th>\n",
       "      <th>s34_phSize</th>\n",
       "      <th>s34_phRelSize</th>\n",
       "      <th>chiralMoment</th>\n",
       "      <th>chiralPhMoment</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OPTUM_LAB_ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>53300413.0</th>\n",
       "      <td>704.02</td>\n",
       "      <td>6.518704</td>\n",
       "      <td>63.0926</td>\n",
       "      <td>107.4464</td>\n",
       "      <td>67.5519</td>\n",
       "      <td>122.5431</td>\n",
       "      <td>0.584191</td>\n",
       "      <td>0.994874</td>\n",
       "      <td>0.625481</td>\n",
       "      <td>1.134658</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>46.750000</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>10.625000</td>\n",
       "      <td>0.208333</td>\n",
       "      <td>50.709541</td>\n",
       "      <td>12.001003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49795501.0</th>\n",
       "      <td>373.47</td>\n",
       "      <td>7.322941</td>\n",
       "      <td>31.3867</td>\n",
       "      <td>51.5196</td>\n",
       "      <td>32.6935</td>\n",
       "      <td>58.0300</td>\n",
       "      <td>0.615425</td>\n",
       "      <td>1.010188</td>\n",
       "      <td>0.641049</td>\n",
       "      <td>1.137843</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>23.500000</td>\n",
       "      <td>0.870370</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>21.400935</td>\n",
       "      <td>6.633250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9551212.0</th>\n",
       "      <td>487.74</td>\n",
       "      <td>6.869577</td>\n",
       "      <td>41.8673</td>\n",
       "      <td>70.7049</td>\n",
       "      <td>45.2221</td>\n",
       "      <td>80.6829</td>\n",
       "      <td>0.589680</td>\n",
       "      <td>0.995844</td>\n",
       "      <td>0.636931</td>\n",
       "      <td>1.136379</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53300217.0</th>\n",
       "      <td>515.47</td>\n",
       "      <td>8.182063</td>\n",
       "      <td>40.9322</td>\n",
       "      <td>63.5306</td>\n",
       "      <td>43.2048</td>\n",
       "      <td>70.5350</td>\n",
       "      <td>0.649717</td>\n",
       "      <td>1.008422</td>\n",
       "      <td>0.685790</td>\n",
       "      <td>1.119603</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>25.500000</td>\n",
       "      <td>0.728571</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.114286</td>\n",
       "      <td>20.296826</td>\n",
       "      <td>3.602880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1254489.0</th>\n",
       "      <td>477.98</td>\n",
       "      <td>8.241034</td>\n",
       "      <td>38.5457</td>\n",
       "      <td>58.6579</td>\n",
       "      <td>40.0684</td>\n",
       "      <td>64.8437</td>\n",
       "      <td>0.664581</td>\n",
       "      <td>1.011343</td>\n",
       "      <td>0.690834</td>\n",
       "      <td>1.117995</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53382587.0</th>\n",
       "      <td>306.35</td>\n",
       "      <td>7.658750</td>\n",
       "      <td>24.8312</td>\n",
       "      <td>40.9089</td>\n",
       "      <td>25.3751</td>\n",
       "      <td>45.3652</td>\n",
       "      <td>0.620780</td>\n",
       "      <td>1.022722</td>\n",
       "      <td>0.634378</td>\n",
       "      <td>1.134130</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>0.772727</td>\n",
       "      <td>5.666667</td>\n",
       "      <td>0.257576</td>\n",
       "      <td>14.965511</td>\n",
       "      <td>5.130768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53301482.0</th>\n",
       "      <td>559.66</td>\n",
       "      <td>7.882535</td>\n",
       "      <td>47.4866</td>\n",
       "      <td>71.4287</td>\n",
       "      <td>49.1878</td>\n",
       "      <td>78.9395</td>\n",
       "      <td>0.668825</td>\n",
       "      <td>1.006038</td>\n",
       "      <td>0.692786</td>\n",
       "      <td>1.111824</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>34.500000</td>\n",
       "      <td>0.821429</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>0.190476</td>\n",
       "      <td>39.408121</td>\n",
       "      <td>9.797959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53301383.0</th>\n",
       "      <td>298.40</td>\n",
       "      <td>7.852632</td>\n",
       "      <td>23.3035</td>\n",
       "      <td>38.6580</td>\n",
       "      <td>24.5683</td>\n",
       "      <td>43.0758</td>\n",
       "      <td>0.613250</td>\n",
       "      <td>1.017316</td>\n",
       "      <td>0.646534</td>\n",
       "      <td>1.133574</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>5.500000</td>\n",
       "      <td>0.275000</td>\n",
       "      <td>22.053235</td>\n",
       "      <td>7.123106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53301632.0</th>\n",
       "      <td>499.57</td>\n",
       "      <td>8.057581</td>\n",
       "      <td>40.9490</td>\n",
       "      <td>62.9815</td>\n",
       "      <td>41.9150</td>\n",
       "      <td>69.6905</td>\n",
       "      <td>0.660468</td>\n",
       "      <td>1.015831</td>\n",
       "      <td>0.676048</td>\n",
       "      <td>1.124040</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>0.810811</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>0.270270</td>\n",
       "      <td>25.455844</td>\n",
       "      <td>10.392305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53301556.0</th>\n",
       "      <td>508.69</td>\n",
       "      <td>7.480735</td>\n",
       "      <td>42.7059</td>\n",
       "      <td>68.1705</td>\n",
       "      <td>45.3526</td>\n",
       "      <td>76.1916</td>\n",
       "      <td>0.628028</td>\n",
       "      <td>1.002507</td>\n",
       "      <td>0.666950</td>\n",
       "      <td>1.120465</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>31.333333</td>\n",
       "      <td>0.870370</td>\n",
       "      <td>6.333333</td>\n",
       "      <td>0.175926</td>\n",
       "      <td>40.126995</td>\n",
       "      <td>9.090127</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1134 rows × 3964 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  MW       AMW       Sv        Se       Sp        Si  \\\n",
       "OPTUM_LAB_ID                                                           \n",
       "53300413.0    704.02  6.518704  63.0926  107.4464  67.5519  122.5431   \n",
       "49795501.0    373.47  7.322941  31.3867   51.5196  32.6935   58.0300   \n",
       "9551212.0     487.74  6.869577  41.8673   70.7049  45.2221   80.6829   \n",
       "53300217.0    515.47  8.182063  40.9322   63.5306  43.2048   70.5350   \n",
       "1254489.0     477.98  8.241034  38.5457   58.6579  40.0684   64.8437   \n",
       "...              ...       ...      ...       ...      ...       ...   \n",
       "53382587.0    306.35  7.658750  24.8312   40.9089  25.3751   45.3652   \n",
       "53301482.0    559.66  7.882535  47.4866   71.4287  49.1878   78.9395   \n",
       "53301383.0    298.40  7.852632  23.3035   38.6580  24.5683   43.0758   \n",
       "53301632.0    499.57  8.057581  40.9490   62.9815  41.9150   69.6905   \n",
       "53301556.0    508.69  7.480735  42.7059   68.1705  45.3526   76.1916   \n",
       "\n",
       "                    Mv        Me        Mp        Mi  ...  s1_numAroBonds  \\\n",
       "OPTUM_LAB_ID                                          ...                   \n",
       "53300413.0    0.584191  0.994874  0.625481  1.134658  ...             0.0   \n",
       "49795501.0    0.615425  1.010188  0.641049  1.137843  ...             0.0   \n",
       "9551212.0     0.589680  0.995844  0.636931  1.136379  ...             0.0   \n",
       "53300217.0    0.649717  1.008422  0.685790  1.119603  ...             0.0   \n",
       "1254489.0     0.664581  1.011343  0.690834  1.117995  ...             0.0   \n",
       "...                ...       ...       ...       ...  ...             ...   \n",
       "53382587.0    0.620780  1.022722  0.634378  1.134130  ...             0.0   \n",
       "53301482.0    0.668825  1.006038  0.692786  1.111824  ...             0.0   \n",
       "53301383.0    0.613250  1.017316  0.646534  1.133574  ...             0.0   \n",
       "53301632.0    0.660468  1.015831  0.676048  1.124040  ...             0.0   \n",
       "53301556.0    0.628028  1.002507  0.666950  1.120465  ...             0.0   \n",
       "\n",
       "              s2_numAroBonds  s3_numAroBonds  s4_numAroBonds   s34_size  \\\n",
       "OPTUM_LAB_ID                                                              \n",
       "53300413.0               0.0             6.0             6.0  46.750000   \n",
       "49795501.0               0.0             5.0             6.0  23.500000   \n",
       "9551212.0                0.0             0.0             0.0   0.000000   \n",
       "53300217.0               0.0             6.0             6.0  25.500000   \n",
       "1254489.0                0.0             0.0             0.0   0.000000   \n",
       "...                      ...             ...             ...        ...   \n",
       "53382587.0               0.0             2.0             6.0  17.000000   \n",
       "53301482.0               6.0             5.0            18.0  34.500000   \n",
       "53301383.0               0.0             1.0             4.0  18.000000   \n",
       "53301632.0               6.0             6.0            11.0  30.000000   \n",
       "53301556.0               2.0             4.0            12.0  31.333333   \n",
       "\n",
       "              s34_relSize  s34_phSize  s34_phRelSize  chiralMoment  \\\n",
       "OPTUM_LAB_ID                                                         \n",
       "53300413.0       0.916667   10.625000       0.208333     50.709541   \n",
       "49795501.0       0.870370    6.000000       0.222222     21.400935   \n",
       "9551212.0        0.000000    0.000000       0.000000      0.000000   \n",
       "53300217.0       0.728571    4.000000       0.114286     20.296826   \n",
       "1254489.0        0.000000    0.000000       0.000000      0.000000   \n",
       "...                   ...         ...            ...           ...   \n",
       "53382587.0       0.772727    5.666667       0.257576     14.965511   \n",
       "53301482.0       0.821429    8.000000       0.190476     39.408121   \n",
       "53301383.0       0.900000    5.500000       0.275000     22.053235   \n",
       "53301632.0       0.810811   10.000000       0.270270     25.455844   \n",
       "53301556.0       0.870370    6.333333       0.175926     40.126995   \n",
       "\n",
       "              chiralPhMoment  \n",
       "OPTUM_LAB_ID                  \n",
       "53300413.0         12.001003  \n",
       "49795501.0          6.633250  \n",
       "9551212.0           0.000000  \n",
       "53300217.0          3.602880  \n",
       "1254489.0           0.000000  \n",
       "...                      ...  \n",
       "53382587.0          5.130768  \n",
       "53301482.0          9.797959  \n",
       "53301383.0          7.123106  \n",
       "53301632.0         10.392305  \n",
       "53301556.0          9.090127  \n",
       "\n",
       "[1134 rows x 3964 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_NAomit_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8129de55-e5e1-44df-bea5-1de439f32345",
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 0.99  # 如果列中 0 的比例超过 90%，则移除该列\n",
    "non_zero_threshold = X_NAomit_data.shape[0] * (1 - threshold)\n",
    "X_NAomit_data =X_NAomit_data.loc[:, (X_NAomit_data != 0).sum(axis=0) > non_zero_threshold]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "25db298a-25a8-4f41-ba0a-23d279862cce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MW</th>\n",
       "      <th>AMW</th>\n",
       "      <th>Sv</th>\n",
       "      <th>Se</th>\n",
       "      <th>Sp</th>\n",
       "      <th>Si</th>\n",
       "      <th>Mv</th>\n",
       "      <th>Me</th>\n",
       "      <th>Mp</th>\n",
       "      <th>Mi</th>\n",
       "      <th>...</th>\n",
       "      <th>s4_numRotBonds</th>\n",
       "      <th>s2_numAroBonds</th>\n",
       "      <th>s3_numAroBonds</th>\n",
       "      <th>s4_numAroBonds</th>\n",
       "      <th>s34_size</th>\n",
       "      <th>s34_relSize</th>\n",
       "      <th>s34_phSize</th>\n",
       "      <th>s34_phRelSize</th>\n",
       "      <th>chiralMoment</th>\n",
       "      <th>chiralPhMoment</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OPTUM_LAB_ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>53300413.0</th>\n",
       "      <td>704.02</td>\n",
       "      <td>6.518704</td>\n",
       "      <td>63.0926</td>\n",
       "      <td>107.4464</td>\n",
       "      <td>67.5519</td>\n",
       "      <td>122.5431</td>\n",
       "      <td>0.584191</td>\n",
       "      <td>0.994874</td>\n",
       "      <td>0.625481</td>\n",
       "      <td>1.134658</td>\n",
       "      <td>...</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>46.750000</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>10.625000</td>\n",
       "      <td>0.208333</td>\n",
       "      <td>50.709541</td>\n",
       "      <td>12.001003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49795501.0</th>\n",
       "      <td>373.47</td>\n",
       "      <td>7.322941</td>\n",
       "      <td>31.3867</td>\n",
       "      <td>51.5196</td>\n",
       "      <td>32.6935</td>\n",
       "      <td>58.0300</td>\n",
       "      <td>0.615425</td>\n",
       "      <td>1.010188</td>\n",
       "      <td>0.641049</td>\n",
       "      <td>1.137843</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>23.500000</td>\n",
       "      <td>0.870370</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>21.400935</td>\n",
       "      <td>6.633250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9551212.0</th>\n",
       "      <td>487.74</td>\n",
       "      <td>6.869577</td>\n",
       "      <td>41.8673</td>\n",
       "      <td>70.7049</td>\n",
       "      <td>45.2221</td>\n",
       "      <td>80.6829</td>\n",
       "      <td>0.589680</td>\n",
       "      <td>0.995844</td>\n",
       "      <td>0.636931</td>\n",
       "      <td>1.136379</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53300217.0</th>\n",
       "      <td>515.47</td>\n",
       "      <td>8.182063</td>\n",
       "      <td>40.9322</td>\n",
       "      <td>63.5306</td>\n",
       "      <td>43.2048</td>\n",
       "      <td>70.5350</td>\n",
       "      <td>0.649717</td>\n",
       "      <td>1.008422</td>\n",
       "      <td>0.685790</td>\n",
       "      <td>1.119603</td>\n",
       "      <td>...</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>25.500000</td>\n",
       "      <td>0.728571</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.114286</td>\n",
       "      <td>20.296826</td>\n",
       "      <td>3.602880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1254489.0</th>\n",
       "      <td>477.98</td>\n",
       "      <td>8.241034</td>\n",
       "      <td>38.5457</td>\n",
       "      <td>58.6579</td>\n",
       "      <td>40.0684</td>\n",
       "      <td>64.8437</td>\n",
       "      <td>0.664581</td>\n",
       "      <td>1.011343</td>\n",
       "      <td>0.690834</td>\n",
       "      <td>1.117995</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53382587.0</th>\n",
       "      <td>306.35</td>\n",
       "      <td>7.658750</td>\n",
       "      <td>24.8312</td>\n",
       "      <td>40.9089</td>\n",
       "      <td>25.3751</td>\n",
       "      <td>45.3652</td>\n",
       "      <td>0.620780</td>\n",
       "      <td>1.022722</td>\n",
       "      <td>0.634378</td>\n",
       "      <td>1.134130</td>\n",
       "      <td>...</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>0.772727</td>\n",
       "      <td>5.666667</td>\n",
       "      <td>0.257576</td>\n",
       "      <td>14.965511</td>\n",
       "      <td>5.130768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53301482.0</th>\n",
       "      <td>559.66</td>\n",
       "      <td>7.882535</td>\n",
       "      <td>47.4866</td>\n",
       "      <td>71.4287</td>\n",
       "      <td>49.1878</td>\n",
       "      <td>78.9395</td>\n",
       "      <td>0.668825</td>\n",
       "      <td>1.006038</td>\n",
       "      <td>0.692786</td>\n",
       "      <td>1.111824</td>\n",
       "      <td>...</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>34.500000</td>\n",
       "      <td>0.821429</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>0.190476</td>\n",
       "      <td>39.408121</td>\n",
       "      <td>9.797959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53301383.0</th>\n",
       "      <td>298.40</td>\n",
       "      <td>7.852632</td>\n",
       "      <td>23.3035</td>\n",
       "      <td>38.6580</td>\n",
       "      <td>24.5683</td>\n",
       "      <td>43.0758</td>\n",
       "      <td>0.613250</td>\n",
       "      <td>1.017316</td>\n",
       "      <td>0.646534</td>\n",
       "      <td>1.133574</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>5.500000</td>\n",
       "      <td>0.275000</td>\n",
       "      <td>22.053235</td>\n",
       "      <td>7.123106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53301632.0</th>\n",
       "      <td>499.57</td>\n",
       "      <td>8.057581</td>\n",
       "      <td>40.9490</td>\n",
       "      <td>62.9815</td>\n",
       "      <td>41.9150</td>\n",
       "      <td>69.6905</td>\n",
       "      <td>0.660468</td>\n",
       "      <td>1.015831</td>\n",
       "      <td>0.676048</td>\n",
       "      <td>1.124040</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>0.810811</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>0.270270</td>\n",
       "      <td>25.455844</td>\n",
       "      <td>10.392305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53301556.0</th>\n",
       "      <td>508.69</td>\n",
       "      <td>7.480735</td>\n",
       "      <td>42.7059</td>\n",
       "      <td>68.1705</td>\n",
       "      <td>45.3526</td>\n",
       "      <td>76.1916</td>\n",
       "      <td>0.628028</td>\n",
       "      <td>1.002507</td>\n",
       "      <td>0.666950</td>\n",
       "      <td>1.120465</td>\n",
       "      <td>...</td>\n",
       "      <td>4.333333</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>31.333333</td>\n",
       "      <td>0.870370</td>\n",
       "      <td>6.333333</td>\n",
       "      <td>0.175926</td>\n",
       "      <td>40.126995</td>\n",
       "      <td>9.090127</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1134 rows × 2258 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  MW       AMW       Sv        Se       Sp        Si  \\\n",
       "OPTUM_LAB_ID                                                           \n",
       "53300413.0    704.02  6.518704  63.0926  107.4464  67.5519  122.5431   \n",
       "49795501.0    373.47  7.322941  31.3867   51.5196  32.6935   58.0300   \n",
       "9551212.0     487.74  6.869577  41.8673   70.7049  45.2221   80.6829   \n",
       "53300217.0    515.47  8.182063  40.9322   63.5306  43.2048   70.5350   \n",
       "1254489.0     477.98  8.241034  38.5457   58.6579  40.0684   64.8437   \n",
       "...              ...       ...      ...       ...      ...       ...   \n",
       "53382587.0    306.35  7.658750  24.8312   40.9089  25.3751   45.3652   \n",
       "53301482.0    559.66  7.882535  47.4866   71.4287  49.1878   78.9395   \n",
       "53301383.0    298.40  7.852632  23.3035   38.6580  24.5683   43.0758   \n",
       "53301632.0    499.57  8.057581  40.9490   62.9815  41.9150   69.6905   \n",
       "53301556.0    508.69  7.480735  42.7059   68.1705  45.3526   76.1916   \n",
       "\n",
       "                    Mv        Me        Mp        Mi  ...  s4_numRotBonds  \\\n",
       "OPTUM_LAB_ID                                          ...                   \n",
       "53300413.0    0.584191  0.994874  0.625481  1.134658  ...       10.000000   \n",
       "49795501.0    0.615425  1.010188  0.641049  1.137843  ...        1.000000   \n",
       "9551212.0     0.589680  0.995844  0.636931  1.136379  ...        0.000000   \n",
       "53300217.0    0.649717  1.008422  0.685790  1.119603  ...        3.000000   \n",
       "1254489.0     0.664581  1.011343  0.690834  1.117995  ...        0.000000   \n",
       "...                ...       ...       ...       ...  ...             ...   \n",
       "53382587.0    0.620780  1.022722  0.634378  1.134130  ...        2.000000   \n",
       "53301482.0    0.668825  1.006038  0.692786  1.111824  ...        6.000000   \n",
       "53301383.0    0.613250  1.017316  0.646534  1.133574  ...        1.000000   \n",
       "53301632.0    0.660468  1.015831  0.676048  1.124040  ...        1.000000   \n",
       "53301556.0    0.628028  1.002507  0.666950  1.120465  ...        4.333333   \n",
       "\n",
       "              s2_numAroBonds  s3_numAroBonds  s4_numAroBonds   s34_size  \\\n",
       "OPTUM_LAB_ID                                                              \n",
       "53300413.0               0.0             6.0             6.0  46.750000   \n",
       "49795501.0               0.0             5.0             6.0  23.500000   \n",
       "9551212.0                0.0             0.0             0.0   0.000000   \n",
       "53300217.0               0.0             6.0             6.0  25.500000   \n",
       "1254489.0                0.0             0.0             0.0   0.000000   \n",
       "...                      ...             ...             ...        ...   \n",
       "53382587.0               0.0             2.0             6.0  17.000000   \n",
       "53301482.0               6.0             5.0            18.0  34.500000   \n",
       "53301383.0               0.0             1.0             4.0  18.000000   \n",
       "53301632.0               6.0             6.0            11.0  30.000000   \n",
       "53301556.0               2.0             4.0            12.0  31.333333   \n",
       "\n",
       "              s34_relSize  s34_phSize  s34_phRelSize  chiralMoment  \\\n",
       "OPTUM_LAB_ID                                                         \n",
       "53300413.0       0.916667   10.625000       0.208333     50.709541   \n",
       "49795501.0       0.870370    6.000000       0.222222     21.400935   \n",
       "9551212.0        0.000000    0.000000       0.000000      0.000000   \n",
       "53300217.0       0.728571    4.000000       0.114286     20.296826   \n",
       "1254489.0        0.000000    0.000000       0.000000      0.000000   \n",
       "...                   ...         ...            ...           ...   \n",
       "53382587.0       0.772727    5.666667       0.257576     14.965511   \n",
       "53301482.0       0.821429    8.000000       0.190476     39.408121   \n",
       "53301383.0       0.900000    5.500000       0.275000     22.053235   \n",
       "53301632.0       0.810811   10.000000       0.270270     25.455844   \n",
       "53301556.0       0.870370    6.333333       0.175926     40.126995   \n",
       "\n",
       "              chiralPhMoment  \n",
       "OPTUM_LAB_ID                  \n",
       "53300413.0         12.001003  \n",
       "49795501.0          6.633250  \n",
       "9551212.0           0.000000  \n",
       "53300217.0          3.602880  \n",
       "1254489.0           0.000000  \n",
       "...                      ...  \n",
       "53382587.0          5.130768  \n",
       "53301482.0          9.797959  \n",
       "53301383.0          7.123106  \n",
       "53301632.0         10.392305  \n",
       "53301556.0          9.090127  \n",
       "\n",
       "[1134 rows x 2258 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_NAomit_data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1cf34dcf-3f11-4e44-83ca-67542efeea48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[7.04020000e+02, 6.51870370e+00, 6.30926000e+01, ...,\n",
       "        2.08333333e-01, 5.07095408e+01, 1.20010035e+01],\n",
       "       [3.73470000e+02, 7.32294118e+00, 3.13867000e+01, ...,\n",
       "        2.22222222e-01, 2.14009346e+01, 6.63324958e+00],\n",
       "       [4.87740000e+02, 6.86957746e+00, 4.18673000e+01, ...,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "       ...,\n",
       "       [2.98400000e+02, 7.85263158e+00, 2.33035000e+01, ...,\n",
       "        2.75000000e-01, 2.20532347e+01, 7.12310563e+00],\n",
       "       [4.99570000e+02, 8.05758065e+00, 4.09490000e+01, ...,\n",
       "        2.70270270e-01, 2.54558441e+01, 1.03923048e+01],\n",
       "       [5.08690000e+02, 7.48073529e+00, 4.27059000e+01, ...,\n",
       "        1.75925926e-01, 4.01269953e+01, 9.09012748e+00]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X=np.array(X_NAomit_data)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fd096547-56ce-48a2-9a6f-210d1e31be3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MW</th>\n",
       "      <th>AMW</th>\n",
       "      <th>Sv</th>\n",
       "      <th>Se</th>\n",
       "      <th>Sp</th>\n",
       "      <th>Si</th>\n",
       "      <th>Mv</th>\n",
       "      <th>Me</th>\n",
       "      <th>Mp</th>\n",
       "      <th>Mi</th>\n",
       "      <th>...</th>\n",
       "      <th>s4_numRotBonds</th>\n",
       "      <th>s2_numAroBonds</th>\n",
       "      <th>s3_numAroBonds</th>\n",
       "      <th>s4_numAroBonds</th>\n",
       "      <th>s34_size</th>\n",
       "      <th>s34_relSize</th>\n",
       "      <th>s34_phSize</th>\n",
       "      <th>s34_phRelSize</th>\n",
       "      <th>chiralMoment</th>\n",
       "      <th>chiralPhMoment</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OPTUM_LAB_ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>53300413.0</th>\n",
       "      <td>704.02</td>\n",
       "      <td>6.518704</td>\n",
       "      <td>63.0926</td>\n",
       "      <td>107.4464</td>\n",
       "      <td>67.5519</td>\n",
       "      <td>122.5431</td>\n",
       "      <td>0.584191</td>\n",
       "      <td>0.994874</td>\n",
       "      <td>0.625481</td>\n",
       "      <td>1.134658</td>\n",
       "      <td>...</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>46.750000</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>10.625000</td>\n",
       "      <td>0.208333</td>\n",
       "      <td>50.709541</td>\n",
       "      <td>12.001003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49795501.0</th>\n",
       "      <td>373.47</td>\n",
       "      <td>7.322941</td>\n",
       "      <td>31.3867</td>\n",
       "      <td>51.5196</td>\n",
       "      <td>32.6935</td>\n",
       "      <td>58.0300</td>\n",
       "      <td>0.615425</td>\n",
       "      <td>1.010188</td>\n",
       "      <td>0.641049</td>\n",
       "      <td>1.137843</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>23.500000</td>\n",
       "      <td>0.870370</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>21.400935</td>\n",
       "      <td>6.633250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9551212.0</th>\n",
       "      <td>487.74</td>\n",
       "      <td>6.869577</td>\n",
       "      <td>41.8673</td>\n",
       "      <td>70.7049</td>\n",
       "      <td>45.2221</td>\n",
       "      <td>80.6829</td>\n",
       "      <td>0.589680</td>\n",
       "      <td>0.995844</td>\n",
       "      <td>0.636931</td>\n",
       "      <td>1.136379</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53300217.0</th>\n",
       "      <td>515.47</td>\n",
       "      <td>8.182063</td>\n",
       "      <td>40.9322</td>\n",
       "      <td>63.5306</td>\n",
       "      <td>43.2048</td>\n",
       "      <td>70.5350</td>\n",
       "      <td>0.649717</td>\n",
       "      <td>1.008422</td>\n",
       "      <td>0.685790</td>\n",
       "      <td>1.119603</td>\n",
       "      <td>...</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>25.500000</td>\n",
       "      <td>0.728571</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.114286</td>\n",
       "      <td>20.296826</td>\n",
       "      <td>3.602880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1254489.0</th>\n",
       "      <td>477.98</td>\n",
       "      <td>8.241034</td>\n",
       "      <td>38.5457</td>\n",
       "      <td>58.6579</td>\n",
       "      <td>40.0684</td>\n",
       "      <td>64.8437</td>\n",
       "      <td>0.664581</td>\n",
       "      <td>1.011343</td>\n",
       "      <td>0.690834</td>\n",
       "      <td>1.117995</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53382587.0</th>\n",
       "      <td>306.35</td>\n",
       "      <td>7.658750</td>\n",
       "      <td>24.8312</td>\n",
       "      <td>40.9089</td>\n",
       "      <td>25.3751</td>\n",
       "      <td>45.3652</td>\n",
       "      <td>0.620780</td>\n",
       "      <td>1.022722</td>\n",
       "      <td>0.634378</td>\n",
       "      <td>1.134130</td>\n",
       "      <td>...</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>0.772727</td>\n",
       "      <td>5.666667</td>\n",
       "      <td>0.257576</td>\n",
       "      <td>14.965511</td>\n",
       "      <td>5.130768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53301482.0</th>\n",
       "      <td>559.66</td>\n",
       "      <td>7.882535</td>\n",
       "      <td>47.4866</td>\n",
       "      <td>71.4287</td>\n",
       "      <td>49.1878</td>\n",
       "      <td>78.9395</td>\n",
       "      <td>0.668825</td>\n",
       "      <td>1.006038</td>\n",
       "      <td>0.692786</td>\n",
       "      <td>1.111824</td>\n",
       "      <td>...</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>34.500000</td>\n",
       "      <td>0.821429</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>0.190476</td>\n",
       "      <td>39.408121</td>\n",
       "      <td>9.797959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53301383.0</th>\n",
       "      <td>298.40</td>\n",
       "      <td>7.852632</td>\n",
       "      <td>23.3035</td>\n",
       "      <td>38.6580</td>\n",
       "      <td>24.5683</td>\n",
       "      <td>43.0758</td>\n",
       "      <td>0.613250</td>\n",
       "      <td>1.017316</td>\n",
       "      <td>0.646534</td>\n",
       "      <td>1.133574</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>5.500000</td>\n",
       "      <td>0.275000</td>\n",
       "      <td>22.053235</td>\n",
       "      <td>7.123106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53301632.0</th>\n",
       "      <td>499.57</td>\n",
       "      <td>8.057581</td>\n",
       "      <td>40.9490</td>\n",
       "      <td>62.9815</td>\n",
       "      <td>41.9150</td>\n",
       "      <td>69.6905</td>\n",
       "      <td>0.660468</td>\n",
       "      <td>1.015831</td>\n",
       "      <td>0.676048</td>\n",
       "      <td>1.124040</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>0.810811</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>0.270270</td>\n",
       "      <td>25.455844</td>\n",
       "      <td>10.392305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53301556.0</th>\n",
       "      <td>508.69</td>\n",
       "      <td>7.480735</td>\n",
       "      <td>42.7059</td>\n",
       "      <td>68.1705</td>\n",
       "      <td>45.3526</td>\n",
       "      <td>76.1916</td>\n",
       "      <td>0.628028</td>\n",
       "      <td>1.002507</td>\n",
       "      <td>0.666950</td>\n",
       "      <td>1.120465</td>\n",
       "      <td>...</td>\n",
       "      <td>4.333333</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>31.333333</td>\n",
       "      <td>0.870370</td>\n",
       "      <td>6.333333</td>\n",
       "      <td>0.175926</td>\n",
       "      <td>40.126995</td>\n",
       "      <td>9.090127</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1134 rows × 2258 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  MW       AMW       Sv        Se       Sp        Si  \\\n",
       "OPTUM_LAB_ID                                                           \n",
       "53300413.0    704.02  6.518704  63.0926  107.4464  67.5519  122.5431   \n",
       "49795501.0    373.47  7.322941  31.3867   51.5196  32.6935   58.0300   \n",
       "9551212.0     487.74  6.869577  41.8673   70.7049  45.2221   80.6829   \n",
       "53300217.0    515.47  8.182063  40.9322   63.5306  43.2048   70.5350   \n",
       "1254489.0     477.98  8.241034  38.5457   58.6579  40.0684   64.8437   \n",
       "...              ...       ...      ...       ...      ...       ...   \n",
       "53382587.0    306.35  7.658750  24.8312   40.9089  25.3751   45.3652   \n",
       "53301482.0    559.66  7.882535  47.4866   71.4287  49.1878   78.9395   \n",
       "53301383.0    298.40  7.852632  23.3035   38.6580  24.5683   43.0758   \n",
       "53301632.0    499.57  8.057581  40.9490   62.9815  41.9150   69.6905   \n",
       "53301556.0    508.69  7.480735  42.7059   68.1705  45.3526   76.1916   \n",
       "\n",
       "                    Mv        Me        Mp        Mi  ...  s4_numRotBonds  \\\n",
       "OPTUM_LAB_ID                                          ...                   \n",
       "53300413.0    0.584191  0.994874  0.625481  1.134658  ...       10.000000   \n",
       "49795501.0    0.615425  1.010188  0.641049  1.137843  ...        1.000000   \n",
       "9551212.0     0.589680  0.995844  0.636931  1.136379  ...        0.000000   \n",
       "53300217.0    0.649717  1.008422  0.685790  1.119603  ...        3.000000   \n",
       "1254489.0     0.664581  1.011343  0.690834  1.117995  ...        0.000000   \n",
       "...                ...       ...       ...       ...  ...             ...   \n",
       "53382587.0    0.620780  1.022722  0.634378  1.134130  ...        2.000000   \n",
       "53301482.0    0.668825  1.006038  0.692786  1.111824  ...        6.000000   \n",
       "53301383.0    0.613250  1.017316  0.646534  1.133574  ...        1.000000   \n",
       "53301632.0    0.660468  1.015831  0.676048  1.124040  ...        1.000000   \n",
       "53301556.0    0.628028  1.002507  0.666950  1.120465  ...        4.333333   \n",
       "\n",
       "              s2_numAroBonds  s3_numAroBonds  s4_numAroBonds   s34_size  \\\n",
       "OPTUM_LAB_ID                                                              \n",
       "53300413.0               0.0             6.0             6.0  46.750000   \n",
       "49795501.0               0.0             5.0             6.0  23.500000   \n",
       "9551212.0                0.0             0.0             0.0   0.000000   \n",
       "53300217.0               0.0             6.0             6.0  25.500000   \n",
       "1254489.0                0.0             0.0             0.0   0.000000   \n",
       "...                      ...             ...             ...        ...   \n",
       "53382587.0               0.0             2.0             6.0  17.000000   \n",
       "53301482.0               6.0             5.0            18.0  34.500000   \n",
       "53301383.0               0.0             1.0             4.0  18.000000   \n",
       "53301632.0               6.0             6.0            11.0  30.000000   \n",
       "53301556.0               2.0             4.0            12.0  31.333333   \n",
       "\n",
       "              s34_relSize  s34_phSize  s34_phRelSize  chiralMoment  \\\n",
       "OPTUM_LAB_ID                                                         \n",
       "53300413.0       0.916667   10.625000       0.208333     50.709541   \n",
       "49795501.0       0.870370    6.000000       0.222222     21.400935   \n",
       "9551212.0        0.000000    0.000000       0.000000      0.000000   \n",
       "53300217.0       0.728571    4.000000       0.114286     20.296826   \n",
       "1254489.0        0.000000    0.000000       0.000000      0.000000   \n",
       "...                   ...         ...            ...           ...   \n",
       "53382587.0       0.772727    5.666667       0.257576     14.965511   \n",
       "53301482.0       0.821429    8.000000       0.190476     39.408121   \n",
       "53301383.0       0.900000    5.500000       0.275000     22.053235   \n",
       "53301632.0       0.810811   10.000000       0.270270     25.455844   \n",
       "53301556.0       0.870370    6.333333       0.175926     40.126995   \n",
       "\n",
       "              chiralPhMoment  \n",
       "OPTUM_LAB_ID                  \n",
       "53300413.0         12.001003  \n",
       "49795501.0          6.633250  \n",
       "9551212.0           0.000000  \n",
       "53300217.0          3.602880  \n",
       "1254489.0           0.000000  \n",
       "...                      ...  \n",
       "53382587.0          5.130768  \n",
       "53301482.0          9.797959  \n",
       "53301383.0          7.123106  \n",
       "53301632.0         10.392305  \n",
       "53301556.0          9.090127  \n",
       "\n",
       "[1134 rows x 2258 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_NAomit_data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f561878b-84e9-41a4-aecf-49bd8626f377",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>IsomericSMILES</th>\n",
       "      <th>Activity</th>\n",
       "      <th>Canonical_smiles</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OPTUM_LAB_ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>53300413.0</th>\n",
       "      <td>CCOC1=CC=C(C=C1)CCN2[C@H](CN(C(=O)C2=O)[C@@H](...</td>\n",
       "      <td>1</td>\n",
       "      <td>CCOc1ccc(CCN2C(=O)C(=O)N([C@@H](CC(C)C)CN3CCC[...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49795501.0</th>\n",
       "      <td>CC1=C(C=C(C=C1)F)C(=O)N2CCCCC2C3=CC(=NO3)C(=O)...</td>\n",
       "      <td>1</td>\n",
       "      <td>Cc1ccc(F)cc1C(=O)N1CCCCC1c1cc(C(=O)NC(C)C)no1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9551212.0</th>\n",
       "      <td>CC1CCN(CC1)CCCNC(=O)CCCNC(=O)CN2C=NC3=C(C2=O)C...</td>\n",
       "      <td>1</td>\n",
       "      <td>CC1CCN(CCCNC(=O)CCCNC(=O)Cn2cnc3sc4c(c3c2=O)CC...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53300217.0</th>\n",
       "      <td>CCOC(=O)[C@]12CCC=C1N(C(=O)[C@@H](C2)CC(=O)NCC...</td>\n",
       "      <td>1</td>\n",
       "      <td>CCOC(=O)[C@]12CCC=C1N(Cc1ccc(Cl)cc1Cl)C(=O)[C@...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1254489.0</th>\n",
       "      <td>C1CN(CCN1C2=CC=C(C=C2)NC(=O)C3=CC4=C(C=C3)OCCO...</td>\n",
       "      <td>1</td>\n",
       "      <td>O=C(Nc1ccc(N2CCN(C(=O)c3ccc(Cl)cc3)CC2)cc1)c1c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53382587.0</th>\n",
       "      <td>COC(=O)C[C@H]1C=C[C@@H]([C@H](O1)CO)NC(=O)C2=C...</td>\n",
       "      <td>0</td>\n",
       "      <td>COC(=O)C[C@H]1C=C[C@H](NC(=O)c2ccccn2)[C@@H](C...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53301482.0</th>\n",
       "      <td>COC1=CC(=CC(=C1)C2=CC3=CC=CC=C3C(N2C4=CC=C(C=C...</td>\n",
       "      <td>0</td>\n",
       "      <td>COc1cc(OC)cc(C2=Cc3ccccc3C(CC(=O)c3ccco3)N2c2c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53301383.0</th>\n",
       "      <td>C[C@H]1COC2=C(C=CC(=C2)N3CC[C@@H](C3)O)S(=O)(=...</td>\n",
       "      <td>0</td>\n",
       "      <td>C[C@H]1COc2cc(N3CC[C@H](O)C3)ccc2S(=O)(=O)N1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53301632.0</th>\n",
       "      <td>COC1=C(C=C(C=C1)CCN2C(C3=CC=CC=C3C2=O)C4=NN=NN...</td>\n",
       "      <td>0</td>\n",
       "      <td>COc1ccc(CCN2C(=O)c3ccccc3C2c2nnnn2-c2ccc3c(c2)...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53301556.0</th>\n",
       "      <td>C[C@H](C1=CC=CC=C1)N2C[C@@H](OC3=C(S2(=O)=O)C=...</td>\n",
       "      <td>0</td>\n",
       "      <td>C[C@H](c1ccccc1)N1C[C@H](COCc2ccccc2)Oc2cc(N3C...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1134 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 IsomericSMILES  Activity  \\\n",
       "OPTUM_LAB_ID                                                                \n",
       "53300413.0    CCOC1=CC=C(C=C1)CCN2[C@H](CN(C(=O)C2=O)[C@@H](...         1   \n",
       "49795501.0    CC1=C(C=C(C=C1)F)C(=O)N2CCCCC2C3=CC(=NO3)C(=O)...         1   \n",
       "9551212.0     CC1CCN(CC1)CCCNC(=O)CCCNC(=O)CN2C=NC3=C(C2=O)C...         1   \n",
       "53300217.0    CCOC(=O)[C@]12CCC=C1N(C(=O)[C@@H](C2)CC(=O)NCC...         1   \n",
       "1254489.0     C1CN(CCN1C2=CC=C(C=C2)NC(=O)C3=CC4=C(C=C3)OCCO...         1   \n",
       "...                                                         ...       ...   \n",
       "53382587.0    COC(=O)C[C@H]1C=C[C@@H]([C@H](O1)CO)NC(=O)C2=C...         0   \n",
       "53301482.0    COC1=CC(=CC(=C1)C2=CC3=CC=CC=C3C(N2C4=CC=C(C=C...         0   \n",
       "53301383.0    C[C@H]1COC2=C(C=CC(=C2)N3CC[C@@H](C3)O)S(=O)(=...         0   \n",
       "53301632.0    COC1=C(C=C(C=C1)CCN2C(C3=CC=CC=C3C2=O)C4=NN=NN...         0   \n",
       "53301556.0    C[C@H](C1=CC=CC=C1)N2C[C@@H](OC3=C(S2(=O)=O)C=...         0   \n",
       "\n",
       "                                               Canonical_smiles  \n",
       "OPTUM_LAB_ID                                                     \n",
       "53300413.0    CCOc1ccc(CCN2C(=O)C(=O)N([C@@H](CC(C)C)CN3CCC[...  \n",
       "49795501.0        Cc1ccc(F)cc1C(=O)N1CCCCC1c1cc(C(=O)NC(C)C)no1  \n",
       "9551212.0     CC1CCN(CCCNC(=O)CCCNC(=O)Cn2cnc3sc4c(c3c2=O)CC...  \n",
       "53300217.0    CCOC(=O)[C@]12CCC=C1N(Cc1ccc(Cl)cc1Cl)C(=O)[C@...  \n",
       "1254489.0     O=C(Nc1ccc(N2CCN(C(=O)c3ccc(Cl)cc3)CC2)cc1)c1c...  \n",
       "...                                                         ...  \n",
       "53382587.0    COC(=O)C[C@H]1C=C[C@H](NC(=O)c2ccccn2)[C@@H](C...  \n",
       "53301482.0    COc1cc(OC)cc(C2=Cc3ccccc3C(CC(=O)c3ccco3)N2c2c...  \n",
       "53301383.0         C[C@H]1COc2cc(N3CC[C@H](O)C3)ccc2S(=O)(=O)N1  \n",
       "53301632.0    COc1ccc(CCN2C(=O)c3ccccc3C2c2nnnn2-c2ccc3c(c2)...  \n",
       "53301556.0    C[C@H](c1ccccc1)N1C[C@H](COCc2ccccc2)Oc2cc(N3C...  \n",
       "\n",
       "[1134 rows x 3 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Raw_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "066559ff-aefe-4de1-98aa-04e6e2d7d8de",
   "metadata": {},
   "outputs": [],
   "source": [
    "y=Raw_data['Activity']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8f04d536-af36-4f80-8c82-b43e30cbf6d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "Cv_model= RepeatedStratifiedKFold(n_splits=5, n_repeats=10, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdf835fc-df29-4f95-ac06-6cc88fa619f2",
   "metadata": {},
   "source": [
    "# 1. LASSO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "07038cde-c52d-4ba2-b851-445a650f8dc7",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.678e-02, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.402e-02, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.026e-02, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.229e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.661e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.395e-02, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.369e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.400e-02, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.048e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.406e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.788e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.146e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.080e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.231e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.125e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.314e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.109e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.882e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.940e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.613e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.128e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.432e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.744e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.775e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.026e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.501e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.589e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.892e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.761e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.235e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.089e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.447e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.567e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.694e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.612e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.811e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.105e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.125e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.173e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.138e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.312e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.578e-02, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.082e-02, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.243e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.592e-02, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.216e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.548e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.991e-02, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.845e-02, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.935e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.492e-02, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.796e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.274e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.376e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.686e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.382e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.174e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.382e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.611e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.733e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.758e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.904e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.118e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.596e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.115e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.139e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.003e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.696e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.611e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.575e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.639e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.585e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.842e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.637e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.327e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.189e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.022e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.337e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.874e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.533e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.898e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.771e-02, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.843e-02, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.325e-02, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.963e-02, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.309e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.450e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.833e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.218e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.262e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.701e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.472e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.877e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.616e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.401e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.242e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.989e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.097e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.780e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.023e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.367e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.409e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.000e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.244e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.293e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.597e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.833e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.146e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.027e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.647e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.877e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.056e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.649e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.107e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.291e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.383e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.446e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.727e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.699e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.764e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.262e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.108e-02, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.215e-02, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.201e-02, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.121e-02, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.108e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.651e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.625e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.146e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.745e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.871e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.587e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.107e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.071e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.861e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.308e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.744e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.697e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.966e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.836e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.949e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.199e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.359e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.270e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.128e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.260e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.481e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.331e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.613e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.121e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.233e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.050e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.340e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.353e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.247e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.048e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.644e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.959e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.997e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.116e-02, tolerance: 2.270e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.424e-02, tolerance: 2.270e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.005e-02, tolerance: 2.270e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.749e-02, tolerance: 2.270e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.545e-02, tolerance: 2.270e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.063e-01, tolerance: 2.270e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.563e-01, tolerance: 2.270e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.683e-01, tolerance: 2.270e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.712e-01, tolerance: 2.270e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.292e-01, tolerance: 2.270e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.020e-01, tolerance: 2.270e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.274e-01, tolerance: 2.270e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.357e-01, tolerance: 2.270e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.538e-01, tolerance: 2.270e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.994e-01, tolerance: 2.270e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.772e-01, tolerance: 2.270e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.590e-01, tolerance: 2.270e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.464e-01, tolerance: 2.270e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.132e-01, tolerance: 2.270e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.548e-01, tolerance: 2.270e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.745e+00, tolerance: 2.270e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.550e+00, tolerance: 2.270e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.066e+00, tolerance: 2.270e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.840e+00, tolerance: 2.270e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.680e+00, tolerance: 2.270e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.560e+00, tolerance: 2.270e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.077e+00, tolerance: 2.270e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.478e+00, tolerance: 2.270e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.996e+00, tolerance: 2.270e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.085e+00, tolerance: 2.270e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.759e+00, tolerance: 2.270e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.300e+00, tolerance: 2.270e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.260e+00, tolerance: 2.270e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.863e+00, tolerance: 2.270e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.949e+00, tolerance: 2.270e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.135e+00, tolerance: 2.270e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.670e+00, tolerance: 2.270e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.758e+00, tolerance: 2.270e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.353e+00, tolerance: 2.270e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.382e-02, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.322e-02, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.643e-02, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.672e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.357e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.871e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.978e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.722e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.336e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.852e-02, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.134e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.892e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.223e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.491e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.308e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.070e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.111e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.175e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.829e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.496e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.062e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.001e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.186e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.486e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.374e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.102e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.232e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.402e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.953e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.153e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.205e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.303e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.402e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.638e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.056e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.775e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.702e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.580e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.198e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.732e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.566e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.578e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.289e-02, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.814e-02, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.131e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.686e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.371e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.322e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.032e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.195e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.959e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.271e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.307e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.390e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.055e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.087e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.094e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.068e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.587e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.663e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.348e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.703e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.510e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.918e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.701e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.558e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.518e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.666e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.152e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.290e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.575e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.903e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.240e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.495e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.342e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.156e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.179e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.904e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.828e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.827e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.910e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.327e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.567e-02, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.554e-02, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.367e-02, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.994e-02, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.180e-02, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.696e-02, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.039e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.027e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.412e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.490e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.195e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.875e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.944e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.659e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.827e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.211e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.804e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.017e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.255e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.315e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.574e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.621e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.405e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.936e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.311e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.070e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.422e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.624e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.062e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.558e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.201e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.574e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.103e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.309e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.724e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.895e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.775e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.245e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.098e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.377e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.180e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.271e-02, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.175e-02, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.387e-02, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.471e-02, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.384e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.816e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.100e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.012e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.663e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.689e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.017e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.251e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.691e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.209e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.137e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.666e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.251e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.173e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.707e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.285e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.536e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.956e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.105e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.501e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.810e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.371e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.367e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.176e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.886e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.779e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.844e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.885e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.838e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.253e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.298e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.659e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.582e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.768e-02, tolerance: 2.270e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.026e-01, tolerance: 2.270e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.526e-02, tolerance: 2.270e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.617e-02, tolerance: 2.270e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.670e-02, tolerance: 2.270e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.961e-02, tolerance: 2.270e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.486e-01, tolerance: 2.270e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.089e-01, tolerance: 2.270e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.916e-01, tolerance: 2.270e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.896e-01, tolerance: 2.270e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.462e-01, tolerance: 2.270e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.096e-01, tolerance: 2.270e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.737e-01, tolerance: 2.270e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.607e-01, tolerance: 2.270e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.152e-01, tolerance: 2.270e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.169e-01, tolerance: 2.270e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.082e-01, tolerance: 2.270e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.661e-01, tolerance: 2.270e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.225e-01, tolerance: 2.270e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.447e-01, tolerance: 2.270e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.644e-01, tolerance: 2.270e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.729e-01, tolerance: 2.270e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.420e-01, tolerance: 2.270e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.799e-01, tolerance: 2.270e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.210e+00, tolerance: 2.270e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.275e+00, tolerance: 2.270e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.158e-01, tolerance: 2.270e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.122e+00, tolerance: 2.270e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.043e+00, tolerance: 2.270e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.218e+00, tolerance: 2.270e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.501e+00, tolerance: 2.270e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.845e+00, tolerance: 2.270e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.154e+00, tolerance: 2.270e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.337e+00, tolerance: 2.270e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.840e+00, tolerance: 2.270e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.921e+00, tolerance: 2.270e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.296e+00, tolerance: 2.270e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.512e+00, tolerance: 2.270e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.697e+00, tolerance: 2.270e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.986e-02, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.406e-02, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.900e-02, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.680e-02, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.953e-02, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.424e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.471e-02, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.712e-02, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.944e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.546e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.830e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.630e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.139e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.003e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.066e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.031e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.709e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.229e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.037e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.083e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.275e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.681e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.638e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.185e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.432e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.365e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.013e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.184e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.028e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.432e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.769e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.196e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.497e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.716e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.478e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.173e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.106e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.917e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.167e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.149e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.732e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.823e-02, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.017e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.215e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.772e-02, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.289e-02, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.257e-02, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.062e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.555e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.167e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.185e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.507e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.599e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.010e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.459e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.836e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.023e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.569e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.953e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.367e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.960e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.007e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.911e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.989e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.034e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.004e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.336e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.311e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.166e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.255e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.500e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.542e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.622e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.737e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.099e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.194e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.689e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.904e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.189e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.491e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.938e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.507e-02, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.044e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.714e-02, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.128e-02, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.614e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.093e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.609e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.974e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.691e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.788e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.659e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.965e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.200e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.980e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.368e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.000e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.286e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.115e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.901e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.089e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.667e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.214e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.232e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.124e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.353e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.545e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.922e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.182e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.713e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.850e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.086e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.961e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.875e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.271e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.617e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.016e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.106e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.061e-02, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.264e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.250e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.744e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.881e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.890e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.355e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.240e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.309e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.848e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.969e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.708e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.315e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.591e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.310e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.454e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.170e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.541e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.300e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.630e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.220e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.873e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.264e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.624e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.028e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.335e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.057e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.521e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.691e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.850e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.916e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.833e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.836e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.758e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.160e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.821e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.242e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.402e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.475e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.434e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.215e-02, tolerance: 2.270e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.943e-02, tolerance: 2.270e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.191e-02, tolerance: 2.270e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.316e-01, tolerance: 2.270e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.312e-01, tolerance: 2.270e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.996e-01, tolerance: 2.270e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.542e-02, tolerance: 2.270e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.405e-01, tolerance: 2.270e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.110e-01, tolerance: 2.270e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.960e-01, tolerance: 2.270e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.369e-01, tolerance: 2.270e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.035e-01, tolerance: 2.270e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.448e-01, tolerance: 2.270e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.273e-01, tolerance: 2.270e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.091e-01, tolerance: 2.270e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.189e-01, tolerance: 2.270e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.657e-01, tolerance: 2.270e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.308e-01, tolerance: 2.270e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.088e+00, tolerance: 2.270e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.247e-01, tolerance: 2.270e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.231e-01, tolerance: 2.270e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.109e-01, tolerance: 2.270e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.969e-01, tolerance: 2.270e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.151e-01, tolerance: 2.270e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.359e+00, tolerance: 2.270e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.578e+00, tolerance: 2.270e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.988e+00, tolerance: 2.270e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.013e+00, tolerance: 2.270e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.316e+00, tolerance: 2.270e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.515e+00, tolerance: 2.270e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.122e+00, tolerance: 2.270e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.058e+00, tolerance: 2.270e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.196e+00, tolerance: 2.270e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.441e+00, tolerance: 2.270e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.454e+00, tolerance: 2.270e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.617e+00, tolerance: 2.270e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.462e+00, tolerance: 2.270e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.243e+00, tolerance: 2.270e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.249e+00, tolerance: 2.270e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.414e-02, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.194e-02, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.008e-02, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.307e-02, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.019e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.686e-02, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.093e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.546e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.977e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.604e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.870e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.509e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.031e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.164e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.708e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.166e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.427e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.728e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.473e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.925e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.433e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.132e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.157e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.474e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.366e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.194e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.271e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.641e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.608e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.221e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.321e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.619e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.584e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.882e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.072e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.337e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.718e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.497e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.312e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.923e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.295e-02, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.385e-02, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.935e-02, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.107e-02, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.834e-02, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.503e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.823e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.105e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.167e-02, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.100e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.438e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.197e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.003e-02, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.127e-02, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.200e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.259e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.776e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.633e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.918e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.476e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.974e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.533e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.341e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.323e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.062e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.045e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.002e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.985e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.526e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.607e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.824e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.278e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.561e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.369e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.442e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.810e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.323e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.083e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.575e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.382e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.541e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.968e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.232e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.983e-02, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.006e-02, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.740e-02, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.372e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.354e-02, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.728e-02, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.823e-02, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.148e-02, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.367e-02, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.187e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.880e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.570e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.946e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.136e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.426e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.963e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.474e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.043e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.156e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.148e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.381e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.192e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.651e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.154e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.663e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.023e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.020e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.346e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.373e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.281e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.079e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.146e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.662e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.088e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.067e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.057e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.784e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.072e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.264e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.921e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.932e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.924e-02, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.624e-02, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.786e-02, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.321e-02, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.323e-02, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.755e-02, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.398e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.832e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.454e-02, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.605e-02, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.489e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.115e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.847e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.080e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.660e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.131e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.861e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.321e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.519e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.378e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.622e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.020e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.247e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.636e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.754e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.826e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.794e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.832e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.954e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.689e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.605e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.823e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.016e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.710e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.616e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.943e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.092e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.242e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.345e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.918e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.182e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.422e-02, tolerance: 2.270e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.479e-02, tolerance: 2.270e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.332e-02, tolerance: 2.270e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.039e-01, tolerance: 2.270e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.646e-02, tolerance: 2.270e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.755e-01, tolerance: 2.270e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.718e-01, tolerance: 2.270e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.483e-01, tolerance: 2.270e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.905e-01, tolerance: 2.270e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.831e-01, tolerance: 2.270e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.177e-01, tolerance: 2.270e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.106e-01, tolerance: 2.270e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.165e-01, tolerance: 2.270e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.367e-01, tolerance: 2.270e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.009e-01, tolerance: 2.270e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.152e-01, tolerance: 2.270e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.441e-01, tolerance: 2.270e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.138e+00, tolerance: 2.270e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.109e-01, tolerance: 2.270e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.054e-01, tolerance: 2.270e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.179e-01, tolerance: 2.270e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.172e+00, tolerance: 2.270e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.053e-01, tolerance: 2.270e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.154e-01, tolerance: 2.270e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.044e+00, tolerance: 2.270e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.140e+00, tolerance: 2.270e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.471e+00, tolerance: 2.270e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.702e+00, tolerance: 2.270e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.331e+00, tolerance: 2.270e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.291e+00, tolerance: 2.270e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.295e+00, tolerance: 2.270e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.460e+00, tolerance: 2.270e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.570e+00, tolerance: 2.270e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.711e+00, tolerance: 2.270e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.423e+00, tolerance: 2.270e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.427e+00, tolerance: 2.270e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.877e+00, tolerance: 2.270e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.022e+00, tolerance: 2.270e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.990e+00, tolerance: 2.270e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.154e+00, tolerance: 2.270e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.163e-02, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.853e-02, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.315e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.757e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.524e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.149e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.762e-02, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.038e-02, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.339e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.290e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.766e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.473e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.669e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.952e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.688e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.524e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.897e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.178e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.747e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.703e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.916e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.377e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.887e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.561e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.248e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.291e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.282e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.118e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.598e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.982e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.689e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.464e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.607e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.563e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.675e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.414e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.248e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.346e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.599e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.688e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.931e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.758e-02, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.599e-02, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.073e-02, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.973e-02, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.044e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.782e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.593e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.774e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.004e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.686e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.406e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.616e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.034e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.982e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.544e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.234e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.549e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.708e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.659e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.514e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.691e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.495e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.805e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.091e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.092e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.708e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.509e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.582e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.650e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.807e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.130e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.467e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.762e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.077e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.241e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.151e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.570e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.491e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.967e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.971e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.501e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.478e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.919e-02, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.721e-02, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.041e-02, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.885e-02, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.335e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.421e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.171e-02, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.019e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.332e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.527e-02, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.176e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.544e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.127e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.815e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.445e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.345e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.987e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.258e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.183e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.297e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.162e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.023e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.007e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.213e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.512e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.717e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.991e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.070e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.172e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.159e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.890e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.535e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.620e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.570e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.275e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.490e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.695e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.740e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.077e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.336e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.692e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.148e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.510e-02, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.550e-02, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.816e-02, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.937e-02, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.519e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.825e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.095e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.676e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.668e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.585e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.168e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.855e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.771e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.633e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.584e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.124e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.086e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.645e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.396e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.011e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.431e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.182e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.110e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.080e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.367e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.730e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.656e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.901e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.147e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.068e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.556e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.072e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.109e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.735e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.194e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.676e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.024e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.116e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.300e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.577e-02, tolerance: 2.270e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.400e-02, tolerance: 2.270e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.190e-01, tolerance: 2.270e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.407e-02, tolerance: 2.270e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.943e-02, tolerance: 2.270e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.363e-01, tolerance: 2.270e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.499e-01, tolerance: 2.270e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.769e-01, tolerance: 2.270e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.018e-01, tolerance: 2.270e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.228e-01, tolerance: 2.270e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.760e-01, tolerance: 2.270e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.649e-01, tolerance: 2.270e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.540e-01, tolerance: 2.270e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.816e-01, tolerance: 2.270e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.051e+00, tolerance: 2.270e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.667e-01, tolerance: 2.270e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.073e+00, tolerance: 2.270e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.024e-01, tolerance: 2.270e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.445e-01, tolerance: 2.270e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.841e-01, tolerance: 2.270e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.255e-01, tolerance: 2.270e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.005e+00, tolerance: 2.270e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.382e+00, tolerance: 2.270e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.437e+00, tolerance: 2.270e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.427e+00, tolerance: 2.270e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.395e+00, tolerance: 2.270e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.495e+00, tolerance: 2.270e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.477e+00, tolerance: 2.270e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.458e+00, tolerance: 2.270e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.659e+00, tolerance: 2.270e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.678e+00, tolerance: 2.270e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.586e+00, tolerance: 2.270e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.269e+00, tolerance: 2.270e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.631e+00, tolerance: 2.270e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.669e+00, tolerance: 2.270e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.713e+00, tolerance: 2.270e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.188e-02, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.398e-02, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.219e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.135e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.012e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.844e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.112e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.931e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.199e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.868e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.680e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.818e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.302e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.482e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.155e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.391e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.445e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.613e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.012e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.347e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.456e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.298e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.138e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.960e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.947e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.098e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.150e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.378e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.232e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.474e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.486e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.153e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.926e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.590e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.546e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.058e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.751e-02, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.567e-02, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.521e-02, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.353e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.546e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.811e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.281e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.256e-02, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.788e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.325e-02, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.445e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.820e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.944e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.049e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.636e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.588e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.601e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.315e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.673e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.229e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.990e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.340e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.041e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.139e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.211e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.522e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.576e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.680e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.648e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.294e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.329e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.544e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.030e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.176e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.410e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.521e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.468e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.231e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.055e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.472e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.502e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.074e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.013e-02, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.317e-02, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.987e-02, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.672e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.980e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.123e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.716e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.491e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.232e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.636e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.155e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.069e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.958e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.176e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.995e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.484e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.817e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.004e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.252e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.163e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.337e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.730e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.313e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.379e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.880e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.967e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.083e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.657e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.723e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.484e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.447e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.677e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.269e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.308e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.386e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.556e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.798e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.353e-02, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.966e-02, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.966e-02, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.833e-02, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.950e-02, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.945e-02, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.596e-02, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.541e-02, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.020e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.353e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.613e-02, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.522e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.937e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.171e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.814e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.454e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.047e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.386e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.014e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.729e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.873e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.994e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.689e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.400e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.634e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.753e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.786e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.699e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.406e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.765e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.709e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.330e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.595e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.639e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.044e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.338e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.726e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.518e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.821e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.849e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.689e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.442e-02, tolerance: 2.270e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.717e-02, tolerance: 2.270e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.348e-01, tolerance: 2.270e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.349e-02, tolerance: 2.270e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.186e-02, tolerance: 2.270e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.053e-01, tolerance: 2.270e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.442e-01, tolerance: 2.270e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.647e-01, tolerance: 2.270e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.699e-01, tolerance: 2.270e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.546e-01, tolerance: 2.270e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.871e-01, tolerance: 2.270e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.648e-01, tolerance: 2.270e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.313e-01, tolerance: 2.270e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.667e-01, tolerance: 2.270e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.853e-01, tolerance: 2.270e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.791e-01, tolerance: 2.270e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.393e-01, tolerance: 2.270e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.373e-01, tolerance: 2.270e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.743e-01, tolerance: 2.270e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.013e-01, tolerance: 2.270e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.072e-01, tolerance: 2.270e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.847e-01, tolerance: 2.270e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.643e-01, tolerance: 2.270e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.105e+00, tolerance: 2.270e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.327e+00, tolerance: 2.270e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.810e+00, tolerance: 2.270e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.359e+00, tolerance: 2.270e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.678e+00, tolerance: 2.270e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.679e+00, tolerance: 2.270e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.592e+00, tolerance: 2.270e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.374e+00, tolerance: 2.270e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.238e+00, tolerance: 2.270e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.317e+00, tolerance: 2.270e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.462e+00, tolerance: 2.270e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.598e+00, tolerance: 2.270e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.711e+00, tolerance: 2.270e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.375e+00, tolerance: 2.270e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.419e+00, tolerance: 2.270e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.538e+00, tolerance: 2.270e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.533e+00, tolerance: 2.270e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.347e-02, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.606e-02, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.384e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.013e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.375e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.761e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.792e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.117e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.426e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.158e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.250e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.300e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.226e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.453e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.368e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.367e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.967e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.270e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.971e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.152e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.543e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.905e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.959e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.492e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.288e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.276e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.048e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.009e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.101e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.434e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.639e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.669e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.901e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.084e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.795e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.146e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.688e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.757e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.185e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.450e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.852e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.939e-02, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.863e-02, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.875e-02, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.474e-02, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.462e-02, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.493e-02, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.786e-02, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.186e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.394e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.796e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.755e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.220e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.254e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.999e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.610e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.993e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.811e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.013e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.534e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.221e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.884e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.189e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.334e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.549e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.393e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.846e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.158e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.657e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.618e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.672e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.948e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.277e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.297e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.660e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.159e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.657e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.879e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.971e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.301e-02, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.422e-02, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.277e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.559e-02, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.050e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.115e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.906e-02, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.064e-02, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.940e-02, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.202e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.040e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.502e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.135e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.192e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.616e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.404e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.611e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.613e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.972e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.087e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.265e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.179e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.470e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.170e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.044e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.796e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.448e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.794e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.835e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.146e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.208e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.461e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.590e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.735e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.698e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.559e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.042e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.029e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.811e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.218e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.136e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.275e-02, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.215e-02, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.723e-02, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.207e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.322e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.212e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.780e-02, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.536e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.170e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.776e-02, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.266e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.696e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.643e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.848e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.567e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.453e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.088e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.975e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.332e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.978e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.090e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.551e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.698e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.560e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.748e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.701e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.341e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.023e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.556e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.775e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.963e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.981e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.125e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.015e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.801e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.306e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.055e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.104e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.478e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.690e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.618e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.449e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.523e-02, tolerance: 2.270e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.641e-02, tolerance: 2.270e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.823e-02, tolerance: 2.270e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.470e-02, tolerance: 2.270e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.646e-02, tolerance: 2.270e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.366e-02, tolerance: 2.270e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.920e-02, tolerance: 2.270e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.029e-01, tolerance: 2.270e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.915e-01, tolerance: 2.270e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.044e-01, tolerance: 2.270e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.833e-01, tolerance: 2.270e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.787e-01, tolerance: 2.270e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.540e-01, tolerance: 2.270e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.749e-01, tolerance: 2.270e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.002e-01, tolerance: 2.270e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.996e-01, tolerance: 2.270e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.176e-01, tolerance: 2.270e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.442e-01, tolerance: 2.270e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.501e-01, tolerance: 2.270e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.549e-01, tolerance: 2.270e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.686e-01, tolerance: 2.270e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.250e-01, tolerance: 2.270e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.925e-01, tolerance: 2.270e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.006e-01, tolerance: 2.270e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.931e-01, tolerance: 2.270e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.169e+00, tolerance: 2.270e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.242e+00, tolerance: 2.270e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.294e+00, tolerance: 2.270e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.002e+00, tolerance: 2.270e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.342e+00, tolerance: 2.270e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.652e+00, tolerance: 2.270e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.629e+00, tolerance: 2.270e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.660e+00, tolerance: 2.270e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.765e+00, tolerance: 2.270e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.856e+00, tolerance: 2.270e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.210e+00, tolerance: 2.270e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.469e+00, tolerance: 2.270e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.546e+00, tolerance: 2.270e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.884e+00, tolerance: 2.270e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.925e+00, tolerance: 2.270e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.788e+00, tolerance: 2.270e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.709e+00, tolerance: 2.270e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.329e+00, tolerance: 2.270e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.920e-02, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.428e-02, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.488e-02, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.039e-02, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.719e-02, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.391e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.949e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.929e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.998e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.185e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.213e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.017e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.731e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.545e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.665e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.978e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.394e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.965e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.669e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.557e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.371e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.934e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.787e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.213e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.596e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.199e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.489e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.334e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.486e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.042e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.632e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.269e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.444e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.590e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.486e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.943e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.108e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.105e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.243e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.339e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.675e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.590e-02, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.058e-02, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.778e-02, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.242e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.612e-02, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.590e-02, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.775e-02, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.005e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.049e-02, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.536e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.140e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.025e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.507e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.537e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.129e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.777e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.698e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.020e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.847e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.764e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.373e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.015e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.247e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.697e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.762e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.164e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.521e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.390e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.453e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.749e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.590e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.093e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.127e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.249e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.411e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.102e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.919e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.776e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.897e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.907e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.747e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.744e-02, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.037e-02, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.533e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.800e-02, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.297e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.252e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.872e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.072e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.567e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.222e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.520e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.513e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.372e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.424e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.260e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.153e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.394e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.560e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.356e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.305e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.391e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.588e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.125e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.518e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.178e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.557e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.235e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.562e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.290e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.239e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.848e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.001e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.025e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.958e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.750e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.389e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.425e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.569e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.652e-02, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.150e-02, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.823e-02, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.016e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.316e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.111e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.251e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.627e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.573e-02, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.461e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.787e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.107e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.362e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.179e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.805e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.968e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.337e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.915e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.889e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.938e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.610e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.986e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.189e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.379e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.165e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.363e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.386e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.703e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.388e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.815e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.978e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.195e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.333e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.716e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.909e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.994e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.250e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.167e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.581e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.005e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.472e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.301e-02, tolerance: 2.270e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.624e-02, tolerance: 2.270e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.902e-02, tolerance: 2.270e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.406e-01, tolerance: 2.270e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.508e-02, tolerance: 2.270e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.960e-02, tolerance: 2.270e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.823e-02, tolerance: 2.270e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.184e-01, tolerance: 2.270e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.679e-01, tolerance: 2.270e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.395e-01, tolerance: 2.270e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.804e-01, tolerance: 2.270e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.878e-01, tolerance: 2.270e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.770e-01, tolerance: 2.270e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.974e-01, tolerance: 2.270e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.652e-01, tolerance: 2.270e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.444e-01, tolerance: 2.270e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.771e-01, tolerance: 2.270e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.248e-01, tolerance: 2.270e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.761e-01, tolerance: 2.270e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.158e-01, tolerance: 2.270e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.437e+00, tolerance: 2.270e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.670e+00, tolerance: 2.270e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.511e+00, tolerance: 2.270e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.288e+00, tolerance: 2.270e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.453e+00, tolerance: 2.270e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.272e+00, tolerance: 2.270e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.212e+00, tolerance: 2.270e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.267e+00, tolerance: 2.270e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.286e+00, tolerance: 2.270e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.273e+00, tolerance: 2.270e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.460e+00, tolerance: 2.270e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.632e+00, tolerance: 2.270e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.831e+00, tolerance: 2.270e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.893e+00, tolerance: 2.270e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.036e+00, tolerance: 2.270e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.217e+00, tolerance: 2.270e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.727e+00, tolerance: 2.270e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.102e+00, tolerance: 2.270e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.056e-02, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.585e-02, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.773e-02, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.444e-02, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.482e-02, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.611e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.294e-02, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.299e-02, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.675e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.275e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.348e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.408e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.057e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.746e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.875e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.944e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.910e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.373e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.628e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.565e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.940e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.886e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.355e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.072e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.105e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.217e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.609e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.981e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.881e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.802e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.725e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.029e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.995e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.397e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.505e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.496e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.797e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.918e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.958e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.072e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.074e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.641e-02, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.342e-02, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.828e-02, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.340e-02, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.180e-02, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.050e-02, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.185e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.245e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.974e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.394e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.901e-02, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.118e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.001e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.333e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.850e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.229e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.746e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.701e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.475e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.384e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.884e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.315e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.594e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.514e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.890e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.283e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.211e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.889e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.236e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.075e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.737e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.788e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.608e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.566e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.061e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.142e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.443e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.119e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.383e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.609e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.753e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.108e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.010e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.309e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.292e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.259e-02, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.425e-02, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.077e-02, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.108e-02, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.337e-02, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.927e-02, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.729e-02, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.528e-02, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.420e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.005e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.274e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.910e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.644e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.395e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.335e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.012e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.075e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.819e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.985e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.125e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.519e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.204e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.936e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.177e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.354e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.044e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.183e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.677e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.225e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.130e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.924e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.500e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.001e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.214e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.930e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.768e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.709e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.585e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.257e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.439e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.147e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.374e-02, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.308e-02, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.185e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.200e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.370e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.734e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.717e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.810e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.702e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.277e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.977e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.293e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.322e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.264e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.356e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.742e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.938e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.248e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.883e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.877e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.353e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.112e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.518e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.071e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.294e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.237e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.142e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.149e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.220e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.198e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.377e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.643e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.736e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.608e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.698e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.285e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.023e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.751e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.097e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.653e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.366e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.217e-02, tolerance: 2.270e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.524e-02, tolerance: 2.270e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.570e-02, tolerance: 2.270e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.218e-02, tolerance: 2.270e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.096e-01, tolerance: 2.270e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.960e-01, tolerance: 2.270e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.299e-01, tolerance: 2.270e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.993e-02, tolerance: 2.270e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.388e-02, tolerance: 2.270e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.036e-02, tolerance: 2.270e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.886e-01, tolerance: 2.270e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.208e-01, tolerance: 2.270e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.778e-01, tolerance: 2.270e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.078e-01, tolerance: 2.270e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.754e-01, tolerance: 2.270e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.881e-01, tolerance: 2.270e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.053e-01, tolerance: 2.270e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.109e-01, tolerance: 2.270e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.613e-01, tolerance: 2.270e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.440e-01, tolerance: 2.270e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.831e-01, tolerance: 2.270e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.382e+00, tolerance: 2.270e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.169e+00, tolerance: 2.270e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.401e+00, tolerance: 2.270e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.688e+00, tolerance: 2.270e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.751e+00, tolerance: 2.270e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.588e+00, tolerance: 2.270e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.542e+00, tolerance: 2.270e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.264e+00, tolerance: 2.270e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.464e+00, tolerance: 2.270e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.448e+00, tolerance: 2.270e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.663e+00, tolerance: 2.270e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.626e+00, tolerance: 2.270e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.249e+00, tolerance: 2.270e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.572e+00, tolerance: 2.270e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.694e+00, tolerance: 2.270e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.169e+00, tolerance: 2.270e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.529e+00, tolerance: 2.270e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.579e+00, tolerance: 2.270e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.911e+00, tolerance: 2.270e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.993e+00, tolerance: 2.270e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.137e+00, tolerance: 2.270e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.238e-02, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.059e-02, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.059e-02, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.097e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.200e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.570e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.224e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.276e-02, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.247e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.632e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.856e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.930e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.164e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.965e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.909e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.283e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.694e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.559e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.530e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.926e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.055e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.107e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.239e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.109e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.506e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.843e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.645e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.105e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.576e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.128e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.032e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.477e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.499e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.765e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.356e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.626e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.605e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.930e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.548e-02, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.520e-02, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.934e-02, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.601e-02, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.140e-02, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.437e-02, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.314e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.211e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.835e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.267e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.038e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.468e-02, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.036e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.170e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.394e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.343e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.542e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.101e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.105e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.106e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.146e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.972e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.813e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.416e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.861e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.121e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.397e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.855e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.425e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.253e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.235e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.543e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.202e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.397e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.276e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.521e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.519e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.053e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.473e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.726e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.221e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.372e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.216e-02, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.216e-02, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.816e-02, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.551e-02, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.341e-02, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.943e-02, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.315e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.100e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.119e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.673e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.654e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.123e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.179e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.661e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.557e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.597e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.846e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.664e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.510e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.764e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.597e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.595e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.404e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.989e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.053e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.610e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.856e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.260e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.429e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.375e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.236e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.225e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.523e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.473e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.026e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.557e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.625e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.867e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.457e-02, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.758e-02, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.386e-02, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.578e-02, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.881e-02, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.143e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.442e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.776e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.025e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.611e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.650e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.315e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.905e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.965e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.675e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.580e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.275e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.514e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.004e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.488e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.788e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.449e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.550e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.360e-01, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.044e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.258e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.103e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.344e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.402e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.386e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.832e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.281e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.315e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.405e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.279e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.023e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.920e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.810e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.945e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.112e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.293e+00, tolerance: 2.267e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.831e-02, tolerance: 2.270e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.882e-02, tolerance: 2.270e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.621e-02, tolerance: 2.270e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.192e-02, tolerance: 2.270e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.059e-01, tolerance: 2.270e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.064e-01, tolerance: 2.270e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.364e-01, tolerance: 2.270e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.829e-01, tolerance: 2.270e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.150e-01, tolerance: 2.270e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.448e-02, tolerance: 2.270e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.317e-01, tolerance: 2.270e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.986e-02, tolerance: 2.270e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.267e-01, tolerance: 2.270e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.113e-01, tolerance: 2.270e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.933e-01, tolerance: 2.270e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.570e-01, tolerance: 2.270e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.846e-01, tolerance: 2.270e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.206e-01, tolerance: 2.270e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.821e-01, tolerance: 2.270e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.926e-01, tolerance: 2.270e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.655e-01, tolerance: 2.270e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.499e-01, tolerance: 2.270e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.899e-01, tolerance: 2.270e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.150e-01, tolerance: 2.270e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.875e-01, tolerance: 2.270e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.243e+00, tolerance: 2.270e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.731e+00, tolerance: 2.270e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.844e+00, tolerance: 2.270e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.891e+00, tolerance: 2.270e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.612e+00, tolerance: 2.270e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.319e-01, tolerance: 2.270e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.611e-01, tolerance: 2.270e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.431e-01, tolerance: 2.270e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.079e+00, tolerance: 2.270e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.030e+00, tolerance: 2.270e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.408e+00, tolerance: 2.270e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.635e+00, tolerance: 2.270e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.545e+00, tolerance: 2.270e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.796e+00, tolerance: 2.270e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.509e+00, tolerance: 2.270e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.779e+00, tolerance: 2.270e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.868e+00, tolerance: 2.270e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.792e+00, tolerance: 2.270e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.874e+00, tolerance: 2.270e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    }
   ],
   "source": [
    "model = make_pipeline(StandardScaler(), LassoCV(cv=Cv_model)).fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "402b4353-a400-45cc-ba23-bddd8b9e5d4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x22cbe16bb50>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ymin, ymax =0, 1\n",
    "lasso = model[-1]\n",
    "plt.semilogx(lasso.alphas_, lasso.mse_path_, linestyle=\":\")\n",
    "plt.plot(\n",
    "    lasso.alphas_,\n",
    "    lasso.mse_path_.mean(axis=-1),\n",
    "    color=\"black\",\n",
    "    label=\"Average across the folds\",\n",
    "    linewidth=2,\n",
    ")\n",
    "plt.axvline(lasso.alpha_, linestyle=\"--\", color=\"black\", label=\"alpha: CV estimate\")\n",
    "\n",
    "plt.ylim(ymin, ymax)\n",
    "plt.xlabel(r\"$\\alpha$\")\n",
    "plt.ylabel(\"Mean square error\")\n",
    "plt.legend()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5d8e3935-01a9-4adb-8939-18d9e9c2c150",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.019831648654000496"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lasso.alpha_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0be9143b-967c-41fc-8e33-04f34afa9a5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "Cv_model= RepeatedStratifiedKFold(n_splits=5, n_repeats=10, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d10f1531-da2b-4bb6-b83b-3558bdac2339",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.011e+02, tolerance: 2.835e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1134, 149)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lsvc =  Lasso(alpha=lasso.alpha_).fit(X, y)\n",
    "model = SelectFromModel(lsvc, prefit=True)\n",
    "X_new = model.transform(X)\n",
    "X_new.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f7b74110-bf78-4a20-973b-7f81bf68a4a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>coef</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>MW</th>\n",
       "      <td>-0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AMW</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sv</th>\n",
       "      <td>-0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Se</th>\n",
       "      <td>-0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sp</th>\n",
       "      <td>-0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>s34_relSize</th>\n",
       "      <td>-0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>s34_phSize</th>\n",
       "      <td>-0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>s34_phRelSize</th>\n",
       "      <td>-0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chiralMoment</th>\n",
       "      <td>-0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chiralPhMoment</th>\n",
       "      <td>-0.003576</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2258 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    coef\n",
       "MW             -0.000000\n",
       "AMW             0.000000\n",
       "Sv             -0.000000\n",
       "Se             -0.000000\n",
       "Sp             -0.000000\n",
       "...                  ...\n",
       "s34_relSize    -0.000000\n",
       "s34_phSize     -0.000000\n",
       "s34_phRelSize  -0.000000\n",
       "chiralMoment   -0.000000\n",
       "chiralPhMoment -0.003576\n",
       "\n",
       "[2258 rows x 1 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lasso_coef=pd.DataFrame(lsvc.coef_)\n",
    "lasso_coef.index=X_NAomit_data.columns\n",
    "lasso_coef.columns=[\"coef\"]\n",
    "lasso_coef\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "013bbde3-8f0e-4b0f-9f7f-8ba774658777",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>coef</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>max_conj_path</th>\n",
       "      <td>0.003253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>D/Dtr03</th>\n",
       "      <td>-0.000369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>D/Dtr04</th>\n",
       "      <td>0.000386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>D/Dtr05</th>\n",
       "      <td>0.000562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>D/Dtr07</th>\n",
       "      <td>-0.001067</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   coef\n",
       "max_conj_path  0.003253\n",
       "D/Dtr03       -0.000369\n",
       "D/Dtr04        0.000386\n",
       "D/Dtr05        0.000562\n",
       "D/Dtr07       -0.001067"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lasso_coef_last=lasso_coef[(lasso_coef[\"coef\"]>0)|(lasso_coef[\"coef\"]<0)]\n",
    "lasso_coef_last.to_csv(\"./Supplementary Data S6.csv\",sep=',')\n",
    "lasso_coef_last.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c39feec4-a989-406f-b6a2-1c3428dc3b3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>max_conj_path</th>\n",
       "      <th>D/Dtr03</th>\n",
       "      <th>D/Dtr04</th>\n",
       "      <th>D/Dtr05</th>\n",
       "      <th>D/Dtr07</th>\n",
       "      <th>D/Dtr08</th>\n",
       "      <th>D/Dtr09</th>\n",
       "      <th>D/Dtr10</th>\n",
       "      <th>D/Dtr11</th>\n",
       "      <th>D/Dtr12</th>\n",
       "      <th>...</th>\n",
       "      <th>SAtot</th>\n",
       "      <th>SAacc</th>\n",
       "      <th>SAdon</th>\n",
       "      <th>Vx</th>\n",
       "      <th>s3_pathLength</th>\n",
       "      <th>s4_pathLength</th>\n",
       "      <th>s2_numAroBonds</th>\n",
       "      <th>s3_numAroBonds</th>\n",
       "      <th>s4_numAroBonds</th>\n",
       "      <th>chiralPhMoment</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OPTUM_LAB_ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>53300413.0</th>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>164.807796</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1014.984535</td>\n",
       "      <td>184.770945</td>\n",
       "      <td>60.694094</td>\n",
       "      <td>934.019934</td>\n",
       "      <td>9.500000</td>\n",
       "      <td>15.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>12.001003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49795501.0</th>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>71.350836</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>493.648034</td>\n",
       "      <td>115.715750</td>\n",
       "      <td>18.010751</td>\n",
       "      <td>463.936877</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.633250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9551212.0</th>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>73.714472</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>283.868540</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>653.418581</td>\n",
       "      <td>134.490440</td>\n",
       "      <td>36.021501</td>\n",
       "      <td>627.458472</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53300217.0</th>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>86.377798</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>152.709043</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>649.469869</td>\n",
       "      <td>107.569734</td>\n",
       "      <td>18.010751</td>\n",
       "      <td>619.219269</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.602880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1254489.0</th>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>184.947089</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>563.560715</td>\n",
       "      <td>96.549008</td>\n",
       "      <td>18.010751</td>\n",
       "      <td>566.877076</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53382587.0</th>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>422.605860</td>\n",
       "      <td>149.769253</td>\n",
       "      <td>60.694094</td>\n",
       "      <td>372.093023</td>\n",
       "      <td>7.333333</td>\n",
       "      <td>7.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.130768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53301482.0</th>\n",
       "      <td>14.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>103.394861</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>199.092648</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>690.291068</td>\n",
       "      <td>104.347310</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>689.784053</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>9.797959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53301383.0</th>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>46.313595</td>\n",
       "      <td>52.729507</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>81.047583</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>369.813744</td>\n",
       "      <td>117.525494</td>\n",
       "      <td>59.088341</td>\n",
       "      <td>346.079734</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>7.123106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53301632.0</th>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>156.592382</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>147.271856</td>\n",
       "      <td>143.147756</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>588.740241</td>\n",
       "      <td>122.012771</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>587.674419</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>10.392305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53301556.0</th>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>97.183681</td>\n",
       "      <td>105.621668</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>171.563892</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>650.325439</td>\n",
       "      <td>113.638946</td>\n",
       "      <td>42.683343</td>\n",
       "      <td>627.973422</td>\n",
       "      <td>4.333333</td>\n",
       "      <td>10.666667</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>9.090127</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1134 rows × 149 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              max_conj_path  D/Dtr03  D/Dtr04     D/Dtr05     D/Dtr07  \\\n",
       "OPTUM_LAB_ID                                                            \n",
       "53300413.0              6.0      0.0      0.0  164.807796    0.000000   \n",
       "49795501.0              8.0      0.0      0.0   71.350836    0.000000   \n",
       "9551212.0               9.0      0.0      0.0   73.714472    0.000000   \n",
       "53300217.0              6.0      0.0      0.0   86.377798    0.000000   \n",
       "1254489.0               8.0      0.0      0.0    0.000000    0.000000   \n",
       "...                     ...      ...      ...         ...         ...   \n",
       "53382587.0              8.0      0.0      0.0    0.000000    0.000000   \n",
       "53301482.0             14.0      0.0      0.0  103.394861    0.000000   \n",
       "53301383.0              6.0      0.0      0.0   46.313595   52.729507   \n",
       "53301632.0             11.0      0.0      0.0  156.592382    0.000000   \n",
       "53301556.0              6.0      0.0      0.0   97.183681  105.621668   \n",
       "\n",
       "              D/Dtr08     D/Dtr09     D/Dtr10     D/Dtr11  D/Dtr12  ...  \\\n",
       "OPTUM_LAB_ID                                                        ...   \n",
       "53300413.0        0.0    0.000000    0.000000    0.000000      0.0  ...   \n",
       "49795501.0        0.0    0.000000    0.000000    0.000000      0.0  ...   \n",
       "9551212.0         0.0  283.868540    0.000000    0.000000      0.0  ...   \n",
       "53300217.0        0.0  152.709043    0.000000    0.000000      0.0  ...   \n",
       "1254489.0         0.0    0.000000  184.947089    0.000000      0.0  ...   \n",
       "...               ...         ...         ...         ...      ...  ...   \n",
       "53382587.0        0.0    0.000000    0.000000    0.000000      0.0  ...   \n",
       "53301482.0        0.0    0.000000  199.092648    0.000000      0.0  ...   \n",
       "53301383.0        0.0    0.000000    0.000000   81.047583      0.0  ...   \n",
       "53301632.0        0.0  147.271856  143.147756    0.000000      0.0  ...   \n",
       "53301556.0        0.0    0.000000    0.000000  171.563892      0.0  ...   \n",
       "\n",
       "                    SAtot       SAacc      SAdon          Vx  s3_pathLength  \\\n",
       "OPTUM_LAB_ID                                                                  \n",
       "53300413.0    1014.984535  184.770945  60.694094  934.019934       9.500000   \n",
       "49795501.0     493.648034  115.715750  18.010751  463.936877       7.000000   \n",
       "9551212.0      653.418581  134.490440  36.021501  627.458472       0.000000   \n",
       "53300217.0     649.469869  107.569734  18.010751  619.219269       8.000000   \n",
       "1254489.0      563.560715   96.549008  18.010751  566.877076       0.000000   \n",
       "...                   ...         ...        ...         ...            ...   \n",
       "53382587.0     422.605860  149.769253  60.694094  372.093023       7.333333   \n",
       "53301482.0     690.291068  104.347310   0.000000  689.784053       5.000000   \n",
       "53301383.0     369.813744  117.525494  59.088341  346.079734       3.500000   \n",
       "53301632.0     588.740241  122.012771   0.000000  587.674419       9.000000   \n",
       "53301556.0     650.325439  113.638946  42.683343  627.973422       4.333333   \n",
       "\n",
       "              s4_pathLength  s2_numAroBonds  s3_numAroBonds  s4_numAroBonds  \\\n",
       "OPTUM_LAB_ID                                                                  \n",
       "53300413.0        15.500000             0.0             6.0             6.0   \n",
       "49795501.0         6.000000             0.0             5.0             6.0   \n",
       "9551212.0          0.000000             0.0             0.0             0.0   \n",
       "53300217.0         9.000000             0.0             6.0             6.0   \n",
       "1254489.0          0.000000             0.0             0.0             0.0   \n",
       "...                     ...             ...             ...             ...   \n",
       "53382587.0         7.333333             0.0             2.0             6.0   \n",
       "53301482.0        11.000000             6.0             5.0            18.0   \n",
       "53301383.0         9.000000             0.0             1.0             4.0   \n",
       "53301632.0         8.000000             6.0             6.0            11.0   \n",
       "53301556.0        10.666667             2.0             4.0            12.0   \n",
       "\n",
       "              chiralPhMoment  \n",
       "OPTUM_LAB_ID                  \n",
       "53300413.0         12.001003  \n",
       "49795501.0          6.633250  \n",
       "9551212.0           0.000000  \n",
       "53300217.0          3.602880  \n",
       "1254489.0           0.000000  \n",
       "...                      ...  \n",
       "53382587.0          5.130768  \n",
       "53301482.0          9.797959  \n",
       "53301383.0          7.123106  \n",
       "53301632.0         10.392305  \n",
       "53301556.0          9.090127  \n",
       "\n",
       "[1134 rows x 149 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Lasso_data=X_NAomit_data[X_NAomit_data.columns[model.get_support()]]\n",
    "Lasso_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "afcca2a8-9ce0-4c49-88db-c3265e6374fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "Lasso_data.to_csv('./Lasso_data.csv',encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c9c9a6da-b735-4689-897c-972cd30e5f64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>max_conj_path</th>\n",
       "      <th>D/Dtr03</th>\n",
       "      <th>D/Dtr04</th>\n",
       "      <th>D/Dtr05</th>\n",
       "      <th>D/Dtr07</th>\n",
       "      <th>D/Dtr08</th>\n",
       "      <th>D/Dtr09</th>\n",
       "      <th>D/Dtr10</th>\n",
       "      <th>D/Dtr11</th>\n",
       "      <th>D/Dtr12</th>\n",
       "      <th>...</th>\n",
       "      <th>SAtot</th>\n",
       "      <th>SAacc</th>\n",
       "      <th>SAdon</th>\n",
       "      <th>Vx</th>\n",
       "      <th>s3_pathLength</th>\n",
       "      <th>s4_pathLength</th>\n",
       "      <th>s2_numAroBonds</th>\n",
       "      <th>s3_numAroBonds</th>\n",
       "      <th>s4_numAroBonds</th>\n",
       "      <th>chiralPhMoment</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OPTUM_LAB_ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>53300413.0</th>\n",
       "      <td>0.230769</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.319903</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.787557</td>\n",
       "      <td>0.375451</td>\n",
       "      <td>0.177745</td>\n",
       "      <td>0.826795</td>\n",
       "      <td>0.745098</td>\n",
       "      <td>0.596154</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.176471</td>\n",
       "      <td>0.351907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49795501.0</th>\n",
       "      <td>0.307692</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.138497</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.269680</td>\n",
       "      <td>0.193352</td>\n",
       "      <td>0.052745</td>\n",
       "      <td>0.290463</td>\n",
       "      <td>0.549020</td>\n",
       "      <td>0.230769</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.176471</td>\n",
       "      <td>0.194508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9551212.0</th>\n",
       "      <td>0.346154</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.143085</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.485380</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.428390</td>\n",
       "      <td>0.242861</td>\n",
       "      <td>0.105491</td>\n",
       "      <td>0.477030</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53300217.0</th>\n",
       "      <td>0.230769</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.167665</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.261113</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.424468</td>\n",
       "      <td>0.171870</td>\n",
       "      <td>0.052745</td>\n",
       "      <td>0.467629</td>\n",
       "      <td>0.627451</td>\n",
       "      <td>0.346154</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.176471</td>\n",
       "      <td>0.105648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1254489.0</th>\n",
       "      <td>0.307692</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.405948</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.339129</td>\n",
       "      <td>0.142809</td>\n",
       "      <td>0.052745</td>\n",
       "      <td>0.407911</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53382587.0</th>\n",
       "      <td>0.307692</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.199110</td>\n",
       "      <td>0.283151</td>\n",
       "      <td>0.177745</td>\n",
       "      <td>0.185676</td>\n",
       "      <td>0.575163</td>\n",
       "      <td>0.282051</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.176471</td>\n",
       "      <td>0.150450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53301482.0</th>\n",
       "      <td>0.538462</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.200696</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.436997</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.465018</td>\n",
       "      <td>0.163373</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.548139</td>\n",
       "      <td>0.392157</td>\n",
       "      <td>0.423077</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.529412</td>\n",
       "      <td>0.287307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53301383.0</th>\n",
       "      <td>0.230769</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.089898</td>\n",
       "      <td>0.226654</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.383550</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.146668</td>\n",
       "      <td>0.198124</td>\n",
       "      <td>0.173043</td>\n",
       "      <td>0.155997</td>\n",
       "      <td>0.274510</td>\n",
       "      <td>0.346154</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.117647</td>\n",
       "      <td>0.208872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53301632.0</th>\n",
       "      <td>0.423077</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.303956</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.251816</td>\n",
       "      <td>0.314201</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.364141</td>\n",
       "      <td>0.209957</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.431639</td>\n",
       "      <td>0.705882</td>\n",
       "      <td>0.307692</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.323529</td>\n",
       "      <td>0.304735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53301556.0</th>\n",
       "      <td>0.230769</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.188640</td>\n",
       "      <td>0.454007</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.811909</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.425318</td>\n",
       "      <td>0.187875</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.477617</td>\n",
       "      <td>0.339869</td>\n",
       "      <td>0.410256</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.352941</td>\n",
       "      <td>0.266551</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1134 rows × 149 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              max_conj_path  D/Dtr03  D/Dtr04   D/Dtr05   D/Dtr07  D/Dtr08  \\\n",
       "OPTUM_LAB_ID                                                                 \n",
       "53300413.0         0.230769      0.0      0.0  0.319903  0.000000      0.0   \n",
       "49795501.0         0.307692      0.0      0.0  0.138497  0.000000      0.0   \n",
       "9551212.0          0.346154      0.0      0.0  0.143085  0.000000      0.0   \n",
       "53300217.0         0.230769      0.0      0.0  0.167665  0.000000      0.0   \n",
       "1254489.0          0.307692      0.0      0.0  0.000000  0.000000      0.0   \n",
       "...                     ...      ...      ...       ...       ...      ...   \n",
       "53382587.0         0.307692      0.0      0.0  0.000000  0.000000      0.0   \n",
       "53301482.0         0.538462      0.0      0.0  0.200696  0.000000      0.0   \n",
       "53301383.0         0.230769      0.0      0.0  0.089898  0.226654      0.0   \n",
       "53301632.0         0.423077      0.0      0.0  0.303956  0.000000      0.0   \n",
       "53301556.0         0.230769      0.0      0.0  0.188640  0.454007      0.0   \n",
       "\n",
       "               D/Dtr09   D/Dtr10   D/Dtr11  D/Dtr12  ...     SAtot     SAacc  \\\n",
       "OPTUM_LAB_ID                                         ...                       \n",
       "53300413.0    0.000000  0.000000  0.000000      0.0  ...  0.787557  0.375451   \n",
       "49795501.0    0.000000  0.000000  0.000000      0.0  ...  0.269680  0.193352   \n",
       "9551212.0     0.485380  0.000000  0.000000      0.0  ...  0.428390  0.242861   \n",
       "53300217.0    0.261113  0.000000  0.000000      0.0  ...  0.424468  0.171870   \n",
       "1254489.0     0.000000  0.405948  0.000000      0.0  ...  0.339129  0.142809   \n",
       "...                ...       ...       ...      ...  ...       ...       ...   \n",
       "53382587.0    0.000000  0.000000  0.000000      0.0  ...  0.199110  0.283151   \n",
       "53301482.0    0.000000  0.436997  0.000000      0.0  ...  0.465018  0.163373   \n",
       "53301383.0    0.000000  0.000000  0.383550      0.0  ...  0.146668  0.198124   \n",
       "53301632.0    0.251816  0.314201  0.000000      0.0  ...  0.364141  0.209957   \n",
       "53301556.0    0.000000  0.000000  0.811909      0.0  ...  0.425318  0.187875   \n",
       "\n",
       "                 SAdon        Vx  s3_pathLength  s4_pathLength  \\\n",
       "OPTUM_LAB_ID                                                     \n",
       "53300413.0    0.177745  0.826795       0.745098       0.596154   \n",
       "49795501.0    0.052745  0.290463       0.549020       0.230769   \n",
       "9551212.0     0.105491  0.477030       0.000000       0.000000   \n",
       "53300217.0    0.052745  0.467629       0.627451       0.346154   \n",
       "1254489.0     0.052745  0.407911       0.000000       0.000000   \n",
       "...                ...       ...            ...            ...   \n",
       "53382587.0    0.177745  0.185676       0.575163       0.282051   \n",
       "53301482.0    0.000000  0.548139       0.392157       0.423077   \n",
       "53301383.0    0.173043  0.155997       0.274510       0.346154   \n",
       "53301632.0    0.000000  0.431639       0.705882       0.307692   \n",
       "53301556.0    0.125000  0.477617       0.339869       0.410256   \n",
       "\n",
       "              s2_numAroBonds  s3_numAroBonds  s4_numAroBonds  chiralPhMoment  \n",
       "OPTUM_LAB_ID                                                                  \n",
       "53300413.0          0.000000        0.500000        0.176471        0.351907  \n",
       "49795501.0          0.000000        0.416667        0.176471        0.194508  \n",
       "9551212.0           0.000000        0.000000        0.000000        0.000000  \n",
       "53300217.0          0.000000        0.500000        0.176471        0.105648  \n",
       "1254489.0           0.000000        0.000000        0.000000        0.000000  \n",
       "...                      ...             ...             ...             ...  \n",
       "53382587.0          0.000000        0.166667        0.176471        0.150450  \n",
       "53301482.0          0.545455        0.416667        0.529412        0.287307  \n",
       "53301383.0          0.000000        0.083333        0.117647        0.208872  \n",
       "53301632.0          0.545455        0.500000        0.323529        0.304735  \n",
       "53301556.0          0.181818        0.333333        0.352941        0.266551  \n",
       "\n",
       "[1134 rows x 149 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Scale data\n",
    "Scaler = preprocessing.MinMaxScaler() #StandardScaler\n",
    "Transformer =Scaler.fit(Lasso_data)\n",
    "X_scaled_data=Transformer.transform(Lasso_data)\n",
    "X_scaled_data =pd.DataFrame(X_scaled_data)\n",
    "X_scaled_data.columns=Lasso_data.columns\n",
    "X_scaled_data.index=Raw_data.index\n",
    "\n",
    "joblib.dump(Transformer, './Lasso_Scaler_transformer.pkl')\n",
    "\n",
    "X_scaled_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebf2fe42-4422-4a22-b6ca-12bc06763fb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "Lasso_data= pd.read_csv(\"./Lasso_data.csvv\",header=0,index_col=0)\n",
    "\n",
    "Raw_data = pd.read_csv('.Lasso_Scaler_transformer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2c0643c9-e6ee-441f-a6e6-f8951935a04a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Model_results(Model_clf,X_test,y,Cv_model):\n",
    "    Model_scores= cross_validate(estimator=Model_clf, X=X_test, y=y, cv=Cv_model,scoring=( 'accuracy','f1','precision','recall','roc_auc'), return_train_score=True)\n",
    "    Model_score= cross_validate(estimator=Model_clf, X=X_test, y=y, cv=Cv_model,scoring=( 'accuracy','f1','precision','recall','roc_auc'), return_train_score=False)\n",
    "#Accuracy\n",
    "    Model_Accuracy_test_mean=Model_scores['test_accuracy'].mean()\n",
    "    Model_Accuracy_test_se=(Model_scores['test_accuracy'].std()/math.sqrt(len(Model_scores['test_accuracy']))) \n",
    "    Model_Accuracy_train_mean=Model_scores['train_accuracy'].mean()\n",
    "    Model_Accuracy_train_se=(Model_scores['train_accuracy'].std()/math.sqrt(len(Model_scores['train_accuracy']))) \n",
    "#f1\n",
    "    Model_f1_mean=Model_score['test_f1'].mean()\n",
    "    Model_f1_se=(Model_score['test_f1'].std()/math.sqrt(len(Model_score['test_f1']))) \n",
    "#precision\n",
    "    Model_precision_mean=Model_score['test_precision'].mean()\n",
    "    Model_precision_se=(Model_score['test_precision'].std()/math.sqrt(len(Model_score['test_precision']))) \n",
    "#recall\n",
    "    Model_recall_mean=Model_score['test_recall'].mean()\n",
    "    Model_recall_se=(Model_score['test_recall'].std()/math.sqrt(len(Model_score['test_recall']))) \n",
    "#roc_auc\n",
    "    Model_roc_auc_mean=Model_score['test_roc_auc'].mean()\n",
    "    Model_roc_auc_se=(Model_score['test_roc_auc'].std()/math.sqrt(len(Model_score['test_roc_auc']))) \n",
    "    Model = {'Mean':[Model_Accuracy_test_mean,Model_Accuracy_train_mean,Model_f1_mean,Model_precision_mean,Model_recall_mean,Model_roc_auc_mean],\n",
    "        'Se':[Model_Accuracy_test_se,Model_Accuracy_train_se,Model_f1_se,Model_precision_se,Model_recall_se,Model_roc_auc_se]}\n",
    "    Model = pd.DataFrame(Model, index=['Accuracy_test','Accuracy_train','F1 Score','Precision','Recall','Roc_auc']) # 这里设定了 index 个数要和列表长度一致\n",
    "    return Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0e49d1bb-d5f4-4e7f-a620-a943c578fba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setting the KFold \n",
    "Cv_optuna= RepeatedStratifiedKFold(n_splits=5, n_repeats=10, random_state=0)\n",
    "Cv_model= RepeatedStratifiedKFold(n_splits=5, n_repeats=10, random_state=0)\n",
    "Cv_RFECV= RepeatedStratifiedKFold(n_splits=5, n_repeats=10, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8b74394b-d874-4115-b66e-0bac0d514965",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data pre-processing of models\n",
    "X=np.array(X_scaled_data)\n",
    "y=Raw_data['Activity'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d026e47-e8b2-467a-a5a0-866a1888a801",
   "metadata": {},
   "source": [
    "## 1.1 DT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e5dd9da6-318e-4a8f-8b6e-46380439376d",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf=DecisionTreeClassifier(random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9d7e67d4-b288-4270-be5d-1598f117e05d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mean</th>\n",
       "      <th>Se</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Accuracy_test</th>\n",
       "      <td>0.611278</td>\n",
       "      <td>0.004576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Accuracy_train</th>\n",
       "      <td>0.999317</td>\n",
       "      <td>0.000076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1 Score</th>\n",
       "      <td>0.609712</td>\n",
       "      <td>0.005344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Precision</th>\n",
       "      <td>0.611890</td>\n",
       "      <td>0.004527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recall</th>\n",
       "      <td>0.609177</td>\n",
       "      <td>0.007503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Roc_auc</th>\n",
       "      <td>0.611871</td>\n",
       "      <td>0.004561</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Mean        Se\n",
       "Accuracy_test   0.611278  0.004576\n",
       "Accuracy_train  0.999317  0.000076\n",
       "F1 Score        0.609712  0.005344\n",
       "Precision       0.611890  0.004527\n",
       "Recall          0.609177  0.007503\n",
       "Roc_auc         0.611871  0.004561"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Model1 （4175 descriptors）\n",
    "Model1_clf=clf\n",
    "#Model1\n",
    "Model1=Model_results(Model1_clf,X,y,Cv_model)\n",
    "Model1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7bb0633b-59c6-4ad7-afb1-e241f713f990",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2024-11-15 06:04:06,756]\u001b[0m A new study created in memory with name: no-name-6adabdfb-2395-4c5a-a5c0-833c9a589db8\u001b[0m\n",
      "\u001b[32m[I 2024-11-15 06:04:09,878]\u001b[0m Trial 0 finished with value: 0.620705625511676 and parameters: {'max_depth': 4, 'max_features': 17, 'min_samples_split': 16}. Best is trial 0 with value: 0.620705625511676.\u001b[0m\n",
      "\u001b[32m[I 2024-11-15 06:04:10,033]\u001b[0m Trial 1 finished with value: 0.6171973802190948 and parameters: {'max_depth': 4, 'max_features': 14, 'min_samples_split': 17}. Best is trial 0 with value: 0.620705625511676.\u001b[0m\n",
      "\u001b[32m[I 2024-11-15 06:04:10,203]\u001b[0m Trial 2 finished with value: 0.6215901914155393 and parameters: {'max_depth': 4, 'max_features': 19, 'min_samples_split': 25}. Best is trial 2 with value: 0.6215901914155393.\u001b[0m\n",
      "\u001b[32m[I 2024-11-15 06:04:10,357]\u001b[0m Trial 3 finished with value: 0.620799578963783 and parameters: {'max_depth': 4, 'max_features': 18, 'min_samples_split': 14}. Best is trial 2 with value: 0.6215901914155393.\u001b[0m\n",
      "\u001b[32m[I 2024-11-15 06:04:10,530]\u001b[0m Trial 4 finished with value: 0.6238041401894663 and parameters: {'max_depth': 4, 'max_features': 20, 'min_samples_split': 3}. Best is trial 4 with value: 0.6238041401894663.\u001b[0m\n",
      "\u001b[32m[I 2024-11-15 06:04:10,683]\u001b[0m Trial 5 finished with value: 0.6135788078437487 and parameters: {'max_depth': 3, 'max_features': 10, 'min_samples_split': 21}. Best is trial 4 with value: 0.6238041401894663.\u001b[0m\n",
      "\u001b[32m[I 2024-11-15 06:04:10,853]\u001b[0m Trial 6 finished with value: 0.6258278429690851 and parameters: {'max_depth': 5, 'max_features': 19, 'min_samples_split': 25}. Best is trial 6 with value: 0.6258278429690851.\u001b[0m\n",
      "\u001b[32m[I 2024-11-15 06:04:11,022]\u001b[0m Trial 7 finished with value: 0.6266991540290827 and parameters: {'max_depth': 5, 'max_features': 15, 'min_samples_split': 20}. Best is trial 7 with value: 0.6266991540290827.\u001b[0m\n",
      "\u001b[32m[I 2024-11-15 06:04:11,177]\u001b[0m Trial 8 finished with value: 0.6269747768118203 and parameters: {'max_depth': 3, 'max_features': 17, 'min_samples_split': 5}. Best is trial 8 with value: 0.6269747768118203.\u001b[0m\n",
      "\u001b[32m[I 2024-11-15 06:04:11,333]\u001b[0m Trial 9 finished with value: 0.6228275700752408 and parameters: {'max_depth': 5, 'max_features': 15, 'min_samples_split': 11}. Best is trial 8 with value: 0.6269747768118203.\u001b[0m\n",
      "\u001b[32m[I 2024-11-15 06:04:11,488]\u001b[0m Trial 10 finished with value: 0.6145549881096254 and parameters: {'max_depth': 3, 'max_features': 12, 'min_samples_split': 2}. Best is trial 8 with value: 0.6269747768118203.\u001b[0m\n",
      "\u001b[32m[I 2024-11-15 06:04:11,660]\u001b[0m Trial 11 finished with value: 0.6184250126700713 and parameters: {'max_depth': 3, 'max_features': 16, 'min_samples_split': 8}. Best is trial 8 with value: 0.6269747768118203.\u001b[0m\n",
      "\u001b[32m[I 2024-11-15 06:04:11,828]\u001b[0m Trial 12 finished with value: 0.6156071888035554 and parameters: {'max_depth': 5, 'max_features': 14, 'min_samples_split': 6}. Best is trial 8 with value: 0.6269747768118203.\u001b[0m\n",
      "\u001b[32m[I 2024-11-15 06:04:11,997]\u001b[0m Trial 13 finished with value: 0.6183365170948502 and parameters: {'max_depth': 3, 'max_features': 16, 'min_samples_split': 20}. Best is trial 8 with value: 0.6269747768118203.\u001b[0m\n",
      "\u001b[32m[I 2024-11-15 06:04:12,154]\u001b[0m Trial 14 finished with value: 0.6201816693306303 and parameters: {'max_depth': 5, 'max_features': 13, 'min_samples_split': 10}. Best is trial 8 with value: 0.6269747768118203.\u001b[0m\n",
      "\u001b[32m[I 2024-11-15 06:04:12,310]\u001b[0m Trial 15 finished with value: 0.6275018517796578 and parameters: {'max_depth': 3, 'max_features': 17, 'min_samples_split': 21}. Best is trial 15 with value: 0.6275018517796578.\u001b[0m\n",
      "\u001b[32m[I 2024-11-15 06:04:12,480]\u001b[0m Trial 16 finished with value: 0.6269747768118203 and parameters: {'max_depth': 3, 'max_features': 17, 'min_samples_split': 5}. Best is trial 15 with value: 0.6275018517796578.\u001b[0m\n",
      "\u001b[32m[I 2024-11-15 06:04:12,636]\u001b[0m Trial 17 finished with value: 0.6118868660091225 and parameters: {'max_depth': 3, 'max_features': 18, 'min_samples_split': 13}. Best is trial 15 with value: 0.6275018517796578.\u001b[0m\n",
      "\u001b[32m[I 2024-11-15 06:04:12,807]\u001b[0m Trial 18 finished with value: 0.6077513547230128 and parameters: {'max_depth': 3, 'max_features': 20, 'min_samples_split': 22}. Best is trial 15 with value: 0.6275018517796578.\u001b[0m\n",
      "\u001b[32m[I 2024-11-15 06:04:12,962]\u001b[0m Trial 19 finished with value: 0.627239093992437 and parameters: {'max_depth': 3, 'max_features': 17, 'min_samples_split': 17}. Best is trial 15 with value: 0.6275018517796578.\u001b[0m\n",
      "\u001b[32m[I 2024-11-15 06:04:13,119]\u001b[0m Trial 20 finished with value: 0.6120763323067326 and parameters: {'max_depth': 4, 'max_features': 11, 'min_samples_split': 17}. Best is trial 15 with value: 0.6275018517796578.\u001b[0m\n",
      "\u001b[32m[I 2024-11-15 06:04:13,274]\u001b[0m Trial 21 finished with value: 0.6268851116915521 and parameters: {'max_depth': 3, 'max_features': 17, 'min_samples_split': 18}. Best is trial 15 with value: 0.6275018517796578.\u001b[0m\n",
      "\u001b[32m[I 2024-11-15 06:04:13,430]\u001b[0m Trial 22 finished with value: 0.6184250126700713 and parameters: {'max_depth': 3, 'max_features': 16, 'min_samples_split': 14}. Best is trial 15 with value: 0.6275018517796578.\u001b[0m\n",
      "\u001b[32m[I 2024-11-15 06:04:13,586]\u001b[0m Trial 23 finished with value: 0.6118868660091225 and parameters: {'max_depth': 3, 'max_features': 18, 'min_samples_split': 23}. Best is trial 15 with value: 0.6275018517796578.\u001b[0m\n",
      "\u001b[32m[I 2024-11-15 06:04:13,756]\u001b[0m Trial 24 finished with value: 0.6275018517796578 and parameters: {'max_depth': 3, 'max_features': 17, 'min_samples_split': 19}. Best is trial 15 with value: 0.6275018517796578.\u001b[0m\n",
      "\u001b[32m[I 2024-11-15 06:04:13,927]\u001b[0m Trial 25 finished with value: 0.6180710303691864 and parameters: {'max_depth': 3, 'max_features': 19, 'min_samples_split': 19}. Best is trial 15 with value: 0.6275018517796578.\u001b[0m\n",
      "\u001b[32m[I 2024-11-15 06:04:14,081]\u001b[0m Trial 26 finished with value: 0.6183365170948502 and parameters: {'max_depth': 3, 'max_features': 16, 'min_samples_split': 23}. Best is trial 15 with value: 0.6275018517796578.\u001b[0m\n",
      "\u001b[32m[I 2024-11-15 06:04:14,239]\u001b[0m Trial 27 finished with value: 0.6276726053565163 and parameters: {'max_depth': 4, 'max_features': 15, 'min_samples_split': 15}. Best is trial 27 with value: 0.6276726053565163.\u001b[0m\n",
      "\u001b[32m[I 2024-11-15 06:04:14,408]\u001b[0m Trial 28 finished with value: 0.6276726053565163 and parameters: {'max_depth': 4, 'max_features': 15, 'min_samples_split': 15}. Best is trial 27 with value: 0.6276726053565163.\u001b[0m\n",
      "\u001b[32m[I 2024-11-15 06:04:14,562]\u001b[0m Trial 29 finished with value: 0.6126926825464895 and parameters: {'max_depth': 4, 'max_features': 14, 'min_samples_split': 12}. Best is trial 27 with value: 0.6276726053565163.\u001b[0m\n",
      "\u001b[32m[I 2024-11-15 06:04:14,718]\u001b[0m Trial 30 finished with value: 0.615076215352228 and parameters: {'max_depth': 4, 'max_features': 13, 'min_samples_split': 15}. Best is trial 27 with value: 0.6276726053565163.\u001b[0m\n",
      "\u001b[32m[I 2024-11-15 06:04:14,887]\u001b[0m Trial 31 finished with value: 0.6274963939027719 and parameters: {'max_depth': 4, 'max_features': 15, 'min_samples_split': 16}. Best is trial 27 with value: 0.6276726053565163.\u001b[0m\n",
      "\u001b[32m[I 2024-11-15 06:04:15,056]\u001b[0m Trial 32 finished with value: 0.6276726053565163 and parameters: {'max_depth': 4, 'max_features': 15, 'min_samples_split': 19}. Best is trial 27 with value: 0.6276726053565163.\u001b[0m\n",
      "\u001b[32m[I 2024-11-15 06:04:15,213]\u001b[0m Trial 33 finished with value: 0.6274963939027719 and parameters: {'max_depth': 4, 'max_features': 15, 'min_samples_split': 16}. Best is trial 27 with value: 0.6276726053565163.\u001b[0m\n",
      "\u001b[32m[I 2024-11-15 06:04:15,369]\u001b[0m Trial 34 finished with value: 0.6142836536587268 and parameters: {'max_depth': 4, 'max_features': 13, 'min_samples_split': 18}. Best is trial 27 with value: 0.6276726053565163.\u001b[0m\n",
      "\u001b[32m[I 2024-11-15 06:04:15,539]\u001b[0m Trial 35 finished with value: 0.6149896690187517 and parameters: {'max_depth': 4, 'max_features': 14, 'min_samples_split': 15}. Best is trial 27 with value: 0.6276726053565163.\u001b[0m\n",
      "\u001b[32m[I 2024-11-15 06:04:15,711]\u001b[0m Trial 36 finished with value: 0.6195719465128066 and parameters: {'max_depth': 4, 'max_features': 16, 'min_samples_split': 19}. Best is trial 27 with value: 0.6276726053565163.\u001b[0m\n",
      "\u001b[32m[I 2024-11-15 06:04:15,882]\u001b[0m Trial 37 finished with value: 0.6194047015710888 and parameters: {'max_depth': 4, 'max_features': 14, 'min_samples_split': 22}. Best is trial 27 with value: 0.6276726053565163.\u001b[0m\n",
      "\u001b[32m[I 2024-11-15 06:04:16,037]\u001b[0m Trial 38 finished with value: 0.6248481540680676 and parameters: {'max_depth': 4, 'max_features': 15, 'min_samples_split': 13}. Best is trial 27 with value: 0.6276726053565163.\u001b[0m\n",
      "\u001b[32m[I 2024-11-15 06:04:16,208]\u001b[0m Trial 39 finished with value: 0.6260882616662119 and parameters: {'max_depth': 5, 'max_features': 18, 'min_samples_split': 10}. Best is trial 27 with value: 0.6276726053565163.\u001b[0m\n",
      "\u001b[32m[I 2024-11-15 06:04:16,364]\u001b[0m Trial 40 finished with value: 0.6222100502904371 and parameters: {'max_depth': 4, 'max_features': 12, 'min_samples_split': 15}. Best is trial 27 with value: 0.6276726053565163.\u001b[0m\n",
      "\u001b[32m[I 2024-11-15 06:04:16,534]\u001b[0m Trial 41 finished with value: 0.6194846204826322 and parameters: {'max_depth': 4, 'max_features': 16, 'min_samples_split': 20}. Best is trial 27 with value: 0.6276726053565163.\u001b[0m\n",
      "\u001b[32m[I 2024-11-15 06:04:16,703]\u001b[0m Trial 42 finished with value: 0.6292663054071966 and parameters: {'max_depth': 4, 'max_features': 15, 'min_samples_split': 21}. Best is trial 42 with value: 0.6292663054071966.\u001b[0m\n",
      "\u001b[32m[I 2024-11-15 06:04:16,876]\u001b[0m Trial 43 finished with value: 0.6290070562551168 and parameters: {'max_depth': 4, 'max_features': 15, 'min_samples_split': 25}. Best is trial 42 with value: 0.6292663054071966.\u001b[0m\n",
      "\u001b[32m[I 2024-11-15 06:04:17,033]\u001b[0m Trial 44 finished with value: 0.6278566137772407 and parameters: {'max_depth': 4, 'max_features': 15, 'min_samples_split': 24}. Best is trial 42 with value: 0.6292663054071966.\u001b[0m\n",
      "\u001b[32m[I 2024-11-15 06:04:17,202]\u001b[0m Trial 45 finished with value: 0.6290070562551168 and parameters: {'max_depth': 4, 'max_features': 15, 'min_samples_split': 25}. Best is trial 42 with value: 0.6292663054071966.\u001b[0m\n",
      "\u001b[32m[I 2024-11-15 06:04:17,371]\u001b[0m Trial 46 finished with value: 0.6156906163502398 and parameters: {'max_depth': 4, 'max_features': 13, 'min_samples_split': 25}. Best is trial 42 with value: 0.6292663054071966.\u001b[0m\n",
      "\u001b[32m[I 2024-11-15 06:04:17,526]\u001b[0m Trial 47 finished with value: 0.6168453471599548 and parameters: {'max_depth': 4, 'max_features': 14, 'min_samples_split': 25}. Best is trial 42 with value: 0.6292663054071966.\u001b[0m\n",
      "\u001b[32m[I 2024-11-15 06:04:17,697]\u001b[0m Trial 48 finished with value: 0.6278566137772407 and parameters: {'max_depth': 4, 'max_features': 15, 'min_samples_split': 24}. Best is trial 42 with value: 0.6292663054071966.\u001b[0m\n",
      "\u001b[32m[I 2024-11-15 06:04:17,870]\u001b[0m Trial 49 finished with value: 0.6210674047795408 and parameters: {'max_depth': 5, 'max_features': 14, 'min_samples_split': 24}. Best is trial 42 with value: 0.6292663054071966.\u001b[0m\n",
      "\u001b[32m[I 2024-11-15 06:04:18,026]\u001b[0m Trial 50 finished with value: 0.6198366535417722 and parameters: {'max_depth': 4, 'max_features': 16, 'min_samples_split': 24}. Best is trial 42 with value: 0.6292663054071966.\u001b[0m\n",
      "\u001b[32m[I 2024-11-15 06:04:18,196]\u001b[0m Trial 51 finished with value: 0.628297142411602 and parameters: {'max_depth': 4, 'max_features': 15, 'min_samples_split': 23}. Best is trial 42 with value: 0.6292663054071966.\u001b[0m\n",
      "\u001b[32m[I 2024-11-15 06:04:18,365]\u001b[0m Trial 52 finished with value: 0.6278566137772407 and parameters: {'max_depth': 4, 'max_features': 15, 'min_samples_split': 24}. Best is trial 42 with value: 0.6292663054071966.\u001b[0m\n",
      "\u001b[32m[I 2024-11-15 06:04:18,522]\u001b[0m Trial 53 finished with value: 0.6194047015710888 and parameters: {'max_depth': 4, 'max_features': 14, 'min_samples_split': 22}. Best is trial 42 with value: 0.6292663054071966.\u001b[0m\n",
      "\u001b[32m[I 2024-11-15 06:04:18,693]\u001b[0m Trial 54 finished with value: 0.6200128649955167 and parameters: {'max_depth': 4, 'max_features': 16, 'min_samples_split': 23}. Best is trial 42 with value: 0.6292663054071966.\u001b[0m\n",
      "\u001b[32m[I 2024-11-15 06:04:18,861]\u001b[0m Trial 55 finished with value: 0.6292663054071966 and parameters: {'max_depth': 4, 'max_features': 15, 'min_samples_split': 21}. Best is trial 42 with value: 0.6292663054071966.\u001b[0m\n",
      "\u001b[32m[I 2024-11-15 06:04:19,033]\u001b[0m Trial 56 finished with value: 0.6186998557561109 and parameters: {'max_depth': 4, 'max_features': 14, 'min_samples_split': 21}. Best is trial 42 with value: 0.6292663054071966.\u001b[0m\n",
      "\u001b[32m[I 2024-11-15 06:04:19,203]\u001b[0m Trial 57 finished with value: 0.6170149311917664 and parameters: {'max_depth': 4, 'max_features': 16, 'min_samples_split': 25}. Best is trial 42 with value: 0.6292663054071966.\u001b[0m\n",
      "\u001b[32m[I 2024-11-15 06:04:19,373]\u001b[0m Trial 58 finished with value: 0.6155144048964953 and parameters: {'max_depth': 4, 'max_features': 13, 'min_samples_split': 22}. Best is trial 42 with value: 0.6292663054071966.\u001b[0m\n",
      "\u001b[32m[I 2024-11-15 06:04:19,541]\u001b[0m Trial 59 finished with value: 0.6292663054071966 and parameters: {'max_depth': 4, 'max_features': 15, 'min_samples_split': 21}. Best is trial 42 with value: 0.6292663054071966.\u001b[0m\n",
      "\u001b[32m[I 2024-11-15 06:04:19,697]\u001b[0m Trial 60 finished with value: 0.6186998557561109 and parameters: {'max_depth': 4, 'max_features': 14, 'min_samples_split': 21}. Best is trial 42 with value: 0.6292663054071966.\u001b[0m\n",
      "\u001b[32m[I 2024-11-15 06:04:19,868]\u001b[0m Trial 61 finished with value: 0.628297142411602 and parameters: {'max_depth': 4, 'max_features': 15, 'min_samples_split': 23}. Best is trial 42 with value: 0.6292663054071966.\u001b[0m\n",
      "\u001b[32m[I 2024-11-15 06:04:20,025]\u001b[0m Trial 62 finished with value: 0.628297142411602 and parameters: {'max_depth': 4, 'max_features': 15, 'min_samples_split': 23}. Best is trial 42 with value: 0.6292663054071966.\u001b[0m\n",
      "\u001b[32m[I 2024-11-15 06:04:20,198]\u001b[0m Trial 63 finished with value: 0.621158629293205 and parameters: {'max_depth': 4, 'max_features': 16, 'min_samples_split': 21}. Best is trial 42 with value: 0.6292663054071966.\u001b[0m\n",
      "\u001b[32m[I 2024-11-15 06:04:20,368]\u001b[0m Trial 64 finished with value: 0.6295306225878133 and parameters: {'max_depth': 4, 'max_features': 15, 'min_samples_split': 20}. Best is trial 64 with value: 0.6295306225878133.\u001b[0m\n",
      "\u001b[32m[I 2024-11-15 06:04:20,525]\u001b[0m Trial 65 finished with value: 0.6295306225878133 and parameters: {'max_depth': 4, 'max_features': 15, 'min_samples_split': 20}. Best is trial 64 with value: 0.6295306225878133.\u001b[0m\n",
      "\u001b[32m[I 2024-11-15 06:04:20,695]\u001b[0m Trial 66 finished with value: 0.6215964289891233 and parameters: {'max_depth': 5, 'max_features': 16, 'min_samples_split': 20}. Best is trial 64 with value: 0.6295306225878133.\u001b[0m\n",
      "\u001b[32m[I 2024-11-15 06:04:20,865]\u001b[0m Trial 67 finished with value: 0.6177291333671202 and parameters: {'max_depth': 4, 'max_features': 14, 'min_samples_split': 18}. Best is trial 64 with value: 0.6295306225878133.\u001b[0m\n",
      "\u001b[32m[I 2024-11-15 06:04:21,036]\u001b[0m Trial 68 finished with value: 0.6240637791898951 and parameters: {'max_depth': 4, 'max_features': 17, 'min_samples_split': 20}. Best is trial 64 with value: 0.6295306225878133.\u001b[0m\n",
      "\u001b[32m[I 2024-11-15 06:04:21,206]\u001b[0m Trial 69 finished with value: 0.6283852481384742 and parameters: {'max_depth': 4, 'max_features': 15, 'min_samples_split': 22}. Best is trial 64 with value: 0.6295306225878133.\u001b[0m\n",
      "\u001b[32m[I 2024-11-15 06:04:21,362]\u001b[0m Trial 70 finished with value: 0.6186998557561109 and parameters: {'max_depth': 4, 'max_features': 14, 'min_samples_split': 21}. Best is trial 64 with value: 0.6295306225878133.\u001b[0m\n",
      "\u001b[32m[I 2024-11-15 06:04:21,532]\u001b[0m Trial 71 finished with value: 0.6283852481384742 and parameters: {'max_depth': 4, 'max_features': 15, 'min_samples_split': 22}. Best is trial 64 with value: 0.6295306225878133.\u001b[0m\n",
      "\u001b[32m[I 2024-11-15 06:04:21,688]\u001b[0m Trial 72 finished with value: 0.6295306225878133 and parameters: {'max_depth': 4, 'max_features': 15, 'min_samples_split': 20}. Best is trial 64 with value: 0.6295306225878133.\u001b[0m\n",
      "\u001b[32m[I 2024-11-15 06:04:21,847]\u001b[0m Trial 73 finished with value: 0.6194846204826322 and parameters: {'max_depth': 4, 'max_features': 16, 'min_samples_split': 20}. Best is trial 64 with value: 0.6295306225878133.\u001b[0m\n",
      "\u001b[32m[I 2024-11-15 06:04:22,003]\u001b[0m Trial 74 finished with value: 0.6193949553623641 and parameters: {'max_depth': 4, 'max_features': 16, 'min_samples_split': 18}. Best is trial 64 with value: 0.6295306225878133.\u001b[0m\n",
      "\u001b[32m[I 2024-11-15 06:04:22,172]\u001b[0m Trial 75 finished with value: 0.6285536626252388 and parameters: {'max_depth': 4, 'max_features': 15, 'min_samples_split': 17}. Best is trial 64 with value: 0.6295306225878133.\u001b[0m\n",
      "\u001b[32m[I 2024-11-15 06:04:22,327]\u001b[0m Trial 76 finished with value: 0.6171123932790145 and parameters: {'max_depth': 4, 'max_features': 14, 'min_samples_split': 19}. Best is trial 64 with value: 0.6295306225878133.\u001b[0m\n",
      "\u001b[32m[I 2024-11-15 06:04:22,498]\u001b[0m Trial 77 finished with value: 0.6295306225878133 and parameters: {'max_depth': 4, 'max_features': 15, 'min_samples_split': 20}. Best is trial 64 with value: 0.6295306225878133.\u001b[0m\n",
      "\u001b[32m[I 2024-11-15 06:04:22,667]\u001b[0m Trial 78 finished with value: 0.6285536626252388 and parameters: {'max_depth': 4, 'max_features': 15, 'min_samples_split': 17}. Best is trial 64 with value: 0.6295306225878133.\u001b[0m\n",
      "\u001b[32m[I 2024-11-15 06:04:22,822]\u001b[0m Trial 79 finished with value: 0.6239764531597208 and parameters: {'max_depth': 4, 'max_features': 10, 'min_samples_split': 20}. Best is trial 64 with value: 0.6295306225878133.\u001b[0m\n",
      "\u001b[32m[I 2024-11-15 06:04:22,995]\u001b[0m Trial 80 finished with value: 0.6195719465128066 and parameters: {'max_depth': 4, 'max_features': 16, 'min_samples_split': 19}. Best is trial 64 with value: 0.6295306225878133.\u001b[0m\n",
      "\u001b[32m[I 2024-11-15 06:04:23,150]\u001b[0m Trial 81 finished with value: 0.6292663054071966 and parameters: {'max_depth': 4, 'max_features': 15, 'min_samples_split': 21}. Best is trial 64 with value: 0.6295306225878133.\u001b[0m\n",
      "\u001b[32m[I 2024-11-15 06:04:23,305]\u001b[0m Trial 82 finished with value: 0.6292663054071966 and parameters: {'max_depth': 4, 'max_features': 15, 'min_samples_split': 21}. Best is trial 64 with value: 0.6295306225878133.\u001b[0m\n",
      "\u001b[32m[I 2024-11-15 06:04:23,459]\u001b[0m Trial 83 finished with value: 0.6186998557561109 and parameters: {'max_depth': 4, 'max_features': 14, 'min_samples_split': 21}. Best is trial 64 with value: 0.6295306225878133.\u001b[0m\n",
      "\u001b[32m[I 2024-11-15 06:04:23,629]\u001b[0m Trial 84 finished with value: 0.6194846204826322 and parameters: {'max_depth': 4, 'max_features': 16, 'min_samples_split': 20}. Best is trial 64 with value: 0.6295306225878133.\u001b[0m\n",
      "\u001b[32m[I 2024-11-15 06:04:23,801]\u001b[0m Trial 85 finished with value: 0.6276726053565163 and parameters: {'max_depth': 4, 'max_features': 15, 'min_samples_split': 19}. Best is trial 64 with value: 0.6295306225878133.\u001b[0m\n",
      "\u001b[32m[I 2024-11-15 06:04:23,970]\u001b[0m Trial 86 finished with value: 0.6186998557561109 and parameters: {'max_depth': 4, 'max_features': 14, 'min_samples_split': 21}. Best is trial 64 with value: 0.6295306225878133.\u001b[0m\n",
      "\u001b[32m[I 2024-11-15 06:04:24,139]\u001b[0m Trial 87 finished with value: 0.6283852481384742 and parameters: {'max_depth': 4, 'max_features': 15, 'min_samples_split': 22}. Best is trial 64 with value: 0.6295306225878133.\u001b[0m\n",
      "\u001b[32m[I 2024-11-15 06:04:24,309]\u001b[0m Trial 88 finished with value: 0.6284655568983666 and parameters: {'max_depth': 4, 'max_features': 15, 'min_samples_split': 18}. Best is trial 64 with value: 0.6295306225878133.\u001b[0m\n",
      "\u001b[32m[I 2024-11-15 06:04:24,479]\u001b[0m Trial 89 finished with value: 0.6142801450235859 and parameters: {'max_depth': 4, 'max_features': 13, 'min_samples_split': 20}. Best is trial 64 with value: 0.6295306225878133.\u001b[0m\n",
      "\u001b[32m[I 2024-11-15 06:04:24,663]\u001b[0m Trial 90 finished with value: 0.6195719465128066 and parameters: {'max_depth': 4, 'max_features': 16, 'min_samples_split': 19}. Best is trial 64 with value: 0.6295306225878133.\u001b[0m\n",
      "\u001b[32m[I 2024-11-15 06:04:24,832]\u001b[0m Trial 91 finished with value: 0.6292663054071966 and parameters: {'max_depth': 4, 'max_features': 15, 'min_samples_split': 21}. Best is trial 64 with value: 0.6295306225878133.\u001b[0m\n",
      "\u001b[32m[I 2024-11-15 06:04:25,000]\u001b[0m Trial 92 finished with value: 0.6292663054071966 and parameters: {'max_depth': 4, 'max_features': 15, 'min_samples_split': 21}. Best is trial 64 with value: 0.6295306225878133.\u001b[0m\n",
      "\u001b[32m[I 2024-11-15 06:04:25,170]\u001b[0m Trial 93 finished with value: 0.6283852481384742 and parameters: {'max_depth': 4, 'max_features': 15, 'min_samples_split': 22}. Best is trial 64 with value: 0.6295306225878133.\u001b[0m\n",
      "\u001b[32m[I 2024-11-15 06:04:25,340]\u001b[0m Trial 94 finished with value: 0.6186998557561109 and parameters: {'max_depth': 4, 'max_features': 14, 'min_samples_split': 21}. Best is trial 64 with value: 0.6295306225878133.\u001b[0m\n",
      "\u001b[32m[I 2024-11-15 06:04:25,494]\u001b[0m Trial 95 finished with value: 0.6194846204826322 and parameters: {'max_depth': 4, 'max_features': 16, 'min_samples_split': 20}. Best is trial 64 with value: 0.6295306225878133.\u001b[0m\n",
      "\u001b[32m[I 2024-11-15 06:04:25,652]\u001b[0m Trial 96 finished with value: 0.6284655568983666 and parameters: {'max_depth': 4, 'max_features': 15, 'min_samples_split': 18}. Best is trial 64 with value: 0.6295306225878133.\u001b[0m\n",
      "\u001b[32m[I 2024-11-15 06:04:25,823]\u001b[0m Trial 97 finished with value: 0.6194047015710888 and parameters: {'max_depth': 4, 'max_features': 14, 'min_samples_split': 22}. Best is trial 64 with value: 0.6295306225878133.\u001b[0m\n",
      "\u001b[32m[I 2024-11-15 06:04:25,995]\u001b[0m Trial 98 finished with value: 0.6292663054071966 and parameters: {'max_depth': 4, 'max_features': 15, 'min_samples_split': 21}. Best is trial 64 with value: 0.6295306225878133.\u001b[0m\n",
      "\u001b[32m[I 2024-11-15 06:04:26,168]\u001b[0m Trial 99 finished with value: 0.623621691162138 and parameters: {'max_depth': 4, 'max_features': 15, 'min_samples_split': 4}. Best is trial 64 with value: 0.6295306225878133.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "#Tuning hyperparameters\n",
    "#Step 1. Define an objective function to be maximized.\n",
    "def objective(trial):\n",
    "    param = {\n",
    "        'max_depth': trial.suggest_int('max_depth',3,5,1),\n",
    "        'max_features' : trial.suggest_int(\"max_features\",10,20,1),\n",
    "        'min_samples_split':trial.suggest_int('min_samples_split',2,25,1)\n",
    "    }\n",
    "    model = DecisionTreeClassifier(**param,random_state=1)\n",
    "\n",
    " \n",
    "# Step 2: Scoring method:\n",
    "    score = model_selection.cross_val_score(model, X, y, n_jobs=12, scoring=\"accuracy\",cv=Cv_optuna)\n",
    "    accuracy = score.mean()\n",
    "    return accuracy\n",
    " \n",
    "# Step 3: Running it\n",
    "study = optuna.create_study(direction=\"maximize\",sampler=optuna.samplers.TPESampler(seed=0))\n",
    "study.optimize(objective, n_trials=100, show_progress_bar=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "28ac7c97-6c21-4117-add1-12a7be2e8f2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best parameters are : \n",
      "{'max_depth': 4, 'max_features': 15, 'min_samples_split': 20}\n"
     ]
    }
   ],
   "source": [
    "# Getting the best parameters:\n",
    "print(f\"The best parameters are : \\n{study.best_params}\")\n",
    "# Setting the best model\n",
    "clf =DecisionTreeClassifier(max_depth = study.best_params['max_depth']\n",
    "              ,max_features = study.best_params['max_features']\n",
    "              #,n_estimators = study.best_params['n_estimators']\n",
    "              #,learning_rate = study.best_params['learning_rate']\n",
    "              ,min_samples_split= study.best_params['min_samples_split']\n",
    "              ,random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c0b71e00-d630-4d2b-b1d4-a79589e02288",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mean</th>\n",
       "      <th>Se</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Accuracy_test</th>\n",
       "      <td>0.629531</td>\n",
       "      <td>0.003900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Accuracy_train</th>\n",
       "      <td>0.704631</td>\n",
       "      <td>0.001940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1 Score</th>\n",
       "      <td>0.608093</td>\n",
       "      <td>0.006565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Precision</th>\n",
       "      <td>0.649133</td>\n",
       "      <td>0.006276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recall</th>\n",
       "      <td>0.583147</td>\n",
       "      <td>0.013156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Roc_auc</th>\n",
       "      <td>0.660283</td>\n",
       "      <td>0.003994</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Mean        Se\n",
       "Accuracy_test   0.629531  0.003900\n",
       "Accuracy_train  0.704631  0.001940\n",
       "F1 Score        0.608093  0.006565\n",
       "Precision       0.649133  0.006276\n",
       "Recall          0.583147  0.013156\n",
       "Roc_auc         0.660283  0.003994"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Model2\n",
    "Model2=Model_results(clf,X,y,Cv_model)\n",
    "Model2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e4359628-316f-47c6-bdef-b9471932492e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th>Method</th>\n",
       "      <th colspan=\"4\" halign=\"left\">DT</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model</th>\n",
       "      <th colspan=\"2\" halign=\"left\">Model 1</th>\n",
       "      <th colspan=\"2\" halign=\"left\">Model 2</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Values</th>\n",
       "      <th>Mean</th>\n",
       "      <th>Se</th>\n",
       "      <th>Mean</th>\n",
       "      <th>Se</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Accuracy_test</th>\n",
       "      <td>0.611278</td>\n",
       "      <td>0.004576</td>\n",
       "      <td>0.629531</td>\n",
       "      <td>0.003900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Accuracy_train</th>\n",
       "      <td>0.999317</td>\n",
       "      <td>0.000076</td>\n",
       "      <td>0.704631</td>\n",
       "      <td>0.001940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1 Score</th>\n",
       "      <td>0.609712</td>\n",
       "      <td>0.005344</td>\n",
       "      <td>0.608093</td>\n",
       "      <td>0.006565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Precision</th>\n",
       "      <td>0.611890</td>\n",
       "      <td>0.004527</td>\n",
       "      <td>0.649133</td>\n",
       "      <td>0.006276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recall</th>\n",
       "      <td>0.609177</td>\n",
       "      <td>0.007503</td>\n",
       "      <td>0.583147</td>\n",
       "      <td>0.013156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Roc_auc</th>\n",
       "      <td>0.611871</td>\n",
       "      <td>0.004561</td>\n",
       "      <td>0.660283</td>\n",
       "      <td>0.003994</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Method                DT                              \n",
       "Model            Model 1             Model 2          \n",
       "Values              Mean        Se      Mean        Se\n",
       "Accuracy_test   0.611278  0.004576  0.629531  0.003900\n",
       "Accuracy_train  0.999317  0.000076  0.704631  0.001940\n",
       "F1 Score        0.609712  0.005344  0.608093  0.006565\n",
       "Precision       0.611890  0.004527  0.649133  0.006276\n",
       "Recall          0.609177  0.007503  0.583147  0.013156\n",
       "Roc_auc         0.611871  0.004561  0.660283  0.003994"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Saving the data of model performance\n",
    "Model_data=pd.concat([Model1,Model2],axis=1)\n",
    "Model_data.columns = [['DT']*4,['Model 1','Model 1', 'Model 2','Model 2'], ['Mean', 'Se', 'Mean', 'Se']]  \n",
    "Model_data.columns.names=['Method','Model','Values']\n",
    "Model_data.to_csv(\"./DT_model_lasso_data.csv\",sep=',')\n",
    "Model_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6047485d-89ab-471b-b393-08d893b317bc",
   "metadata": {},
   "source": [
    "## 1.2 LR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7e67efc5-4154-43ea-ad89-57f6ba68ec1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf=LogisticRegression(solver='liblinear',random_state=0,dual=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4e72f778-0bc0-4da2-b17d-d66357ab161c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mean</th>\n",
       "      <th>Se</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Accuracy_test</th>\n",
       "      <td>0.702293</td>\n",
       "      <td>0.004176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Accuracy_train</th>\n",
       "      <td>0.746120</td>\n",
       "      <td>0.001286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1 Score</th>\n",
       "      <td>0.705000</td>\n",
       "      <td>0.004515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Precision</th>\n",
       "      <td>0.698443</td>\n",
       "      <td>0.004082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recall</th>\n",
       "      <td>0.712731</td>\n",
       "      <td>0.006222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Roc_auc</th>\n",
       "      <td>0.765978</td>\n",
       "      <td>0.004563</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Mean        Se\n",
       "Accuracy_test   0.702293  0.004176\n",
       "Accuracy_train  0.746120  0.001286\n",
       "F1 Score        0.705000  0.004515\n",
       "Precision       0.698443  0.004082\n",
       "Recall          0.712731  0.006222\n",
       "Roc_auc         0.765978  0.004563"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Model1 \n",
    "Model1_clf=clf\n",
    "#Model1\n",
    "Model1=Model_results(Model1_clf,X,y,Cv_model)\n",
    "Model1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b9338635-62a3-4fe9-912b-6acc77ef994a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2024-11-15 06:04:27,807]\u001b[0m A new study created in memory with name: no-name-a9daf120-b53d-41db-94e4-3d1d7017bd36\u001b[0m\n",
      "\u001b[32m[I 2024-11-15 06:04:30,353]\u001b[0m Trial 0 finished with value: 0.6904728860473276 and parameters: {'logreg_c': 0.3177840006884068, 'l1_ratio': 0.7482920440979423, 'max_iter': 100}. Best is trial 0 with value: 0.6904728860473276.\u001b[0m\n",
      "\u001b[32m[I 2024-11-15 06:04:30,524]\u001b[0m Trial 1 finished with value: 0.674863358153678 and parameters: {'logreg_c': 0.0651621545821569, 'l1_ratio': 0.23208030173540176, 'max_iter': 275}. Best is trial 0 with value: 0.6904728860473276.\u001b[0m\n",
      "\u001b[32m[I 2024-11-15 06:04:30,694]\u001b[0m Trial 2 finished with value: 0.6645514794744843 and parameters: {'logreg_c': 0.013108749615263334, 'l1_ratio': 0.411004654338743, 'max_iter': 854}. Best is trial 0 with value: 0.6904728860473276.\u001b[0m\n",
      "\u001b[32m[I 2024-11-15 06:04:30,914]\u001b[0m Trial 3 finished with value: 0.7073209621457253 and parameters: {'logreg_c': 1.7096232052870346, 'l1_ratio': 0.4772750629629653, 'max_iter': 1402}. Best is trial 3 with value: 0.7073209621457253.\u001b[0m\n",
      "\u001b[32m[I 2024-11-15 06:04:31,084]\u001b[0m Trial 4 finished with value: 0.6676344002183151 and parameters: {'logreg_c': 0.016854407828169382, 'l1_ratio': 0.8903056927518509, 'max_iter': 152}. Best is trial 3 with value: 0.7073209621457253.\u001b[0m\n",
      "\u001b[32m[I 2024-11-15 06:04:31,317]\u001b[0m Trial 5 finished with value: 0.7198362636934234 and parameters: {'logreg_c': 10.539137268289434, 'l1_ratio': 0.4755743221304143, 'max_iter': 1162}. Best is trial 5 with value: 0.7198362636934234.\u001b[0m\n",
      "\u001b[32m[I 2024-11-15 06:04:31,487]\u001b[0m Trial 6 finished with value: 0.6523788546255507 and parameters: {'logreg_c': 0.006955392321661603, 'l1_ratio': 0.2782913401763909, 'max_iter': 1622}. Best is trial 5 with value: 0.7198362636934234.\u001b[0m\n",
      "\u001b[32m[I 2024-11-15 06:04:31,984]\u001b[0m Trial 7 finished with value: 0.7177310826088652 and parameters: {'logreg_c': 645.0144652189372, 'l1_ratio': 0.38208176034331853, 'max_iter': 1416}. Best is trial 5 with value: 0.7198362636934234.\u001b[0m\n",
      "\u001b[32m[I 2024-11-15 06:04:32,362]\u001b[0m Trial 8 finished with value: 0.7218704923784648 and parameters: {'logreg_c': 181.27374779133626, 'l1_ratio': 0.9051459971534626, 'max_iter': 261}. Best is trial 8 with value: 0.7218704923784648.\u001b[0m\n",
      "\u001b[32m[I 2024-11-15 06:04:32,531]\u001b[0m Trial 9 finished with value: 0.5658679973490313 and parameters: {'logreg_c': 0.001715255021408637, 'l1_ratio': 0.25284737760811204, 'max_iter': 1769}. Best is trial 8 with value: 0.7218704923784648.\u001b[0m\n",
      "\u001b[32m[I 2024-11-15 06:04:33,073]\u001b[0m Trial 10 finished with value: 0.7176441464270398 and parameters: {'logreg_c': 909.7939268284556, 'l1_ratio': 0.9808743317423054, 'max_iter': 644}. Best is trial 8 with value: 0.7218704923784648.\u001b[0m\n",
      "\u001b[32m[I 2024-11-15 06:04:33,352]\u001b[0m Trial 11 finished with value: 0.723367899886944 and parameters: {'logreg_c': 26.68235334285073, 'l1_ratio': 0.6357475149295672, 'max_iter': 1091}. Best is trial 11 with value: 0.723367899886944.\u001b[0m\n",
      "\u001b[32m[I 2024-11-15 06:04:33,630]\u001b[0m Trial 12 finished with value: 0.7245175626681221 and parameters: {'logreg_c': 44.35701792413822, 'l1_ratio': 0.6710388017194717, 'max_iter': 591}. Best is trial 12 with value: 0.7245175626681221.\u001b[0m\n",
      "\u001b[32m[I 2024-11-15 06:04:33,879]\u001b[0m Trial 13 finished with value: 0.7204557327199719 and parameters: {'logreg_c': 18.12120438471593, 'l1_ratio': 0.6622377900385221, 'max_iter': 643}. Best is trial 12 with value: 0.7245175626681221.\u001b[0m\n",
      "\u001b[32m[I 2024-11-15 06:04:34,159]\u001b[0m Trial 14 finished with value: 0.7238992631866203 and parameters: {'logreg_c': 41.10283925126469, 'l1_ratio': 0.6503653208977435, 'max_iter': 972}. Best is trial 12 with value: 0.7245175626681221.\u001b[0m\n",
      "\u001b[32m[I 2024-11-15 06:04:34,484]\u001b[0m Trial 15 finished with value: 0.7239016022767143 and parameters: {'logreg_c': 92.97448374233609, 'l1_ratio': 0.7417235472842081, 'max_iter': 606}. Best is trial 12 with value: 0.7245175626681221.\u001b[0m\n",
      "\u001b[32m[I 2024-11-15 06:04:34,687]\u001b[0m Trial 16 finished with value: 0.707585669174691 and parameters: {'logreg_c': 1.7461431304188877, 'l1_ratio': 0.7856154966698916, 'max_iter': 526}. Best is trial 12 with value: 0.7245175626681221.\u001b[0m\n",
      "\u001b[32m[I 2024-11-15 06:04:35,077]\u001b[0m Trial 17 finished with value: 0.7226650033137111 and parameters: {'logreg_c': 133.7219845991231, 'l1_ratio': 0.7683639981317943, 'max_iter': 447}. Best is trial 12 with value: 0.7245175626681221.\u001b[0m\n",
      "\u001b[32m[I 2024-11-15 06:04:35,307]\u001b[0m Trial 18 finished with value: 0.715074266110483 and parameters: {'logreg_c': 4.601465365991288, 'l1_ratio': 0.11939691870101943, 'max_iter': 803}. Best is trial 12 with value: 0.7245175626681221.\u001b[0m\n",
      "\u001b[32m[I 2024-11-15 06:04:35,666]\u001b[0m Trial 19 finished with value: 0.7231059217964212 and parameters: {'logreg_c': 118.99620833917453, 'l1_ratio': 0.5707036982837058, 'max_iter': 398}. Best is trial 12 with value: 0.7245175626681221.\u001b[0m\n",
      "\u001b[32m[I 2024-11-15 06:04:35,850]\u001b[0m Trial 20 finished with value: 0.6935589255779502 and parameters: {'logreg_c': 0.40572636875754825, 'l1_ratio': 0.8486952402125144, 'max_iter': 701}. Best is trial 12 with value: 0.7245175626681221.\u001b[0m\n",
      "\u001b[32m[I 2024-11-15 06:04:36,178]\u001b[0m Trial 21 finished with value: 0.7241647499122841 and parameters: {'logreg_c': 51.30273993435784, 'l1_ratio': 0.6586224145896447, 'max_iter': 990}. Best is trial 12 with value: 0.7245175626681221.\u001b[0m\n",
      "\u001b[32m[I 2024-11-15 06:04:36,521]\u001b[0m Trial 22 finished with value: 0.7251358621496238 and parameters: {'logreg_c': 73.9620227962533, 'l1_ratio': 0.7085805073169676, 'max_iter': 1266}. Best is trial 22 with value: 0.7251358621496238.\u001b[0m\n",
      "\u001b[32m[I 2024-11-15 06:04:36,771]\u001b[0m Trial 23 finished with value: 0.7160434291060777 and parameters: {'logreg_c': 4.744031713227156, 'l1_ratio': 0.5778049485973562, 'max_iter': 1284}. Best is trial 22 with value: 0.7251358621496238.\u001b[0m\n",
      "\u001b[32m[I 2024-11-15 06:04:37,309]\u001b[0m Trial 24 finished with value: 0.7206374020506024 and parameters: {'logreg_c': 331.14123582198175, 'l1_ratio': 0.6976009495127798, 'max_iter': 918}. Best is trial 22 with value: 0.7251358621496238.\u001b[0m\n",
      "\u001b[32m[I 2024-11-15 06:04:37,618]\u001b[0m Trial 25 finished with value: 0.7244294569412497 and parameters: {'logreg_c': 57.65942195975665, 'l1_ratio': 0.5509930291075086, 'max_iter': 1169}. Best is trial 22 with value: 0.7251358621496238.\u001b[0m\n",
      "\u001b[32m[I 2024-11-15 06:04:37,867]\u001b[0m Trial 26 finished with value: 0.7170164905851624 and parameters: {'logreg_c': 7.382523140807327, 'l1_ratio': 0.4958968295663409, 'max_iter': 1567}. Best is trial 22 with value: 0.7251358621496238.\u001b[0m\n",
      "\u001b[32m[I 2024-11-15 06:04:38,267]\u001b[0m Trial 27 finished with value: 0.7210771509882656 and parameters: {'logreg_c': 284.47922542036724, 'l1_ratio': 0.5762894435679414, 'max_iter': 1128}. Best is trial 22 with value: 0.7251358621496238.\u001b[0m\n",
      "\u001b[32m[I 2024-11-15 06:04:38,564]\u001b[0m Trial 28 finished with value: 0.7240762543370627 and parameters: {'logreg_c': 46.193170406921645, 'l1_ratio': 0.389254438802234, 'max_iter': 1962}. Best is trial 22 with value: 0.7251358621496238.\u001b[0m\n",
      "\u001b[32m[I 2024-11-15 06:04:38,751]\u001b[0m Trial 29 finished with value: 0.694266500331371 and parameters: {'logreg_c': 0.4370815219585703, 'l1_ratio': 0.8113231248816064, 'max_iter': 1270}. Best is trial 22 with value: 0.7251358621496238.\u001b[0m\n",
      "\u001b[32m[I 2024-11-15 06:04:39,016]\u001b[0m Trial 30 finished with value: 0.7205434485984951 and parameters: {'logreg_c': 17.381791280345077, 'l1_ratio': 0.7170966363635477, 'max_iter': 1465}. Best is trial 22 with value: 0.7251358621496238.\u001b[0m\n",
      "\u001b[32m[I 2024-11-15 06:04:39,358]\u001b[0m Trial 31 finished with value: 0.724871544969007 and parameters: {'logreg_c': 77.25640301179719, 'l1_ratio': 0.6240773787484641, 'max_iter': 1011}. Best is trial 22 with value: 0.7251358621496238.\u001b[0m\n",
      "\u001b[32m[I 2024-11-15 06:04:39,808]\u001b[0m Trial 32 finished with value: 0.7204608007485089 and parameters: {'logreg_c': 399.4650103242186, 'l1_ratio': 0.6091667987585009, 'max_iter': 1236}. Best is trial 22 with value: 0.7251358621496238.\u001b[0m\n",
      "\u001b[32m[I 2024-11-15 06:04:40,134]\u001b[0m Trial 33 finished with value: 0.7249588709991812 and parameters: {'logreg_c': 72.92167430174761, 'l1_ratio': 0.5305835538432216, 'max_iter': 823}. Best is trial 22 with value: 0.7251358621496238.\u001b[0m\n",
      "\u001b[32m[I 2024-11-15 06:04:40,335]\u001b[0m Trial 34 finished with value: 0.7080261978090522 and parameters: {'logreg_c': 1.8533647532123818, 'l1_ratio': 0.5148562381928449, 'max_iter': 785}. Best is trial 22 with value: 0.7251358621496238.\u001b[0m\n",
      "\u001b[32m[I 2024-11-15 06:04:40,521]\u001b[0m Trial 35 finished with value: 0.6845639546216522 and parameters: {'logreg_c': 0.1855176985300252, 'l1_ratio': 0.4468060105193794, 'max_iter': 825}. Best is trial 22 with value: 0.7251358621496238.\u001b[0m\n",
      "\u001b[32m[I 2024-11-15 06:04:40,775]\u001b[0m Trial 36 finished with value: 0.7199259288136914 and parameters: {'logreg_c': 11.800494599308218, 'l1_ratio': 0.32518996467359107, 'max_iter': 1032}. Best is trial 22 with value: 0.7251358621496238.\u001b[0m\n",
      "\u001b[32m[I 2024-11-15 06:04:41,129]\u001b[0m Trial 37 finished with value: 0.7239897080035865 and parameters: {'logreg_c': 93.2952955224281, 'l1_ratio': 0.7017914668263832, 'max_iter': 514}. Best is trial 22 with value: 0.7251358621496238.\u001b[0m\n",
      "\u001b[32m[I 2024-11-15 06:04:41,348]\u001b[0m Trial 38 finished with value: 0.7129605083622471 and parameters: {'logreg_c': 3.25491282434725, 'l1_ratio': 0.4379576923435746, 'max_iter': 890}. Best is trial 22 with value: 0.7251358621496238.\u001b[0m\n",
      "\u001b[32m[I 2024-11-15 06:04:41,533]\u001b[0m Trial 39 finished with value: 0.6758321313009239 and parameters: {'logreg_c': 0.0759664769855453, 'l1_ratio': 0.8447670217893137, 'max_iter': 117}. Best is trial 22 with value: 0.7251358621496238.\u001b[0m\n",
      "\u001b[32m[I 2024-11-15 06:04:41,924]\u001b[0m Trial 40 finished with value: 0.7216073447428951 and parameters: {'logreg_c': 230.25353533321626, 'l1_ratio': 0.5349585447657683, 'max_iter': 332}. Best is trial 22 with value: 0.7251358621496238.\u001b[0m\n",
      "\u001b[32m[I 2024-11-15 06:04:42,236]\u001b[0m Trial 41 finished with value: 0.724517562668122 and parameters: {'logreg_c': 57.139257192618025, 'l1_ratio': 0.6073299249846431, 'max_iter': 1204}. Best is trial 22 with value: 0.7251358621496238.\u001b[0m\n",
      "\u001b[32m[I 2024-11-15 06:04:42,516]\u001b[0m Trial 42 finished with value: 0.7228388756773616 and parameters: {'logreg_c': 25.556392740823014, 'l1_ratio': 0.5926264973002575, 'max_iter': 719}. Best is trial 22 with value: 0.7251358621496238.\u001b[0m\n",
      "\u001b[32m[I 2024-11-15 06:04:43,012]\u001b[0m Trial 43 finished with value: 0.7178164593972944 and parameters: {'logreg_c': 575.4582890888469, 'l1_ratio': 0.6229602463074435, 'max_iter': 1327}. Best is trial 22 with value: 0.7251358621496238.\u001b[0m\n",
      "\u001b[32m[I 2024-11-15 06:04:43,325]\u001b[0m Trial 44 finished with value: 0.7247834392421347 and parameters: {'logreg_c': 75.87383779327358, 'l1_ratio': 0.711060155248022, 'max_iter': 1087}. Best is trial 22 with value: 0.7251358621496238.\u001b[0m\n",
      "\u001b[32m[I 2024-11-15 06:04:43,896]\u001b[0m Trial 45 finished with value: 0.7178203578807845 and parameters: {'logreg_c': 973.9150432892579, 'l1_ratio': 0.6888477843692198, 'max_iter': 1040}. Best is trial 22 with value: 0.7251358621496238.\u001b[0m\n",
      "\u001b[32m[I 2024-11-15 06:04:44,285]\u001b[0m Trial 46 finished with value: 0.7218704923784648 and parameters: {'logreg_c': 206.5410239526619, 'l1_ratio': 0.7380136917630947, 'max_iter': 955}. Best is trial 22 with value: 0.7251358621496238.\u001b[0m\n",
      "\u001b[32m[I 2024-11-15 06:04:44,532]\u001b[0m Trial 47 finished with value: 0.7188682702428754 and parameters: {'logreg_c': 9.248096422890772, 'l1_ratio': 0.7943121444505257, 'max_iter': 1367}. Best is trial 22 with value: 0.7251358621496238.\u001b[0m\n",
      "\u001b[32m[I 2024-11-15 06:04:44,796]\u001b[0m Trial 48 finished with value: 0.7246033293049003 and parameters: {'logreg_c': 31.46785884680774, 'l1_ratio': 0.9422751796441555, 'max_iter': 1100}. Best is trial 22 with value: 0.7251358621496238.\u001b[0m\n",
      "\u001b[32m[I 2024-11-15 06:04:45,059]\u001b[0m Trial 49 finished with value: 0.7232797941600718 and parameters: {'logreg_c': 26.7923337673019, 'l1_ratio': 0.9597902120321117, 'max_iter': 1091}. Best is trial 22 with value: 0.7251358621496238.\u001b[0m\n",
      "\u001b[32m[I 2024-11-15 06:04:45,398]\u001b[0m Trial 50 finished with value: 0.723813106701493 and parameters: {'logreg_c': 98.38579259835495, 'l1_ratio': 0.9195818368234348, 'max_iter': 1593}. Best is trial 22 with value: 0.7251358621496238.\u001b[0m\n",
      "\u001b[32m[I 2024-11-15 06:04:45,676]\u001b[0m Trial 51 finished with value: 0.7246033293049003 and parameters: {'logreg_c': 31.71841231440523, 'l1_ratio': 0.6632786118018056, 'max_iter': 858}. Best is trial 22 with value: 0.7251358621496238.\u001b[0m\n",
      "\u001b[32m[I 2024-11-15 06:04:45,926]\u001b[0m Trial 52 finished with value: 0.7205434485984952 and parameters: {'logreg_c': 16.870661579465935, 'l1_ratio': 0.8529588172015476, 'max_iter': 743}. Best is trial 22 with value: 0.7251358621496238.\u001b[0m\n",
      "\u001b[32m[I 2024-11-15 06:04:46,301]\u001b[0m Trial 53 finished with value: 0.7224884020116176 and parameters: {'logreg_c': 166.38416391134885, 'l1_ratio': 0.7604621676784578, 'max_iter': 1113}. Best is trial 22 with value: 0.7251358621496238.\u001b[0m\n",
      "\u001b[32m[I 2024-11-15 06:04:46,563]\u001b[0m Trial 54 finished with value: 0.7235464504307825 and parameters: {'logreg_c': 28.55841465850788, 'l1_ratio': 0.6428341094460359, 'max_iter': 841}. Best is trial 22 with value: 0.7251358621496238.\u001b[0m\n",
      "\u001b[32m[I 2024-11-15 06:04:46,877]\u001b[0m Trial 55 finished with value: 0.7251358621496238 and parameters: {'logreg_c': 74.32686788212062, 'l1_ratio': 0.9334775416319586, 'max_iter': 901}. Best is trial 22 with value: 0.7251358621496238.\u001b[0m\n",
      "\u001b[32m[I 2024-11-15 06:04:47,343]\u001b[0m Trial 56 finished with value: 0.7196682390550077 and parameters: {'logreg_c': 467.1399848323779, 'l1_ratio': 0.8156159160308419, 'max_iter': 901}. Best is trial 22 with value: 0.7251358621496238.\u001b[0m\n",
      "\u001b[32m[I 2024-11-15 06:04:47,669]\u001b[0m Trial 57 finished with value: 0.7250473665744025 and parameters: {'logreg_c': 74.63658957083037, 'l1_ratio': 0.9902465545945943, 'max_iter': 1011}. Best is trial 22 with value: 0.7251358621496238.\u001b[0m\n",
      "\u001b[32m[I 2024-11-15 06:04:48,010]\u001b[0m Trial 58 finished with value: 0.7238134965498421 and parameters: {'logreg_c': 91.45313311393716, 'l1_ratio': 0.8803893135639894, 'max_iter': 1426}. Best is trial 22 with value: 0.7251358621496238.\u001b[0m\n",
      "\u001b[32m[I 2024-11-15 06:04:48,318]\u001b[0m Trial 59 finished with value: 0.7248711551206581 and parameters: {'logreg_c': 78.35782143552734, 'l1_ratio': 0.9572166840852083, 'max_iter': 992}. Best is trial 22 with value: 0.7251358621496238.\u001b[0m\n",
      "\u001b[32m[I 2024-11-15 06:04:48,489]\u001b[0m Trial 60 finished with value: 0.5472620950450274 and parameters: {'logreg_c': 0.0014647914843692897, 'l1_ratio': 0.9989897109123516, 'max_iter': 994}. Best is trial 22 with value: 0.7251358621496238.\u001b[0m\n",
      "\u001b[32m[I 2024-11-15 06:04:48,800]\u001b[0m Trial 61 finished with value: 0.7249592608475303 and parameters: {'logreg_c': 66.69039401992073, 'l1_ratio': 0.9689519937081047, 'max_iter': 951}. Best is trial 22 with value: 0.7251358621496238.\u001b[0m\n",
      "\u001b[32m[I 2024-11-15 06:04:49,187]\u001b[0m Trial 62 finished with value: 0.7234583447039102 and parameters: {'logreg_c': 150.15383981228206, 'l1_ratio': 0.9544034967490415, 'max_iter': 956}. Best is trial 22 with value: 0.7251358621496238.\u001b[0m\n",
      "\u001b[32m[I 2024-11-15 06:04:49,486]\u001b[0m Trial 63 finished with value: 0.7243413512143775 and parameters: {'logreg_c': 63.88418740012592, 'l1_ratio': 0.9006507379024626, 'max_iter': 681}. Best is trial 22 with value: 0.7251358621496238.\u001b[0m\n",
      "\u001b[32m[I 2024-11-15 06:04:49,877]\u001b[0m Trial 64 finished with value: 0.7216077345912439 and parameters: {'logreg_c': 246.67465300444485, 'l1_ratio': 0.9983190314889416, 'max_iter': 1182}. Best is trial 22 with value: 0.7251358621496238.\u001b[0m\n",
      "\u001b[32m[I 2024-11-15 06:04:50,126]\u001b[0m Trial 65 finished with value: 0.7203660675997038 and parameters: {'logreg_c': 13.535750222593325, 'l1_ratio': 0.9235580205788608, 'max_iter': 769}. Best is trial 22 with value: 0.7251358621496238.\u001b[0m\n",
      "\u001b[32m[I 2024-11-15 06:04:50,467]\u001b[0m Trial 66 finished with value: 0.7227531090405833 and parameters: {'logreg_c': 132.8083114885233, 'l1_ratio': 0.9636805032464141, 'max_iter': 1017}. Best is trial 22 with value: 0.7251358621496238.\u001b[0m\n",
      "\u001b[32m[I 2024-11-15 06:04:50,641]\u001b[0m Trial 67 finished with value: 0.6318338466336595 and parameters: {'logreg_c': 0.003114708027338804, 'l1_ratio': 0.8757073308329788, 'max_iter': 935}. Best is trial 22 with value: 0.7251358621496238.\u001b[0m\n",
      "\u001b[32m[I 2024-11-15 06:04:50,871]\u001b[0m Trial 68 finished with value: 0.7162211999532182 and parameters: {'logreg_c': 6.6727154143750615, 'l1_ratio': 0.930744736662442, 'max_iter': 574}. Best is trial 22 with value: 0.7251358621496238.\u001b[0m\n",
      "\u001b[32m[I 2024-11-15 06:04:51,293]\u001b[0m Trial 69 finished with value: 0.7203730848699855 and parameters: {'logreg_c': 390.2189999655433, 'l1_ratio': 0.9868169767467511, 'max_iter': 861}. Best is trial 22 with value: 0.7251358621496238.\u001b[0m\n",
      "\u001b[32m[I 2024-11-15 06:04:51,573]\u001b[0m Trial 70 finished with value: 0.7240762543370627 and parameters: {'logreg_c': 46.13001925576219, 'l1_ratio': 0.8697901763481819, 'max_iter': 1232}. Best is trial 22 with value: 0.7251358621496238.\u001b[0m\n",
      "\u001b[32m[I 2024-11-15 06:04:51,885]\u001b[0m Trial 71 finished with value: 0.7250477564227515 and parameters: {'logreg_c': 74.54785310459229, 'l1_ratio': 0.4815041372059907, 'max_iter': 1157}. Best is trial 22 with value: 0.7251358621496238.\u001b[0m\n",
      "\u001b[32m[I 2024-11-15 06:04:52,196]\u001b[0m Trial 72 finished with value: 0.7246953335152625 and parameters: {'logreg_c': 76.6626794355745, 'l1_ratio': 0.4672750994077342, 'max_iter': 1042}. Best is trial 22 with value: 0.7251358621496238.\u001b[0m\n",
      "\u001b[32m[I 2024-11-15 06:04:52,552]\u001b[0m Trial 73 finished with value: 0.7228416046158046 and parameters: {'logreg_c': 132.7218625654072, 'l1_ratio': 0.344810373524486, 'max_iter': 1143}. Best is trial 22 with value: 0.7251358621496238.\u001b[0m\n",
      "\u001b[32m[I 2024-11-15 06:04:52,803]\u001b[0m Trial 74 finished with value: 0.7203691863864957 and parameters: {'logreg_c': 19.501842316560754, 'l1_ratio': 0.5324079709111399, 'max_iter': 907}. Best is trial 22 with value: 0.7251358621496238.\u001b[0m\n",
      "\u001b[32m[I 2024-11-15 06:04:53,118]\u001b[0m Trial 75 finished with value: 0.7238992631866203 and parameters: {'logreg_c': 41.31628950297421, 'l1_ratio': 0.49454575132999734, 'max_iter': 1496}. Best is trial 22 with value: 0.7251358621496238.\u001b[0m\n",
      "\u001b[32m[I 2024-11-15 06:04:53,553]\u001b[0m Trial 76 finished with value: 0.7210771509882656 and parameters: {'logreg_c': 282.75013213729653, 'l1_ratio': 0.41997248699606454, 'max_iter': 1276}. Best is trial 22 with value: 0.7251358621496238.\u001b[0m\n",
      "\u001b[32m[I 2024-11-15 06:04:54,123]\u001b[0m Trial 77 finished with value: 0.7178184086390393 and parameters: {'logreg_c': 635.7003302823333, 'l1_ratio': 0.5610344252072816, 'max_iter': 1070}. Best is trial 22 with value: 0.7251358621496238.\u001b[0m\n",
      "\u001b[32m[I 2024-11-15 06:04:54,538]\u001b[0m Trial 78 finished with value: 0.725223578028147 and parameters: {'logreg_c': 70.67918903476476, 'l1_ratio': 0.2011669824999463, 'max_iter': 792}. Best is trial 78 with value: 0.725223578028147.\u001b[0m\n",
      "\u001b[32m[I 2024-11-15 06:04:55,052]\u001b[0m Trial 79 finished with value: 0.7216061751978481 and parameters: {'logreg_c': 187.98976868311155, 'l1_ratio': 0.17167210617081707, 'max_iter': 792}. Best is trial 78 with value: 0.725223578028147.\u001b[0m\n",
      "\u001b[32m[I 2024-11-15 06:04:55,270]\u001b[0m Trial 80 finished with value: 0.6732766753732798 and parameters: {'logreg_c': 0.03110009233658771, 'l1_ratio': 0.2730542690607256, 'max_iter': 631}. Best is trial 78 with value: 0.725223578028147.\u001b[0m\n",
      "\u001b[32m[I 2024-11-15 06:04:55,657]\u001b[0m Trial 81 finished with value: 0.7230189856145958 and parameters: {'logreg_c': 106.0995800921651, 'l1_ratio': 0.9671000752434181, 'max_iter': 975}. Best is trial 78 with value: 0.725223578028147.\u001b[0m\n",
      "\u001b[32m[I 2024-11-15 06:04:56,032]\u001b[0m Trial 82 finished with value: 0.7249588709991812 and parameters: {'logreg_c': 66.3522363764539, 'l1_ratio': 0.9034998078578611, 'max_iter': 693}. Best is trial 78 with value: 0.725223578028147.\u001b[0m\n",
      "\u001b[32m[I 2024-11-15 06:04:56,405]\u001b[0m Trial 83 finished with value: 0.7240766441854117 and parameters: {'logreg_c': 59.206567720464705, 'l1_ratio': 0.9076725089296325, 'max_iter': 684}. Best is trial 78 with value: 0.725223578028147.\u001b[0m\n",
      "\u001b[32m[I 2024-11-15 06:04:56,717]\u001b[0m Trial 84 finished with value: 0.7240766441854118 and parameters: {'logreg_c': 43.001826734319664, 'l1_ratio': 0.22994609096175728, 'max_iter': 812}. Best is trial 78 with value: 0.725223578028147.\u001b[0m\n",
      "\u001b[32m[I 2024-11-15 06:04:57,023]\u001b[0m Trial 85 finished with value: 0.7227503801021403 and parameters: {'logreg_c': 24.113344675566065, 'l1_ratio': 0.8290262975879137, 'max_iter': 559}. Best is trial 78 with value: 0.725223578028147.\u001b[0m\n",
      "\u001b[32m[I 2024-11-15 06:04:57,447]\u001b[0m Trial 86 finished with value: 0.7217823866515926 and parameters: {'logreg_c': 181.51507270979718, 'l1_ratio': 0.2003578357776426, 'max_iter': 1336}. Best is trial 78 with value: 0.725223578028147.\u001b[0m\n",
      "\u001b[32m[I 2024-11-15 06:04:57,740]\u001b[0m Trial 87 finished with value: 0.7252200693930061 and parameters: {'logreg_c': 34.54839790715207, 'l1_ratio': 0.11187048461143305, 'max_iter': 740}. Best is trial 78 with value: 0.725223578028147.\u001b[0m\n",
      "\u001b[32m[I 2024-11-15 06:04:58,099]\u001b[0m Trial 88 finished with value: 0.7230178160695488 and parameters: {'logreg_c': 118.117926470082, 'l1_ratio': 0.13323105377118422, 'max_iter': 480}. Best is trial 78 with value: 0.725223578028147.\u001b[0m\n",
      "\u001b[32m[I 2024-11-15 06:04:58,421]\u001b[0m Trial 89 finished with value: 0.7248668667888191 and parameters: {'logreg_c': 37.029500433715306, 'l1_ratio': 0.10536821304698138, 'max_iter': 742}. Best is trial 78 with value: 0.725223578028147.\u001b[0m\n",
      "\u001b[32m[I 2024-11-15 06:04:58,777]\u001b[0m Trial 90 finished with value: 0.7244294569412497 and parameters: {'logreg_c': 57.589956368657326, 'l1_ratio': 0.15013431249938386, 'max_iter': 665}. Best is trial 78 with value: 0.725223578028147.\u001b[0m\n",
      "\u001b[32m[I 2024-11-15 06:04:59,182]\u001b[0m Trial 91 finished with value: 0.7249588709991812 and parameters: {'logreg_c': 73.06674825704607, 'l1_ratio': 0.19374740366721477, 'max_iter': 888}. Best is trial 78 with value: 0.725223578028147.\u001b[0m\n",
      "\u001b[32m[I 2024-11-15 06:04:59,433]\u001b[0m Trial 92 finished with value: 0.7018517796577131 and parameters: {'logreg_c': 0.9599801139564393, 'l1_ratio': 0.1843770559578387, 'max_iter': 881}. Best is trial 78 with value: 0.725223578028147.\u001b[0m\n",
      "\u001b[32m[I 2024-11-15 06:04:59,743]\u001b[0m Trial 93 finished with value: 0.7219566488635921 and parameters: {'logreg_c': 22.148318513507867, 'l1_ratio': 0.19815629775184943, 'max_iter': 740}. Best is trial 78 with value: 0.725223578028147.\u001b[0m\n",
      "\u001b[32m[I 2024-11-15 06:05:00,116]\u001b[0m Trial 94 finished with value: 0.725223578028147 and parameters: {'logreg_c': 70.61675945523235, 'l1_ratio': 0.23489515537839442, 'max_iter': 830}. Best is trial 78 with value: 0.725223578028147.\u001b[0m\n",
      "\u001b[32m[I 2024-11-15 06:05:00,424]\u001b[0m Trial 95 finished with value: 0.7250434680909126 and parameters: {'logreg_c': 35.90177856773067, 'l1_ratio': 0.30959991820634425, 'max_iter': 619}. Best is trial 78 with value: 0.725223578028147.\u001b[0m\n",
      "\u001b[32m[I 2024-11-15 06:05:00,688]\u001b[0m Trial 96 finished with value: 0.7201894662976103 and parameters: {'logreg_c': 12.426866039510037, 'l1_ratio': 0.22866569657628605, 'max_iter': 613}. Best is trial 78 with value: 0.725223578028147.\u001b[0m\n",
      "\u001b[32m[I 2024-11-15 06:05:00,999]\u001b[0m Trial 97 finished with value: 0.7246033293049003 and parameters: {'logreg_c': 32.71927934514952, 'l1_ratio': 0.2514815040838068, 'max_iter': 708}. Best is trial 78 with value: 0.725223578028147.\u001b[0m\n",
      "\u001b[32m[I 2024-11-15 06:05:01,260]\u001b[0m Trial 98 finished with value: 0.7203672371447506 and parameters: {'logreg_c': 17.56731097505454, 'l1_ratio': 0.32111910639622, 'max_iter': 424}. Best is trial 78 with value: 0.725223578028147.\u001b[0m\n",
      "\u001b[32m[I 2024-11-15 06:05:01,605]\u001b[0m Trial 99 finished with value: 0.7234602939456551 and parameters: {'logreg_c': 102.42861965482669, 'l1_ratio': 0.31679530499537006, 'max_iter': 777}. Best is trial 78 with value: 0.725223578028147.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "#Tuning hyperparameters\n",
    "#Step 1. Define an objective function to be maximized.\n",
    "def objective(trial):\n",
    "    logreg_c = trial.suggest_float(\"logreg_c\", 1e-3,  1e3, log=True)\n",
    "    l1_ratio = trial.suggest_float(\"l1_ratio\",0.1,1,log=False) \n",
    "    #penalty = trial.suggest_categorical(\"penalty\",['l1','l2'])\n",
    "    max_iter = trial.suggest_int(\"max_iter\", 100,2000)\n",
    "    model =LogisticRegression(C=logreg_c,\n",
    "                              max_iter=max_iter,\n",
    "                              l1_ratio=l1_ratio,\n",
    "                              solver='liblinear',random_state=1)\n",
    "    \n",
    "# Step 2: Scoring method:\n",
    "    score = model_selection.cross_val_score(model, X, y, n_jobs=8, scoring=\"accuracy\",cv=Cv_optuna)\n",
    "    accuracy = score.mean()\n",
    "    return accuracy\n",
    "\n",
    "# Step 3: Running it\n",
    "study = optuna.create_study(direction=\"maximize\",sampler=optuna.samplers.TPESampler(seed=1))\n",
    "study.optimize(objective, n_trials=100, show_progress_bar=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "cd09afa2-c7ae-4f28-acb3-9a0c06e89504",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best parameters are : \n",
      "{'logreg_c': 70.67918903476476, 'l1_ratio': 0.2011669824999463, 'max_iter': 792}\n"
     ]
    }
   ],
   "source": [
    "# Getting the best parameters:\n",
    "print(f\"The best parameters are : \\n{study.best_params}\")\n",
    "# Setting the best model\n",
    "clf=LogisticRegression(C=study.best_params['logreg_c'],\n",
    "                              max_iter=study.best_params['max_iter'],\n",
    "                              l1_ratio=study.best_params['l1_ratio'],\n",
    "                              solver='liblinear',\n",
    "                              random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "18f98263-5b44-4a58-ad76-bd2288347abf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mean</th>\n",
       "      <th>Se</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Accuracy_test</th>\n",
       "      <td>0.725224</td>\n",
       "      <td>0.004909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Accuracy_train</th>\n",
       "      <td>0.794510</td>\n",
       "      <td>0.001356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1 Score</th>\n",
       "      <td>0.726101</td>\n",
       "      <td>0.005013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Precision</th>\n",
       "      <td>0.724247</td>\n",
       "      <td>0.005249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recall</th>\n",
       "      <td>0.729315</td>\n",
       "      <td>0.006561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Roc_auc</th>\n",
       "      <td>0.784072</td>\n",
       "      <td>0.004418</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Mean        Se\n",
       "Accuracy_test   0.725224  0.004909\n",
       "Accuracy_train  0.794510  0.001356\n",
       "F1 Score        0.726101  0.005013\n",
       "Precision       0.724247  0.005249\n",
       "Recall          0.729315  0.006561\n",
       "Roc_auc         0.784072  0.004418"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Model2\n",
    "Model2=Model_results(clf,X,y,Cv_model)\n",
    "Model2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "0eba0a05-824b-4da4-8a16-535220341d36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th>Method</th>\n",
       "      <th colspan=\"4\" halign=\"left\">LR</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model</th>\n",
       "      <th colspan=\"2\" halign=\"left\">Model 1</th>\n",
       "      <th colspan=\"2\" halign=\"left\">Model 2</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Values</th>\n",
       "      <th>Mean</th>\n",
       "      <th>Se</th>\n",
       "      <th>Mean</th>\n",
       "      <th>Se</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Accuracy_test</th>\n",
       "      <td>0.702293</td>\n",
       "      <td>0.004176</td>\n",
       "      <td>0.725224</td>\n",
       "      <td>0.004909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Accuracy_train</th>\n",
       "      <td>0.746120</td>\n",
       "      <td>0.001286</td>\n",
       "      <td>0.794510</td>\n",
       "      <td>0.001356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1 Score</th>\n",
       "      <td>0.705000</td>\n",
       "      <td>0.004515</td>\n",
       "      <td>0.726101</td>\n",
       "      <td>0.005013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Precision</th>\n",
       "      <td>0.698443</td>\n",
       "      <td>0.004082</td>\n",
       "      <td>0.724247</td>\n",
       "      <td>0.005249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recall</th>\n",
       "      <td>0.712731</td>\n",
       "      <td>0.006222</td>\n",
       "      <td>0.729315</td>\n",
       "      <td>0.006561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Roc_auc</th>\n",
       "      <td>0.765978</td>\n",
       "      <td>0.004563</td>\n",
       "      <td>0.784072</td>\n",
       "      <td>0.004418</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Method                LR                              \n",
       "Model            Model 1             Model 2          \n",
       "Values              Mean        Se      Mean        Se\n",
       "Accuracy_test   0.702293  0.004176  0.725224  0.004909\n",
       "Accuracy_train  0.746120  0.001286  0.794510  0.001356\n",
       "F1 Score        0.705000  0.004515  0.726101  0.005013\n",
       "Precision       0.698443  0.004082  0.724247  0.005249\n",
       "Recall          0.712731  0.006222  0.729315  0.006561\n",
       "Roc_auc         0.765978  0.004563  0.784072  0.004418"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Saving the data of model performance\n",
    "Model_data=pd.concat([Model1,Model2],axis=1)\n",
    "Model_data.columns = [['LR']*4,['Model 1','Model 1', 'Model 2','Model 2'], ['Mean', 'Se', 'Mean', 'Se']]  \n",
    "Model_data.columns.names=['Method','Model','Values']\n",
    "Model_data.to_csv(\"./LR_model_lasso_data.csv\",sep=',')\n",
    "Model_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0844c7c8-f6b1-410a-b253-879aedd14e57",
   "metadata": {},
   "source": [
    "## 1.3 RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d9c4731c-bbfe-47eb-bb7f-7d8b2909ea2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf=RandomForestClassifier(random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ffdd2f35-ec29-4ef8-8309-6a84646f4539",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mean</th>\n",
       "      <th>Se</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Accuracy_test</th>\n",
       "      <td>0.684210</td>\n",
       "      <td>0.004595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Accuracy_train</th>\n",
       "      <td>0.999317</td>\n",
       "      <td>0.000076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1 Score</th>\n",
       "      <td>0.680396</td>\n",
       "      <td>0.004839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Precision</th>\n",
       "      <td>0.689501</td>\n",
       "      <td>0.005290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recall</th>\n",
       "      <td>0.673363</td>\n",
       "      <td>0.006661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Roc_auc</th>\n",
       "      <td>0.752851</td>\n",
       "      <td>0.004617</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Mean        Se\n",
       "Accuracy_test   0.684210  0.004595\n",
       "Accuracy_train  0.999317  0.000076\n",
       "F1 Score        0.680396  0.004839\n",
       "Precision       0.689501  0.005290\n",
       "Recall          0.673363  0.006661\n",
       "Roc_auc         0.752851  0.004617"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Model1 （4175 descriptors）\n",
    "Model1_clf=clf\n",
    "#Model1\n",
    "Model1=Model_results(Model1_clf,X,y,Cv_model)\n",
    "Model1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "6f4b6d2b-6cf0-4f44-8bd5-02b5d1377add",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2024-11-15 06:05:32,523]\u001b[0m A new study created in memory with name: no-name-f3a3393c-ae76-4f65-9087-cc496c458d52\u001b[0m\n",
      "\u001b[32m[I 2024-11-15 06:05:37,388]\u001b[0m Trial 0 finished with value: 0.4982378854625551 and parameters: {'n_estimators': 594, 'max_depth': 16, 'max_features': 20, 'min_impurity_decrease': 2.724415914984484}. Best is trial 0 with value: 0.4982378854625551.\u001b[0m\n",
      "\u001b[32m[I 2024-11-15 06:05:41,272]\u001b[0m Trial 1 finished with value: 0.4982378854625551 and parameters: {'n_estimators': 481, 'max_depth': 15, 'max_features': 16, 'min_impurity_decrease': 4.4588650039103985}. Best is trial 0 with value: 0.4982378854625551.\u001b[0m\n",
      "\u001b[32m[I 2024-11-15 06:05:48,944]\u001b[0m Trial 2 finished with value: 0.4982378854625551 and parameters: {'n_estimators': 968, 'max_depth': 11, 'max_features': 25, 'min_impurity_decrease': 2.644474598764522}. Best is trial 0 with value: 0.4982378854625551.\u001b[0m\n",
      "\u001b[32m[I 2024-11-15 06:05:53,899]\u001b[0m Trial 3 finished with value: 0.4982378854625551 and parameters: {'n_estimators': 611, 'max_depth': 19, 'max_features': 6, 'min_impurity_decrease': 0.43564649850770354}. Best is trial 0 with value: 0.4982378854625551.\u001b[0m\n",
      "\u001b[32m[I 2024-11-15 06:05:55,021]\u001b[0m Trial 4 finished with value: 0.5 and parameters: {'n_estimators': 118, 'max_depth': 18, 'max_features': 25, 'min_impurity_decrease': 4.3500607412340955}. Best is trial 4 with value: 0.5.\u001b[0m\n",
      "\u001b[32m[I 2024-11-15 06:06:02,800]\u001b[0m Trial 5 finished with value: 0.4982378854625551 and parameters: {'n_estimators': 981, 'max_depth': 17, 'max_features': 16, 'min_impurity_decrease': 3.902645881432277}. Best is trial 4 with value: 0.5.\u001b[0m\n",
      "\u001b[32m[I 2024-11-15 06:06:04,480]\u001b[0m Trial 6 finished with value: 0.5 and parameters: {'n_estimators': 206, 'max_depth': 15, 'max_features': 8, 'min_impurity_decrease': 4.7233445852479194}. Best is trial 4 with value: 0.5.\u001b[0m\n",
      "\u001b[32m[I 2024-11-15 06:06:08,787]\u001b[0m Trial 7 finished with value: 0.4982378854625551 and parameters: {'n_estimators': 570, 'max_depth': 11, 'max_features': 11, 'min_impurity_decrease': 3.871168447171083}. Best is trial 4 with value: 0.5.\u001b[0m\n",
      "\u001b[32m[I 2024-11-15 06:06:12,602]\u001b[0m Trial 8 finished with value: 0.4982378854625551 and parameters: {'n_estimators': 510, 'max_depth': 14, 'max_features': 5, 'min_impurity_decrease': 3.0881774853793855}. Best is trial 4 with value: 0.5.\u001b[0m\n",
      "\u001b[32m[I 2024-11-15 06:06:17,735]\u001b[0m Trial 9 finished with value: 0.4982378854625551 and parameters: {'n_estimators': 651, 'max_depth': 14, 'max_features': 29, 'min_impurity_decrease': 3.409101495517417}. Best is trial 4 with value: 0.5.\u001b[0m\n",
      "\u001b[32m[I 2024-11-15 06:06:18,811]\u001b[0m Trial 10 finished with value: 0.5 and parameters: {'n_estimators': 118, 'max_depth': 7, 'max_features': 23, 'min_impurity_decrease': 1.5925189256906216}. Best is trial 4 with value: 0.5.\u001b[0m\n",
      "\u001b[32m[I 2024-11-15 06:06:19,965]\u001b[0m Trial 11 finished with value: 0.5 and parameters: {'n_estimators': 124, 'max_depth': 20, 'max_features': 12, 'min_impurity_decrease': 4.92344269588344}. Best is trial 4 with value: 0.5.\u001b[0m\n",
      "\u001b[32m[I 2024-11-15 06:06:22,620]\u001b[0m Trial 12 finished with value: 0.5 and parameters: {'n_estimators': 324, 'max_depth': 18, 'max_features': 29, 'min_impurity_decrease': 4.902627126552196}. Best is trial 4 with value: 0.5.\u001b[0m\n",
      "\u001b[32m[I 2024-11-15 06:06:24,852]\u001b[0m Trial 13 finished with value: 0.5 and parameters: {'n_estimators': 287, 'max_depth': 6, 'max_features': 10, 'min_impurity_decrease': 1.623183405239199}. Best is trial 4 with value: 0.5.\u001b[0m\n",
      "\u001b[32m[I 2024-11-15 06:06:26,922]\u001b[0m Trial 14 finished with value: 0.5 and parameters: {'n_estimators': 253, 'max_depth': 11, 'max_features': 21, 'min_impurity_decrease': 4.1293377417421695}. Best is trial 4 with value: 0.5.\u001b[0m\n",
      "\u001b[32m[I 2024-11-15 06:06:30,042]\u001b[0m Trial 15 finished with value: 0.5 and parameters: {'n_estimators': 381, 'max_depth': 17, 'max_features': 26, 'min_impurity_decrease': 2.0049935735461806}. Best is trial 4 with value: 0.5.\u001b[0m\n",
      "\u001b[32m[I 2024-11-15 06:06:31,765]\u001b[0m Trial 16 finished with value: 0.5 and parameters: {'n_estimators': 213, 'max_depth': 13, 'max_features': 18, 'min_impurity_decrease': 3.4814210246729473}. Best is trial 4 with value: 0.5.\u001b[0m\n",
      "\u001b[32m[I 2024-11-15 06:06:37,994]\u001b[0m Trial 17 finished with value: 0.4982378854625551 and parameters: {'n_estimators': 807, 'max_depth': 9, 'max_features': 21, 'min_impurity_decrease': 3.5908341056521604}. Best is trial 4 with value: 0.5.\u001b[0m\n",
      "\u001b[32m[I 2024-11-15 06:06:41,258]\u001b[0m Trial 18 finished with value: 0.5 and parameters: {'n_estimators': 401, 'max_depth': 11, 'max_features': 26, 'min_impurity_decrease': 1.796535064127053}. Best is trial 4 with value: 0.5.\u001b[0m\n",
      "\u001b[32m[I 2024-11-15 06:06:44,312]\u001b[0m Trial 19 finished with value: 0.5 and parameters: {'n_estimators': 398, 'max_depth': 8, 'max_features': 14, 'min_impurity_decrease': 0.7203844545912395}. Best is trial 4 with value: 0.5.\u001b[0m\n",
      "\u001b[32m[I 2024-11-15 06:06:49,882]\u001b[0m Trial 20 finished with value: 0.4982378854625551 and parameters: {'n_estimators': 737, 'max_depth': 8, 'max_features': 14, 'min_impurity_decrease': 0.2358219011064575}. Best is trial 4 with value: 0.5.\u001b[0m\n",
      "\u001b[32m[I 2024-11-15 06:06:51,456]\u001b[0m Trial 21 finished with value: 0.5 and parameters: {'n_estimators': 183, 'max_depth': 5, 'max_features': 23, 'min_impurity_decrease': 1.327901176161716}. Best is trial 4 with value: 0.5.\u001b[0m\n",
      "\u001b[32m[I 2024-11-15 06:06:54,714]\u001b[0m Trial 22 finished with value: 0.4982378854625551 and parameters: {'n_estimators': 409, 'max_depth': 8, 'max_features': 27, 'min_impurity_decrease': 0.829906574090217}. Best is trial 4 with value: 0.5.\u001b[0m\n",
      "\u001b[32m[I 2024-11-15 06:06:58,039]\u001b[0m Trial 23 finished with value: 0.4982378854625551 and parameters: {'n_estimators': 437, 'max_depth': 20, 'max_features': 13, 'min_impurity_decrease': 0.8982128301077474}. Best is trial 4 with value: 0.5.\u001b[0m\n",
      "\u001b[32m[I 2024-11-15 06:06:59,519]\u001b[0m Trial 24 finished with value: 0.5 and parameters: {'n_estimators': 175, 'max_depth': 5, 'max_features': 12, 'min_impurity_decrease': 1.1009643308350792}. Best is trial 4 with value: 0.5.\u001b[0m\n",
      "\u001b[32m[I 2024-11-15 06:07:02,252]\u001b[0m Trial 25 finished with value: 0.5 and parameters: {'n_estimators': 330, 'max_depth': 5, 'max_features': 29, 'min_impurity_decrease': 1.2507142742158308}. Best is trial 4 with value: 0.5.\u001b[0m\n",
      "\u001b[32m[I 2024-11-15 06:07:05,230]\u001b[0m Trial 26 finished with value: 0.6463775291411641 and parameters: {'n_estimators': 323, 'max_depth': 9, 'max_features': 23, 'min_impurity_decrease': 0.015406488407678887}. Best is trial 26 with value: 0.6463775291411641.\u001b[0m\n",
      "\u001b[32m[I 2024-11-15 06:07:07,042]\u001b[0m Trial 27 finished with value: 0.6479677205567035 and parameters: {'n_estimators': 190, 'max_depth': 5, 'max_features': 19, 'min_impurity_decrease': 0.01337735907912796}. Best is trial 27 with value: 0.6479677205567035.\u001b[0m\n",
      "\u001b[32m[I 2024-11-15 06:07:09,916]\u001b[0m Trial 28 finished with value: 0.6327078866321001 and parameters: {'n_estimators': 316, 'max_depth': 6, 'max_features': 30, 'min_impurity_decrease': 0.0444905724402096}. Best is trial 27 with value: 0.6479677205567035.\u001b[0m\n",
      "\u001b[32m[I 2024-11-15 06:07:12,314]\u001b[0m Trial 29 finished with value: 0.5973665744025574 and parameters: {'n_estimators': 299, 'max_depth': 9, 'max_features': 19, 'min_impurity_decrease': 0.06593023869472255}. Best is trial 27 with value: 0.6479677205567035.\u001b[0m\n",
      "\u001b[32m[I 2024-11-15 06:07:14,291]\u001b[0m Trial 30 finished with value: 0.5 and parameters: {'n_estimators': 239, 'max_depth': 6, 'max_features': 22, 'min_impurity_decrease': 0.4047611173850654}. Best is trial 27 with value: 0.6479677205567035.\u001b[0m\n",
      "\u001b[32m[I 2024-11-15 06:07:16,903]\u001b[0m Trial 31 finished with value: 0.5 and parameters: {'n_estimators': 327, 'max_depth': 9, 'max_features': 19, 'min_impurity_decrease': 0.1794969711095402}. Best is trial 27 with value: 0.6479677205567035.\u001b[0m\n",
      "\u001b[32m[I 2024-11-15 06:07:20,047]\u001b[0m Trial 32 finished with value: 0.6798066352189 and parameters: {'n_estimators': 284, 'max_depth': 7, 'max_features': 16, 'min_impurity_decrease': 0.004742948376979174}. Best is trial 32 with value: 0.6798066352189.\u001b[0m\n",
      "\u001b[32m[I 2024-11-15 06:07:25,212]\u001b[0m Trial 33 finished with value: 0.6864196327628552 and parameters: {'n_estimators': 467, 'max_depth': 7, 'max_features': 16, 'min_impurity_decrease': 0.002074882267097497}. Best is trial 33 with value: 0.6864196327628552.\u001b[0m\n",
      "\u001b[32m[I 2024-11-15 06:07:28,743]\u001b[0m Trial 34 finished with value: 0.4982378854625551 and parameters: {'n_estimators': 462, 'max_depth': 7, 'max_features': 16, 'min_impurity_decrease': 0.6299639399500273}. Best is trial 33 with value: 0.6864196327628552.\u001b[0m\n",
      "\u001b[32m[I 2024-11-15 06:07:32,514]\u001b[0m Trial 35 finished with value: 0.4982378854625551 and parameters: {'n_estimators': 482, 'max_depth': 10, 'max_features': 17, 'min_impurity_decrease': 2.297690264919427}. Best is trial 33 with value: 0.6864196327628552.\u001b[0m\n",
      "\u001b[32m[I 2024-11-15 06:07:36,532]\u001b[0m Trial 36 finished with value: 0.4982378854625551 and parameters: {'n_estimators': 538, 'max_depth': 7, 'max_features': 15, 'min_impurity_decrease': 0.43239141926521335}. Best is trial 33 with value: 0.6864196327628552.\u001b[0m\n",
      "\u001b[32m[I 2024-11-15 06:07:39,527]\u001b[0m Trial 37 finished with value: 0.5 and parameters: {'n_estimators': 356, 'max_depth': 7, 'max_features': 18, 'min_impurity_decrease': 0.5530514287722431}. Best is trial 33 with value: 0.6864196327628552.\u001b[0m\n",
      "\u001b[32m[I 2024-11-15 06:07:41,650]\u001b[0m Trial 38 finished with value: 0.5 and parameters: {'n_estimators': 262, 'max_depth': 10, 'max_features': 20, 'min_impurity_decrease': 0.3103660728247826}. Best is trial 33 with value: 0.6864196327628552.\u001b[0m\n",
      "\u001b[32m[I 2024-11-15 06:07:46,487]\u001b[0m Trial 39 finished with value: 0.4982378854625551 and parameters: {'n_estimators': 633, 'max_depth': 6, 'max_features': 24, 'min_impurity_decrease': 1.0171201657053728}. Best is trial 33 with value: 0.6864196327628552.\u001b[0m\n",
      "\u001b[32m[I 2024-11-15 06:07:54,213]\u001b[0m Trial 40 finished with value: 0.6570504073915246 and parameters: {'n_estimators': 911, 'max_depth': 12, 'max_features': 9, 'min_impurity_decrease': 0.008540374099514124}. Best is trial 33 with value: 0.6864196327628552.\u001b[0m\n",
      "\u001b[32m[I 2024-11-15 06:07:59,753]\u001b[0m Trial 41 finished with value: 0.6336786090210907 and parameters: {'n_estimators': 749, 'max_depth': 12, 'max_features': 7, 'min_impurity_decrease': 0.0531403193873689}. Best is trial 33 with value: 0.6864196327628552.\u001b[0m\n",
      "\u001b[32m[I 2024-11-15 06:08:06,269]\u001b[0m Trial 42 finished with value: 0.4982378854625551 and parameters: {'n_estimators': 894, 'max_depth': 8, 'max_features': 10, 'min_impurity_decrease': 0.5264772244805026}. Best is trial 33 with value: 0.6864196327628552.\u001b[0m\n",
      "\u001b[32m[I 2024-11-15 06:08:07,633]\u001b[0m Trial 43 finished with value: 0.6297083934349538 and parameters: {'n_estimators': 158, 'max_depth': 10, 'max_features': 8, 'min_impurity_decrease': 0.03658212802972258}. Best is trial 33 with value: 0.6864196327628552.\u001b[0m\n",
      "\u001b[32m[I 2024-11-15 06:08:12,073]\u001b[0m Trial 44 finished with value: 0.4982378854625551 and parameters: {'n_estimators': 573, 'max_depth': 13, 'max_features': 17, 'min_impurity_decrease': 0.28186236164798095}. Best is trial 33 with value: 0.6864196327628552.\u001b[0m\n",
      "\u001b[32m[I 2024-11-15 06:08:18,421]\u001b[0m Trial 45 finished with value: 0.4982378854625551 and parameters: {'n_estimators': 901, 'max_depth': 5, 'max_features': 5, 'min_impurity_decrease': 2.8293759758960437}. Best is trial 33 with value: 0.6864196327628552.\u001b[0m\n",
      "\u001b[32m[I 2024-11-15 06:08:22,494]\u001b[0m Trial 46 finished with value: 0.4982378854625551 and parameters: {'n_estimators': 529, 'max_depth': 15, 'max_features': 15, 'min_impurity_decrease': 0.6915813865054513}. Best is trial 33 with value: 0.6864196327628552.\u001b[0m\n",
      "\u001b[32m[I 2024-11-15 06:08:24,215]\u001b[0m Trial 47 finished with value: 0.5 and parameters: {'n_estimators': 211, 'max_depth': 7, 'max_features': 20, 'min_impurity_decrease': 0.3323319332707677}. Best is trial 33 with value: 0.6864196327628552.\u001b[0m\n",
      "\u001b[32m[I 2024-11-15 06:08:29,453]\u001b[0m Trial 48 finished with value: 0.4982378854625551 and parameters: {'n_estimators': 710, 'max_depth': 12, 'max_features': 10, 'min_impurity_decrease': 0.8511817489687437}. Best is trial 33 with value: 0.6864196327628552.\u001b[0m\n",
      "\u001b[32m[I 2024-11-15 06:08:30,451]\u001b[0m Trial 49 finished with value: 0.5 and parameters: {'n_estimators': 107, 'max_depth': 9, 'max_features': 22, 'min_impurity_decrease': 0.5408427243875316}. Best is trial 33 with value: 0.6864196327628552.\u001b[0m\n",
      "\u001b[32m[I 2024-11-15 06:08:34,290]\u001b[0m Trial 50 finished with value: 0.6835094148376283 and parameters: {'n_estimators': 359, 'max_depth': 6, 'max_features': 16, 'min_impurity_decrease': 0.0016101730829128362}. Best is trial 33 with value: 0.6864196327628552.\u001b[0m\n",
      "\u001b[32m[I 2024-11-15 06:08:37,395]\u001b[0m Trial 51 finished with value: 0.6333269658102998 and parameters: {'n_estimators': 362, 'max_depth': 6, 'max_features': 16, 'min_impurity_decrease': 0.021236436660079846}. Best is trial 33 with value: 0.6864196327628552.\u001b[0m\n",
      "\u001b[32m[I 2024-11-15 06:08:39,629]\u001b[0m Trial 52 finished with value: 0.5 and parameters: {'n_estimators': 277, 'max_depth': 6, 'max_features': 14, 'min_impurity_decrease': 0.2201477468127777}. Best is trial 33 with value: 0.6864196327628552.\u001b[0m\n",
      "\u001b[32m[I 2024-11-15 06:08:43,029]\u001b[0m Trial 53 finished with value: 0.4982378854625551 and parameters: {'n_estimators': 439, 'max_depth': 7, 'max_features': 19, 'min_impurity_decrease': 0.410453869523175}. Best is trial 33 with value: 0.6864196327628552.\u001b[0m\n",
      "\u001b[32m[I 2024-11-15 06:08:48,763]\u001b[0m Trial 54 finished with value: 0.6898608241394097 and parameters: {'n_estimators': 500, 'max_depth': 8, 'max_features': 15, 'min_impurity_decrease': 0.00020102658536092465}. Best is trial 54 with value: 0.6898608241394097.\u001b[0m\n",
      "\u001b[32m[I 2024-11-15 06:08:52,494]\u001b[0m Trial 55 finished with value: 0.4982378854625551 and parameters: {'n_estimators': 487, 'max_depth': 5, 'max_features': 12, 'min_impurity_decrease': 0.22281120324125298}. Best is trial 54 with value: 0.6898608241394097.\u001b[0m\n",
      "\u001b[32m[I 2024-11-15 06:08:57,102]\u001b[0m Trial 56 finished with value: 0.4982378854625551 and parameters: {'n_estimators': 615, 'max_depth': 8, 'max_features': 15, 'min_impurity_decrease': 0.6776821652052497}. Best is trial 54 with value: 0.6898608241394097.\u001b[0m\n",
      "\u001b[32m[I 2024-11-15 06:09:00,507]\u001b[0m Trial 57 finished with value: 0.4982378854625551 and parameters: {'n_estimators': 430, 'max_depth': 16, 'max_features': 17, 'min_impurity_decrease': 1.3211680734730344}. Best is trial 54 with value: 0.6898608241394097.\u001b[0m\n",
      "\u001b[32m[I 2024-11-15 06:09:04,789]\u001b[0m Trial 58 finished with value: 0.4982378854625551 and parameters: {'n_estimators': 577, 'max_depth': 7, 'max_features': 11, 'min_impurity_decrease': 0.2169676176431805}. Best is trial 54 with value: 0.6898608241394097.\u001b[0m\n",
      "\u001b[32m[I 2024-11-15 06:09:09,875]\u001b[0m Trial 59 finished with value: 0.4982378854625551 and parameters: {'n_estimators': 677, 'max_depth': 6, 'max_features': 13, 'min_impurity_decrease': 1.080121295421938}. Best is trial 54 with value: 0.6898608241394097.\u001b[0m\n",
      "\u001b[32m[I 2024-11-15 06:09:13,676]\u001b[0m Trial 60 finished with value: 0.4982378854625551 and parameters: {'n_estimators': 506, 'max_depth': 5, 'max_features': 16, 'min_impurity_decrease': 0.462624385988004}. Best is trial 54 with value: 0.6898608241394097.\u001b[0m\n",
      "\u001b[32m[I 2024-11-15 06:09:17,333]\u001b[0m Trial 61 finished with value: 0.6673638454641144 and parameters: {'n_estimators': 370, 'max_depth': 8, 'max_features': 18, 'min_impurity_decrease': 0.008044152548873792}. Best is trial 54 with value: 0.6898608241394097.\u001b[0m\n",
      "\u001b[32m[I 2024-11-15 06:09:19,351]\u001b[0m Trial 62 finished with value: 0.5 and parameters: {'n_estimators': 247, 'max_depth': 8, 'max_features': 18, 'min_impurity_decrease': 0.17477634681284226}. Best is trial 54 with value: 0.6898608241394097.\u001b[0m\n",
      "\u001b[32m[I 2024-11-15 06:09:22,290]\u001b[0m Trial 63 finished with value: 0.5 and parameters: {'n_estimators': 371, 'max_depth': 8, 'max_features': 18, 'min_impurity_decrease': 0.3484188328834943}. Best is trial 54 with value: 0.6898608241394097.\u001b[0m\n",
      "\u001b[32m[I 2024-11-15 06:09:25,870]\u001b[0m Trial 64 finished with value: 0.4982378854625551 and parameters: {'n_estimators': 459, 'max_depth': 6, 'max_features': 21, 'min_impurity_decrease': 0.7643414653098681}. Best is trial 54 with value: 0.6898608241394097.\u001b[0m\n",
      "\u001b[32m[I 2024-11-15 06:09:28,963]\u001b[0m Trial 65 finished with value: 0.5 and parameters: {'n_estimators': 404, 'max_depth': 10, 'max_features': 16, 'min_impurity_decrease': 0.1479159463335758}. Best is trial 54 with value: 0.6898608241394097.\u001b[0m\n",
      "\u001b[32m[I 2024-11-15 06:09:31,694]\u001b[0m Trial 66 finished with value: 0.5 and parameters: {'n_estimators': 343, 'max_depth': 5, 'max_features': 13, 'min_impurity_decrease': 4.595524820081348}. Best is trial 54 with value: 0.6898608241394097.\u001b[0m\n",
      "\u001b[32m[I 2024-11-15 06:09:38,715]\u001b[0m Trial 67 finished with value: 0.4982378854625551 and parameters: {'n_estimators': 956, 'max_depth': 7, 'max_features': 19, 'min_impurity_decrease': 0.49251514591542844}. Best is trial 54 with value: 0.6898608241394097.\u001b[0m\n",
      "\u001b[32m[I 2024-11-15 06:09:41,135]\u001b[0m Trial 68 finished with value: 0.5 and parameters: {'n_estimators': 298, 'max_depth': 9, 'max_features': 15, 'min_impurity_decrease': 2.2804530802608207}. Best is trial 54 with value: 0.6898608241394097.\u001b[0m\n",
      "\u001b[32m[I 2024-11-15 06:09:42,331]\u001b[0m Trial 69 finished with value: 0.5 and parameters: {'n_estimators': 143, 'max_depth': 14, 'max_features': 9, 'min_impurity_decrease': 0.9200725325595908}. Best is trial 54 with value: 0.6898608241394097.\u001b[0m\n",
      "\u001b[32m[I 2024-11-15 06:09:44,145]\u001b[0m Trial 70 finished with value: 0.5 and parameters: {'n_estimators': 218, 'max_depth': 8, 'max_features': 20, 'min_impurity_decrease': 0.17041832658983547}. Best is trial 54 with value: 0.6898608241394097.\u001b[0m\n",
      "\u001b[32m[I 2024-11-15 06:09:47,140]\u001b[0m Trial 71 finished with value: 0.5041409691629956 and parameters: {'n_estimators': 377, 'max_depth': 11, 'max_features': 25, 'min_impurity_decrease': 0.08623767580816735}. Best is trial 54 with value: 0.6898608241394097.\u001b[0m\n",
      "\u001b[32m[I 2024-11-15 06:09:49,822]\u001b[0m Trial 72 finished with value: 0.6310303691863866 and parameters: {'n_estimators': 307, 'max_depth': 9, 'max_features': 17, 'min_impurity_decrease': 0.03051661389667197}. Best is trial 54 with value: 0.6898608241394097.\u001b[0m\n",
      "\u001b[32m[I 2024-11-15 06:09:51,366]\u001b[0m Trial 73 finished with value: 0.5 and parameters: {'n_estimators': 185, 'max_depth': 6, 'max_features': 14, 'min_impurity_decrease': 0.2897350291077096}. Best is trial 54 with value: 0.6898608241394097.\u001b[0m\n",
      "\u001b[32m[I 2024-11-15 06:09:54,636]\u001b[0m Trial 74 finished with value: 0.4982378854625551 and parameters: {'n_estimators': 427, 'max_depth': 7, 'max_features': 17, 'min_impurity_decrease': 0.6082056861026157}. Best is trial 54 with value: 0.6898608241394097.\u001b[0m\n",
      "\u001b[32m[I 2024-11-15 06:09:58,495]\u001b[0m Trial 75 finished with value: 0.6895080113835718 and parameters: {'n_estimators': 278, 'max_depth': 9, 'max_features': 23, 'min_impurity_decrease': 0.0033084604183808786}. Best is trial 54 with value: 0.6898608241394097.\u001b[0m\n",
      "\u001b[32m[I 2024-11-15 06:10:00,717]\u001b[0m Trial 76 finished with value: 0.5 and parameters: {'n_estimators': 264, 'max_depth': 8, 'max_features': 6, 'min_impurity_decrease': 0.3624404145045157}. Best is trial 54 with value: 0.6898608241394097.\u001b[0m\n",
      "\u001b[32m[I 2024-11-15 06:10:05,134]\u001b[0m Trial 77 finished with value: 0.644877782542591 and parameters: {'n_estimators': 512, 'max_depth': 7, 'max_features': 15, 'min_impurity_decrease': 0.013876960520429993}. Best is trial 54 with value: 0.6898608241394097.\u001b[0m\n",
      "\u001b[32m[I 2024-11-15 06:10:07,027]\u001b[0m Trial 78 finished with value: 0.5 and parameters: {'n_estimators': 233, 'max_depth': 10, 'max_features': 21, 'min_impurity_decrease': 3.2310359657907313}. Best is trial 54 with value: 0.6898608241394097.\u001b[0m\n",
      "\u001b[32m[I 2024-11-15 06:10:09,753]\u001b[0m Trial 79 finished with value: 0.5 and parameters: {'n_estimators': 337, 'max_depth': 6, 'max_features': 22, 'min_impurity_decrease': 4.180692321956915}. Best is trial 54 with value: 0.6898608241394097.\u001b[0m\n",
      "\u001b[32m[I 2024-11-15 06:10:16,014]\u001b[0m Trial 80 finished with value: 0.4982378854625551 and parameters: {'n_estimators': 834, 'max_depth': 5, 'max_features': 18, 'min_impurity_decrease': 1.5694235317823755}. Best is trial 54 with value: 0.6898608241394097.\u001b[0m\n",
      "\u001b[32m[I 2024-11-15 06:10:19,471]\u001b[0m Trial 81 finished with value: 0.6772488402011618 and parameters: {'n_estimators': 282, 'max_depth': 9, 'max_features': 24, 'min_impurity_decrease': 0.006418222368846199}. Best is trial 54 with value: 0.6898608241394097.\u001b[0m\n",
      "\u001b[32m[I 2024-11-15 06:10:21,861]\u001b[0m Trial 82 finished with value: 0.5 and parameters: {'n_estimators': 289, 'max_depth': 9, 'max_features': 24, 'min_impurity_decrease': 0.1454562577460649}. Best is trial 54 with value: 0.6898608241394097.\u001b[0m\n",
      "\u001b[32m[I 2024-11-15 06:10:25,016]\u001b[0m Trial 83 finished with value: 0.4982378854625551 and parameters: {'n_estimators': 391, 'max_depth': 8, 'max_features': 28, 'min_impurity_decrease': 0.3072796629701957}. Best is trial 54 with value: 0.6898608241394097.\u001b[0m\n",
      "\u001b[32m[I 2024-11-15 06:10:27,859]\u001b[0m Trial 84 finished with value: 0.6878293243928113 and parameters: {'n_estimators': 193, 'max_depth': 9, 'max_features': 26, 'min_impurity_decrease': 0.003860482078347169}. Best is trial 54 with value: 0.6898608241394097.\u001b[0m\n",
      "\u001b[32m[I 2024-11-15 06:10:30,166]\u001b[0m Trial 85 finished with value: 0.5 and parameters: {'n_estimators': 272, 'max_depth': 12, 'max_features': 26, 'min_impurity_decrease': 0.44020251250923426}. Best is trial 54 with value: 0.6898608241394097.\u001b[0m\n",
      "\u001b[32m[I 2024-11-15 06:10:31,547]\u001b[0m Trial 86 finished with value: 0.5 and parameters: {'n_estimators': 158, 'max_depth': 10, 'max_features': 27, 'min_impurity_decrease': 0.15330472789373323}. Best is trial 54 with value: 0.6898608241394097.\u001b[0m\n",
      "\u001b[32m[I 2024-11-15 06:10:35,110]\u001b[0m Trial 87 finished with value: 0.4982378854625551 and parameters: {'n_estimators': 456, 'max_depth': 9, 'max_features': 24, 'min_impurity_decrease': 0.5869843914870814}. Best is trial 54 with value: 0.6898608241394097.\u001b[0m\n",
      "\u001b[32m[I 2024-11-15 06:10:39,411]\u001b[0m Trial 88 finished with value: 0.4982378854625551 and parameters: {'n_estimators': 545, 'max_depth': 11, 'max_features': 27, 'min_impurity_decrease': 0.3042165025876535}. Best is trial 54 with value: 0.6898608241394097.\u001b[0m\n",
      "\u001b[32m[I 2024-11-15 06:10:42,973]\u001b[0m Trial 89 finished with value: 0.6581026080854548 and parameters: {'n_estimators': 350, 'max_depth': 9, 'max_features': 26, 'min_impurity_decrease': 0.012024956224623223}. Best is trial 54 with value: 0.6898608241394097.\u001b[0m\n",
      "\u001b[32m[I 2024-11-15 06:10:44,838]\u001b[0m Trial 90 finished with value: 0.5 and parameters: {'n_estimators': 227, 'max_depth': 9, 'max_features': 25, 'min_impurity_decrease': 0.14845640144810232}. Best is trial 54 with value: 0.6898608241394097.\u001b[0m\n",
      "\u001b[32m[I 2024-11-15 06:10:48,743]\u001b[0m Trial 91 finished with value: 0.669752056450041 and parameters: {'n_estimators': 357, 'max_depth': 8, 'max_features': 23, 'min_impurity_decrease': 0.007725212574371583}. Best is trial 54 with value: 0.6898608241394097.\u001b[0m\n",
      "\u001b[32m[I 2024-11-15 06:10:51,636]\u001b[0m Trial 92 finished with value: 0.5 and parameters: {'n_estimators': 352, 'max_depth': 8, 'max_features': 23, 'min_impurity_decrease': 0.2511725321648865}. Best is trial 54 with value: 0.6898608241394097.\u001b[0m\n",
      "\u001b[32m[I 2024-11-15 06:10:54,158]\u001b[0m Trial 93 finished with value: 0.5 and parameters: {'n_estimators': 312, 'max_depth': 8, 'max_features': 26, 'min_impurity_decrease': 0.41513003204073623}. Best is trial 54 with value: 0.6898608241394097.\u001b[0m\n",
      "\u001b[32m[I 2024-11-15 06:10:57,509]\u001b[0m Trial 94 finished with value: 0.5022907488986784 and parameters: {'n_estimators': 422, 'max_depth': 10, 'max_features': 25, 'min_impurity_decrease': 0.092258527583706}. Best is trial 54 with value: 0.6898608241394097.\u001b[0m\n",
      "\u001b[32m[I 2024-11-15 06:11:02,751]\u001b[0m Trial 95 finished with value: 0.6783942146505008 and parameters: {'n_estimators': 389, 'max_depth': 7, 'max_features': 28, 'min_impurity_decrease': 0.005748117391830519}. Best is trial 54 with value: 0.6898608241394097.\u001b[0m\n",
      "\u001b[32m[I 2024-11-15 06:11:05,822]\u001b[0m Trial 96 finished with value: 0.5 and parameters: {'n_estimators': 385, 'max_depth': 7, 'max_features': 30, 'min_impurity_decrease': 3.7593455633451374}. Best is trial 54 with value: 0.6898608241394097.\u001b[0m\n",
      "\u001b[32m[I 2024-11-15 06:11:09,091]\u001b[0m Trial 97 finished with value: 0.4982378854625551 and parameters: {'n_estimators': 408, 'max_depth': 7, 'max_features': 28, 'min_impurity_decrease': 0.25029182301920627}. Best is trial 54 with value: 0.6898608241394097.\u001b[0m\n",
      "\u001b[32m[I 2024-11-15 06:11:13,007]\u001b[0m Trial 98 finished with value: 0.4982378854625551 and parameters: {'n_estimators': 482, 'max_depth': 8, 'max_features': 28, 'min_impurity_decrease': 0.49494225393386965}. Best is trial 54 with value: 0.6898608241394097.\u001b[0m\n",
      "\u001b[32m[I 2024-11-15 06:11:15,632]\u001b[0m Trial 99 finished with value: 0.5 and parameters: {'n_estimators': 329, 'max_depth': 7, 'max_features': 24, 'min_impurity_decrease': 0.10908904113217796}. Best is trial 54 with value: 0.6898608241394097.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "#Tuning hyperparameters\n",
    "#Step 1. Define an objective function to be maximized.\n",
    "def objective(trial):\n",
    "    n_estimators = trial.suggest_int(\"n_estimators\",100,1000,1) \n",
    "    max_depth = trial.suggest_int(\"max_depth\",5,20,1)\n",
    "    max_features = trial.suggest_int(\"max_features\",5,30,1)\n",
    "    min_impurity_decrease = trial.suggest_float(\"min_impurity_decrease\",0,5,log=False) \n",
    "    model = RandomForestClassifier(n_estimators = n_estimators\n",
    "              ,max_depth = max_depth\n",
    "              ,max_features = max_features\n",
    "              ,min_impurity_decrease = min_impurity_decrease\n",
    "              ,random_state=1\n",
    "              ,verbose=False\n",
    "              ,n_jobs=8)\n",
    "\n",
    "# Step 2: Scoring method:\n",
    "    score = model_selection.cross_val_score(model, X, y, n_jobs=8, scoring=\"accuracy\",cv=Cv_optuna)\n",
    "    accuracy = score.mean()\n",
    "    return accuracy\n",
    " \n",
    "# Step 3: Running it\n",
    "study = optuna.create_study(direction=\"maximize\",sampler=optuna.samplers.TPESampler(seed=0))\n",
    "study.optimize(objective, n_trials=100, show_progress_bar=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "3ea7fc26-11ae-497b-ab4a-949cd12a43a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best parameters are : \n",
      "{'n_estimators': 500, 'max_depth': 8, 'max_features': 15, 'min_impurity_decrease': 0.00020102658536092465}\n"
     ]
    }
   ],
   "source": [
    "# Getting the best parameters:\n",
    "print(f\"The best parameters are : \\n{study.best_params}\")\n",
    "# Setting the best model\n",
    "clf=RandomForestClassifier(n_estimators = study.best_params['n_estimators']\n",
    "              ,max_depth = study.best_params['max_depth']\n",
    "              ,max_features = study.best_params['max_features']\n",
    "              ,min_impurity_decrease = study.best_params['min_impurity_decrease']\n",
    "              ,random_state=0\n",
    "              ,verbose=False\n",
    "              ,n_jobs=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "90cca67e-3df8-43ff-8b96-2c9bec87ee43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mean</th>\n",
       "      <th>Se</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Accuracy_test</th>\n",
       "      <td>0.690040</td>\n",
       "      <td>0.004418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Accuracy_train</th>\n",
       "      <td>0.974559</td>\n",
       "      <td>0.000639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1 Score</th>\n",
       "      <td>0.689921</td>\n",
       "      <td>0.004605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Precision</th>\n",
       "      <td>0.690673</td>\n",
       "      <td>0.004717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recall</th>\n",
       "      <td>0.690829</td>\n",
       "      <td>0.006580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Roc_auc</th>\n",
       "      <td>0.761245</td>\n",
       "      <td>0.004561</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Mean        Se\n",
       "Accuracy_test   0.690040  0.004418\n",
       "Accuracy_train  0.974559  0.000639\n",
       "F1 Score        0.689921  0.004605\n",
       "Precision       0.690673  0.004717\n",
       "Recall          0.690829  0.006580\n",
       "Roc_auc         0.761245  0.004561"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Model2\n",
    "Model2=Model_results(clf,X,y,Cv_model)\n",
    "Model2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "346eea08-6a51-48fc-bfcd-1a8d913649a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th>Method</th>\n",
       "      <th colspan=\"4\" halign=\"left\">RF</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model</th>\n",
       "      <th colspan=\"2\" halign=\"left\">Model 1</th>\n",
       "      <th colspan=\"2\" halign=\"left\">Model 2</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Values</th>\n",
       "      <th>Mean</th>\n",
       "      <th>Se</th>\n",
       "      <th>Mean</th>\n",
       "      <th>Se</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Accuracy_test</th>\n",
       "      <td>0.684210</td>\n",
       "      <td>0.004595</td>\n",
       "      <td>0.690040</td>\n",
       "      <td>0.004418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Accuracy_train</th>\n",
       "      <td>0.999317</td>\n",
       "      <td>0.000076</td>\n",
       "      <td>0.974559</td>\n",
       "      <td>0.000639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1 Score</th>\n",
       "      <td>0.680396</td>\n",
       "      <td>0.004839</td>\n",
       "      <td>0.689921</td>\n",
       "      <td>0.004605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Precision</th>\n",
       "      <td>0.689501</td>\n",
       "      <td>0.005290</td>\n",
       "      <td>0.690673</td>\n",
       "      <td>0.004717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recall</th>\n",
       "      <td>0.673363</td>\n",
       "      <td>0.006661</td>\n",
       "      <td>0.690829</td>\n",
       "      <td>0.006580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Roc_auc</th>\n",
       "      <td>0.752851</td>\n",
       "      <td>0.004617</td>\n",
       "      <td>0.761245</td>\n",
       "      <td>0.004561</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Method                RF                              \n",
       "Model            Model 1             Model 2          \n",
       "Values              Mean        Se      Mean        Se\n",
       "Accuracy_test   0.684210  0.004595  0.690040  0.004418\n",
       "Accuracy_train  0.999317  0.000076  0.974559  0.000639\n",
       "F1 Score        0.680396  0.004839  0.689921  0.004605\n",
       "Precision       0.689501  0.005290  0.690673  0.004717\n",
       "Recall          0.673363  0.006661  0.690829  0.006580\n",
       "Roc_auc         0.752851  0.004617  0.761245  0.004561"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Saving the data of model performance\n",
    "Model_data=pd.concat([Model1,Model2],axis=1)\n",
    "Model_data.columns = [['RF']*4,['Model 1','Model 1', 'Model 2','Model 2'], ['Mean', 'Se', 'Mean', 'Se']]  \n",
    "Model_data.columns.names=['Method','Model','Values']\n",
    "Model_data.to_csv(\"./RF_model_lasso_data.csv\",sep=',')\n",
    "Model_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "115be659-b066-4abf-85ac-59fccd101ad4",
   "metadata": {},
   "source": [
    "## 1.4 XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "3ff2324c-d316-43ae-96dc-e58f404273a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf=xgb.XGBClassifier(random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "03979633-d8bb-44e7-a9d7-b7050c4c32c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mean</th>\n",
       "      <th>Se</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Accuracy_test</th>\n",
       "      <td>0.688091</td>\n",
       "      <td>0.004008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Accuracy_train</th>\n",
       "      <td>0.999317</td>\n",
       "      <td>0.000076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1 Score</th>\n",
       "      <td>0.685420</td>\n",
       "      <td>0.004215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Precision</th>\n",
       "      <td>0.691997</td>\n",
       "      <td>0.004584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recall</th>\n",
       "      <td>0.680587</td>\n",
       "      <td>0.006059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Roc_auc</th>\n",
       "      <td>0.756918</td>\n",
       "      <td>0.004106</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Mean        Se\n",
       "Accuracy_test   0.688091  0.004008\n",
       "Accuracy_train  0.999317  0.000076\n",
       "F1 Score        0.685420  0.004215\n",
       "Precision       0.691997  0.004584\n",
       "Recall          0.680587  0.006059\n",
       "Roc_auc         0.756918  0.004106"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Model1 \n",
    "Model1_clf=clf\n",
    "#Model1\n",
    "Model1=Model_results(Model1_clf,X,y,Cv_model)\n",
    "Model1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "c6e5e42b-3688-4c6f-aa87-cf0fe5b1ff05",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2024-11-15 06:12:09,340]\u001b[0m A new study created in memory with name: no-name-8e6ccf6e-8eae-4e72-9cce-42eb3226e702\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_98568\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_98568\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-11-15 06:12:26,387]\u001b[0m Trial 0 finished with value: 0.6918907644926122 and parameters: {'lambda': 0.15676677195506075, 'alpha': 0.7257005721594281, 'colsample_bytree': 0.7, 'subsample': 0.7000000000000001, 'learning_rate': 0.0801, 'n_estimators': 664}. Best is trial 0 with value: 0.6918907644926122.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_98568\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_98568\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-11-15 06:12:38,914]\u001b[0m Trial 1 finished with value: 0.7000097462087247 and parameters: {'lambda': 0.0562793204741517, 'alpha': 3.6905577292137624, 'colsample_bytree': 1.0, 'subsample': 0.6000000000000001, 'learning_rate': 0.1551, 'n_estimators': 552}. Best is trial 1 with value: 0.7000097462087247.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_98568\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_98568\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-11-15 06:12:51,452]\u001b[0m Trial 2 finished with value: 0.6700974620872481 and parameters: {'lambda': 0.18714500686240676, 'alpha': 5.039489598671215, 'colsample_bytree': 0.3, 'subsample': 0.4, 'learning_rate': 0.0001, 'n_estimators': 841}. Best is trial 1 with value: 0.7000097462087247.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_98568\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_98568\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-11-15 06:13:09,859]\u001b[0m Trial 3 finished with value: 0.7000896651202682 and parameters: {'lambda': 1.2960656597279736, 'alpha': 3.0202896401586674, 'colsample_bytree': 1.0, 'subsample': 0.9, 'learning_rate': 0.0901, 'n_estimators': 792}. Best is trial 3 with value: 0.7000896651202682.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_98568\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_98568\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-11-15 06:13:18,166]\u001b[0m Trial 4 finished with value: 0.6896842228373162 and parameters: {'lambda': 0.0029723346443356552, 'alpha': 0.3628140404024381, 'colsample_bytree': 0.4, 'subsample': 1.0, 'learning_rate': 0.10010000000000001, 'n_estimators': 444}. Best is trial 3 with value: 0.7000896651202682.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_98568\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_98568\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-11-15 06:13:38,929]\u001b[0m Trial 5 finished with value: 0.6882702428755215 and parameters: {'lambda': 0.011434638743472197, 'alpha': 1.2500712230836255, 'colsample_bytree': 0.6000000000000001, 'subsample': 0.7000000000000001, 'learning_rate': 0.0001, 'n_estimators': 637}. Best is trial 3 with value: 0.7000896651202682.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_98568\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_98568\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-11-15 06:13:55,877]\u001b[0m Trial 6 finished with value: 0.697177108104947 and parameters: {'lambda': 0.2807908107885728, 'alpha': 0.2935864364395359, 'colsample_bytree': 1.0, 'subsample': 0.8, 'learning_rate': 0.07010000000000001, 'n_estimators': 465}. Best is trial 3 with value: 0.7000896651202682.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_98568\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_98568\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-11-15 06:14:02,224]\u001b[0m Trial 7 finished with value: 0.6936540485751044 and parameters: {'lambda': 0.6173405204074314, 'alpha': 0.0017414134181586202, 'colsample_bytree': 0.8, 'subsample': 0.8, 'learning_rate': 0.040100000000000004, 'n_estimators': 172}. Best is trial 3 with value: 0.7000896651202682.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_98568\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_98568\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-11-15 06:14:06,397]\u001b[0m Trial 8 finished with value: 0.6906518264395148 and parameters: {'lambda': 0.01826894228153233, 'alpha': 0.028499883436971588, 'colsample_bytree': 0.7, 'subsample': 0.7000000000000001, 'learning_rate': 0.1951, 'n_estimators': 147}. Best is trial 3 with value: 0.7000896651202682.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_98568\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_98568\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-11-15 06:14:13,800]\u001b[0m Trial 9 finished with value: 0.6925897625823554 and parameters: {'lambda': 0.006847105576684045, 'alpha': 0.004418125737902547, 'colsample_bytree': 0.8, 'subsample': 0.5, 'learning_rate': 0.0901, 'n_estimators': 282}. Best is trial 3 with value: 0.7000896651202682.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_98568\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_98568\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-11-15 06:14:33,120]\u001b[0m Trial 10 finished with value: 0.6933889516977894 and parameters: {'lambda': 6.8179090749657245, 'alpha': 0.05930570259610594, 'colsample_bytree': 0.5, 'subsample': 1.0, 'learning_rate': 0.1301, 'n_estimators': 987}. Best is trial 3 with value: 0.7000896651202682.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_98568\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_98568\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-11-15 06:14:45,298]\u001b[0m Trial 11 finished with value: 0.7026521383181943 and parameters: {'lambda': 1.5720941748660842, 'alpha': 7.942090836522697, 'colsample_bytree': 1.0, 'subsample': 0.5, 'learning_rate': 0.15009999999999998, 'n_estimators': 754}. Best is trial 11 with value: 0.7026521383181943.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_98568\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_98568\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-11-15 06:14:56,754]\u001b[0m Trial 12 finished with value: 0.7002647070289657 and parameters: {'lambda': 2.3527923006380522, 'alpha': 8.19008932305862, 'colsample_bytree': 0.9000000000000001, 'subsample': 0.9, 'learning_rate': 0.14509999999999998, 'n_estimators': 829}. Best is trial 11 with value: 0.7026521383181943.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_98568\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_98568\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-11-15 06:15:09,506]\u001b[0m Trial 13 finished with value: 0.7045004093407663 and parameters: {'lambda': 6.084340330665776, 'alpha': 8.659534143596002, 'colsample_bytree': 0.9000000000000001, 'subsample': 0.4, 'learning_rate': 0.1601, 'n_estimators': 976}. Best is trial 13 with value: 0.7045004093407663.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_98568\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_98568\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-11-15 06:15:31,219]\u001b[0m Trial 14 finished with value: 0.6993859888503371 and parameters: {'lambda': 7.387772726133953, 'alpha': 1.5492496434473824, 'colsample_bytree': 0.9000000000000001, 'subsample': 0.4, 'learning_rate': 0.1901, 'n_estimators': 1000}. Best is trial 13 with value: 0.7045004093407663.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_98568\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_98568\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-11-15 06:15:41,909]\u001b[0m Trial 15 finished with value: 0.7007099138435149 and parameters: {'lambda': 2.0038171983991875, 'alpha': 9.485113190377765, 'colsample_bytree': 0.9000000000000001, 'subsample': 0.5, 'learning_rate': 0.1651, 'n_estimators': 749}. Best is trial 13 with value: 0.7045004093407663.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_98568\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_98568\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-11-15 06:16:03,967]\u001b[0m Trial 16 finished with value: 0.70035203305914 and parameters: {'lambda': 7.714860917045715, 'alpha': 0.16888877355169551, 'colsample_bytree': 0.8, 'subsample': 0.5, 'learning_rate': 0.11510000000000001, 'n_estimators': 910}. Best is trial 13 with value: 0.7045004093407663.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_98568\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_98568\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-11-15 06:16:14,893]\u001b[0m Trial 17 finished with value: 0.6900307980195701 and parameters: {'lambda': 0.0010007385532741766, 'alpha': 0.02505168442772111, 'colsample_bytree': 0.9000000000000001, 'subsample': 0.4, 'learning_rate': 0.1701, 'n_estimators': 697}. Best is trial 13 with value: 0.7045004093407663.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_98568\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_98568\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-11-15 06:16:30,329]\u001b[0m Trial 18 finished with value: 0.7014132002650969 and parameters: {'lambda': 0.6223944476897907, 'alpha': 1.8060345008451184, 'colsample_bytree': 0.6000000000000001, 'subsample': 0.6000000000000001, 'learning_rate': 0.1251, 'n_estimators': 909}. Best is trial 13 with value: 0.7045004093407663.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_98568\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_98568\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-11-15 06:16:45,102]\u001b[0m Trial 19 finished with value: 0.696739308409029 and parameters: {'lambda': 0.04489514796306682, 'alpha': 0.8198206632645962, 'colsample_bytree': 1.0, 'subsample': 0.6000000000000001, 'learning_rate': 0.1751, 'n_estimators': 604}. Best is trial 13 with value: 0.7045004093407663.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_98568\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_98568\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-11-15 06:17:02,103]\u001b[0m Trial 20 finished with value: 0.6991189427312776 and parameters: {'lambda': 2.5132520362548596, 'alpha': 0.009617820188922183, 'colsample_bytree': 0.8, 'subsample': 0.5, 'learning_rate': 0.1401, 'n_estimators': 888}. Best is trial 13 with value: 0.7045004093407663.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_98568\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_98568\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-11-15 06:17:17,151]\u001b[0m Trial 21 finished with value: 0.700093953452107 and parameters: {'lambda': 0.7087036620194995, 'alpha': 2.6760498044577927, 'colsample_bytree': 0.6000000000000001, 'subsample': 0.6000000000000001, 'learning_rate': 0.1201, 'n_estimators': 917}. Best is trial 13 with value: 0.7045004093407663.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_98568\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_98568\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-11-15 06:17:25,995]\u001b[0m Trial 22 finished with value: 0.7047662859147792 and parameters: {'lambda': 0.4592751524320432, 'alpha': 6.959110224477685, 'colsample_bytree': 0.5, 'subsample': 0.6000000000000001, 'learning_rate': 0.15009999999999998, 'n_estimators': 768}. Best is trial 22 with value: 0.7047662859147792.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_98568\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_98568\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-11-15 06:17:33,796]\u001b[0m Trial 23 finished with value: 0.7016802463841566 and parameters: {'lambda': 3.9474033774844837, 'alpha': 8.725116392971993, 'colsample_bytree': 0.5, 'subsample': 0.4, 'learning_rate': 0.15009999999999998, 'n_estimators': 747}. Best is trial 22 with value: 0.7047662859147792.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_98568\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_98568\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-11-15 06:17:38,854]\u001b[0m Trial 24 finished with value: 0.6985926474601379 and parameters: {'lambda': 1.0105934242173862, 'alpha': 4.952969106652406, 'colsample_bytree': 0.4, 'subsample': 0.5, 'learning_rate': 0.18009999999999998, 'n_estimators': 366}. Best is trial 22 with value: 0.7047662859147792.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_98568\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_98568\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-11-15 06:17:49,255]\u001b[0m Trial 25 finished with value: 0.6963841565630969 and parameters: {'lambda': 0.3780314876736387, 'alpha': 0.45404272139337687, 'colsample_bytree': 0.5, 'subsample': 0.4, 'learning_rate': 0.1101, 'n_estimators': 711}. Best is trial 22 with value: 0.7047662859147792.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_98568\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_98568\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-11-15 06:17:57,300]\u001b[0m Trial 26 finished with value: 0.7000861564851273 and parameters: {'lambda': 4.382762538433655, 'alpha': 4.311488884270082, 'colsample_bytree': 0.4, 'subsample': 0.5, 'learning_rate': 0.1601, 'n_estimators': 558}. Best is trial 22 with value: 0.7047662859147792.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_98568\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_98568\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-11-15 06:18:14,456]\u001b[0m Trial 27 finished with value: 0.6989364937039491 and parameters: {'lambda': 0.0963907161054906, 'alpha': 1.7938177006333427, 'colsample_bytree': 0.9000000000000001, 'subsample': 0.6000000000000001, 'learning_rate': 0.1351, 'n_estimators': 797}. Best is trial 22 with value: 0.7047662859147792.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_98568\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_98568\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-11-15 06:18:35,577]\u001b[0m Trial 28 finished with value: 0.7015055943238079 and parameters: {'lambda': 1.5200089027626094, 'alpha': 0.12366705188529266, 'colsample_bytree': 0.7, 'subsample': 0.5, 'learning_rate': 0.050100000000000006, 'n_estimators': 951}. Best is trial 22 with value: 0.7047662859147792.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_98568\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_98568\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-11-15 06:18:47,662]\u001b[0m Trial 29 finished with value: 0.6990339557911972 and parameters: {'lambda': 0.3613239064993018, 'alpha': 0.7297885974341038, 'colsample_bytree': 0.7, 'subsample': 0.6000000000000001, 'learning_rate': 0.1851, 'n_estimators': 638}. Best is trial 22 with value: 0.7047662859147792.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_98568\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_98568\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-11-15 06:18:55,511]\u001b[0m Trial 30 finished with value: 0.6963911738333788 and parameters: {'lambda': 4.0026551048761325, 'alpha': 5.955393389085462, 'colsample_bytree': 0.3, 'subsample': 0.8, 'learning_rate': 0.1551, 'n_estimators': 844}. Best is trial 22 with value: 0.7047662859147792.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_98568\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_98568\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-11-15 06:19:02,252]\u001b[0m Trial 31 finished with value: 0.7036189622236949 and parameters: {'lambda': 3.7318266558737143, 'alpha': 8.381596817075506, 'colsample_bytree': 0.4, 'subsample': 0.4, 'learning_rate': 0.14509999999999998, 'n_estimators': 729}. Best is trial 22 with value: 0.7047662859147792.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_98568\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_98568\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-11-15 06:19:08,195]\u001b[0m Trial 32 finished with value: 0.702562083349577 and parameters: {'lambda': 3.1190507534091365, 'alpha': 9.950176607293296, 'colsample_bytree': 0.4, 'subsample': 0.4, 'learning_rate': 0.14509999999999998, 'n_estimators': 689}. Best is trial 22 with value: 0.7047662859147792.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_98568\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_98568\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-11-15 06:19:09,736]\u001b[0m Trial 33 finished with value: 0.6906611827998909 and parameters: {'lambda': 9.29634840081536, 'alpha': 2.9776445249426233, 'colsample_bytree': 0.5, 'subsample': 0.4, 'learning_rate': 0.1651, 'n_estimators': 54}. Best is trial 22 with value: 0.7047662859147792.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_98568\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_98568\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-11-15 06:19:17,598]\u001b[0m Trial 34 finished with value: 0.6958535729601185 and parameters: {'lambda': 0.13059763855605414, 'alpha': 3.9858272268069386, 'colsample_bytree': 0.3, 'subsample': 0.4, 'learning_rate': 0.1351, 'n_estimators': 758}. Best is trial 22 with value: 0.7047662859147792.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_98568\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_98568\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-11-15 06:19:32,896]\u001b[0m Trial 35 finished with value: 0.7040583213130093 and parameters: {'lambda': 1.3350861308526873, 'alpha': 2.5290618697033636, 'colsample_bytree': 1.0, 'subsample': 0.5, 'learning_rate': 0.1051, 'n_estimators': 517}. Best is trial 22 with value: 0.7047662859147792.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_98568\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_98568\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-11-15 06:19:42,699]\u001b[0m Trial 36 finished with value: 0.7010642859927487 and parameters: {'lambda': 0.9629657496004499, 'alpha': 0.9571368021409378, 'colsample_bytree': 0.4, 'subsample': 0.6000000000000001, 'learning_rate': 0.07010000000000001, 'n_estimators': 502}. Best is trial 22 with value: 0.7047662859147792.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_98568\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_98568\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-11-15 06:19:53,552]\u001b[0m Trial 37 finished with value: 0.7014167089002379 and parameters: {'lambda': 0.21691134485107075, 'alpha': 2.326999830450076, 'colsample_bytree': 1.0, 'subsample': 0.4, 'learning_rate': 0.10010000000000001, 'n_estimators': 399}. Best is trial 22 with value: 0.7047662859147792.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_98568\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_98568\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-11-15 06:20:03,912]\u001b[0m Trial 38 finished with value: 0.7024708588359129 and parameters: {'lambda': 4.866678259559126, 'alpha': 5.208300586816042, 'colsample_bytree': 0.6000000000000001, 'subsample': 0.5, 'learning_rate': 0.1051, 'n_estimators': 534}. Best is trial 22 with value: 0.7047662859147792.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_98568\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_98568\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-11-15 06:20:12,970]\u001b[0m Trial 39 finished with value: 0.6953288370823748 and parameters: {'lambda': 0.0670371952272321, 'alpha': 0.43852363362759106, 'colsample_bytree': 0.3, 'subsample': 0.7000000000000001, 'learning_rate': 0.0801, 'n_estimators': 596}. Best is trial 22 with value: 0.7047662859147792.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_98568\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_98568\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-11-15 06:20:19,219]\u001b[0m Trial 40 finished with value: 0.6981583563993606 and parameters: {'lambda': 0.43645595777856905, 'alpha': 3.3083552406562697, 'colsample_bytree': 0.5, 'subsample': 0.4, 'learning_rate': 0.0301, 'n_estimators': 296}. Best is trial 22 with value: 0.7047662859147792.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_98568\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_98568\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-11-15 06:20:33,700]\u001b[0m Trial 41 finished with value: 0.7028267903785428 and parameters: {'lambda': 1.2907801142583875, 'alpha': 6.528028307680289, 'colsample_bytree': 1.0, 'subsample': 0.5, 'learning_rate': 0.15009999999999998, 'n_estimators': 866}. Best is trial 22 with value: 0.7047662859147792.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_98568\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_98568\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-11-15 06:20:50,143]\u001b[0m Trial 42 finished with value: 0.7007110833885619 and parameters: {'lambda': 1.078567101792176, 'alpha': 5.409280374147742, 'colsample_bytree': 1.0, 'subsample': 0.5, 'learning_rate': 0.1201, 'n_estimators': 845}. Best is trial 22 with value: 0.7047662859147792.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_98568\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_98568\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-11-15 06:21:13,596]\u001b[0m Trial 43 finished with value: 0.7005321429963743 and parameters: {'lambda': 1.7880112343338415, 'alpha': 1.185524966619178, 'colsample_bytree': 1.0, 'subsample': 0.6000000000000001, 'learning_rate': 0.1601, 'n_estimators': 962}. Best is trial 22 with value: 0.7047662859147792.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_98568\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_98568\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-11-15 06:21:26,789]\u001b[0m Trial 44 finished with value: 0.7014993567502242 and parameters: {'lambda': 5.672191884724922, 'alpha': 6.502182102688964, 'colsample_bytree': 0.9000000000000001, 'subsample': 0.5, 'learning_rate': 0.1751, 'n_estimators': 809}. Best is trial 22 with value: 0.7047662859147792.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_98568\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_98568\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-11-15 06:21:48,697]\u001b[0m Trial 45 finished with value: 0.7001781606954893 and parameters: {'lambda': 2.889854184481324, 'alpha': 2.176387860032439, 'colsample_bytree': 1.0, 'subsample': 0.7000000000000001, 'learning_rate': 0.1301, 'n_estimators': 874}. Best is trial 22 with value: 0.7047662859147792.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_98568\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_98568\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-11-15 06:21:58,268]\u001b[0m Trial 46 finished with value: 0.6938306498771978 and parameters: {'lambda': 0.8111421859094646, 'alpha': 0.0010936023875764086, 'colsample_bytree': 0.9000000000000001, 'subsample': 0.4, 'learning_rate': 0.15009999999999998, 'n_estimators': 449}. Best is trial 22 with value: 0.7047662859147792.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_98568\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_98568\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-11-15 06:22:21,835]\u001b[0m Trial 47 finished with value: 0.7013270437799696 and parameters: {'lambda': 1.2742453777360425, 'alpha': 3.5226040806251766, 'colsample_bytree': 1.0, 'subsample': 0.5, 'learning_rate': 0.0901, 'n_estimators': 946}. Best is trial 22 with value: 0.7047662859147792.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_98568\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_98568\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-11-15 06:22:28,383]\u001b[0m Trial 48 finished with value: 0.7011512221745742 and parameters: {'lambda': 0.19813183606952187, 'alpha': 6.543366624557168, 'colsample_bytree': 0.4, 'subsample': 0.4, 'learning_rate': 0.1401, 'n_estimators': 640}. Best is trial 22 with value: 0.7047662859147792.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_98568\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_98568\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-11-15 06:22:47,672]\u001b[0m Trial 49 finished with value: 0.7030825308954816 and parameters: {'lambda': 9.969887074247847, 'alpha': 1.4758513334972716, 'colsample_bytree': 0.8, 'subsample': 0.5, 'learning_rate': 0.1901, 'n_estimators': 780}. Best is trial 22 with value: 0.7047662859147792.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_98568\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_98568\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-11-15 06:23:02,537]\u001b[0m Trial 50 finished with value: 0.6999146232115706 and parameters: {'lambda': 9.883614317864316, 'alpha': 1.3946545881007113, 'colsample_bytree': 0.8, 'subsample': 0.6000000000000001, 'learning_rate': 0.1951, 'n_estimators': 495}. Best is trial 22 with value: 0.7047662859147792.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_98568\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_98568\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-11-15 06:23:19,846]\u001b[0m Trial 51 finished with value: 0.7001828388756772 and parameters: {'lambda': 5.885270462906052, 'alpha': 3.3470327565644817, 'colsample_bytree': 0.9000000000000001, 'subsample': 0.5, 'learning_rate': 0.1851, 'n_estimators': 789}. Best is trial 22 with value: 0.7047662859147792.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_98568\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_98568\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-11-15 06:23:29,929]\u001b[0m Trial 52 finished with value: 0.7015917508089352 and parameters: {'lambda': 2.1852869383881037, 'alpha': 9.894890554108642, 'colsample_bytree': 0.8, 'subsample': 0.5, 'learning_rate': 0.1701, 'n_estimators': 871}. Best is trial 22 with value: 0.7047662859147792.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_98568\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_98568\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-11-15 06:23:44,806]\u001b[0m Trial 53 finished with value: 0.6977002845892948 and parameters: {'lambda': 2.955596401098603, 'alpha': 0.25781691073515345, 'colsample_bytree': 0.9000000000000001, 'subsample': 0.4, 'learning_rate': 0.1601, 'n_estimators': 717}. Best is trial 22 with value: 0.7047662859147792.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_98568\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_98568\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-11-15 06:23:54,975]\u001b[0m Trial 54 finished with value: 0.7038856184944057 and parameters: {'lambda': 0.50049873354328, 'alpha': 6.741251575744796, 'colsample_bytree': 1.0, 'subsample': 0.5, 'learning_rate': 0.1951, 'n_estimators': 595}. Best is trial 22 with value: 0.7047662859147792.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_98568\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_98568\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-11-15 06:24:06,653]\u001b[0m Trial 55 finished with value: 0.7000912245136641 and parameters: {'lambda': 0.522829323430004, 'alpha': 2.4935879497451365, 'colsample_bytree': 0.8, 'subsample': 0.6000000000000001, 'learning_rate': 0.1901, 'n_estimators': 579}. Best is trial 22 with value: 0.7047662859147792.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_98568\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_98568\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-11-15 06:24:25,040]\u001b[0m Trial 56 finished with value: 0.6971806167400879 and parameters: {'lambda': 6.471882787472036, 'alpha': 0.043389551665792975, 'colsample_bytree': 0.9000000000000001, 'subsample': 0.7000000000000001, 'learning_rate': 0.18009999999999998, 'n_estimators': 655}. Best is trial 22 with value: 0.7047662859147792.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_98568\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_98568\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-11-15 06:24:38,471]\u001b[0m Trial 57 finished with value: 0.705471131729757 and parameters: {'lambda': 3.6402138213642234, 'alpha': 4.2905048874411404, 'colsample_bytree': 1.0, 'subsample': 0.5, 'learning_rate': 0.1951, 'n_estimators': 671}. Best is trial 57 with value: 0.705471131729757.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_98568\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_98568\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-11-15 06:24:49,341]\u001b[0m Trial 58 finished with value: 0.6986823125804063 and parameters: {'lambda': 0.020862438696612296, 'alpha': 4.429041031706972, 'colsample_bytree': 1.0, 'subsample': 0.4, 'learning_rate': 0.1701, 'n_estimators': 618}. Best is trial 57 with value: 0.705471131729757.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_98568\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_98568\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-11-15 06:24:55,678]\u001b[0m Trial 59 finished with value: 0.6970036255896456 and parameters: {'lambda': 0.27786863132744355, 'alpha': 6.75534096825984, 'colsample_bytree': 1.0, 'subsample': 1.0, 'learning_rate': 0.18009999999999998, 'n_estimators': 548}. Best is trial 57 with value: 0.705471131729757.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_98568\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_98568\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-11-15 06:25:10,723]\u001b[0m Trial 60 finished with value: 0.6970843241978869 and parameters: {'lambda': 0.7414161565137574, 'alpha': 1.995098349126315, 'colsample_bytree': 1.0, 'subsample': 0.6000000000000001, 'learning_rate': 0.1951, 'n_estimators': 683}. Best is trial 57 with value: 0.705471131729757.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_98568\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_98568\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-11-15 06:25:24,470]\u001b[0m Trial 61 finished with value: 0.6985914779150909 and parameters: {'lambda': 3.530315135951458, 'alpha': 4.186924861392755, 'colsample_bytree': 0.9000000000000001, 'subsample': 0.5, 'learning_rate': 0.1901, 'n_estimators': 743}. Best is trial 57 with value: 0.705471131729757.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_98568\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_98568\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-11-15 06:25:37,880]\u001b[0m Trial 62 finished with value: 0.6984109781295076 and parameters: {'lambda': 2.061831656029363, 'alpha': 1.180314676055994, 'colsample_bytree': 0.7, 'subsample': 0.5, 'learning_rate': 0.1951, 'n_estimators': 667}. Best is trial 57 with value: 0.705471131729757.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_98568\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_98568\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-11-15 06:25:51,216]\u001b[0m Trial 63 finished with value: 0.7022973763206112 and parameters: {'lambda': 6.824750588380354, 'alpha': 7.234732109570587, 'colsample_bytree': 1.0, 'subsample': 0.5, 'learning_rate': 0.1851, 'n_estimators': 725}. Best is trial 57 with value: 0.705471131729757.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_98568\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_98568\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-11-15 06:26:02,668]\u001b[0m Trial 64 finished with value: 0.7005259054227904 and parameters: {'lambda': 4.5737271683991425, 'alpha': 2.7024751177755686, 'colsample_bytree': 0.5, 'subsample': 0.4, 'learning_rate': 0.1751, 'n_estimators': 779}. Best is trial 57 with value: 0.705471131729757.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_98568\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_98568\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-11-15 06:26:19,095]\u001b[0m Trial 65 finished with value: 0.6997388016061751 and parameters: {'lambda': 8.11131082278963, 'alpha': 0.5766037749958738, 'colsample_bytree': 0.8, 'subsample': 0.6000000000000001, 'learning_rate': 0.1651, 'n_estimators': 586}. Best is trial 57 with value: 0.705471131729757.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_98568\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_98568\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-11-15 06:26:30,793]\u001b[0m Trial 66 finished with value: 0.6947982534793965 and parameters: {'lambda': 1.5858103858396364, 'alpha': 0.004568944568228128, 'colsample_bytree': 0.9000000000000001, 'subsample': 0.5, 'learning_rate': 0.1551, 'n_estimators': 505}. Best is trial 57 with value: 0.705471131729757.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_98568\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_98568\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-11-15 06:26:43,551]\u001b[0m Trial 67 finished with value: 0.7047627772796381 and parameters: {'lambda': 2.3741807193276094, 'alpha': 7.9094239165080396, 'colsample_bytree': 0.6000000000000001, 'subsample': 0.4, 'learning_rate': 0.0551, 'n_estimators': 819}. Best is trial 57 with value: 0.705471131729757.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_98568\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_98568\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-11-15 06:26:58,348]\u001b[0m Trial 68 finished with value: 0.7025585747144361 and parameters: {'lambda': 2.484837975276532, 'alpha': 8.434280684493528, 'colsample_bytree': 0.6000000000000001, 'subsample': 0.4, 'learning_rate': 0.0251, 'n_estimators': 830}. Best is trial 57 with value: 0.705471131729757.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_98568\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_98568\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-11-15 06:27:10,808]\u001b[0m Trial 69 finished with value: 0.6909145842267357 and parameters: {'lambda': 0.5401396948092986, 'alpha': 4.734844262392637, 'colsample_bytree': 0.5, 'subsample': 0.4, 'learning_rate': 0.0051, 'n_estimators': 618}. Best is trial 57 with value: 0.705471131729757.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_98568\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_98568\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-11-15 06:27:20,156]\u001b[0m Trial 70 finished with value: 0.7062625238782112 and parameters: {'lambda': 0.003804979794126558, 'alpha': 8.974529989744845, 'colsample_bytree': 0.6000000000000001, 'subsample': 0.4, 'learning_rate': 0.0601, 'n_estimators': 680}. Best is trial 70 with value: 0.7062625238782112.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_98568\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_98568\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-11-15 06:27:29,747]\u001b[0m Trial 71 finished with value: 0.7038821098592646 and parameters: {'lambda': 0.002521957969501266, 'alpha': 9.882222266764378, 'colsample_bytree': 0.6000000000000001, 'subsample': 0.4, 'learning_rate': 0.050100000000000006, 'n_estimators': 690}. Best is trial 70 with value: 0.7062625238782112.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_98568\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_98568\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-11-15 06:27:38,838]\u001b[0m Trial 72 finished with value: 0.7026451210479123 and parameters: {'lambda': 0.0024867471001350293, 'alpha': 9.835071757479584, 'colsample_bytree': 0.6000000000000001, 'subsample': 0.4, 'learning_rate': 0.0551, 'n_estimators': 683}. Best is trial 70 with value: 0.7062625238782112.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_98568\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_98568\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-11-15 06:27:50,228]\u001b[0m Trial 73 finished with value: 0.702913726560368 and parameters: {'lambda': 0.0017769453448696832, 'alpha': 5.329140024025706, 'colsample_bytree': 0.6000000000000001, 'subsample': 0.4, 'learning_rate': 0.0601, 'n_estimators': 659}. Best is trial 70 with value: 0.7062625238782112.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_98568\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_98568\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-11-15 06:28:00,250]\u001b[0m Trial 74 finished with value: 0.703170246774005 and parameters: {'lambda': 0.010967308595234482, 'alpha': 7.32235593999692, 'colsample_bytree': 0.6000000000000001, 'subsample': 0.4, 'learning_rate': 0.0451, 'n_estimators': 570}. Best is trial 70 with value: 0.7062625238782112.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_98568\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_98568\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-11-15 06:28:12,785]\u001b[0m Trial 75 finished with value: 0.7027379049549726 and parameters: {'lambda': 0.00605441565073284, 'alpha': 3.7545138837734644, 'colsample_bytree': 0.7, 'subsample': 0.4, 'learning_rate': 0.07010000000000001, 'n_estimators': 618}. Best is trial 70 with value: 0.7062625238782112.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_98568\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_98568\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-11-15 06:28:26,726]\u001b[0m Trial 76 finished with value: 0.7013289930217144 and parameters: {'lambda': 0.0010557952284797971, 'alpha': 5.223031192068556, 'colsample_bytree': 0.6000000000000001, 'subsample': 0.8, 'learning_rate': 0.0601, 'n_estimators': 707}. Best is trial 70 with value: 0.7062625238782112.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_98568\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_98568\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-11-15 06:28:45,691]\u001b[0m Trial 77 finished with value: 0.7046816888230478 and parameters: {'lambda': 0.0043128772325057305, 'alpha': 3.143612265642668, 'colsample_bytree': 0.7, 'subsample': 0.4, 'learning_rate': 0.035100000000000006, 'n_estimators': 764}. Best is trial 70 with value: 0.7062625238782112.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_98568\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_98568\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-11-15 06:29:00,176]\u001b[0m Trial 78 finished with value: 0.6962087248060504 and parameters: {'lambda': 0.004652321971013198, 'alpha': 2.7521082174870157, 'colsample_bytree': 0.7, 'subsample': 0.9, 'learning_rate': 0.035100000000000006, 'n_estimators': 407}. Best is trial 70 with value: 0.7062625238782112.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_98568\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_98568\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-11-15 06:29:18,009]\u001b[0m Trial 79 finished with value: 0.7000050680285369 and parameters: {'lambda': 0.004236912784945951, 'alpha': 1.7981933776105528, 'colsample_bytree': 0.5, 'subsample': 0.5, 'learning_rate': 0.0201, 'n_estimators': 762}. Best is trial 70 with value: 0.7062625238782112.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_98568\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_98568\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-11-15 06:29:33,486]\u001b[0m Trial 80 finished with value: 0.6988585240341507 and parameters: {'lambda': 0.018819226862219034, 'alpha': 0.01399576367624882, 'colsample_bytree': 0.5, 'subsample': 0.4, 'learning_rate': 0.015099999999999999, 'n_estimators': 816}. Best is trial 70 with value: 0.7062625238782112.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_98568\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_98568\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-11-15 06:29:43,719]\u001b[0m Trial 81 finished with value: 0.7029117773186229 and parameters: {'lambda': 0.002334728540326845, 'alpha': 5.817805934521893, 'colsample_bytree': 0.6000000000000001, 'subsample': 0.4, 'learning_rate': 0.040100000000000004, 'n_estimators': 528}. Best is trial 70 with value: 0.7062625238782112.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_98568\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_98568\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-11-15 06:29:55,350]\u001b[0m Trial 82 finished with value: 0.7065241121203851 and parameters: {'lambda': 0.0014120707067339939, 'alpha': 8.030994366953419, 'colsample_bytree': 0.6000000000000001, 'subsample': 0.4, 'learning_rate': 0.0751, 'n_estimators': 978}. Best is trial 82 with value: 0.7065241121203851.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_98568\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_98568\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-11-15 06:30:09,258]\u001b[0m Trial 83 finished with value: 0.7037947838290904 and parameters: {'lambda': 0.0017416354053875942, 'alpha': 7.501558860420587, 'colsample_bytree': 0.7, 'subsample': 0.4, 'learning_rate': 0.0751, 'n_estimators': 989}. Best is trial 82 with value: 0.7065241121203851.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_98568\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_98568\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-11-15 06:30:29,847]\u001b[0m Trial 84 finished with value: 0.7002666562707105 and parameters: {'lambda': 0.011041466461012542, 'alpha': 3.5101373982847366, 'colsample_bytree': 1.0, 'subsample': 0.5, 'learning_rate': 0.0951, 'n_estimators': 913}. Best is trial 82 with value: 0.7065241121203851.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_98568\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_98568\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-11-15 06:30:44,340]\u001b[0m Trial 85 finished with value: 0.7037086273439631 and parameters: {'lambda': 0.0013832005940633736, 'alpha': 4.444810400911311, 'colsample_bytree': 0.7, 'subsample': 0.4, 'learning_rate': 0.08510000000000001, 'n_estimators': 939}. Best is trial 82 with value: 0.7065241121203851.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_98568\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_98568\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-11-15 06:30:52,207]\u001b[0m Trial 86 finished with value: 0.7055592374566294 and parameters: {'lambda': 0.028594274601651055, 'alpha': 7.7609131067104755, 'colsample_bytree': 0.6000000000000001, 'subsample': 0.4, 'learning_rate': 0.0651, 'n_estimators': 479}. Best is trial 82 with value: 0.7065241121203851.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_98568\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_98568\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-11-15 06:31:01,584]\u001b[0m Trial 87 finished with value: 0.6929425753381934 and parameters: {'lambda': 0.0031450089859199697, 'alpha': 0.08301824924019259, 'colsample_bytree': 0.6000000000000001, 'subsample': 0.4, 'learning_rate': 0.0651, 'n_estimators': 477}. Best is trial 82 with value: 0.7065241121203851.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_98568\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_98568\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-11-15 06:31:06,513]\u001b[0m Trial 88 finished with value: 0.7005364313282135 and parameters: {'lambda': 0.04768323163624848, 'alpha': 8.155432489498711, 'colsample_bytree': 0.5, 'subsample': 0.4, 'learning_rate': 0.0801, 'n_estimators': 321}. Best is trial 82 with value: 0.7065241121203851.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_98568\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_98568\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-11-15 06:31:23,120]\u001b[0m Trial 89 finished with value: 0.7048520525515574 and parameters: {'lambda': 0.02781101148457406, 'alpha': 2.9387935145396753, 'colsample_bytree': 0.6000000000000001, 'subsample': 0.4, 'learning_rate': 0.050100000000000006, 'n_estimators': 893}. Best is trial 82 with value: 0.7065241121203851.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_98568\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_98568\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-11-15 06:31:39,819]\u001b[0m Trial 90 finished with value: 0.7003582706327238 and parameters: {'lambda': 0.0338549305872104, 'alpha': 3.111066993013133, 'colsample_bytree': 0.6000000000000001, 'subsample': 0.4, 'learning_rate': 0.050100000000000006, 'n_estimators': 931}. Best is trial 82 with value: 0.7065241121203851.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_98568\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_98568\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-11-15 06:31:54,010]\u001b[0m Trial 91 finished with value: 0.7025558457759931 and parameters: {'lambda': 0.08500251705250197, 'alpha': 5.846865624920541, 'colsample_bytree': 0.6000000000000001, 'subsample': 0.4, 'learning_rate': 0.0601, 'n_estimators': 902}. Best is trial 82 with value: 0.7065241121203851.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_98568\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_98568\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-11-15 06:32:09,655]\u001b[0m Trial 92 finished with value: 0.7040591010097071 and parameters: {'lambda': 0.006465863138986464, 'alpha': 2.2321120894845783, 'colsample_bytree': 0.6000000000000001, 'subsample': 0.4, 'learning_rate': 0.07010000000000001, 'n_estimators': 855}. Best is trial 82 with value: 0.7065241121203851.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_98568\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_98568\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-11-15 06:32:23,636]\u001b[0m Trial 93 finished with value: 0.7020330591399946 and parameters: {'lambda': 0.008448408129462376, 'alpha': 4.160940927423135, 'colsample_bytree': 0.6000000000000001, 'subsample': 0.4, 'learning_rate': 0.07010000000000001, 'n_estimators': 897}. Best is trial 82 with value: 0.7065241121203851.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_98568\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_98568\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-11-15 06:32:36,808]\u001b[0m Trial 94 finished with value: 0.7036150637402051 and parameters: {'lambda': 0.004796841308642991, 'alpha': 7.939636314172396, 'colsample_bytree': 0.6000000000000001, 'subsample': 0.4, 'learning_rate': 0.040100000000000004, 'n_estimators': 857}. Best is trial 82 with value: 0.7065241121203851.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_98568\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_98568\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-11-15 06:32:56,941]\u001b[0m Trial 95 finished with value: 0.7028267903785427 and parameters: {'lambda': 0.029148243770607984, 'alpha': 2.1864045155281415, 'colsample_bytree': 0.7, 'subsample': 0.4, 'learning_rate': 0.0551, 'n_estimators': 970}. Best is trial 82 with value: 0.7065241121203851.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_98568\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_98568\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-11-15 06:33:10,236]\u001b[0m Trial 96 finished with value: 0.7048489337647653 and parameters: {'lambda': 0.014690862668075505, 'alpha': 5.144390668386542, 'colsample_bytree': 0.5, 'subsample': 0.4, 'learning_rate': 0.0651, 'n_estimators': 976}. Best is trial 82 with value: 0.7065241121203851.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_98568\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_98568\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-11-15 06:33:24,844]\u001b[0m Trial 97 finished with value: 0.7045019687341623 and parameters: {'lambda': 0.01445439723571072, 'alpha': 5.549230254263537, 'colsample_bytree': 0.5, 'subsample': 0.4, 'learning_rate': 0.0451, 'n_estimators': 999}. Best is trial 82 with value: 0.7065241121203851.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_98568\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_98568\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-11-15 06:33:39,058]\u001b[0m Trial 98 finished with value: 0.70150481462711 and parameters: {'lambda': 0.016096512301029424, 'alpha': 5.792931793945786, 'colsample_bytree': 0.5, 'subsample': 0.4, 'learning_rate': 0.0451, 'n_estimators': 989}. Best is trial 82 with value: 0.7065241121203851.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_98568\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_98568\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-11-15 06:33:52,911]\u001b[0m Trial 99 finished with value: 0.7041491559783245 and parameters: {'lambda': 0.02405384877395033, 'alpha': 4.805143524167407, 'colsample_bytree': 0.5, 'subsample': 0.4, 'learning_rate': 0.0651, 'n_estimators': 961}. Best is trial 82 with value: 0.7065241121203851.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "#Tuning hyperparameters\n",
    "#Step 1. Define an objective function to be maximized.\n",
    "def objective(trial):\n",
    "    param = {\n",
    "        'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
    "        'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
    "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.3,1.0,step=0.1),\n",
    "        'subsample': trial.suggest_float('subsample', 0.4, 1.0, step=0.1),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.0001, 0.2, step=0.005),\n",
    "        'n_estimators': trial.suggest_int(\"n_estimators\",50,1000,1)\n",
    "        #'min_child_weight': trial.suggest_int('min_child_weight', 1, 300),\n",
    "    }\n",
    "    model = xgb.XGBClassifier(**param,random_state=1,n_jobs=8)\n",
    "\n",
    " \n",
    "# Step 2: Scoring method:\n",
    "    score = model_selection.cross_val_score(model, X, y, n_jobs=8, scoring=\"accuracy\",cv=Cv_optuna)\n",
    "    accuracy = score.mean()\n",
    "    return accuracy\n",
    "\n",
    "# Step 3: Running it\n",
    "study = optuna.create_study(direction=\"maximize\",sampler=optuna.samplers.TPESampler(seed=0))\n",
    "study.optimize(objective, n_trials=100, show_progress_bar=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "b2be4542-3f0e-438f-8e41-c67d96410fab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best parameters are : \n",
      "{'lambda': 0.0014120707067339939, 'alpha': 8.030994366953419, 'colsample_bytree': 0.6000000000000001, 'subsample': 0.4, 'learning_rate': 0.0751, 'n_estimators': 978}\n"
     ]
    }
   ],
   "source": [
    "# Getting the best parameters:\n",
    "print(f\"The best parameters are : \\n{study.best_params}\")\n",
    "# Setting the best model\n",
    "clf=xgb.XGBClassifier(alpha = study.best_params['alpha']\n",
    "              ,colsample_bytree = study.best_params['colsample_bytree']\n",
    "              ,subsample = study.best_params['subsample']\n",
    "              ,n_estimators = study.best_params['n_estimators']\n",
    "              ,learning_rate= study.best_params['learning_rate'], n_jobs=8\n",
    "              ,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "d0687ace-1f1a-44a0-9329-fc50b681ff53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mean</th>\n",
       "      <th>Se</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Accuracy_test</th>\n",
       "      <td>0.705466</td>\n",
       "      <td>0.003962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Accuracy_train</th>\n",
       "      <td>0.966755</td>\n",
       "      <td>0.000557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1 Score</th>\n",
       "      <td>0.703966</td>\n",
       "      <td>0.004165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Precision</th>\n",
       "      <td>0.708131</td>\n",
       "      <td>0.004632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recall</th>\n",
       "      <td>0.701217</td>\n",
       "      <td>0.005744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Roc_auc</th>\n",
       "      <td>0.777842</td>\n",
       "      <td>0.003955</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Mean        Se\n",
       "Accuracy_test   0.705466  0.003962\n",
       "Accuracy_train  0.966755  0.000557\n",
       "F1 Score        0.703966  0.004165\n",
       "Precision       0.708131  0.004632\n",
       "Recall          0.701217  0.005744\n",
       "Roc_auc         0.777842  0.003955"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Model2\n",
    "Model2=Model_results(clf,X,y,Cv_model)\n",
    "Model2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "0bb46026-eb5e-4693-8e81-0a0a2ed16564",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th>Method</th>\n",
       "      <th colspan=\"4\" halign=\"left\">XGB</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model</th>\n",
       "      <th colspan=\"2\" halign=\"left\">Model 1</th>\n",
       "      <th colspan=\"2\" halign=\"left\">Model 2</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Values</th>\n",
       "      <th>Mean</th>\n",
       "      <th>Se</th>\n",
       "      <th>Mean</th>\n",
       "      <th>Se</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Accuracy_test</th>\n",
       "      <td>0.688091</td>\n",
       "      <td>0.004008</td>\n",
       "      <td>0.705466</td>\n",
       "      <td>0.003962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Accuracy_train</th>\n",
       "      <td>0.999317</td>\n",
       "      <td>0.000076</td>\n",
       "      <td>0.966755</td>\n",
       "      <td>0.000557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1 Score</th>\n",
       "      <td>0.685420</td>\n",
       "      <td>0.004215</td>\n",
       "      <td>0.703966</td>\n",
       "      <td>0.004165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Precision</th>\n",
       "      <td>0.691997</td>\n",
       "      <td>0.004584</td>\n",
       "      <td>0.708131</td>\n",
       "      <td>0.004632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recall</th>\n",
       "      <td>0.680587</td>\n",
       "      <td>0.006059</td>\n",
       "      <td>0.701217</td>\n",
       "      <td>0.005744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Roc_auc</th>\n",
       "      <td>0.756918</td>\n",
       "      <td>0.004106</td>\n",
       "      <td>0.777842</td>\n",
       "      <td>0.003955</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Method               XGB                              \n",
       "Model            Model 1             Model 2          \n",
       "Values              Mean        Se      Mean        Se\n",
       "Accuracy_test   0.688091  0.004008  0.705466  0.003962\n",
       "Accuracy_train  0.999317  0.000076  0.966755  0.000557\n",
       "F1 Score        0.685420  0.004215  0.703966  0.004165\n",
       "Precision       0.691997  0.004584  0.708131  0.004632\n",
       "Recall          0.680587  0.006059  0.701217  0.005744\n",
       "Roc_auc         0.756918  0.004106  0.777842  0.003955"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Saving the data of model performance\n",
    "Model_data=pd.concat([Model1,Model2],axis=1)\n",
    "Model_data.columns = [['XGB']*4,['Model 1','Model 1', 'Model 2','Model 2'], ['Mean', 'Se', 'Mean', 'Se']]  \n",
    "Model_data.columns.names=['Method','Model','Values']\n",
    "Model_data.to_csv(\"./XGB_model_lasso_data.csv\",sep=',')\n",
    "Model_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "208fbfd4-b156-43fb-b7b8-5f38ee0e24ef",
   "metadata": {},
   "source": [
    "# 2. MLREM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "45019f5e-5468-4d1b-a4de-8b8c86e33654",
   "metadata": {},
   "outputs": [],
   "source": [
    "col_data= pd.read_csv(\"./Results/MLREM_col.csv\",header=0,index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "f6d91ba6-9049-4060-818a-8cf59d7a47b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MW</th>\n",
       "      <th>D/Dtr09</th>\n",
       "      <th>ZM1MulPer</th>\n",
       "      <th>ECC</th>\n",
       "      <th>CENT</th>\n",
       "      <th>SMTI</th>\n",
       "      <th>SMTIV</th>\n",
       "      <th>GMTIV</th>\n",
       "      <th>Wap</th>\n",
       "      <th>IDMT</th>\n",
       "      <th>...</th>\n",
       "      <th>ATSC5s</th>\n",
       "      <th>P_VSA_MR_3</th>\n",
       "      <th>P_VSA_ppp_ar</th>\n",
       "      <th>P_VSA_ppp_con</th>\n",
       "      <th>P_VSA_charge_2</th>\n",
       "      <th>SM15_EA(ed)</th>\n",
       "      <th>T(O..Br)</th>\n",
       "      <th>TPSA(Tot)</th>\n",
       "      <th>SAdon</th>\n",
       "      <th>Vx</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Ma_2019_A</th>\n",
       "      <td>267.28</td>\n",
       "      <td>66.871159</td>\n",
       "      <td>348.869542</td>\n",
       "      <td>135.0</td>\n",
       "      <td>383.0</td>\n",
       "      <td>2886.0</td>\n",
       "      <td>5576.0</td>\n",
       "      <td>10547.0</td>\n",
       "      <td>5729.0</td>\n",
       "      <td>4739.692713</td>\n",
       "      <td>...</td>\n",
       "      <td>90.763661</td>\n",
       "      <td>139.049917</td>\n",
       "      <td>75.680233</td>\n",
       "      <td>63.202194</td>\n",
       "      <td>1.899093</td>\n",
       "      <td>36.892542</td>\n",
       "      <td>0.0</td>\n",
       "      <td>139.54</td>\n",
       "      <td>160.947217</td>\n",
       "      <td>291.295681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ma_2019_U</th>\n",
       "      <td>244.23</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>340.039426</td>\n",
       "      <td>118.0</td>\n",
       "      <td>295.0</td>\n",
       "      <td>2084.0</td>\n",
       "      <td>4432.0</td>\n",
       "      <td>8734.0</td>\n",
       "      <td>2194.0</td>\n",
       "      <td>3416.557603</td>\n",
       "      <td>...</td>\n",
       "      <td>139.839496</td>\n",
       "      <td>139.049917</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>48.373245</td>\n",
       "      <td>46.279992</td>\n",
       "      <td>36.205320</td>\n",
       "      <td>0.0</td>\n",
       "      <td>124.78</td>\n",
       "      <td>146.060780</td>\n",
       "      <td>262.840532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ma_2019_C</th>\n",
       "      <td>243.25</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>319.988367</td>\n",
       "      <td>118.0</td>\n",
       "      <td>295.0</td>\n",
       "      <td>2084.0</td>\n",
       "      <td>4240.0</td>\n",
       "      <td>7972.0</td>\n",
       "      <td>2194.0</td>\n",
       "      <td>3416.557603</td>\n",
       "      <td>...</td>\n",
       "      <td>137.031903</td>\n",
       "      <td>139.049917</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>67.057867</td>\n",
       "      <td>3.124314</td>\n",
       "      <td>36.205320</td>\n",
       "      <td>0.0</td>\n",
       "      <td>130.83</td>\n",
       "      <td>160.947217</td>\n",
       "      <td>269.667774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ma_2019_G</th>\n",
       "      <td>283.28</td>\n",
       "      <td>71.547747</td>\n",
       "      <td>387.546658</td>\n",
       "      <td>144.0</td>\n",
       "      <td>446.0</td>\n",
       "      <td>3270.0</td>\n",
       "      <td>6542.0</td>\n",
       "      <td>12768.0</td>\n",
       "      <td>6578.0</td>\n",
       "      <td>5547.544286</td>\n",
       "      <td>...</td>\n",
       "      <td>117.471961</td>\n",
       "      <td>139.049917</td>\n",
       "      <td>32.387883</td>\n",
       "      <td>80.922082</td>\n",
       "      <td>45.054770</td>\n",
       "      <td>36.939118</td>\n",
       "      <td>0.0</td>\n",
       "      <td>159.51</td>\n",
       "      <td>178.957968</td>\n",
       "      <td>301.046512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ma_2019_dA</th>\n",
       "      <td>251.28</td>\n",
       "      <td>63.146800</td>\n",
       "      <td>315.599992</td>\n",
       "      <td>128.0</td>\n",
       "      <td>336.0</td>\n",
       "      <td>2584.0</td>\n",
       "      <td>4822.0</td>\n",
       "      <td>8812.0</td>\n",
       "      <td>5068.0</td>\n",
       "      <td>4099.715332</td>\n",
       "      <td>...</td>\n",
       "      <td>52.221046</td>\n",
       "      <td>96.366574</td>\n",
       "      <td>75.680233</td>\n",
       "      <td>63.202194</td>\n",
       "      <td>1.899093</td>\n",
       "      <td>36.335611</td>\n",
       "      <td>0.0</td>\n",
       "      <td>119.31</td>\n",
       "      <td>118.263874</td>\n",
       "      <td>281.544850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tang_2019_ArabinoC</th>\n",
       "      <td>243.25</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>319.988367</td>\n",
       "      <td>118.0</td>\n",
       "      <td>295.0</td>\n",
       "      <td>2084.0</td>\n",
       "      <td>4240.0</td>\n",
       "      <td>7972.0</td>\n",
       "      <td>2194.0</td>\n",
       "      <td>3416.557603</td>\n",
       "      <td>...</td>\n",
       "      <td>137.031903</td>\n",
       "      <td>139.049917</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>67.057867</td>\n",
       "      <td>3.124314</td>\n",
       "      <td>36.205320</td>\n",
       "      <td>0.0</td>\n",
       "      <td>130.83</td>\n",
       "      <td>160.947217</td>\n",
       "      <td>269.667774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tang_2019_DideoxyC</th>\n",
       "      <td>211.25</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>253.494297</td>\n",
       "      <td>103.0</td>\n",
       "      <td>213.0</td>\n",
       "      <td>1585.0</td>\n",
       "      <td>2963.0</td>\n",
       "      <td>5062.0</td>\n",
       "      <td>1633.0</td>\n",
       "      <td>2398.199373</td>\n",
       "      <td>...</td>\n",
       "      <td>59.519699</td>\n",
       "      <td>53.683231</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>67.057867</td>\n",
       "      <td>3.124314</td>\n",
       "      <td>34.619300</td>\n",
       "      <td>0.0</td>\n",
       "      <td>90.37</td>\n",
       "      <td>75.580531</td>\n",
       "      <td>250.166113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Peters_2014_3</th>\n",
       "      <td>268.26</td>\n",
       "      <td>66.871159</td>\n",
       "      <td>369.000658</td>\n",
       "      <td>135.0</td>\n",
       "      <td>383.0</td>\n",
       "      <td>2886.0</td>\n",
       "      <td>5763.0</td>\n",
       "      <td>11275.0</td>\n",
       "      <td>5729.0</td>\n",
       "      <td>4739.692713</td>\n",
       "      <td>...</td>\n",
       "      <td>100.945467</td>\n",
       "      <td>139.049917</td>\n",
       "      <td>32.387883</td>\n",
       "      <td>87.641582</td>\n",
       "      <td>27.044020</td>\n",
       "      <td>36.892542</td>\n",
       "      <td>0.0</td>\n",
       "      <td>133.49</td>\n",
       "      <td>146.060780</td>\n",
       "      <td>284.468439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Plank_2016_2</th>\n",
       "      <td>393.17</td>\n",
       "      <td>71.547747</td>\n",
       "      <td>412.608258</td>\n",
       "      <td>144.0</td>\n",
       "      <td>446.0</td>\n",
       "      <td>3270.0</td>\n",
       "      <td>6760.0</td>\n",
       "      <td>13668.0</td>\n",
       "      <td>6578.0</td>\n",
       "      <td>5547.544286</td>\n",
       "      <td>...</td>\n",
       "      <td>73.852917</td>\n",
       "      <td>96.366574</td>\n",
       "      <td>32.387883</td>\n",
       "      <td>80.922082</td>\n",
       "      <td>45.054770</td>\n",
       "      <td>36.939118</td>\n",
       "      <td>0.0</td>\n",
       "      <td>139.28</td>\n",
       "      <td>136.274624</td>\n",
       "      <td>334.202658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Du2021_L_G</th>\n",
       "      <td>283.28</td>\n",
       "      <td>71.547747</td>\n",
       "      <td>387.546658</td>\n",
       "      <td>144.0</td>\n",
       "      <td>446.0</td>\n",
       "      <td>3270.0</td>\n",
       "      <td>6542.0</td>\n",
       "      <td>12768.0</td>\n",
       "      <td>6578.0</td>\n",
       "      <td>5547.544286</td>\n",
       "      <td>...</td>\n",
       "      <td>117.471961</td>\n",
       "      <td>139.049917</td>\n",
       "      <td>32.387883</td>\n",
       "      <td>80.922082</td>\n",
       "      <td>45.054770</td>\n",
       "      <td>36.939118</td>\n",
       "      <td>0.0</td>\n",
       "      <td>159.51</td>\n",
       "      <td>178.957968</td>\n",
       "      <td>301.046512</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>71 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        MW    D/Dtr09   ZM1MulPer    ECC   CENT    SMTI  \\\n",
       "ID                                                                        \n",
       "Ma_2019_A           267.28  66.871159  348.869542  135.0  383.0  2886.0   \n",
       "Ma_2019_U           244.23   0.000000  340.039426  118.0  295.0  2084.0   \n",
       "Ma_2019_C           243.25   0.000000  319.988367  118.0  295.0  2084.0   \n",
       "Ma_2019_G           283.28  71.547747  387.546658  144.0  446.0  3270.0   \n",
       "Ma_2019_dA          251.28  63.146800  315.599992  128.0  336.0  2584.0   \n",
       "...                    ...        ...         ...    ...    ...     ...   \n",
       "Tang_2019_ArabinoC  243.25   0.000000  319.988367  118.0  295.0  2084.0   \n",
       "Tang_2019_DideoxyC  211.25   0.000000  253.494297  103.0  213.0  1585.0   \n",
       "Peters_2014_3       268.26  66.871159  369.000658  135.0  383.0  2886.0   \n",
       "Plank_2016_2        393.17  71.547747  412.608258  144.0  446.0  3270.0   \n",
       "Du2021_L_G          283.28  71.547747  387.546658  144.0  446.0  3270.0   \n",
       "\n",
       "                     SMTIV    GMTIV     Wap         IDMT  ...      ATSC5s  \\\n",
       "ID                                                        ...               \n",
       "Ma_2019_A           5576.0  10547.0  5729.0  4739.692713  ...   90.763661   \n",
       "Ma_2019_U           4432.0   8734.0  2194.0  3416.557603  ...  139.839496   \n",
       "Ma_2019_C           4240.0   7972.0  2194.0  3416.557603  ...  137.031903   \n",
       "Ma_2019_G           6542.0  12768.0  6578.0  5547.544286  ...  117.471961   \n",
       "Ma_2019_dA          4822.0   8812.0  5068.0  4099.715332  ...   52.221046   \n",
       "...                    ...      ...     ...          ...  ...         ...   \n",
       "Tang_2019_ArabinoC  4240.0   7972.0  2194.0  3416.557603  ...  137.031903   \n",
       "Tang_2019_DideoxyC  2963.0   5062.0  1633.0  2398.199373  ...   59.519699   \n",
       "Peters_2014_3       5763.0  11275.0  5729.0  4739.692713  ...  100.945467   \n",
       "Plank_2016_2        6760.0  13668.0  6578.0  5547.544286  ...   73.852917   \n",
       "Du2021_L_G          6542.0  12768.0  6578.0  5547.544286  ...  117.471961   \n",
       "\n",
       "                    P_VSA_MR_3  P_VSA_ppp_ar  P_VSA_ppp_con  P_VSA_charge_2  \\\n",
       "ID                                                                            \n",
       "Ma_2019_A           139.049917     75.680233      63.202194        1.899093   \n",
       "Ma_2019_U           139.049917      0.000000      48.373245       46.279992   \n",
       "Ma_2019_C           139.049917      0.000000      67.057867        3.124314   \n",
       "Ma_2019_G           139.049917     32.387883      80.922082       45.054770   \n",
       "Ma_2019_dA           96.366574     75.680233      63.202194        1.899093   \n",
       "...                        ...           ...            ...             ...   \n",
       "Tang_2019_ArabinoC  139.049917      0.000000      67.057867        3.124314   \n",
       "Tang_2019_DideoxyC   53.683231      0.000000      67.057867        3.124314   \n",
       "Peters_2014_3       139.049917     32.387883      87.641582       27.044020   \n",
       "Plank_2016_2         96.366574     32.387883      80.922082       45.054770   \n",
       "Du2021_L_G          139.049917     32.387883      80.922082       45.054770   \n",
       "\n",
       "                    SM15_EA(ed)  T(O..Br)  TPSA(Tot)       SAdon          Vx  \n",
       "ID                                                                            \n",
       "Ma_2019_A             36.892542       0.0     139.54  160.947217  291.295681  \n",
       "Ma_2019_U             36.205320       0.0     124.78  146.060780  262.840532  \n",
       "Ma_2019_C             36.205320       0.0     130.83  160.947217  269.667774  \n",
       "Ma_2019_G             36.939118       0.0     159.51  178.957968  301.046512  \n",
       "Ma_2019_dA            36.335611       0.0     119.31  118.263874  281.544850  \n",
       "...                         ...       ...        ...         ...         ...  \n",
       "Tang_2019_ArabinoC    36.205320       0.0     130.83  160.947217  269.667774  \n",
       "Tang_2019_DideoxyC    34.619300       0.0      90.37   75.580531  250.166113  \n",
       "Peters_2014_3         36.892542       0.0     133.49  146.060780  284.468439  \n",
       "Plank_2016_2          36.939118       0.0     139.28  136.274624  334.202658  \n",
       "Du2021_L_G            36.939118       0.0     159.51  178.957968  301.046512  \n",
       "\n",
       "[71 rows x 28 columns]"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MRLEM_data=X_NAomit_data[col_data.index]\n",
    "MRLEM_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "6d8bf42e-2223-4c7b-9bd2-7c2787032802",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MW</th>\n",
       "      <th>D/Dtr09</th>\n",
       "      <th>ZM1MulPer</th>\n",
       "      <th>ECC</th>\n",
       "      <th>CENT</th>\n",
       "      <th>SMTI</th>\n",
       "      <th>SMTIV</th>\n",
       "      <th>GMTIV</th>\n",
       "      <th>Wap</th>\n",
       "      <th>IDMT</th>\n",
       "      <th>...</th>\n",
       "      <th>ATSC5s</th>\n",
       "      <th>P_VSA_MR_3</th>\n",
       "      <th>P_VSA_ppp_ar</th>\n",
       "      <th>P_VSA_ppp_con</th>\n",
       "      <th>P_VSA_charge_2</th>\n",
       "      <th>SM15_EA(ed)</th>\n",
       "      <th>T(O..Br)</th>\n",
       "      <th>TPSA(Tot)</th>\n",
       "      <th>SAdon</th>\n",
       "      <th>Vx</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Ma_2019_A</th>\n",
       "      <td>0.128645</td>\n",
       "      <td>0.181294</td>\n",
       "      <td>0.193207</td>\n",
       "      <td>0.036281</td>\n",
       "      <td>0.026667</td>\n",
       "      <td>0.030815</td>\n",
       "      <td>0.037803</td>\n",
       "      <td>0.044265</td>\n",
       "      <td>0.024087</td>\n",
       "      <td>0.024617</td>\n",
       "      <td>...</td>\n",
       "      <td>0.176802</td>\n",
       "      <td>0.999046</td>\n",
       "      <td>0.285905</td>\n",
       "      <td>0.104723</td>\n",
       "      <td>0.015761</td>\n",
       "      <td>0.446054</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.472652</td>\n",
       "      <td>0.769847</td>\n",
       "      <td>0.069993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ma_2019_U</th>\n",
       "      <td>0.075722</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.175319</td>\n",
       "      <td>0.017007</td>\n",
       "      <td>0.012863</td>\n",
       "      <td>0.011819</td>\n",
       "      <td>0.021252</td>\n",
       "      <td>0.029633</td>\n",
       "      <td>0.003299</td>\n",
       "      <td>0.010706</td>\n",
       "      <td>...</td>\n",
       "      <td>0.401921</td>\n",
       "      <td>0.999046</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.031193</td>\n",
       "      <td>0.384100</td>\n",
       "      <td>0.311208</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.330770</td>\n",
       "      <td>0.665700</td>\n",
       "      <td>0.021569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ma_2019_C</th>\n",
       "      <td>0.073472</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.134701</td>\n",
       "      <td>0.017007</td>\n",
       "      <td>0.012863</td>\n",
       "      <td>0.011819</td>\n",
       "      <td>0.018475</td>\n",
       "      <td>0.023484</td>\n",
       "      <td>0.003299</td>\n",
       "      <td>0.010706</td>\n",
       "      <td>...</td>\n",
       "      <td>0.389042</td>\n",
       "      <td>0.999046</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.123842</td>\n",
       "      <td>0.025930</td>\n",
       "      <td>0.311208</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.388926</td>\n",
       "      <td>0.769847</td>\n",
       "      <td>0.033187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ma_2019_G</th>\n",
       "      <td>0.165381</td>\n",
       "      <td>0.193972</td>\n",
       "      <td>0.271557</td>\n",
       "      <td>0.046485</td>\n",
       "      <td>0.036549</td>\n",
       "      <td>0.039910</td>\n",
       "      <td>0.051778</td>\n",
       "      <td>0.062188</td>\n",
       "      <td>0.029080</td>\n",
       "      <td>0.033111</td>\n",
       "      <td>...</td>\n",
       "      <td>0.299317</td>\n",
       "      <td>0.999046</td>\n",
       "      <td>0.122355</td>\n",
       "      <td>0.192589</td>\n",
       "      <td>0.373931</td>\n",
       "      <td>0.455193</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.664616</td>\n",
       "      <td>0.895853</td>\n",
       "      <td>0.086587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ma_2019_dA</th>\n",
       "      <td>0.091909</td>\n",
       "      <td>0.171197</td>\n",
       "      <td>0.125811</td>\n",
       "      <td>0.028345</td>\n",
       "      <td>0.019294</td>\n",
       "      <td>0.023662</td>\n",
       "      <td>0.026894</td>\n",
       "      <td>0.030263</td>\n",
       "      <td>0.020200</td>\n",
       "      <td>0.017889</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.666030</td>\n",
       "      <td>0.285905</td>\n",
       "      <td>0.104723</td>\n",
       "      <td>0.015761</td>\n",
       "      <td>0.336774</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.278189</td>\n",
       "      <td>0.471230</td>\n",
       "      <td>0.053399</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  MW   D/Dtr09  ZM1MulPer       ECC      CENT      SMTI  \\\n",
       "ID                                                                        \n",
       "Ma_2019_A   0.128645  0.181294   0.193207  0.036281  0.026667  0.030815   \n",
       "Ma_2019_U   0.075722  0.000000   0.175319  0.017007  0.012863  0.011819   \n",
       "Ma_2019_C   0.073472  0.000000   0.134701  0.017007  0.012863  0.011819   \n",
       "Ma_2019_G   0.165381  0.193972   0.271557  0.046485  0.036549  0.039910   \n",
       "Ma_2019_dA  0.091909  0.171197   0.125811  0.028345  0.019294  0.023662   \n",
       "\n",
       "               SMTIV     GMTIV       Wap      IDMT  ...    ATSC5s  P_VSA_MR_3  \\\n",
       "ID                                                  ...                         \n",
       "Ma_2019_A   0.037803  0.044265  0.024087  0.024617  ...  0.176802    0.999046   \n",
       "Ma_2019_U   0.021252  0.029633  0.003299  0.010706  ...  0.401921    0.999046   \n",
       "Ma_2019_C   0.018475  0.023484  0.003299  0.010706  ...  0.389042    0.999046   \n",
       "Ma_2019_G   0.051778  0.062188  0.029080  0.033111  ...  0.299317    0.999046   \n",
       "Ma_2019_dA  0.026894  0.030263  0.020200  0.017889  ...  0.000000    0.666030   \n",
       "\n",
       "            P_VSA_ppp_ar  P_VSA_ppp_con  P_VSA_charge_2  SM15_EA(ed)  \\\n",
       "ID                                                                     \n",
       "Ma_2019_A       0.285905       0.104723        0.015761     0.446054   \n",
       "Ma_2019_U       0.000000       0.031193        0.384100     0.311208   \n",
       "Ma_2019_C       0.000000       0.123842        0.025930     0.311208   \n",
       "Ma_2019_G       0.122355       0.192589        0.373931     0.455193   \n",
       "Ma_2019_dA      0.285905       0.104723        0.015761     0.336774   \n",
       "\n",
       "            T(O..Br)  TPSA(Tot)     SAdon        Vx  \n",
       "ID                                                   \n",
       "Ma_2019_A        0.0   0.472652  0.769847  0.069993  \n",
       "Ma_2019_U        0.0   0.330770  0.665700  0.021569  \n",
       "Ma_2019_C        0.0   0.388926  0.769847  0.033187  \n",
       "Ma_2019_G        0.0   0.664616  0.895853  0.086587  \n",
       "Ma_2019_dA       0.0   0.278189  0.471230  0.053399  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Scale data\n",
    "Scaler = preprocessing.MinMaxScaler() #StandardScaler\n",
    "Transformer =Scaler.fit(MRLEM_data)\n",
    "X_scaled_data=Transformer.transform(MRLEM_data)\n",
    "X_scaled_data =pd.DataFrame(X_scaled_data)\n",
    "X_scaled_data.columns=MRLEM_data.columns\n",
    "X_scaled_data.index=Raw_data.index\n",
    "X_scaled_data.to_csv(\"./Original data/MRLEM_data_X_scaled_data.csv\",sep=',',header=1,index=1)\n",
    "joblib.dump(Transformer, './Models/MRLEM_data_Scaler_transformer.pkl')\n",
    "\n",
    "X_scaled_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "c5eb8b75-76bc-4fcb-aad5-6762048df1c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Model_results(Model_clf,X_test,y,Cv_model):\n",
    "    Model_scores= cross_validate(estimator=Model_clf, X=X_test, y=y, cv=Cv_model,scoring=( 'accuracy','f1','precision','recall','roc_auc'), return_train_score=True)\n",
    "    Model_score= cross_validate(estimator=Model_clf, X=X_test, y=y, cv=Cv_model,scoring=( 'accuracy','f1','precision','recall','roc_auc'), return_train_score=False)\n",
    "#Accuracy\n",
    "    Model_Accuracy_test_mean=Model_scores['test_accuracy'].mean()\n",
    "    Model_Accuracy_test_se=(Model_scores['test_accuracy'].std()/math.sqrt(len(Model_scores['test_accuracy']))) \n",
    "    Model_Accuracy_train_mean=Model_scores['train_accuracy'].mean()\n",
    "    Model_Accuracy_train_se=(Model_scores['train_accuracy'].std()/math.sqrt(len(Model_scores['train_accuracy']))) \n",
    "#f1\n",
    "    Model_f1_mean=Model_score['test_f1'].mean()\n",
    "    Model_f1_se=(Model_score['test_f1'].std()/math.sqrt(len(Model_score['test_f1']))) \n",
    "#precision\n",
    "    Model_precision_mean=Model_score['test_precision'].mean()\n",
    "    Model_precision_se=(Model_score['test_precision'].std()/math.sqrt(len(Model_score['test_precision']))) \n",
    "#recall\n",
    "    Model_recall_mean=Model_score['test_recall'].mean()\n",
    "    Model_recall_se=(Model_score['test_recall'].std()/math.sqrt(len(Model_score['test_recall']))) \n",
    "#roc_auc\n",
    "    Model_roc_auc_mean=Model_score['test_roc_auc'].mean()\n",
    "    Model_roc_auc_se=(Model_score['test_roc_auc'].std()/math.sqrt(len(Model_score['test_roc_auc']))) \n",
    "    Model = {'Mean':[Model_Accuracy_test_mean,Model_Accuracy_train_mean,Model_f1_mean,Model_precision_mean,Model_recall_mean,Model_roc_auc_mean],\n",
    "        'Se':[Model_Accuracy_test_se,Model_Accuracy_train_se,Model_f1_se,Model_precision_se,Model_recall_se,Model_roc_auc_se]}\n",
    "    Model = pd.DataFrame(Model, index=['Accuracy_test','Accuracy_train','F1 Score','Precision','Recall','Roc_auc'])\n",
    "    return Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "43024221-dcb1-4c20-a862-8ba15cc4978a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setting the KFold \n",
    "Cv_optuna= RepeatedStratifiedKFold(n_splits=5, n_repeats=10, random_state=0)\n",
    "Cv_model= RepeatedStratifiedKFold(n_splits=5, n_repeats=10, random_state=0)\n",
    "Cv_RFECV= RepeatedStratifiedKFold(n_splits=5, n_repeats=10, random_state=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "ef2d9106-5c7e-4daa-89d3-1c228a5ac78a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data pre-processing of models\n",
    "X=np.array(X_scaled_data)\n",
    "y=Raw_data['Hydrogel-forming ability'].values\n",
    "clf=LogisticRegression(solver='liblinear',random_state=0,dual=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48b68d6d-1a1e-439b-aee8-42486486d23e",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 2.1 DT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "74f1bf04-5bde-4d51-bc10-aee4e7d2c583",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf=DecisionTreeClassifier(random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "7c30897c-633f-4a53-96c3-a415fd50308c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mean</th>\n",
       "      <th>Se</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Accuracy_test</th>\n",
       "      <td>0.629333</td>\n",
       "      <td>0.015032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Accuracy_train</th>\n",
       "      <td>0.729981</td>\n",
       "      <td>0.004700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1 Score</th>\n",
       "      <td>0.697627</td>\n",
       "      <td>0.013235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Precision</th>\n",
       "      <td>0.620752</td>\n",
       "      <td>0.011961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recall</th>\n",
       "      <td>0.811071</td>\n",
       "      <td>0.020893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Roc_auc</th>\n",
       "      <td>0.664796</td>\n",
       "      <td>0.020543</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Mean        Se\n",
       "Accuracy_test   0.629333  0.015032\n",
       "Accuracy_train  0.729981  0.004700\n",
       "F1 Score        0.697627  0.013235\n",
       "Precision       0.620752  0.011961\n",
       "Recall          0.811071  0.020893\n",
       "Roc_auc         0.664796  0.020543"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Model1 \n",
    "Model1_clf=clf\n",
    "#Model1\n",
    "Model1=Model_results(Model1_clf,X,y,Cv_model)\n",
    "Model1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "f86a6975-0d73-46e6-9ba4-c3c488b2a565",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2024-01-12 01:29:56,212]\u001b[0m A new study created in memory with name: no-name-6a0b1671-0ec2-4905-98f9-69d2f7e33654\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:29:57,476]\u001b[0m Trial 0 finished with value: 0.6312380952380953 and parameters: {'max_depth': 4, 'max_features': 17, 'min_samples_split': 16}. Best is trial 0 with value: 0.6312380952380953.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:29:57,505]\u001b[0m Trial 1 finished with value: 0.5926666666666667 and parameters: {'max_depth': 4, 'max_features': 14, 'min_samples_split': 17}. Best is trial 0 with value: 0.6312380952380953.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:29:57,530]\u001b[0m Trial 2 finished with value: 0.6375238095238095 and parameters: {'max_depth': 4, 'max_features': 19, 'min_samples_split': 25}. Best is trial 2 with value: 0.6375238095238095.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:29:57,554]\u001b[0m Trial 3 finished with value: 0.6208571428571428 and parameters: {'max_depth': 4, 'max_features': 18, 'min_samples_split': 14}. Best is trial 2 with value: 0.6375238095238095.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:29:57,579]\u001b[0m Trial 4 finished with value: 0.6296190476190476 and parameters: {'max_depth': 4, 'max_features': 20, 'min_samples_split': 3}. Best is trial 2 with value: 0.6375238095238095.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:29:57,600]\u001b[0m Trial 5 finished with value: 0.6120952380952381 and parameters: {'max_depth': 3, 'max_features': 10, 'min_samples_split': 21}. Best is trial 2 with value: 0.6375238095238095.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:29:57,624]\u001b[0m Trial 6 finished with value: 0.6318095238095238 and parameters: {'max_depth': 5, 'max_features': 19, 'min_samples_split': 25}. Best is trial 2 with value: 0.6375238095238095.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:29:57,646]\u001b[0m Trial 7 finished with value: 0.5998095238095238 and parameters: {'max_depth': 5, 'max_features': 15, 'min_samples_split': 20}. Best is trial 2 with value: 0.6375238095238095.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:29:57,666]\u001b[0m Trial 8 finished with value: 0.6439999999999999 and parameters: {'max_depth': 3, 'max_features': 17, 'min_samples_split': 5}. Best is trial 8 with value: 0.6439999999999999.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:29:57,689]\u001b[0m Trial 9 finished with value: 0.6057142857142856 and parameters: {'max_depth': 5, 'max_features': 15, 'min_samples_split': 11}. Best is trial 8 with value: 0.6439999999999999.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:29:57,714]\u001b[0m Trial 10 finished with value: 0.601047619047619 and parameters: {'max_depth': 3, 'max_features': 12, 'min_samples_split': 2}. Best is trial 8 with value: 0.6439999999999999.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:29:57,739]\u001b[0m Trial 11 finished with value: 0.6411428571428571 and parameters: {'max_depth': 3, 'max_features': 17, 'min_samples_split': 8}. Best is trial 8 with value: 0.6439999999999999.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:29:57,765]\u001b[0m Trial 12 finished with value: 0.6411428571428571 and parameters: {'max_depth': 3, 'max_features': 17, 'min_samples_split': 9}. Best is trial 8 with value: 0.6439999999999999.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:29:57,789]\u001b[0m Trial 13 finished with value: 0.6411428571428571 and parameters: {'max_depth': 3, 'max_features': 17, 'min_samples_split': 7}. Best is trial 8 with value: 0.6439999999999999.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:29:57,813]\u001b[0m Trial 14 finished with value: 0.6280952380952382 and parameters: {'max_depth': 3, 'max_features': 13, 'min_samples_split': 6}. Best is trial 8 with value: 0.6439999999999999.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:29:57,838]\u001b[0m Trial 15 finished with value: 0.64 and parameters: {'max_depth': 3, 'max_features': 16, 'min_samples_split': 5}. Best is trial 8 with value: 0.6439999999999999.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:29:57,862]\u001b[0m Trial 16 finished with value: 0.64 and parameters: {'max_depth': 3, 'max_features': 16, 'min_samples_split': 10}. Best is trial 8 with value: 0.6439999999999999.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:29:57,887]\u001b[0m Trial 17 finished with value: 0.6042857142857144 and parameters: {'max_depth': 3, 'max_features': 20, 'min_samples_split': 6}. Best is trial 8 with value: 0.6439999999999999.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:29:57,914]\u001b[0m Trial 18 finished with value: 0.6207619047619047 and parameters: {'max_depth': 4, 'max_features': 18, 'min_samples_split': 12}. Best is trial 8 with value: 0.6439999999999999.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:29:57,939]\u001b[0m Trial 19 finished with value: 0.6295238095238096 and parameters: {'max_depth': 3, 'max_features': 13, 'min_samples_split': 4}. Best is trial 8 with value: 0.6439999999999999.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:29:57,964]\u001b[0m Trial 20 finished with value: 0.6385714285714286 and parameters: {'max_depth': 3, 'max_features': 16, 'min_samples_split': 7}. Best is trial 8 with value: 0.6439999999999999.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:29:57,989]\u001b[0m Trial 21 finished with value: 0.6411428571428571 and parameters: {'max_depth': 3, 'max_features': 17, 'min_samples_split': 9}. Best is trial 8 with value: 0.6439999999999999.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:29:58,013]\u001b[0m Trial 22 finished with value: 0.6111428571428571 and parameters: {'max_depth': 3, 'max_features': 18, 'min_samples_split': 13}. Best is trial 8 with value: 0.6439999999999999.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:29:58,038]\u001b[0m Trial 23 finished with value: 0.6411428571428571 and parameters: {'max_depth': 3, 'max_features': 17, 'min_samples_split': 8}. Best is trial 8 with value: 0.6439999999999999.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:29:58,063]\u001b[0m Trial 24 finished with value: 0.6253333333333333 and parameters: {'max_depth': 3, 'max_features': 19, 'min_samples_split': 9}. Best is trial 8 with value: 0.6439999999999999.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:29:58,088]\u001b[0m Trial 25 finished with value: 0.6405714285714285 and parameters: {'max_depth': 4, 'max_features': 16, 'min_samples_split': 10}. Best is trial 8 with value: 0.6439999999999999.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:29:58,114]\u001b[0m Trial 26 finished with value: 0.6097142857142858 and parameters: {'max_depth': 3, 'max_features': 14, 'min_samples_split': 4}. Best is trial 8 with value: 0.6439999999999999.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:29:58,137]\u001b[0m Trial 27 finished with value: 0.6129523809523809 and parameters: {'max_depth': 3, 'max_features': 15, 'min_samples_split': 6}. Best is trial 8 with value: 0.6439999999999999.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:29:58,163]\u001b[0m Trial 28 finished with value: 0.6222857142857143 and parameters: {'max_depth': 4, 'max_features': 18, 'min_samples_split': 7}. Best is trial 8 with value: 0.6439999999999999.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:29:58,187]\u001b[0m Trial 29 finished with value: 0.6396190476190476 and parameters: {'max_depth': 4, 'max_features': 17, 'min_samples_split': 14}. Best is trial 8 with value: 0.6439999999999999.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:29:58,212]\u001b[0m Trial 30 finished with value: 0.6363809523809524 and parameters: {'max_depth': 3, 'max_features': 19, 'min_samples_split': 16}. Best is trial 8 with value: 0.6439999999999999.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:29:58,237]\u001b[0m Trial 31 finished with value: 0.6411428571428571 and parameters: {'max_depth': 3, 'max_features': 17, 'min_samples_split': 8}. Best is trial 8 with value: 0.6439999999999999.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:29:58,260]\u001b[0m Trial 32 finished with value: 0.6385714285714286 and parameters: {'max_depth': 3, 'max_features': 16, 'min_samples_split': 9}. Best is trial 8 with value: 0.6439999999999999.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:29:58,285]\u001b[0m Trial 33 finished with value: 0.624 and parameters: {'max_depth': 3, 'max_features': 18, 'min_samples_split': 2}. Best is trial 8 with value: 0.6439999999999999.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:29:58,312]\u001b[0m Trial 34 finished with value: 0.6411428571428571 and parameters: {'max_depth': 3, 'max_features': 17, 'min_samples_split': 11}. Best is trial 8 with value: 0.6439999999999999.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:29:58,335]\u001b[0m Trial 35 finished with value: 0.614 and parameters: {'max_depth': 4, 'max_features': 15, 'min_samples_split': 4}. Best is trial 8 with value: 0.6439999999999999.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:29:58,360]\u001b[0m Trial 36 finished with value: 0.6111428571428571 and parameters: {'max_depth': 3, 'max_features': 18, 'min_samples_split': 12}. Best is trial 8 with value: 0.6439999999999999.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:29:58,386]\u001b[0m Trial 37 finished with value: 0.6011428571428571 and parameters: {'max_depth': 4, 'max_features': 14, 'min_samples_split': 7}. Best is trial 8 with value: 0.6439999999999999.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:29:58,413]\u001b[0m Trial 38 finished with value: 0.6281904761904762 and parameters: {'max_depth': 3, 'max_features': 19, 'min_samples_split': 5}. Best is trial 8 with value: 0.6439999999999999.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:29:58,439]\u001b[0m Trial 39 finished with value: 0.6067619047619047 and parameters: {'max_depth': 4, 'max_features': 10, 'min_samples_split': 16}. Best is trial 8 with value: 0.6439999999999999.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:29:58,466]\u001b[0m Trial 40 finished with value: 0.6393333333333333 and parameters: {'max_depth': 5, 'max_features': 16, 'min_samples_split': 11}. Best is trial 8 with value: 0.6439999999999999.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:29:58,491]\u001b[0m Trial 41 finished with value: 0.6411428571428571 and parameters: {'max_depth': 3, 'max_features': 17, 'min_samples_split': 9}. Best is trial 8 with value: 0.6439999999999999.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:29:58,519]\u001b[0m Trial 42 finished with value: 0.6368571428571428 and parameters: {'max_depth': 3, 'max_features': 17, 'min_samples_split': 14}. Best is trial 8 with value: 0.6439999999999999.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:29:58,545]\u001b[0m Trial 43 finished with value: 0.6411428571428571 and parameters: {'max_depth': 3, 'max_features': 17, 'min_samples_split': 8}. Best is trial 8 with value: 0.6439999999999999.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:29:58,570]\u001b[0m Trial 44 finished with value: 0.614 and parameters: {'max_depth': 3, 'max_features': 18, 'min_samples_split': 10}. Best is trial 8 with value: 0.6439999999999999.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:29:58,597]\u001b[0m Trial 45 finished with value: 0.6411428571428571 and parameters: {'max_depth': 3, 'max_features': 17, 'min_samples_split': 8}. Best is trial 8 with value: 0.6439999999999999.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:29:58,624]\u001b[0m Trial 46 finished with value: 0.6056190476190477 and parameters: {'max_depth': 3, 'max_features': 20, 'min_samples_split': 5}. Best is trial 8 with value: 0.6439999999999999.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:29:58,651]\u001b[0m Trial 47 finished with value: 0.64 and parameters: {'max_depth': 3, 'max_features': 16, 'min_samples_split': 3}. Best is trial 8 with value: 0.6439999999999999.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:29:58,678]\u001b[0m Trial 48 finished with value: 0.6143809523809524 and parameters: {'max_depth': 3, 'max_features': 15, 'min_samples_split': 8}. Best is trial 8 with value: 0.6439999999999999.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:29:58,704]\u001b[0m Trial 49 finished with value: 0.6180952380952381 and parameters: {'max_depth': 3, 'max_features': 18, 'min_samples_split': 21}. Best is trial 8 with value: 0.6439999999999999.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:29:58,729]\u001b[0m Trial 50 finished with value: 0.6406666666666666 and parameters: {'max_depth': 3, 'max_features': 11, 'min_samples_split': 3}. Best is trial 8 with value: 0.6439999999999999.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:29:58,758]\u001b[0m Trial 51 finished with value: 0.6411428571428571 and parameters: {'max_depth': 3, 'max_features': 17, 'min_samples_split': 11}. Best is trial 8 with value: 0.6439999999999999.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:29:58,785]\u001b[0m Trial 52 finished with value: 0.6411428571428571 and parameters: {'max_depth': 3, 'max_features': 17, 'min_samples_split': 11}. Best is trial 8 with value: 0.6439999999999999.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:29:58,811]\u001b[0m Trial 53 finished with value: 0.6371428571428572 and parameters: {'max_depth': 3, 'max_features': 16, 'min_samples_split': 12}. Best is trial 8 with value: 0.6439999999999999.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:29:58,838]\u001b[0m Trial 54 finished with value: 0.6425714285714286 and parameters: {'max_depth': 3, 'max_features': 17, 'min_samples_split': 6}. Best is trial 8 with value: 0.6439999999999999.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:29:58,863]\u001b[0m Trial 55 finished with value: 0.6211428571428571 and parameters: {'max_depth': 3, 'max_features': 18, 'min_samples_split': 6}. Best is trial 8 with value: 0.6439999999999999.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:29:58,888]\u001b[0m Trial 56 finished with value: 0.6375238095238095 and parameters: {'max_depth': 3, 'max_features': 19, 'min_samples_split': 24}. Best is trial 8 with value: 0.6439999999999999.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:29:58,915]\u001b[0m Trial 57 finished with value: 0.6422857142857145 and parameters: {'max_depth': 5, 'max_features': 16, 'min_samples_split': 7}. Best is trial 8 with value: 0.6439999999999999.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:29:58,941]\u001b[0m Trial 58 finished with value: 0.6604761904761905 and parameters: {'max_depth': 5, 'max_features': 16, 'min_samples_split': 5}. Best is trial 58 with value: 0.6604761904761905.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:29:58,966]\u001b[0m Trial 59 finished with value: 0.6406666666666666 and parameters: {'max_depth': 5, 'max_features': 15, 'min_samples_split': 6}. Best is trial 58 with value: 0.6604761904761905.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:29:58,992]\u001b[0m Trial 60 finished with value: 0.6604761904761905 and parameters: {'max_depth': 5, 'max_features': 16, 'min_samples_split': 5}. Best is trial 58 with value: 0.6604761904761905.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:29:59,017]\u001b[0m Trial 61 finished with value: 0.6604761904761905 and parameters: {'max_depth': 5, 'max_features': 16, 'min_samples_split': 5}. Best is trial 58 with value: 0.6604761904761905.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:29:59,044]\u001b[0m Trial 62 finished with value: 0.647904761904762 and parameters: {'max_depth': 5, 'max_features': 14, 'min_samples_split': 3}. Best is trial 58 with value: 0.6604761904761905.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:29:59,073]\u001b[0m Trial 63 finished with value: 0.6742857142857143 and parameters: {'max_depth': 5, 'max_features': 13, 'min_samples_split': 2}. Best is trial 63 with value: 0.6742857142857143.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:29:59,099]\u001b[0m Trial 64 finished with value: 0.6520952380952381 and parameters: {'max_depth': 5, 'max_features': 14, 'min_samples_split': 2}. Best is trial 63 with value: 0.6742857142857143.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:29:59,125]\u001b[0m Trial 65 finished with value: 0.6742857142857143 and parameters: {'max_depth': 5, 'max_features': 13, 'min_samples_split': 2}. Best is trial 63 with value: 0.6742857142857143.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:29:59,151]\u001b[0m Trial 66 finished with value: 0.68 and parameters: {'max_depth': 5, 'max_features': 13, 'min_samples_split': 3}. Best is trial 66 with value: 0.68.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:29:59,176]\u001b[0m Trial 67 finished with value: 0.6742857142857143 and parameters: {'max_depth': 5, 'max_features': 13, 'min_samples_split': 2}. Best is trial 66 with value: 0.68.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:29:59,201]\u001b[0m Trial 68 finished with value: 0.6742857142857143 and parameters: {'max_depth': 5, 'max_features': 13, 'min_samples_split': 2}. Best is trial 66 with value: 0.68.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:29:59,226]\u001b[0m Trial 69 finished with value: 0.6742857142857143 and parameters: {'max_depth': 5, 'max_features': 13, 'min_samples_split': 2}. Best is trial 66 with value: 0.68.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:29:59,252]\u001b[0m Trial 70 finished with value: 0.6742857142857143 and parameters: {'max_depth': 5, 'max_features': 13, 'min_samples_split': 2}. Best is trial 66 with value: 0.68.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:29:59,278]\u001b[0m Trial 71 finished with value: 0.6742857142857143 and parameters: {'max_depth': 5, 'max_features': 13, 'min_samples_split': 2}. Best is trial 66 with value: 0.68.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:29:59,302]\u001b[0m Trial 72 finished with value: 0.6742857142857143 and parameters: {'max_depth': 5, 'max_features': 13, 'min_samples_split': 2}. Best is trial 66 with value: 0.68.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:29:59,328]\u001b[0m Trial 73 finished with value: 0.6690476190476191 and parameters: {'max_depth': 5, 'max_features': 12, 'min_samples_split': 3}. Best is trial 66 with value: 0.68.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:29:59,355]\u001b[0m Trial 74 finished with value: 0.6761904761904762 and parameters: {'max_depth': 5, 'max_features': 12, 'min_samples_split': 2}. Best is trial 66 with value: 0.68.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:29:59,380]\u001b[0m Trial 75 finished with value: 0.6676190476190478 and parameters: {'max_depth': 5, 'max_features': 12, 'min_samples_split': 4}. Best is trial 66 with value: 0.68.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:29:59,416]\u001b[0m Trial 76 finished with value: 0.6742857142857143 and parameters: {'max_depth': 5, 'max_features': 13, 'min_samples_split': 2}. Best is trial 66 with value: 0.68.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:29:59,444]\u001b[0m Trial 77 finished with value: 0.6690476190476191 and parameters: {'max_depth': 5, 'max_features': 12, 'min_samples_split': 3}. Best is trial 66 with value: 0.68.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:29:59,471]\u001b[0m Trial 78 finished with value: 0.6451428571428572 and parameters: {'max_depth': 5, 'max_features': 11, 'min_samples_split': 4}. Best is trial 66 with value: 0.68.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:29:59,496]\u001b[0m Trial 79 finished with value: 0.6742857142857143 and parameters: {'max_depth': 5, 'max_features': 13, 'min_samples_split': 2}. Best is trial 66 with value: 0.68.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:29:59,522]\u001b[0m Trial 80 finished with value: 0.6676190476190478 and parameters: {'max_depth': 5, 'max_features': 12, 'min_samples_split': 4}. Best is trial 66 with value: 0.68.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:29:59,548]\u001b[0m Trial 81 finished with value: 0.6742857142857143 and parameters: {'max_depth': 5, 'max_features': 13, 'min_samples_split': 2}. Best is trial 66 with value: 0.68.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:29:59,573]\u001b[0m Trial 82 finished with value: 0.68 and parameters: {'max_depth': 5, 'max_features': 13, 'min_samples_split': 3}. Best is trial 66 with value: 0.68.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:29:59,599]\u001b[0m Trial 83 finished with value: 0.647904761904762 and parameters: {'max_depth': 5, 'max_features': 14, 'min_samples_split': 3}. Best is trial 66 with value: 0.68.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:29:59,624]\u001b[0m Trial 84 finished with value: 0.6478095238095238 and parameters: {'max_depth': 5, 'max_features': 11, 'min_samples_split': 3}. Best is trial 66 with value: 0.68.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:29:59,649]\u001b[0m Trial 85 finished with value: 0.6759999999999999 and parameters: {'max_depth': 5, 'max_features': 13, 'min_samples_split': 4}. Best is trial 66 with value: 0.68.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:29:59,675]\u001b[0m Trial 86 finished with value: 0.6676190476190478 and parameters: {'max_depth': 5, 'max_features': 12, 'min_samples_split': 4}. Best is trial 66 with value: 0.68.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:29:59,701]\u001b[0m Trial 87 finished with value: 0.6337142857142858 and parameters: {'max_depth': 5, 'max_features': 12, 'min_samples_split': 18}. Best is trial 66 with value: 0.68.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:29:59,729]\u001b[0m Trial 88 finished with value: 0.68 and parameters: {'max_depth': 5, 'max_features': 13, 'min_samples_split': 3}. Best is trial 66 with value: 0.68.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:29:59,758]\u001b[0m Trial 89 finished with value: 0.647904761904762 and parameters: {'max_depth': 5, 'max_features': 14, 'min_samples_split': 3}. Best is trial 66 with value: 0.68.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:29:59,784]\u001b[0m Trial 90 finished with value: 0.68 and parameters: {'max_depth': 5, 'max_features': 13, 'min_samples_split': 3}. Best is trial 66 with value: 0.68.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:29:59,809]\u001b[0m Trial 91 finished with value: 0.6759999999999999 and parameters: {'max_depth': 5, 'max_features': 13, 'min_samples_split': 4}. Best is trial 66 with value: 0.68.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:29:59,836]\u001b[0m Trial 92 finished with value: 0.6759999999999999 and parameters: {'max_depth': 5, 'max_features': 13, 'min_samples_split': 4}. Best is trial 66 with value: 0.68.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:29:59,862]\u001b[0m Trial 93 finished with value: 0.6759999999999999 and parameters: {'max_depth': 5, 'max_features': 13, 'min_samples_split': 4}. Best is trial 66 with value: 0.68.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:29:59,889]\u001b[0m Trial 94 finished with value: 0.6379047619047619 and parameters: {'max_depth': 5, 'max_features': 14, 'min_samples_split': 4}. Best is trial 66 with value: 0.68.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:29:59,915]\u001b[0m Trial 95 finished with value: 0.6676190476190478 and parameters: {'max_depth': 5, 'max_features': 12, 'min_samples_split': 4}. Best is trial 66 with value: 0.68.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:29:59,942]\u001b[0m Trial 96 finished with value: 0.68 and parameters: {'max_depth': 5, 'max_features': 13, 'min_samples_split': 3}. Best is trial 66 with value: 0.68.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:29:59,968]\u001b[0m Trial 97 finished with value: 0.6421904761904762 and parameters: {'max_depth': 5, 'max_features': 14, 'min_samples_split': 5}. Best is trial 66 with value: 0.68.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:29:59,993]\u001b[0m Trial 98 finished with value: 0.6634285714285714 and parameters: {'max_depth': 5, 'max_features': 12, 'min_samples_split': 5}. Best is trial 66 with value: 0.68.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:30:00,019]\u001b[0m Trial 99 finished with value: 0.6478095238095238 and parameters: {'max_depth': 5, 'max_features': 11, 'min_samples_split': 3}. Best is trial 66 with value: 0.68.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "#Tuning hyperparameters\n",
    "#Step 1. Define an objective function to be maximized.\n",
    "def objective(trial):\n",
    "    param = {\n",
    "        'max_depth': trial.suggest_int('max_depth',3,5,1),\n",
    "        'max_features' : trial.suggest_int(\"max_features\",10,20,1),\n",
    "        'min_samples_split':trial.suggest_int('min_samples_split',2,25,1)\n",
    "    }\n",
    "    model = DecisionTreeClassifier(**param,random_state=1)\n",
    "\n",
    " \n",
    "# Step 2: Scoring method:\n",
    "    score = model_selection.cross_val_score(model, X, y, n_jobs=8, scoring=\"accuracy\",cv=Cv_optuna)\n",
    "    accuracy = score.mean()\n",
    "    return accuracy\n",
    " \n",
    "# Step 3: Running it\n",
    "study = optuna.create_study(direction=\"maximize\",sampler=optuna.samplers.TPESampler(seed=0))\n",
    "study.optimize(objective, n_trials=100, show_progress_bar=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "6ec0811a-1713-4b39-b21f-cb09e9594c4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best parameters are : \n",
      "{'max_depth': 5, 'max_features': 13, 'min_samples_split': 3}\n"
     ]
    }
   ],
   "source": [
    "# Getting the best parameters:\n",
    "print(f\"The best parameters are : \\n{study.best_params}\")\n",
    "# Setting the best model\n",
    "clf =DecisionTreeClassifier(max_depth = study.best_params['max_depth']\n",
    "              ,max_features = study.best_params['max_features']\n",
    "              #,n_estimators = study.best_params['n_estimators']\n",
    "              #,learning_rate = study.best_params['learning_rate']\n",
    "              ,min_samples_split= study.best_params['min_samples_split']\n",
    "              ,random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "9d1899f3-a5c0-4f3d-8fb2-176c72ea4a4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mean</th>\n",
       "      <th>Se</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Accuracy_test</th>\n",
       "      <td>0.680000</td>\n",
       "      <td>0.012329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Accuracy_train</th>\n",
       "      <td>0.925345</td>\n",
       "      <td>0.005584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1 Score</th>\n",
       "      <td>0.706865</td>\n",
       "      <td>0.012092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Precision</th>\n",
       "      <td>0.698240</td>\n",
       "      <td>0.013460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recall</th>\n",
       "      <td>0.735714</td>\n",
       "      <td>0.020076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Roc_auc</th>\n",
       "      <td>0.690561</td>\n",
       "      <td>0.015281</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Mean        Se\n",
       "Accuracy_test   0.680000  0.012329\n",
       "Accuracy_train  0.925345  0.005584\n",
       "F1 Score        0.706865  0.012092\n",
       "Precision       0.698240  0.013460\n",
       "Recall          0.735714  0.020076\n",
       "Roc_auc         0.690561  0.015281"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Model2\n",
    "Model2=Model_results(clf,X,y,Cv_model)\n",
    "Model2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "390c5554-ccf3-490e-9e3e-7d53299bb3bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th>Method</th>\n",
       "      <th colspan=\"4\" halign=\"left\">DT</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model</th>\n",
       "      <th colspan=\"2\" halign=\"left\">Model 1</th>\n",
       "      <th colspan=\"2\" halign=\"left\">Model 2</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Values</th>\n",
       "      <th>Mean</th>\n",
       "      <th>Se</th>\n",
       "      <th>Mean</th>\n",
       "      <th>Se</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Accuracy_test</th>\n",
       "      <td>0.629333</td>\n",
       "      <td>0.015032</td>\n",
       "      <td>0.680000</td>\n",
       "      <td>0.012329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Accuracy_train</th>\n",
       "      <td>0.729981</td>\n",
       "      <td>0.004700</td>\n",
       "      <td>0.925345</td>\n",
       "      <td>0.005584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1 Score</th>\n",
       "      <td>0.697627</td>\n",
       "      <td>0.013235</td>\n",
       "      <td>0.706865</td>\n",
       "      <td>0.012092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Precision</th>\n",
       "      <td>0.620752</td>\n",
       "      <td>0.011961</td>\n",
       "      <td>0.698240</td>\n",
       "      <td>0.013460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recall</th>\n",
       "      <td>0.811071</td>\n",
       "      <td>0.020893</td>\n",
       "      <td>0.735714</td>\n",
       "      <td>0.020076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Roc_auc</th>\n",
       "      <td>0.664796</td>\n",
       "      <td>0.020543</td>\n",
       "      <td>0.690561</td>\n",
       "      <td>0.015281</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Method                DT                              \n",
       "Model            Model 1             Model 2          \n",
       "Values              Mean        Se      Mean        Se\n",
       "Accuracy_test   0.629333  0.015032  0.680000  0.012329\n",
       "Accuracy_train  0.729981  0.004700  0.925345  0.005584\n",
       "F1 Score        0.697627  0.013235  0.706865  0.012092\n",
       "Precision       0.620752  0.011961  0.698240  0.013460\n",
       "Recall          0.811071  0.020893  0.735714  0.020076\n",
       "Roc_auc         0.664796  0.020543  0.690561  0.015281"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Saving the data of model performance\n",
    "Model_data=pd.concat([Model1,Model2],axis=1)\n",
    "Model_data.columns = [['DT']*4,['Model 1','Model 1', 'Model 2','Model 2'], ['Mean', 'Se', 'Mean', 'Se']]  \n",
    "Model_data.columns.names=['Method','Model','Values']\n",
    "Model_data.to_csv(\"./Results/DT_model_mlrem_data.csv\",sep=',')\n",
    "Model_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff716df6-f48a-4890-819b-cca04c92e57c",
   "metadata": {},
   "source": [
    "## 2.2 LR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "96eeb954-8032-43c2-afb2-e47f675b2d15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mean</th>\n",
       "      <th>Se</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Accuracy_test</th>\n",
       "      <td>0.680000</td>\n",
       "      <td>0.012329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Accuracy_train</th>\n",
       "      <td>0.925345</td>\n",
       "      <td>0.005584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1 Score</th>\n",
       "      <td>0.706865</td>\n",
       "      <td>0.012092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Precision</th>\n",
       "      <td>0.698240</td>\n",
       "      <td>0.013460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recall</th>\n",
       "      <td>0.735714</td>\n",
       "      <td>0.020076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Roc_auc</th>\n",
       "      <td>0.690561</td>\n",
       "      <td>0.015281</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Mean        Se\n",
       "Accuracy_test   0.680000  0.012329\n",
       "Accuracy_train  0.925345  0.005584\n",
       "F1 Score        0.706865  0.012092\n",
       "Precision       0.698240  0.013460\n",
       "Recall          0.735714  0.020076\n",
       "Roc_auc         0.690561  0.015281"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Model1\n",
    "Model1_clf=clf\n",
    "#Model1\n",
    "Model1=Model_results(Model1_clf,X,y,Cv_model)\n",
    "Model1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "662dc3e0-7ca9-41f6-ad45-99db640a18b8",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2024-01-12 01:33:46,194]\u001b[0m A new study created in memory with name: no-name-e4ba7b5b-b8fd-4929-82c3-50137ca4832b\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:33:46,218]\u001b[0m Trial 0 finished with value: 0.6096190476190476 and parameters: {'logreg_c': 0.3177840006884068, 'l1_ratio': 0.7482920440979423, 'max_iter': 100}. Best is trial 0 with value: 0.6096190476190476.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:33:46,239]\u001b[0m Trial 1 finished with value: 0.6195238095238095 and parameters: {'logreg_c': 0.0651621545821569, 'l1_ratio': 0.23208030173540176, 'max_iter': 275}. Best is trial 1 with value: 0.6195238095238095.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:33:46,262]\u001b[0m Trial 2 finished with value: 0.570095238095238 and parameters: {'logreg_c': 0.013108749615263334, 'l1_ratio': 0.411004654338743, 'max_iter': 854}. Best is trial 1 with value: 0.6195238095238095.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:33:46,284]\u001b[0m Trial 3 finished with value: 0.6294285714285714 and parameters: {'logreg_c': 1.7096232052870346, 'l1_ratio': 0.4772750629629653, 'max_iter': 1402}. Best is trial 3 with value: 0.6294285714285714.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:33:46,305]\u001b[0m Trial 4 finished with value: 0.574095238095238 and parameters: {'logreg_c': 0.016854407828169382, 'l1_ratio': 0.8903056927518509, 'max_iter': 152}. Best is trial 3 with value: 0.6294285714285714.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:33:46,328]\u001b[0m Trial 5 finished with value: 0.6167619047619047 and parameters: {'logreg_c': 10.539137268289434, 'l1_ratio': 0.4755743221304143, 'max_iter': 1162}. Best is trial 3 with value: 0.6294285714285714.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:33:46,351]\u001b[0m Trial 6 finished with value: 0.5672380952380952 and parameters: {'logreg_c': 0.006955392321661603, 'l1_ratio': 0.2782913401763909, 'max_iter': 1622}. Best is trial 3 with value: 0.6294285714285714.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:33:46,373]\u001b[0m Trial 7 finished with value: 0.6282857142857143 and parameters: {'logreg_c': 645.0144652189372, 'l1_ratio': 0.38208176034331853, 'max_iter': 1416}. Best is trial 3 with value: 0.6294285714285714.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:33:46,397]\u001b[0m Trial 8 finished with value: 0.6093333333333334 and parameters: {'logreg_c': 181.27374779133626, 'l1_ratio': 0.9051459971534626, 'max_iter': 261}. Best is trial 3 with value: 0.6294285714285714.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:33:46,418]\u001b[0m Trial 9 finished with value: 0.5601904761904761 and parameters: {'logreg_c': 0.001715255021408637, 'l1_ratio': 0.25284737760811204, 'max_iter': 1769}. Best is trial 3 with value: 0.6294285714285714.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:33:46,444]\u001b[0m Trial 10 finished with value: 0.6153333333333333 and parameters: {'logreg_c': 9.589685409552947, 'l1_ratio': 0.6553689413187243, 'max_iter': 845}. Best is trial 3 with value: 0.6294285714285714.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:33:46,469]\u001b[0m Trial 11 finished with value: 0.6268571428571428 and parameters: {'logreg_c': 843.2126062012233, 'l1_ratio': 0.5380831473609496, 'max_iter': 1376}. Best is trial 3 with value: 0.6294285714285714.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:33:46,493]\u001b[0m Trial 12 finished with value: 0.6167619047619047 and parameters: {'logreg_c': 7.624466107886496, 'l1_ratio': 0.378272352651409, 'max_iter': 1494}. Best is trial 3 with value: 0.6294285714285714.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:33:46,518]\u001b[0m Trial 13 finished with value: 0.6162857142857143 and parameters: {'logreg_c': 51.786339691986214, 'l1_ratio': 0.6316370562712422, 'max_iter': 1128}. Best is trial 3 with value: 0.6294285714285714.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:33:46,543]\u001b[0m Trial 14 finished with value: 0.627904761904762 and parameters: {'logreg_c': 0.8529452363532304, 'l1_ratio': 0.13738672304214128, 'max_iter': 1780}. Best is trial 3 with value: 0.6294285714285714.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:33:46,570]\u001b[0m Trial 15 finished with value: 0.6281904761904762 and parameters: {'logreg_c': 763.5588094994378, 'l1_ratio': 0.3689322680983461, 'max_iter': 1971}. Best is trial 3 with value: 0.6294285714285714.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:33:46,596]\u001b[0m Trial 16 finished with value: 0.6195238095238096 and parameters: {'logreg_c': 0.13707192890174966, 'l1_ratio': 0.5845266407991517, 'max_iter': 1309}. Best is trial 3 with value: 0.6294285714285714.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:33:46,623]\u001b[0m Trial 17 finished with value: 0.6120000000000001 and parameters: {'logreg_c': 76.37303329769077, 'l1_ratio': 0.7683639981317943, 'max_iter': 716}. Best is trial 3 with value: 0.6294285714285714.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:33:46,649]\u001b[0m Trial 18 finished with value: 0.6252380952380953 and parameters: {'logreg_c': 2.932001936719566, 'l1_ratio': 0.10084185856253824, 'max_iter': 553}. Best is trial 3 with value: 0.6294285714285714.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:33:46,674]\u001b[0m Trial 19 finished with value: 0.6307619047619046 and parameters: {'logreg_c': 1.3160447446956969, 'l1_ratio': 0.4671561613242705, 'max_iter': 1312}. Best is trial 19 with value: 0.6307619047619046.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:33:46,701]\u001b[0m Trial 20 finished with value: 0.6293333333333333 and parameters: {'logreg_c': 1.4651691779773963, 'l1_ratio': 0.4935134748265029, 'max_iter': 983}. Best is trial 19 with value: 0.6307619047619046.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:33:46,725]\u001b[0m Trial 21 finished with value: 0.6237142857142858 and parameters: {'logreg_c': 0.8287025892084571, 'l1_ratio': 0.5199862466969595, 'max_iter': 1054}. Best is trial 19 with value: 0.6307619047619046.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:33:46,751]\u001b[0m Trial 22 finished with value: 0.6238095238095238 and parameters: {'logreg_c': 3.1654611271505058, 'l1_ratio': 0.4597028916076701, 'max_iter': 1266}. Best is trial 19 with value: 0.6307619047619046.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:33:46,777]\u001b[0m Trial 23 finished with value: 0.6166666666666667 and parameters: {'logreg_c': 0.1535200845989714, 'l1_ratio': 0.6782814588832947, 'max_iter': 981}. Best is trial 19 with value: 0.6307619047619046.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:33:46,803]\u001b[0m Trial 24 finished with value: 0.6294285714285714 and parameters: {'logreg_c': 1.8873063599506599, 'l1_ratio': 0.326102166138698, 'max_iter': 1522}. Best is trial 19 with value: 0.6307619047619046.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:33:46,827]\u001b[0m Trial 25 finished with value: 0.6180952380952381 and parameters: {'logreg_c': 0.41516225975438653, 'l1_ratio': 0.2979284535359352, 'max_iter': 1547}. Best is trial 19 with value: 0.6307619047619046.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:33:46,853]\u001b[0m Trial 26 finished with value: 0.6191428571428571 and parameters: {'logreg_c': 17.953162228525414, 'l1_ratio': 0.31727555023219167, 'max_iter': 1687}. Best is trial 19 with value: 0.6307619047619046.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:33:46,878]\u001b[0m Trial 27 finished with value: 0.6266666666666666 and parameters: {'logreg_c': 2.602409837373429, 'l1_ratio': 0.19868034857393024, 'max_iter': 1919}. Best is trial 19 with value: 0.6307619047619046.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:33:46,905]\u001b[0m Trial 28 finished with value: 0.6195238095238095 and parameters: {'logreg_c': 0.07229078967635784, 'l1_ratio': 0.42868388614084174, 'max_iter': 1511}. Best is trial 19 with value: 0.6307619047619046.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:33:46,931]\u001b[0m Trial 29 finished with value: 0.6194285714285716 and parameters: {'logreg_c': 0.3860177138367054, 'l1_ratio': 0.8158505713189557, 'max_iter': 1211}. Best is trial 19 with value: 0.6307619047619046.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:33:46,956]\u001b[0m Trial 30 finished with value: 0.6168571428571429 and parameters: {'logreg_c': 4.8505444157280655, 'l1_ratio': 0.989090737470458, 'max_iter': 1389}. Best is trial 19 with value: 0.6307619047619046.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:33:46,984]\u001b[0m Trial 31 finished with value: 0.6293333333333334 and parameters: {'logreg_c': 1.2065391735314397, 'l1_ratio': 0.4963584342131737, 'max_iter': 1011}. Best is trial 19 with value: 0.6307619047619046.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:33:47,011]\u001b[0m Trial 32 finished with value: 0.6162857142857143 and parameters: {'logreg_c': 28.72272514710678, 'l1_ratio': 0.581199409657952, 'max_iter': 582}. Best is trial 19 with value: 0.6307619047619046.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:33:47,038]\u001b[0m Trial 33 finished with value: 0.6293333333333333 and parameters: {'logreg_c': 1.3696220900607625, 'l1_ratio': 0.42558482659301816, 'max_iter': 1297}. Best is trial 19 with value: 0.6307619047619046.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:33:47,063]\u001b[0m Trial 34 finished with value: 0.6067619047619047 and parameters: {'logreg_c': 0.2875637249472787, 'l1_ratio': 0.3482207466346646, 'max_iter': 1109}. Best is trial 19 with value: 0.6307619047619046.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:33:47,088]\u001b[0m Trial 35 finished with value: 0.6009523809523809 and parameters: {'logreg_c': 0.03576221722627603, 'l1_ratio': 0.5765441371212959, 'max_iter': 870}. Best is trial 19 with value: 0.6307619047619046.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:33:47,116]\u001b[0m Trial 36 finished with value: 0.6209523809523809 and parameters: {'logreg_c': 0.6626791637945557, 'l1_ratio': 0.20185400717777569, 'max_iter': 1676}. Best is trial 19 with value: 0.6307619047619046.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:33:47,140]\u001b[0m Trial 37 finished with value: 0.6294285714285714 and parameters: {'logreg_c': 1.9120072183363928, 'l1_ratio': 0.4733809188346099, 'max_iter': 1467}. Best is trial 19 with value: 0.6307619047619046.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:33:47,165]\u001b[0m Trial 38 finished with value: 0.6177142857142858 and parameters: {'logreg_c': 19.34210830669201, 'l1_ratio': 0.44990617999528343, 'max_iter': 1557}. Best is trial 19 with value: 0.6307619047619046.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:33:47,192]\u001b[0m Trial 39 finished with value: 0.6139047619047618 and parameters: {'logreg_c': 0.22059945415572177, 'l1_ratio': 0.3267785933880323, 'max_iter': 1424}. Best is trial 19 with value: 0.6307619047619046.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:33:47,219]\u001b[0m Trial 40 finished with value: 0.6139047619047618 and parameters: {'logreg_c': 5.702688279032213, 'l1_ratio': 0.706870700092175, 'max_iter': 1216}. Best is trial 19 with value: 0.6307619047619046.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:33:47,247]\u001b[0m Trial 41 finished with value: 0.6307619047619047 and parameters: {'logreg_c': 2.1083445203193767, 'l1_ratio': 0.5013573618384977, 'max_iter': 1814}. Best is trial 41 with value: 0.6307619047619047.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:33:47,273]\u001b[0m Trial 42 finished with value: 0.6294285714285714 and parameters: {'logreg_c': 1.8778046360697456, 'l1_ratio': 0.39812276354777576, 'max_iter': 1899}. Best is trial 41 with value: 0.6307619047619047.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:33:47,308]\u001b[0m Trial 43 finished with value: 0.6196190476190475 and parameters: {'logreg_c': 4.005595097886426, 'l1_ratio': 0.40683807642605113, 'max_iter': 1851}. Best is trial 41 with value: 0.6307619047619047.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:33:47,335]\u001b[0m Trial 44 finished with value: 0.6153333333333333 and parameters: {'logreg_c': 10.51995398501394, 'l1_ratio': 0.5242462748652383, 'max_iter': 1635}. Best is trial 41 with value: 0.6307619047619047.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:33:47,361]\u001b[0m Trial 45 finished with value: 0.6166666666666667 and parameters: {'logreg_c': 0.43649305773415953, 'l1_ratio': 0.62669435281089, 'max_iter': 1803}. Best is trial 41 with value: 0.6307619047619047.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:33:47,387]\u001b[0m Trial 46 finished with value: 0.6195238095238095 and parameters: {'logreg_c': 0.07187646725784044, 'l1_ratio': 0.281967448657918, 'max_iter': 1917}. Best is trial 41 with value: 0.6307619047619047.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:33:47,414]\u001b[0m Trial 47 finished with value: 0.627904761904762 and parameters: {'logreg_c': 2.0310237754182316, 'l1_ratio': 0.39414395429506727, 'max_iter': 1726}. Best is trial 41 with value: 0.6307619047619047.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:33:47,441]\u001b[0m Trial 48 finished with value: 0.620952380952381 and parameters: {'logreg_c': 0.6082079556285477, 'l1_ratio': 0.5660058818783812, 'max_iter': 1618}. Best is trial 41 with value: 0.6307619047619047.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:33:47,466]\u001b[0m Trial 49 finished with value: 0.6108571428571429 and parameters: {'logreg_c': 240.59569344033093, 'l1_ratio': 0.24451803344912826, 'max_iter': 1985}. Best is trial 41 with value: 0.6307619047619047.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:33:47,492]\u001b[0m Trial 50 finished with value: 0.5643809523809523 and parameters: {'logreg_c': 0.003166482546125131, 'l1_ratio': 0.4598078240788601, 'max_iter': 1365}. Best is trial 41 with value: 0.6307619047619047.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:33:47,518]\u001b[0m Trial 51 finished with value: 0.6167619047619047 and parameters: {'logreg_c': 7.943065063340901, 'l1_ratio': 0.3551537545361903, 'max_iter': 1474}. Best is trial 41 with value: 0.6307619047619047.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:33:47,545]\u001b[0m Trial 52 finished with value: 0.6294285714285714 and parameters: {'logreg_c': 1.8518389019522237, 'l1_ratio': 0.49224974644280434, 'max_iter': 1844}. Best is trial 41 with value: 0.6307619047619047.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:33:47,571]\u001b[0m Trial 53 finished with value: 0.627904761904762 and parameters: {'logreg_c': 1.3572714107165977, 'l1_ratio': 0.49277895678099476, 'max_iter': 1458}. Best is trial 41 with value: 0.6307619047619047.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:33:47,598]\u001b[0m Trial 54 finished with value: 0.6210476190476191 and parameters: {'logreg_c': 3.7115076962149858, 'l1_ratio': 0.6102000361609092, 'max_iter': 1590}. Best is trial 41 with value: 0.6307619047619047.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:33:47,625]\u001b[0m Trial 55 finished with value: 0.6264761904761904 and parameters: {'logreg_c': 0.8911994905571492, 'l1_ratio': 0.3993140649769618, 'max_iter': 1883}. Best is trial 41 with value: 0.6307619047619047.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:33:47,651]\u001b[0m Trial 56 finished with value: 0.6294285714285714 and parameters: {'logreg_c': 2.2506604255090674, 'l1_ratio': 0.5420213510321465, 'max_iter': 1719}. Best is trial 41 with value: 0.6307619047619047.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:33:47,678]\u001b[0m Trial 57 finished with value: 0.6191428571428571 and parameters: {'logreg_c': 19.197800367683012, 'l1_ratio': 0.4652438210429772, 'max_iter': 1762}. Best is trial 41 with value: 0.6307619047619047.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:33:47,705]\u001b[0m Trial 58 finished with value: 0.6195238095238096 and parameters: {'logreg_c': 0.17391612699617703, 'l1_ratio': 0.5464710550797393, 'max_iter': 1365}. Best is trial 41 with value: 0.6307619047619047.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:33:47,730]\u001b[0m Trial 59 finished with value: 0.613904761904762 and parameters: {'logreg_c': 6.575270743844423, 'l1_ratio': 0.5466415698694522, 'max_iter': 1686}. Best is trial 41 with value: 0.6307619047619047.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:33:47,758]\u001b[0m Trial 60 finished with value: 0.6163809523809525 and parameters: {'logreg_c': 54.54049186437329, 'l1_ratio': 0.4325278919043865, 'max_iter': 1996}. Best is trial 41 with value: 0.6307619047619047.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:33:47,784]\u001b[0m Trial 61 finished with value: 0.6307619047619047 and parameters: {'logreg_c': 2.096362271932597, 'l1_ratio': 0.5160078527964562, 'max_iter': 1556}. Best is trial 41 with value: 0.6307619047619047.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:33:47,811]\u001b[0m Trial 62 finished with value: 0.6266666666666666 and parameters: {'logreg_c': 2.538893199184801, 'l1_ratio': 0.504806699044337, 'max_iter': 1744}. Best is trial 41 with value: 0.6307619047619047.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:33:47,838]\u001b[0m Trial 63 finished with value: 0.6308571428571428 and parameters: {'logreg_c': 1.6491171164828378, 'l1_ratio': 0.37983614680640526, 'max_iter': 1831}. Best is trial 63 with value: 0.6308571428571428.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:33:47,865]\u001b[0m Trial 64 finished with value: 0.6207619047619048 and parameters: {'logreg_c': 0.5680946103743453, 'l1_ratio': 0.6124516385720995, 'max_iter': 1804}. Best is trial 63 with value: 0.6308571428571428.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:33:47,891]\u001b[0m Trial 65 finished with value: 0.6194285714285714 and parameters: {'logreg_c': 12.835933863876129, 'l1_ratio': 0.3307896654069705, 'max_iter': 1545}. Best is trial 63 with value: 0.6308571428571428.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:33:47,916]\u001b[0m Trial 66 finished with value: 0.6167619047619047 and parameters: {'logreg_c': 4.284809135627299, 'l1_ratio': 0.49198373373937326, 'max_iter': 1318}. Best is trial 63 with value: 0.6308571428571428.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:33:47,944]\u001b[0m Trial 67 finished with value: 0.6307619047619047 and parameters: {'logreg_c': 0.9489377554918126, 'l1_ratio': 0.37627684812340034, 'max_iter': 1225}. Best is trial 63 with value: 0.6308571428571428.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:33:47,968]\u001b[0m Trial 68 finished with value: 0.6292380952380953 and parameters: {'logreg_c': 1.0538708885678392, 'l1_ratio': 0.6781276320502876, 'max_iter': 1209}. Best is trial 63 with value: 0.6308571428571428.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:33:47,993]\u001b[0m Trial 69 finished with value: 0.6067619047619047 and parameters: {'logreg_c': 0.29155306833483985, 'l1_ratio': 0.36263117743566936, 'max_iter': 1660}. Best is trial 63 with value: 0.6308571428571428.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:33:48,018]\u001b[0m Trial 70 finished with value: 0.6251428571428571 and parameters: {'logreg_c': 0.8333203040302765, 'l1_ratio': 0.43197726798313846, 'max_iter': 1169}. Best is trial 63 with value: 0.6308571428571428.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:33:48,045]\u001b[0m Trial 71 finished with value: 0.6224761904761905 and parameters: {'logreg_c': 3.2825957984619203, 'l1_ratio': 0.52930545567372, 'max_iter': 1902}. Best is trial 63 with value: 0.6308571428571428.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:33:48,071]\u001b[0m Trial 72 finished with value: 0.6294285714285714 and parameters: {'logreg_c': 1.707563442346071, 'l1_ratio': 0.2692265008939825, 'max_iter': 1804}. Best is trial 63 with value: 0.6308571428571428.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:33:48,098]\u001b[0m Trial 73 finished with value: 0.627904761904762 and parameters: {'logreg_c': 1.244565542128993, 'l1_ratio': 0.22628313375302067, 'max_iter': 1283}. Best is trial 63 with value: 0.6308571428571428.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:33:48,124]\u001b[0m Trial 74 finished with value: 0.617904761904762 and parameters: {'logreg_c': 0.5423233219501331, 'l1_ratio': 0.37441966805804505, 'max_iter': 1429}. Best is trial 63 with value: 0.6308571428571428.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:33:48,150]\u001b[0m Trial 75 finished with value: 0.6238095238095238 and parameters: {'logreg_c': 2.6428530082211377, 'l1_ratio': 0.2853040906189891, 'max_iter': 1736}. Best is trial 63 with value: 0.6308571428571428.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:33:48,175]\u001b[0m Trial 76 finished with value: 0.6209523809523809 and parameters: {'logreg_c': 0.10939627711828923, 'l1_ratio': 0.4735312789321377, 'max_iter': 1846}. Best is trial 63 with value: 0.6308571428571428.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:33:48,201]\u001b[0m Trial 77 finished with value: 0.6264761904761904 and parameters: {'logreg_c': 0.8745518604877525, 'l1_ratio': 0.442590140651025, 'max_iter': 1078}. Best is trial 63 with value: 0.6308571428571428.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:33:48,227]\u001b[0m Trial 78 finished with value: 0.6154285714285713 and parameters: {'logreg_c': 5.330321809025692, 'l1_ratio': 0.4137370416803211, 'max_iter': 1943}. Best is trial 63 with value: 0.6308571428571428.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:33:48,254]\u001b[0m Trial 79 finished with value: 0.6321904761904762 and parameters: {'logreg_c': 1.5684558195868687, 'l1_ratio': 0.51063148634346, 'max_iter': 1863}. Best is trial 79 with value: 0.6321904761904762.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:33:48,280]\u001b[0m Trial 80 finished with value: 0.6194285714285716 and parameters: {'logreg_c': 0.37976816840820854, 'l1_ratio': 0.34025799616210806, 'max_iter': 1579}. Best is trial 79 with value: 0.6321904761904762.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:33:48,304]\u001b[0m Trial 81 finished with value: 0.6308571428571428 and parameters: {'logreg_c': 1.5835184104709785, 'l1_ratio': 0.5016015552438089, 'max_iter': 1871}. Best is trial 79 with value: 0.6321904761904762.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:33:48,327]\u001b[0m Trial 82 finished with value: 0.6308571428571428 and parameters: {'logreg_c': 1.6594874201724938, 'l1_ratio': 0.3063290111973975, 'max_iter': 1960}. Best is trial 79 with value: 0.6321904761904762.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:33:48,352]\u001b[0m Trial 83 finished with value: 0.6307619047619046 and parameters: {'logreg_c': 1.343979148614231, 'l1_ratio': 0.5176219420701993, 'max_iter': 1967}. Best is trial 79 with value: 0.6321904761904762.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:33:48,376]\u001b[0m Trial 84 finished with value: 0.6223809523809524 and parameters: {'logreg_c': 0.7187697779331849, 'l1_ratio': 0.5672396458148798, 'max_iter': 1939}. Best is trial 79 with value: 0.6321904761904762.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:33:48,402]\u001b[0m Trial 85 finished with value: 0.6293333333333334 and parameters: {'logreg_c': 1.2029830464414577, 'l1_ratio': 0.5185295899090988, 'max_iter': 1859}. Best is trial 79 with value: 0.6321904761904762.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:33:48,427]\u001b[0m Trial 86 finished with value: 0.6266666666666666 and parameters: {'logreg_c': 2.9061910777908393, 'l1_ratio': 0.3132992841051993, 'max_iter': 1949}. Best is trial 79 with value: 0.6321904761904762.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:33:48,450]\u001b[0m Trial 87 finished with value: 0.6096190476190476 and parameters: {'logreg_c': 0.2725593715364528, 'l1_ratio': 0.3860887328318272, 'max_iter': 1796}. Best is trial 79 with value: 0.6321904761904762.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:33:48,475]\u001b[0m Trial 88 finished with value: 0.6165714285714287 and parameters: {'logreg_c': 0.4912865251268892, 'l1_ratio': 0.5945013797755109, 'max_iter': 2000}. Best is trial 79 with value: 0.6321904761904762.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:33:48,499]\u001b[0m Trial 89 finished with value: 0.6153333333333333 and parameters: {'logreg_c': 8.240833064906228, 'l1_ratio': 0.5139563256443173, 'max_iter': 162}. Best is trial 79 with value: 0.6321904761904762.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:33:48,523]\u001b[0m Trial 90 finished with value: 0.6307619047619047 and parameters: {'logreg_c': 1.4731369609639198, 'l1_ratio': 0.4554672724433561, 'max_iter': 1883}. Best is trial 79 with value: 0.6321904761904762.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:33:48,546]\u001b[0m Trial 91 finished with value: 0.627904761904762 and parameters: {'logreg_c': 1.2362306827283187, 'l1_ratio': 0.45224194854848165, 'max_iter': 1869}. Best is trial 79 with value: 0.6321904761904762.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:33:48,572]\u001b[0m Trial 92 finished with value: 0.628 and parameters: {'logreg_c': 1.8218108234980488, 'l1_ratio': 0.47339867982647943, 'max_iter': 1823}. Best is trial 79 with value: 0.6321904761904762.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:33:48,595]\u001b[0m Trial 93 finished with value: 0.6167619047619047 and parameters: {'logreg_c': 4.271962308570505, 'l1_ratio': 0.5609556013046808, 'max_iter': 1914}. Best is trial 79 with value: 0.6321904761904762.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:33:48,618]\u001b[0m Trial 94 finished with value: 0.6307619047619047 and parameters: {'logreg_c': 0.9774627856036887, 'l1_ratio': 0.42302130014987804, 'max_iter': 1700}. Best is trial 79 with value: 0.6321904761904762.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:33:48,643]\u001b[0m Trial 95 finished with value: 0.6222857142857143 and parameters: {'logreg_c': 0.8082919920657609, 'l1_ratio': 0.41564559443826843, 'max_iter': 1765}. Best is trial 79 with value: 0.6321904761904762.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:33:48,667]\u001b[0m Trial 96 finished with value: 0.6308571428571428 and parameters: {'logreg_c': 1.576347619069216, 'l1_ratio': 0.37665937232889934, 'max_iter': 1705}. Best is trial 79 with value: 0.6321904761904762.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:33:48,691]\u001b[0m Trial 97 finished with value: 0.6252380952380953 and parameters: {'logreg_c': 3.119735317205072, 'l1_ratio': 0.3724348739191003, 'max_iter': 1701}. Best is trial 79 with value: 0.6321904761904762.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:33:48,715]\u001b[0m Trial 98 finished with value: 0.613904761904762 and parameters: {'logreg_c': 6.204154164274675, 'l1_ratio': 0.3480031298152046, 'max_iter': 1631}. Best is trial 79 with value: 0.6321904761904762.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:33:48,739]\u001b[0m Trial 99 finished with value: 0.6195238095238096 and parameters: {'logreg_c': 0.6240590821298014, 'l1_ratio': 0.39483273607916664, 'max_iter': 1765}. Best is trial 79 with value: 0.6321904761904762.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "#Tuning hyperparameters\n",
    "#Step 1. Define an objective function to be maximized.\n",
    "def objective(trial):\n",
    "    logreg_c = trial.suggest_float(\"logreg_c\", 1e-3,  1e3, log=True)\n",
    "    l1_ratio = trial.suggest_float(\"l1_ratio\",0.1,1,log=False) \n",
    "    #penalty = trial.suggest_categorical(\"penalty\",['l1','l2'])\n",
    "    max_iter = trial.suggest_int(\"max_iter\", 100,2000)\n",
    "    model =LogisticRegression(C=logreg_c,\n",
    "                              max_iter=max_iter,\n",
    "                              l1_ratio=l1_ratio,\n",
    "                              solver='liblinear',random_state=1)\n",
    "    \n",
    "# Step 2: Scoring method:\n",
    "    score = model_selection.cross_val_score(model, X, y, n_jobs=8, scoring=\"accuracy\",cv=Cv_optuna)\n",
    "    accuracy = score.mean()\n",
    "    return accuracy\n",
    "\n",
    "# Step 3: Running it\n",
    "study = optuna.create_study(direction=\"maximize\",sampler=optuna.samplers.TPESampler(seed=1))\n",
    "study.optimize(objective, n_trials=100, show_progress_bar=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "36a76651-b007-4715-a58f-8776deab4b8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best parameters are : \n",
      "{'logreg_c': 1.5684558195868687, 'l1_ratio': 0.51063148634346, 'max_iter': 1863}\n"
     ]
    }
   ],
   "source": [
    "# Getting the best parameters:\n",
    "print(f\"The best parameters are : \\n{study.best_params}\")\n",
    "# Setting the best model\n",
    "clf=LogisticRegression(C=study.best_params['logreg_c'],\n",
    "                              max_iter=study.best_params['max_iter'],\n",
    "                              l1_ratio=study.best_params['l1_ratio'],\n",
    "                              solver='liblinear',\n",
    "                              random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "b3ae0d1b-badc-4865-802b-396e3ee1b6cf",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1106: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mean</th>\n",
       "      <th>Se</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Accuracy_test</th>\n",
       "      <td>0.632190</td>\n",
       "      <td>0.014648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Accuracy_train</th>\n",
       "      <td>0.735909</td>\n",
       "      <td>0.004541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1 Score</th>\n",
       "      <td>0.694496</td>\n",
       "      <td>0.013341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Precision</th>\n",
       "      <td>0.627650</td>\n",
       "      <td>0.012121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recall</th>\n",
       "      <td>0.794643</td>\n",
       "      <td>0.021058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Roc_auc</th>\n",
       "      <td>0.673325</td>\n",
       "      <td>0.020325</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Mean        Se\n",
       "Accuracy_test   0.632190  0.014648\n",
       "Accuracy_train  0.735909  0.004541\n",
       "F1 Score        0.694496  0.013341\n",
       "Precision       0.627650  0.012121\n",
       "Recall          0.794643  0.021058\n",
       "Roc_auc         0.673325  0.020325"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Model2\n",
    "Model2=Model_results(clf,X,y,Cv_model)\n",
    "Model2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "a5007e9c-21fb-4007-bc2e-d5875dabe240",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th>Method</th>\n",
       "      <th colspan=\"4\" halign=\"left\">LR</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model</th>\n",
       "      <th colspan=\"2\" halign=\"left\">Model 1</th>\n",
       "      <th colspan=\"2\" halign=\"left\">Model 2</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Values</th>\n",
       "      <th>Mean</th>\n",
       "      <th>Se</th>\n",
       "      <th>Mean</th>\n",
       "      <th>Se</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Accuracy_test</th>\n",
       "      <td>0.680000</td>\n",
       "      <td>0.012329</td>\n",
       "      <td>0.632190</td>\n",
       "      <td>0.014648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Accuracy_train</th>\n",
       "      <td>0.925345</td>\n",
       "      <td>0.005584</td>\n",
       "      <td>0.735909</td>\n",
       "      <td>0.004541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1 Score</th>\n",
       "      <td>0.706865</td>\n",
       "      <td>0.012092</td>\n",
       "      <td>0.694496</td>\n",
       "      <td>0.013341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Precision</th>\n",
       "      <td>0.698240</td>\n",
       "      <td>0.013460</td>\n",
       "      <td>0.627650</td>\n",
       "      <td>0.012121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recall</th>\n",
       "      <td>0.735714</td>\n",
       "      <td>0.020076</td>\n",
       "      <td>0.794643</td>\n",
       "      <td>0.021058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Roc_auc</th>\n",
       "      <td>0.690561</td>\n",
       "      <td>0.015281</td>\n",
       "      <td>0.673325</td>\n",
       "      <td>0.020325</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Method                LR                              \n",
       "Model            Model 1             Model 2          \n",
       "Values              Mean        Se      Mean        Se\n",
       "Accuracy_test   0.680000  0.012329  0.632190  0.014648\n",
       "Accuracy_train  0.925345  0.005584  0.735909  0.004541\n",
       "F1 Score        0.706865  0.012092  0.694496  0.013341\n",
       "Precision       0.698240  0.013460  0.627650  0.012121\n",
       "Recall          0.735714  0.020076  0.794643  0.021058\n",
       "Roc_auc         0.690561  0.015281  0.673325  0.020325"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Saving the data of model performance\n",
    "Model_data=pd.concat([Model1,Model2],axis=1)\n",
    "Model_data.columns = [['LR']*4,['Model 1','Model 1', 'Model 2','Model 2'], ['Mean', 'Se', 'Mean', 'Se']]  \n",
    "Model_data.columns.names=['Method','Model','Values']\n",
    "Model_data.to_csv(\"./Results/LR_model_mlrem_data.csv\",sep=',')\n",
    "Model_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "892cd0c1-3914-4d08-a63a-550ffd5f60fb",
   "metadata": {},
   "source": [
    "## 2.3 RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "570a3fc5-5ce1-4bd8-a18a-b9209126a44e",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf=RandomForestClassifier(random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "4448a0ec-3f59-45ad-be0b-3713b3c0072b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mean</th>\n",
       "      <th>Se</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Accuracy_test</th>\n",
       "      <td>0.676381</td>\n",
       "      <td>0.014691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Accuracy_train</th>\n",
       "      <td>0.978164</td>\n",
       "      <td>0.001539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1 Score</th>\n",
       "      <td>0.711877</td>\n",
       "      <td>0.013423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Precision</th>\n",
       "      <td>0.688878</td>\n",
       "      <td>0.014746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recall</th>\n",
       "      <td>0.757857</td>\n",
       "      <td>0.020561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Roc_auc</th>\n",
       "      <td>0.756424</td>\n",
       "      <td>0.017012</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Mean        Se\n",
       "Accuracy_test   0.676381  0.014691\n",
       "Accuracy_train  0.978164  0.001539\n",
       "F1 Score        0.711877  0.013423\n",
       "Precision       0.688878  0.014746\n",
       "Recall          0.757857  0.020561\n",
       "Roc_auc         0.756424  0.017012"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Model1\n",
    "Model1_clf=clf\n",
    "#Model1\n",
    "Model1=Model_results(Model1_clf,X,y,Cv_model)\n",
    "Model1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "d0f9ce84-3537-484b-9862-bf7cefca94b8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2024-01-12 01:35:16,075]\u001b[0m A new study created in memory with name: no-name-0e368382-34a5-42fd-91ba-b1b1a0a8e3bf\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:35:19,314]\u001b[0m Trial 0 finished with value: 0.5352380952380952 and parameters: {'n_estimators': 594, 'max_depth': 16, 'max_features': 20, 'min_impurity_decrease': 2.724415914984484}. Best is trial 0 with value: 0.5352380952380952.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:35:21,908]\u001b[0m Trial 1 finished with value: 0.5352380952380952 and parameters: {'n_estimators': 481, 'max_depth': 15, 'max_features': 16, 'min_impurity_decrease': 4.4588650039103985}. Best is trial 0 with value: 0.5352380952380952.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:35:27,120]\u001b[0m Trial 2 finished with value: 0.5352380952380952 and parameters: {'n_estimators': 968, 'max_depth': 11, 'max_features': 25, 'min_impurity_decrease': 2.644474598764522}. Best is trial 0 with value: 0.5352380952380952.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:35:30,335]\u001b[0m Trial 3 finished with value: 0.5352380952380952 and parameters: {'n_estimators': 611, 'max_depth': 19, 'max_features': 6, 'min_impurity_decrease': 0.43564649850770354}. Best is trial 0 with value: 0.5352380952380952.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:35:31,006]\u001b[0m Trial 4 finished with value: 0.5352380952380952 and parameters: {'n_estimators': 118, 'max_depth': 18, 'max_features': 25, 'min_impurity_decrease': 4.3500607412340955}. Best is trial 0 with value: 0.5352380952380952.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:35:36,134]\u001b[0m Trial 5 finished with value: 0.5352380952380952 and parameters: {'n_estimators': 981, 'max_depth': 17, 'max_features': 16, 'min_impurity_decrease': 3.902645881432277}. Best is trial 0 with value: 0.5352380952380952.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:35:37,261]\u001b[0m Trial 6 finished with value: 0.5352380952380952 and parameters: {'n_estimators': 206, 'max_depth': 15, 'max_features': 8, 'min_impurity_decrease': 4.7233445852479194}. Best is trial 0 with value: 0.5352380952380952.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:35:40,255]\u001b[0m Trial 7 finished with value: 0.5352380952380952 and parameters: {'n_estimators': 570, 'max_depth': 11, 'max_features': 11, 'min_impurity_decrease': 3.871168447171083}. Best is trial 0 with value: 0.5352380952380952.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:35:42,854]\u001b[0m Trial 8 finished with value: 0.5352380952380952 and parameters: {'n_estimators': 510, 'max_depth': 14, 'max_features': 5, 'min_impurity_decrease': 3.0881774853793855}. Best is trial 0 with value: 0.5352380952380952.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:35:46,294]\u001b[0m Trial 9 finished with value: 0.5352380952380952 and parameters: {'n_estimators': 651, 'max_depth': 14, 'max_features': 29, 'min_impurity_decrease': 3.409101495517417}. Best is trial 0 with value: 0.5352380952380952.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:35:50,414]\u001b[0m Trial 10 finished with value: 0.5352380952380952 and parameters: {'n_estimators': 790, 'max_depth': 7, 'max_features': 21, 'min_impurity_decrease': 1.5046577569438309}. Best is trial 0 with value: 0.5352380952380952.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:35:52,562]\u001b[0m Trial 11 finished with value: 0.5352380952380952 and parameters: {'n_estimators': 397, 'max_depth': 20, 'max_features': 16, 'min_impurity_decrease': 1.9887909510549393}. Best is trial 0 with value: 0.5352380952380952.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:35:54,439]\u001b[0m Trial 12 finished with value: 0.5352380952380952 and parameters: {'n_estimators': 353, 'max_depth': 16, 'max_features': 20, 'min_impurity_decrease': 0.7029374955194359}. Best is trial 0 with value: 0.5352380952380952.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:35:56,713]\u001b[0m Trial 13 finished with value: 0.5352380952380952 and parameters: {'n_estimators': 411, 'max_depth': 12, 'max_features': 12, 'min_impurity_decrease': 4.931175650908394}. Best is trial 0 with value: 0.5352380952380952.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:36:00,636]\u001b[0m Trial 14 finished with value: 0.5352380952380952 and parameters: {'n_estimators': 743, 'max_depth': 7, 'max_features': 19, 'min_impurity_decrease': 1.5253121430442067}. Best is trial 0 with value: 0.5352380952380952.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:36:04,681]\u001b[0m Trial 15 finished with value: 0.5352380952380952 and parameters: {'n_estimators': 757, 'max_depth': 13, 'max_features': 12, 'min_impurity_decrease': 2.668111844473928}. Best is trial 0 with value: 0.5352380952380952.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:36:06,269]\u001b[0m Trial 16 finished with value: 0.5352380952380952 and parameters: {'n_estimators': 286, 'max_depth': 9, 'max_features': 24, 'min_impurity_decrease': 3.4814210246729473}. Best is trial 0 with value: 0.5352380952380952.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:36:10,648]\u001b[0m Trial 17 finished with value: 0.5352380952380952 and parameters: {'n_estimators': 807, 'max_depth': 5, 'max_features': 19, 'min_impurity_decrease': 1.4307627258174422}. Best is trial 0 with value: 0.5352380952380952.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:36:14,484]\u001b[0m Trial 18 finished with value: 0.5352380952380952 and parameters: {'n_estimators': 714, 'max_depth': 13, 'max_features': 12, 'min_impurity_decrease': 2.574069984147719}. Best is trial 0 with value: 0.5352380952380952.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:36:16,040]\u001b[0m Trial 19 finished with value: 0.5352380952380952 and parameters: {'n_estimators': 291, 'max_depth': 8, 'max_features': 24, 'min_impurity_decrease': 3.3144569973486893}. Best is trial 0 with value: 0.5352380952380952.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:36:20,679]\u001b[0m Trial 20 finished with value: 0.5352380952380952 and parameters: {'n_estimators': 871, 'max_depth': 5, 'max_features': 29, 'min_impurity_decrease': 1.0528796896599464}. Best is trial 0 with value: 0.5352380952380952.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:36:24,313]\u001b[0m Trial 21 finished with value: 0.5352380952380952 and parameters: {'n_estimators': 670, 'max_depth': 10, 'max_features': 14, 'min_impurity_decrease': 2.1272690676619246}. Best is trial 0 with value: 0.5352380952380952.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:36:27,036]\u001b[0m Trial 22 finished with value: 0.5352380952380952 and parameters: {'n_estimators': 502, 'max_depth': 9, 'max_features': 23, 'min_impurity_decrease': 3.0212243946132653}. Best is trial 0 with value: 0.5352380952380952.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:36:31,734]\u001b[0m Trial 23 finished with value: 0.5352380952380952 and parameters: {'n_estimators': 871, 'max_depth': 6, 'max_features': 30, 'min_impurity_decrease': 0.8924229302747374}. Best is trial 0 with value: 0.5352380952380952.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:36:35,612]\u001b[0m Trial 24 finished with value: 0.5352380952380952 and parameters: {'n_estimators': 673, 'max_depth': 11, 'max_features': 28, 'min_impurity_decrease': 2.183958261339378}. Best is trial 0 with value: 0.5352380952380952.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:36:41,146]\u001b[0m Trial 25 finished with value: 0.5352380952380952 and parameters: {'n_estimators': 548, 'max_depth': 9, 'max_features': 22, 'min_impurity_decrease': 2.0762642939740097}. Best is trial 0 with value: 0.5352380952380952.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:36:51,062]\u001b[0m Trial 26 finished with value: 0.6323809523809524 and parameters: {'n_estimators': 859, 'max_depth': 7, 'max_features': 27, 'min_impurity_decrease': 0.05016303754931206}. Best is trial 26 with value: 0.6323809523809524.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:37:01,691]\u001b[0m Trial 27 finished with value: 0.672 and parameters: {'n_estimators': 889, 'max_depth': 6, 'max_features': 27, 'min_impurity_decrease': 0.008573433661244079}. Best is trial 27 with value: 0.672.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:37:11,727]\u001b[0m Trial 28 finished with value: 0.6322857142857143 and parameters: {'n_estimators': 901, 'max_depth': 7, 'max_features': 27, 'min_impurity_decrease': 0.04449057244021093}. Best is trial 27 with value: 0.672.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:37:22,093]\u001b[0m Trial 29 finished with value: 0.6254285714285714 and parameters: {'n_estimators': 918, 'max_depth': 7, 'max_features': 27, 'min_impurity_decrease': 0.06568686852538762}. Best is trial 27 with value: 0.672.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:37:30,555]\u001b[0m Trial 30 finished with value: 0.5352380952380952 and parameters: {'n_estimators': 855, 'max_depth': 6, 'max_features': 26, 'min_impurity_decrease': 0.3179551086113602}. Best is trial 27 with value: 0.672.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:37:38,485]\u001b[0m Trial 31 finished with value: 0.597047619047619 and parameters: {'n_estimators': 937, 'max_depth': 7, 'max_features': 27, 'min_impurity_decrease': 0.18490386200494244}. Best is trial 27 with value: 0.672.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:37:46,299]\u001b[0m Trial 32 finished with value: 0.6747619047619048 and parameters: {'n_estimators': 913, 'max_depth': 8, 'max_features': 27, 'min_impurity_decrease': 0.004905793398417582}. Best is trial 32 with value: 0.6747619047619048.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:37:56,619]\u001b[0m Trial 33 finished with value: 0.6761904761904762 and parameters: {'n_estimators': 917, 'max_depth': 6, 'max_features': 30, 'min_impurity_decrease': 0.0020653183224317627}. Best is trial 33 with value: 0.6761904761904762.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:38:05,942]\u001b[0m Trial 34 finished with value: 0.5352380952380952 and parameters: {'n_estimators': 989, 'max_depth': 5, 'max_features': 29, 'min_impurity_decrease': 0.6299600959488392}. Best is trial 33 with value: 0.6761904761904762.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:38:13,475]\u001b[0m Trial 35 finished with value: 0.5352380952380952 and parameters: {'n_estimators': 815, 'max_depth': 8, 'max_features': 30, 'min_impurity_decrease': 0.4674586648441808}. Best is trial 33 with value: 0.6761904761904762.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:38:23,053]\u001b[0m Trial 36 finished with value: 0.5352380952380952 and parameters: {'n_estimators': 961, 'max_depth': 6, 'max_features': 25, 'min_impurity_decrease': 1.1357603095945366}. Best is trial 33 with value: 0.6761904761904762.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:38:31,082]\u001b[0m Trial 37 finished with value: 0.5352380952380952 and parameters: {'n_estimators': 840, 'max_depth': 8, 'max_features': 26, 'min_impurity_decrease': 0.4114799952729883}. Best is trial 33 with value: 0.6761904761904762.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:38:40,979]\u001b[0m Trial 38 finished with value: 0.5352380952380952 and parameters: {'n_estimators': 998, 'max_depth': 10, 'max_features': 23, 'min_impurity_decrease': 0.7115028745023322}. Best is trial 33 with value: 0.6761904761904762.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:38:51,024]\u001b[0m Trial 39 finished with value: 0.6297142857142857 and parameters: {'n_estimators': 903, 'max_depth': 6, 'max_features': 28, 'min_impurity_decrease': 0.06208220513260173}. Best is trial 33 with value: 0.6761904761904762.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:38:58,675]\u001b[0m Trial 40 finished with value: 0.5352380952380952 and parameters: {'n_estimators': 758, 'max_depth': 5, 'max_features': 25, 'min_impurity_decrease': 1.2530333907876288}. Best is trial 33 with value: 0.6761904761904762.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:39:08,515]\u001b[0m Trial 41 finished with value: 0.6322857142857143 and parameters: {'n_estimators': 907, 'max_depth': 8, 'max_features': 27, 'min_impurity_decrease': 0.05286677087361633}. Best is trial 33 with value: 0.6761904761904762.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:39:17,698]\u001b[0m Trial 42 finished with value: 0.5352380952380952 and parameters: {'n_estimators': 942, 'max_depth': 8, 'max_features': 30, 'min_impurity_decrease': 0.5113387488083093}. Best is trial 33 with value: 0.6761904761904762.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:39:26,348]\u001b[0m Trial 43 finished with value: 0.5421904761904762 and parameters: {'n_estimators': 888, 'max_depth': 10, 'max_features': 28, 'min_impurity_decrease': 0.22488874368369016}. Best is trial 33 with value: 0.6761904761904762.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:39:34,856]\u001b[0m Trial 44 finished with value: 0.5352380952380952 and parameters: {'n_estimators': 829, 'max_depth': 6, 'max_features': 26, 'min_impurity_decrease': 0.9284394996974525}. Best is trial 33 with value: 0.6761904761904762.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:39:45,663]\u001b[0m Trial 45 finished with value: 0.6718095238095237 and parameters: {'n_estimators': 948, 'max_depth': 9, 'max_features': 28, 'min_impurity_decrease': 0.0222031983719142}. Best is trial 33 with value: 0.6761904761904762.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:39:55,567]\u001b[0m Trial 46 finished with value: 0.5352380952380952 and parameters: {'n_estimators': 949, 'max_depth': 9, 'max_features': 29, 'min_impurity_decrease': 0.3420653743587697}. Best is trial 33 with value: 0.6761904761904762.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:40:02,772]\u001b[0m Trial 47 finished with value: 0.5352380952380952 and parameters: {'n_estimators': 785, 'max_depth': 7, 'max_features': 9, 'min_impurity_decrease': 0.6816047837540026}. Best is trial 33 with value: 0.6761904761904762.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:40:08,909]\u001b[0m Trial 48 finished with value: 0.5352380952380952 and parameters: {'n_estimators': 622, 'max_depth': 6, 'max_features': 24, 'min_impurity_decrease': 0.8511767213202808}. Best is trial 33 with value: 0.6761904761904762.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:40:09,968]\u001b[0m Trial 49 finished with value: 0.5309523809523808 and parameters: {'n_estimators': 107, 'max_depth': 10, 'max_features': 21, 'min_impurity_decrease': 0.26320721389361473}. Best is trial 33 with value: 0.6761904761904762.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:40:17,265]\u001b[0m Trial 50 finished with value: 0.5352380952380952 and parameters: {'n_estimators': 708, 'max_depth': 12, 'max_features': 28, 'min_impurity_decrease': 1.8082382735708258}. Best is trial 33 with value: 0.6761904761904762.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:40:28,042]\u001b[0m Trial 51 finished with value: 0.676095238095238 and parameters: {'n_estimators': 962, 'max_depth': 7, 'max_features': 27, 'min_impurity_decrease': 0.02106459317315383}. Best is trial 33 with value: 0.6761904761904762.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:40:37,749]\u001b[0m Trial 52 finished with value: 0.5352380952380952 and parameters: {'n_estimators': 955, 'max_depth': 7, 'max_features': 26, 'min_impurity_decrease': 0.49937746742507}. Best is trial 33 with value: 0.6761904761904762.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:40:47,221]\u001b[0m Trial 53 finished with value: 0.5323809523809523 and parameters: {'n_estimators': 989, 'max_depth': 5, 'max_features': 30, 'min_impurity_decrease': 0.24933984959020736}. Best is trial 33 with value: 0.6761904761904762.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:40:57,354]\u001b[0m Trial 54 finished with value: 0.671904761904762 and parameters: {'n_estimators': 850, 'max_depth': 8, 'max_features': 29, 'min_impurity_decrease': 0.00020460322913867096}. Best is trial 33 with value: 0.6761904761904762.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:41:06,231]\u001b[0m Trial 55 finished with value: 0.5352380952380952 and parameters: {'n_estimators': 926, 'max_depth': 8, 'max_features': 29, 'min_impurity_decrease': 0.5829495913183985}. Best is trial 33 with value: 0.6761904761904762.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:41:13,996]\u001b[0m Trial 56 finished with value: 0.5352380952380952 and parameters: {'n_estimators': 807, 'max_depth': 9, 'max_features': 25, 'min_impurity_decrease': 4.063447563238093}. Best is trial 33 with value: 0.6761904761904762.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:41:24,402]\u001b[0m Trial 57 finished with value: 0.6761904761904762 and parameters: {'n_estimators': 880, 'max_depth': 11, 'max_features': 28, 'min_impurity_decrease': 0.007051219363487071}. Best is trial 33 with value: 0.6761904761904762.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:41:26,100]\u001b[0m Trial 58 finished with value: 0.5352380952380952 and parameters: {'n_estimators': 167, 'max_depth': 11, 'max_features': 29, 'min_impurity_decrease': 0.798147610103549}. Best is trial 33 with value: 0.6761904761904762.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:41:33,758]\u001b[0m Trial 59 finished with value: 0.5352380952380952 and parameters: {'n_estimators': 770, 'max_depth': 18, 'max_features': 30, 'min_impurity_decrease': 0.382341636539112}. Best is trial 33 with value: 0.6761904761904762.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:41:41,537]\u001b[0m Trial 60 finished with value: 0.5309523809523808 and parameters: {'n_estimators': 843, 'max_depth': 16, 'max_features': 17, 'min_impurity_decrease': 0.2654469511283595}. Best is trial 33 with value: 0.6761904761904762.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:41:52,032]\u001b[0m Trial 61 finished with value: 0.6776190476190476 and parameters: {'n_estimators': 879, 'max_depth': 9, 'max_features': 28, 'min_impurity_decrease': 0.008123194334826785}. Best is trial 61 with value: 0.6776190476190476.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:42:01,231]\u001b[0m Trial 62 finished with value: 0.5956190476190477 and parameters: {'n_estimators': 876, 'max_depth': 12, 'max_features': 28, 'min_impurity_decrease': 0.18049512848250882}. Best is trial 61 with value: 0.6776190476190476.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:42:09,726]\u001b[0m Trial 63 finished with value: 0.5352380952380952 and parameters: {'n_estimators': 889, 'max_depth': 8, 'max_features': 26, 'min_impurity_decrease': 0.5086713670369812}. Best is trial 61 with value: 0.6776190476190476.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:42:16,982]\u001b[0m Trial 64 finished with value: 0.5983809523809525 and parameters: {'n_estimators': 736, 'max_depth': 14, 'max_features': 23, 'min_impurity_decrease': 0.17773926474715257}. Best is trial 61 with value: 0.6776190476190476.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:42:26,203]\u001b[0m Trial 65 finished with value: 0.5352380952380952 and parameters: {'n_estimators': 969, 'max_depth': 10, 'max_features': 29, 'min_impurity_decrease': 0.33631758132430556}. Best is trial 61 with value: 0.6776190476190476.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:42:35,065]\u001b[0m Trial 66 finished with value: 0.6165714285714285 and parameters: {'n_estimators': 925, 'max_depth': 11, 'max_features': 27, 'min_impurity_decrease': 0.1425798717417805}. Best is trial 61 with value: 0.6776190476190476.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:42:44,003]\u001b[0m Trial 67 finished with value: 0.5352380952380952 and parameters: {'n_estimators': 862, 'max_depth': 6, 'max_features': 24, 'min_impurity_decrease': 2.868193262665083}. Best is trial 61 with value: 0.6776190476190476.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:42:51,348]\u001b[0m Trial 68 finished with value: 0.5352380952380952 and parameters: {'n_estimators': 797, 'max_depth': 9, 'max_features': 25, 'min_impurity_decrease': 0.994325851568861}. Best is trial 61 with value: 0.6776190476190476.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:43:00,977]\u001b[0m Trial 69 finished with value: 0.6535238095238095 and parameters: {'n_estimators': 828, 'max_depth': 7, 'max_features': 30, 'min_impurity_decrease': 0.031484934359399815}. Best is trial 61 with value: 0.6776190476190476.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:43:09,542]\u001b[0m Trial 70 finished with value: 0.5352380952380952 and parameters: {'n_estimators': 974, 'max_depth': 8, 'max_features': 15, 'min_impurity_decrease': 0.634550934357082}. Best is trial 61 with value: 0.6776190476190476.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:43:19,004]\u001b[0m Trial 71 finished with value: 0.5352380952380952 and parameters: {'n_estimators': 931, 'max_depth': 9, 'max_features': 28, 'min_impurity_decrease': 0.38649297888281287}. Best is trial 61 with value: 0.6776190476190476.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:43:29,212]\u001b[0m Trial 72 finished with value: 0.6577142857142857 and parameters: {'n_estimators': 899, 'max_depth': 9, 'max_features': 28, 'min_impurity_decrease': 0.030118637469662382}. Best is trial 61 with value: 0.6776190476190476.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:43:40,472]\u001b[0m Trial 73 finished with value: 0.6464761904761906 and parameters: {'n_estimators': 997, 'max_depth': 8, 'max_features': 27, 'min_impurity_decrease': 0.03301911564319314}. Best is trial 61 with value: 0.6776190476190476.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:43:49,058]\u001b[0m Trial 74 finished with value: 0.5832380952380952 and parameters: {'n_estimators': 869, 'max_depth': 7, 'max_features': 29, 'min_impurity_decrease': 0.19804900719497173}. Best is trial 61 with value: 0.6776190476190476.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:44:00,411]\u001b[0m Trial 75 finished with value: 0.6733333333333333 and parameters: {'n_estimators': 960, 'max_depth': 11, 'max_features': 27, 'min_impurity_decrease': 0.0033010724541531968}. Best is trial 61 with value: 0.6776190476190476.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:44:09,453]\u001b[0m Trial 76 finished with value: 0.5352380952380952 and parameters: {'n_estimators': 913, 'max_depth': 11, 'max_features': 26, 'min_impurity_decrease': 0.42939915296424785}. Best is trial 61 with value: 0.6776190476190476.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:44:18,106]\u001b[0m Trial 77 finished with value: 0.5941904761904763 and parameters: {'n_estimators': 841, 'max_depth': 13, 'max_features': 27, 'min_impurity_decrease': 0.16676348958431253}. Best is trial 61 with value: 0.6776190476190476.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:44:22,894]\u001b[0m Trial 78 finished with value: 0.5352380952380952 and parameters: {'n_estimators': 457, 'max_depth': 6, 'max_features': 29, 'min_impurity_decrease': 0.7933694921818996}. Best is trial 61 with value: 0.6776190476190476.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:44:31,918]\u001b[0m Trial 79 finished with value: 0.5352380952380952 and parameters: {'n_estimators': 965, 'max_depth': 12, 'max_features': 26, 'min_impurity_decrease': 0.5862286818332793}. Best is trial 61 with value: 0.6776190476190476.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:44:40,745]\u001b[0m Trial 80 finished with value: 0.5352380952380952 and parameters: {'n_estimators': 894, 'max_depth': 10, 'max_features': 30, 'min_impurity_decrease': 0.3144294030115981}. Best is trial 61 with value: 0.6776190476190476.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:44:51,308]\u001b[0m Trial 81 finished with value: 0.6733333333333335 and parameters: {'n_estimators': 934, 'max_depth': 10, 'max_features': 28, 'min_impurity_decrease': 0.006323452295319941}. Best is trial 61 with value: 0.6776190476190476.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:45:00,829]\u001b[0m Trial 82 finished with value: 0.6165714285714285 and parameters: {'n_estimators': 927, 'max_depth': 10, 'max_features': 28, 'min_impurity_decrease': 0.14545468932474404}. Best is trial 61 with value: 0.6776190476190476.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:45:10,329]\u001b[0m Trial 83 finished with value: 0.5352380952380952 and parameters: {'n_estimators': 975, 'max_depth': 5, 'max_features': 27, 'min_impurity_decrease': 0.33087900745123566}. Best is trial 61 with value: 0.6776190476190476.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:45:19,087]\u001b[0m Trial 84 finished with value: 0.5352380952380952 and parameters: {'n_estimators': 874, 'max_depth': 10, 'max_features': 28, 'min_impurity_decrease': 2.387601930957447}. Best is trial 61 with value: 0.6776190476190476.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:45:29,929]\u001b[0m Trial 85 finished with value: 0.6748571428571429 and parameters: {'n_estimators': 952, 'max_depth': 11, 'max_features': 25, 'min_impurity_decrease': 0.0007392099609671288}. Best is trial 61 with value: 0.6776190476190476.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:45:39,247]\u001b[0m Trial 86 finished with value: 0.5352380952380952 and parameters: {'n_estimators': 947, 'max_depth': 11, 'max_features': 26, 'min_impurity_decrease': 0.48146683809049023}. Best is trial 61 with value: 0.6776190476190476.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:45:47,789]\u001b[0m Trial 87 finished with value: 0.6207619047619047 and parameters: {'n_estimators': 915, 'max_depth': 13, 'max_features': 24, 'min_impurity_decrease': 0.13757031221334323}. Best is trial 61 with value: 0.6776190476190476.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:45:58,181]\u001b[0m Trial 88 finished with value: 0.5352380952380952 and parameters: {'n_estimators': 998, 'max_depth': 12, 'max_features': 25, 'min_impurity_decrease': 0.30676748165353357}. Best is trial 61 with value: 0.6776190476190476.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:46:07,313]\u001b[0m Trial 89 finished with value: 0.5352380952380952 and parameters: {'n_estimators': 956, 'max_depth': 11, 'max_features': 27, 'min_impurity_decrease': 4.576798205075603}. Best is trial 61 with value: 0.6776190476190476.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:46:10,360]\u001b[0m Trial 90 finished with value: 0.620952380952381 and parameters: {'n_estimators': 289, 'max_depth': 12, 'max_features': 7, 'min_impurity_decrease': 0.1288307028354426}. Best is trial 61 with value: 0.6776190476190476.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:46:20,365]\u001b[0m Trial 91 finished with value: 0.6761904761904762 and parameters: {'n_estimators': 852, 'max_depth': 7, 'max_features': 29, 'min_impurity_decrease': 0.007725264887275658}. Best is trial 61 with value: 0.6776190476190476.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:46:29,221]\u001b[0m Trial 92 finished with value: 0.5295238095238095 and parameters: {'n_estimators': 889, 'max_depth': 11, 'max_features': 30, 'min_impurity_decrease': 0.2520599220602134}. Best is trial 61 with value: 0.6776190476190476.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:46:38,312]\u001b[0m Trial 93 finished with value: 0.6732380952380952 and parameters: {'n_estimators': 822, 'max_depth': 7, 'max_features': 29, 'min_impurity_decrease': 0.02259369678524981}. Best is trial 61 with value: 0.6776190476190476.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:46:42,912]\u001b[0m Trial 94 finished with value: 0.617904761904762 and parameters: {'n_estimators': 812, 'max_depth': 7, 'max_features': 29, 'min_impurity_decrease': 0.14831488771027054}. Best is trial 61 with value: 0.6776190476190476.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:46:48,995]\u001b[0m Trial 95 finished with value: 0.6761904761904762 and parameters: {'n_estimators': 940, 'max_depth': 7, 'max_features': 28, 'min_impurity_decrease': 0.005823654890190223}. Best is trial 61 with value: 0.6776190476190476.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:46:54,400]\u001b[0m Trial 96 finished with value: 0.5352380952380952 and parameters: {'n_estimators': 938, 'max_depth': 9, 'max_features': 28, 'min_impurity_decrease': 0.4235083475944678}. Best is trial 61 with value: 0.6776190476190476.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:46:59,625]\u001b[0m Trial 97 finished with value: 0.5352380952380952 and parameters: {'n_estimators': 978, 'max_depth': 10, 'max_features': 27, 'min_impurity_decrease': 0.5367328068166792}. Best is trial 61 with value: 0.6776190476190476.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:47:05,409]\u001b[0m Trial 98 finished with value: 0.6733333333333335 and parameters: {'n_estimators': 919, 'max_depth': 8, 'max_features': 30, 'min_impurity_decrease': 0.0005874942435908203}. Best is trial 61 with value: 0.6776190476190476.\u001b[0m\n",
      "\u001b[32m[I 2024-01-12 01:47:10,306]\u001b[0m Trial 99 finished with value: 0.5352380952380952 and parameters: {'n_estimators': 909, 'max_depth': 8, 'max_features': 30, 'min_impurity_decrease': 0.719689906318086}. Best is trial 61 with value: 0.6776190476190476.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "#Tuning hyperparameters\n",
    "#Step 1. Define an objective function to be maximized.\n",
    "def objective(trial):\n",
    "    n_estimators = trial.suggest_int(\"n_estimators\",100,1000,1) \n",
    "    max_depth = trial.suggest_int(\"max_depth\",5,20,1)\n",
    "    max_features = trial.suggest_int(\"max_features\",5,30,1)\n",
    "    min_impurity_decrease = trial.suggest_float(\"min_impurity_decrease\",0,5,log=False) \n",
    "    model = RandomForestClassifier(n_estimators = n_estimators\n",
    "              ,max_depth = max_depth\n",
    "              ,max_features = max_features\n",
    "              ,min_impurity_decrease = min_impurity_decrease\n",
    "              ,random_state=1\n",
    "              ,verbose=False\n",
    "              ,n_jobs=8)\n",
    "\n",
    "# Step 2: Scoring method:\n",
    "    score = model_selection.cross_val_score(model, X, y, n_jobs=8, scoring=\"accuracy\",cv=Cv_optuna)\n",
    "    accuracy = score.mean()\n",
    "    return accuracy\n",
    " \n",
    "# Step 3: Running it\n",
    "study = optuna.create_study(direction=\"maximize\",sampler=optuna.samplers.TPESampler(seed=0))\n",
    "study.optimize(objective, n_trials=100, show_progress_bar=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "9b88d250-7567-4062-b7d5-0a9638d732c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best parameters are : \n",
      "{'n_estimators': 879, 'max_depth': 9, 'max_features': 28, 'min_impurity_decrease': 0.008123194334826785}\n"
     ]
    }
   ],
   "source": [
    "# Getting the best parameters:\n",
    "print(f\"The best parameters are : \\n{study.best_params}\")\n",
    "# Setting the best model\n",
    "clf=RandomForestClassifier(n_estimators = study.best_params['n_estimators']\n",
    "              ,max_depth = study.best_params['max_depth']\n",
    "              ,max_features = study.best_params['max_features']\n",
    "              ,min_impurity_decrease = study.best_params['min_impurity_decrease']\n",
    "              ,random_state=0\n",
    "              ,verbose=False\n",
    "              ,n_jobs=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "a4281260-9ed3-4ed2-93c1-ed1888b7625f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mean</th>\n",
       "      <th>Se</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Accuracy_test</th>\n",
       "      <td>0.670571</td>\n",
       "      <td>0.013460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Accuracy_train</th>\n",
       "      <td>0.974643</td>\n",
       "      <td>0.001874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1 Score</th>\n",
       "      <td>0.703054</td>\n",
       "      <td>0.013994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Precision</th>\n",
       "      <td>0.681364</td>\n",
       "      <td>0.014131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recall</th>\n",
       "      <td>0.749643</td>\n",
       "      <td>0.022551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Roc_auc</th>\n",
       "      <td>0.752985</td>\n",
       "      <td>0.015938</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Mean        Se\n",
       "Accuracy_test   0.670571  0.013460\n",
       "Accuracy_train  0.974643  0.001874\n",
       "F1 Score        0.703054  0.013994\n",
       "Precision       0.681364  0.014131\n",
       "Recall          0.749643  0.022551\n",
       "Roc_auc         0.752985  0.015938"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Model2\n",
    "Model2=Model_results(clf,X,y,Cv_model)\n",
    "Model2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "c06b82a5-a8ce-4b80-b011-d93c0ab3a6cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th>Method</th>\n",
       "      <th colspan=\"4\" halign=\"left\">RF</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model</th>\n",
       "      <th colspan=\"2\" halign=\"left\">Model 1</th>\n",
       "      <th colspan=\"2\" halign=\"left\">Model 2</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Values</th>\n",
       "      <th>Mean</th>\n",
       "      <th>Se</th>\n",
       "      <th>Mean</th>\n",
       "      <th>Se</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Accuracy_test</th>\n",
       "      <td>0.676381</td>\n",
       "      <td>0.014691</td>\n",
       "      <td>0.670571</td>\n",
       "      <td>0.013460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Accuracy_train</th>\n",
       "      <td>0.978164</td>\n",
       "      <td>0.001539</td>\n",
       "      <td>0.974643</td>\n",
       "      <td>0.001874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1 Score</th>\n",
       "      <td>0.711877</td>\n",
       "      <td>0.013423</td>\n",
       "      <td>0.703054</td>\n",
       "      <td>0.013994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Precision</th>\n",
       "      <td>0.688878</td>\n",
       "      <td>0.014746</td>\n",
       "      <td>0.681364</td>\n",
       "      <td>0.014131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recall</th>\n",
       "      <td>0.757857</td>\n",
       "      <td>0.020561</td>\n",
       "      <td>0.749643</td>\n",
       "      <td>0.022551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Roc_auc</th>\n",
       "      <td>0.756424</td>\n",
       "      <td>0.017012</td>\n",
       "      <td>0.752985</td>\n",
       "      <td>0.015938</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Method                RF                              \n",
       "Model            Model 1             Model 2          \n",
       "Values              Mean        Se      Mean        Se\n",
       "Accuracy_test   0.676381  0.014691  0.670571  0.013460\n",
       "Accuracy_train  0.978164  0.001539  0.974643  0.001874\n",
       "F1 Score        0.711877  0.013423  0.703054  0.013994\n",
       "Precision       0.688878  0.014746  0.681364  0.014131\n",
       "Recall          0.757857  0.020561  0.749643  0.022551\n",
       "Roc_auc         0.756424  0.017012  0.752985  0.015938"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Saving the data of model performance\n",
    "Model_data=pd.concat([Model1,Model2],axis=1)\n",
    "Model_data.columns = [['RF']*4,['Model 1','Model 1', 'Model 2','Model 2'], ['Mean', 'Se', 'Mean', 'Se']]  \n",
    "Model_data.columns.names=['Method','Model','Values']\n",
    "Model_data.to_csv(\"./Results/RF_model_mlrem_data.csv\",sep=',')\n",
    "Model_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de27d5ec-8039-4cfd-8629-ad30d87ca90f",
   "metadata": {},
   "source": [
    "## 2.4 XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "19aa8297-4182-4dac-8857-008a9ad45f1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf=xgb.XGBClassifier(random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "66336653-640b-407f-8c25-80c9e29b3651",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mean</th>\n",
       "      <th>Se</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Accuracy_test</th>\n",
       "      <td>0.662476</td>\n",
       "      <td>0.016918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Accuracy_train</th>\n",
       "      <td>0.978164</td>\n",
       "      <td>0.001539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1 Score</th>\n",
       "      <td>0.693483</td>\n",
       "      <td>0.017356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Precision</th>\n",
       "      <td>0.671509</td>\n",
       "      <td>0.015551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recall</th>\n",
       "      <td>0.737143</td>\n",
       "      <td>0.025112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Roc_auc</th>\n",
       "      <td>0.749660</td>\n",
       "      <td>0.017686</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Mean        Se\n",
       "Accuracy_test   0.662476  0.016918\n",
       "Accuracy_train  0.978164  0.001539\n",
       "F1 Score        0.693483  0.017356\n",
       "Precision       0.671509  0.015551\n",
       "Recall          0.737143  0.025112\n",
       "Roc_auc         0.749660  0.017686"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Model1 \n",
    "Model1_clf=clf\n",
    "#Model1\n",
    "Model1=Model_results(Model1_clf,X,y,Cv_model)\n",
    "Model1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "2184b863-0c03-4641-8e98-2b00c0fd5878",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2024-01-12 01:49:39,219]\u001b[0m A new study created in memory with name: no-name-9bfd5a88-8b2a-4996-844c-9f159bf96100\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-01-12 01:49:44,945]\u001b[0m Trial 0 finished with value: 0.6608571428571429 and parameters: {'lambda': 0.15676677195506075, 'alpha': 0.7257005721594281, 'colsample_bytree': 0.7, 'subsample': 0.7000000000000001, 'learning_rate': 0.0801, 'n_estimators': 664}. Best is trial 0 with value: 0.6608571428571429.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-01-12 01:49:47,925]\u001b[0m Trial 1 finished with value: 0.6323809523809524 and parameters: {'lambda': 0.0562793204741517, 'alpha': 3.6905577292137624, 'colsample_bytree': 1.0, 'subsample': 0.6000000000000001, 'learning_rate': 0.1551, 'n_estimators': 552}. Best is trial 0 with value: 0.6608571428571429.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-01-12 01:49:51,796]\u001b[0m Trial 2 finished with value: 0.5408571428571428 and parameters: {'lambda': 0.18714500686240676, 'alpha': 5.039489598671215, 'colsample_bytree': 0.3, 'subsample': 0.4, 'learning_rate': 0.0001, 'n_estimators': 841}. Best is trial 0 with value: 0.6608571428571429.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-01-12 01:49:56,159]\u001b[0m Trial 3 finished with value: 0.6392380952380953 and parameters: {'lambda': 1.2960656597279736, 'alpha': 3.0202896401586674, 'colsample_bytree': 1.0, 'subsample': 0.9, 'learning_rate': 0.0901, 'n_estimators': 792}. Best is trial 0 with value: 0.6608571428571429.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-01-12 01:49:59,349]\u001b[0m Trial 4 finished with value: 0.6553333333333334 and parameters: {'lambda': 0.0029723346443356552, 'alpha': 0.3628140404024381, 'colsample_bytree': 0.4, 'subsample': 1.0, 'learning_rate': 0.10010000000000001, 'n_estimators': 444}. Best is trial 0 with value: 0.6608571428571429.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-01-12 01:50:06,638]\u001b[0m Trial 5 finished with value: 0.638 and parameters: {'lambda': 0.011434638743472197, 'alpha': 1.2500712230836255, 'colsample_bytree': 0.6000000000000001, 'subsample': 0.7000000000000001, 'learning_rate': 0.0001, 'n_estimators': 637}. Best is trial 0 with value: 0.6608571428571429.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-01-12 01:50:10,699]\u001b[0m Trial 6 finished with value: 0.6510476190476191 and parameters: {'lambda': 0.2807908107885728, 'alpha': 0.2935864364395359, 'colsample_bytree': 1.0, 'subsample': 0.8, 'learning_rate': 0.07010000000000001, 'n_estimators': 465}. Best is trial 0 with value: 0.6608571428571429.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-01-12 01:50:12,762]\u001b[0m Trial 7 finished with value: 0.6508571428571429 and parameters: {'lambda': 0.6173405204074314, 'alpha': 0.0017414134181586202, 'colsample_bytree': 0.8, 'subsample': 0.8, 'learning_rate': 0.040100000000000004, 'n_estimators': 172}. Best is trial 0 with value: 0.6608571428571429.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-01-12 01:50:13,989]\u001b[0m Trial 8 finished with value: 0.6779047619047618 and parameters: {'lambda': 0.01826894228153233, 'alpha': 0.028499883436971588, 'colsample_bytree': 0.7, 'subsample': 0.7000000000000001, 'learning_rate': 0.1951, 'n_estimators': 147}. Best is trial 8 with value: 0.6779047619047618.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-01-12 01:50:16,120]\u001b[0m Trial 9 finished with value: 0.667904761904762 and parameters: {'lambda': 0.006847105576684045, 'alpha': 0.004418125737902547, 'colsample_bytree': 0.8, 'subsample': 0.5, 'learning_rate': 0.0901, 'n_estimators': 282}. Best is trial 8 with value: 0.6779047619047618.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-01-12 01:50:16,755]\u001b[0m Trial 10 finished with value: 0.6451428571428572 and parameters: {'lambda': 5.790132527437195, 'alpha': 0.025043968115100592, 'colsample_bytree': 0.5, 'subsample': 0.5, 'learning_rate': 0.1901, 'n_estimators': 57}. Best is trial 8 with value: 0.6779047619047618.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-01-12 01:50:18,686]\u001b[0m Trial 11 finished with value: 0.6690476190476192 and parameters: {'lambda': 0.017123553109627314, 'alpha': 0.013676263870483537, 'colsample_bytree': 0.8, 'subsample': 0.5, 'learning_rate': 0.14509999999999998, 'n_estimators': 277}. Best is trial 8 with value: 0.6779047619047618.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-01-12 01:50:20,734]\u001b[0m Trial 12 finished with value: 0.6763809523809523 and parameters: {'lambda': 0.02491353701899208, 'alpha': 0.023063141329483616, 'colsample_bytree': 0.8, 'subsample': 0.4, 'learning_rate': 0.15009999999999998, 'n_estimators': 319}. Best is trial 8 with value: 0.6779047619047618.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-01-12 01:50:22,688]\u001b[0m Trial 13 finished with value: 0.662 and parameters: {'lambda': 0.04474111800996658, 'alpha': 0.038990832725213885, 'colsample_bytree': 0.6000000000000001, 'subsample': 0.4, 'learning_rate': 0.1951, 'n_estimators': 316}. Best is trial 8 with value: 0.6779047619047618.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-01-12 01:50:23,622]\u001b[0m Trial 14 finished with value: 0.6509523809523808 and parameters: {'lambda': 0.0012140452982167488, 'alpha': 0.06910620324453418, 'colsample_bytree': 0.7, 'subsample': 0.6000000000000001, 'learning_rate': 0.1551, 'n_estimators': 94}. Best is trial 8 with value: 0.6779047619047618.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-01-12 01:50:25,465]\u001b[0m Trial 15 finished with value: 0.6680000000000001 and parameters: {'lambda': 0.027126643489253296, 'alpha': 0.0045017087887461935, 'colsample_bytree': 0.9000000000000001, 'subsample': 1.0, 'learning_rate': 0.1301, 'n_estimators': 204}. Best is trial 8 with value: 0.6779047619047618.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-01-12 01:50:27,896]\u001b[0m Trial 16 finished with value: 0.6703809523809525 and parameters: {'lambda': 0.004818440651909064, 'alpha': 0.16888877355169551, 'colsample_bytree': 0.5, 'subsample': 0.6000000000000001, 'learning_rate': 0.1751, 'n_estimators': 358}. Best is trial 8 with value: 0.6779047619047618.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-01-12 01:50:29,534]\u001b[0m Trial 17 finished with value: 0.6649523809523811 and parameters: {'lambda': 0.0010007385532741818, 'alpha': 0.009646273191219181, 'colsample_bytree': 0.9000000000000001, 'subsample': 0.8, 'learning_rate': 0.1201, 'n_estimators': 181}. Best is trial 8 with value: 0.6779047619047618.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-01-12 01:50:31,793]\u001b[0m Trial 18 finished with value: 0.6763809523809524 and parameters: {'lambda': 0.061634227943790754, 'alpha': 0.07305295568841107, 'colsample_bytree': 0.7, 'subsample': 0.4, 'learning_rate': 0.1701, 'n_estimators': 367}. Best is trial 8 with value: 0.6779047619047618.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-01-12 01:50:36,908]\u001b[0m Trial 19 finished with value: 0.6748571428571429 and parameters: {'lambda': 0.08189216606299816, 'alpha': 0.09137793328553549, 'colsample_bytree': 0.5, 'subsample': 0.6000000000000001, 'learning_rate': 0.1751, 'n_estimators': 930}. Best is trial 8 with value: 0.6779047619047618.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-01-12 01:50:40,298]\u001b[0m Trial 20 finished with value: 0.6764761904761906 and parameters: {'lambda': 1.6767154928982846, 'alpha': 0.0016483661900255071, 'colsample_bytree': 0.7, 'subsample': 0.9, 'learning_rate': 0.1751, 'n_estimators': 429}. Best is trial 8 with value: 0.6779047619047618.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-01-12 01:50:44,316]\u001b[0m Trial 21 finished with value: 0.6525714285714286 and parameters: {'lambda': 7.401604059812908, 'alpha': 0.0010968075467978052, 'colsample_bytree': 0.7, 'subsample': 0.9, 'learning_rate': 0.18009999999999998, 'n_estimators': 421}. Best is trial 8 with value: 0.6779047619047618.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-01-12 01:50:48,618]\u001b[0m Trial 22 finished with value: 0.6694285714285715 and parameters: {'lambda': 2.0928422583512405, 'alpha': 0.0036652235601470915, 'colsample_bytree': 0.6000000000000001, 'subsample': 0.9, 'learning_rate': 0.1701, 'n_estimators': 558}. Best is trial 8 with value: 0.6779047619047618.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-01-12 01:50:51,373]\u001b[0m Trial 23 finished with value: 0.6751428571428572 and parameters: {'lambda': 0.6439279076937869, 'alpha': 0.04386602055339343, 'colsample_bytree': 0.7, 'subsample': 0.7000000000000001, 'learning_rate': 0.1951, 'n_estimators': 391}. Best is trial 8 with value: 0.6779047619047618.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-01-12 01:50:54,900]\u001b[0m Trial 24 finished with value: 0.6764761904761905 and parameters: {'lambda': 0.3883136303907193, 'alpha': 0.010049953917114773, 'colsample_bytree': 0.6000000000000001, 'subsample': 0.8, 'learning_rate': 0.1301, 'n_estimators': 496}. Best is trial 8 with value: 0.6779047619047618.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-01-12 01:50:59,980]\u001b[0m Trial 25 finished with value: 0.6653333333333333 and parameters: {'lambda': 2.7802503139996473, 'alpha': 0.008337657822509066, 'colsample_bytree': 0.6000000000000001, 'subsample': 0.8, 'learning_rate': 0.1301, 'n_estimators': 656}. Best is trial 8 with value: 0.6779047619047618.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-01-12 01:51:05,250]\u001b[0m Trial 26 finished with value: 0.6790476190476192 and parameters: {'lambda': 0.5989769734564016, 'alpha': 0.001754204354028918, 'colsample_bytree': 0.4, 'subsample': 0.9, 'learning_rate': 0.11510000000000001, 'n_estimators': 725}. Best is trial 26 with value: 0.6790476190476192.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-01-12 01:51:12,244]\u001b[0m Trial 27 finished with value: 0.6693333333333336 and parameters: {'lambda': 1.2518838419016274, 'alpha': 0.002084110757581769, 'colsample_bytree': 0.4, 'subsample': 0.9, 'learning_rate': 0.0451, 'n_estimators': 779}. Best is trial 26 with value: 0.6790476190476192.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-01-12 01:51:21,465]\u001b[0m Trial 28 finished with value: 0.6609523809523811 and parameters: {'lambda': 4.723187635059192, 'alpha': 0.002467585771750723, 'colsample_bytree': 0.3, 'subsample': 1.0, 'learning_rate': 0.050100000000000006, 'n_estimators': 916}. Best is trial 26 with value: 0.6790476190476192.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-01-12 01:51:26,158]\u001b[0m Trial 29 finished with value: 0.6861904761904764 and parameters: {'lambda': 0.1357530766063751, 'alpha': 0.00604912334356112, 'colsample_bytree': 0.4, 'subsample': 0.7000000000000001, 'learning_rate': 0.11510000000000001, 'n_estimators': 740}. Best is trial 29 with value: 0.6861904761904764.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-01-12 01:51:30,752]\u001b[0m Trial 30 finished with value: 0.6750476190476192 and parameters: {'lambda': 0.18092199214591256, 'alpha': 0.0010057216538091605, 'colsample_bytree': 0.4, 'subsample': 0.7000000000000001, 'learning_rate': 0.1101, 'n_estimators': 709}. Best is trial 29 with value: 0.6861904761904764.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-01-12 01:51:35,311]\u001b[0m Trial 31 finished with value: 0.6751428571428572 and parameters: {'lambda': 0.11119277519798368, 'alpha': 0.006118149756823851, 'colsample_bytree': 0.5, 'subsample': 0.7000000000000001, 'learning_rate': 0.11510000000000001, 'n_estimators': 723}. Best is trial 29 with value: 0.6861904761904764.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-01-12 01:51:40,257]\u001b[0m Trial 32 finished with value: 0.6821904761904765 and parameters: {'lambda': 0.6301118583785598, 'alpha': 0.01900920382279658, 'colsample_bytree': 0.4, 'subsample': 0.9, 'learning_rate': 0.0651, 'n_estimators': 591}. Best is trial 29 with value: 0.6861904761904764.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-01-12 01:51:45,058]\u001b[0m Trial 33 finished with value: 0.6763809523809524 and parameters: {'lambda': 0.6999320996994477, 'alpha': 0.016156842125445648, 'colsample_bytree': 0.3, 'subsample': 0.7000000000000001, 'learning_rate': 0.0601, 'n_estimators': 588}. Best is trial 29 with value: 0.6861904761904764.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-01-12 01:51:52,041]\u001b[0m Trial 34 finished with value: 0.674952380952381 and parameters: {'lambda': 0.3527627967271589, 'alpha': 0.030241715405447074, 'colsample_bytree': 0.4, 'subsample': 0.8, 'learning_rate': 0.0751, 'n_estimators': 991}. Best is trial 29 with value: 0.6861904761904764.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-01-12 01:51:59,408]\u001b[0m Trial 35 finished with value: 0.6609523809523811 and parameters: {'lambda': 0.14364941444825624, 'alpha': 0.017627889213148507, 'colsample_bytree': 0.3, 'subsample': 0.6000000000000001, 'learning_rate': 0.0201, 'n_estimators': 836}. Best is trial 29 with value: 0.6861904761904764.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-01-12 01:52:04,321]\u001b[0m Trial 36 finished with value: 0.6680000000000001 and parameters: {'lambda': 1.0360787933743876, 'alpha': 0.006610100039382611, 'colsample_bytree': 0.4, 'subsample': 1.0, 'learning_rate': 0.10010000000000001, 'n_estimators': 590}. Best is trial 29 with value: 0.6861904761904764.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-01-12 01:52:07,614]\u001b[0m Trial 37 finished with value: 0.5927619047619048 and parameters: {'lambda': 0.24008342239429287, 'alpha': 8.861629685772453, 'colsample_bytree': 0.5, 'subsample': 0.7000000000000001, 'learning_rate': 0.08510000000000001, 'n_estimators': 730}. Best is trial 29 with value: 0.6861904761904764.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-01-12 01:52:14,227]\u001b[0m Trial 38 finished with value: 0.6707619047619049 and parameters: {'lambda': 0.037769804089962805, 'alpha': 0.17532934883981124, 'colsample_bytree': 0.4, 'subsample': 0.9, 'learning_rate': 0.0201, 'n_estimators': 622}. Best is trial 29 with value: 0.6861904761904764.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-01-12 01:52:17,939]\u001b[0m Trial 39 finished with value: 0.677904761904762 and parameters: {'lambda': 0.08654988469845346, 'alpha': 0.0033305961239733462, 'colsample_bytree': 0.3, 'subsample': 0.8, 'learning_rate': 0.1401, 'n_estimators': 535}. Best is trial 29 with value: 0.6861904761904764.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-01-12 01:52:22,157]\u001b[0m Trial 40 finished with value: 0.667904761904762 and parameters: {'lambda': 0.4364559577785702, 'alpha': 0.002986127875870649, 'colsample_bytree': 0.3, 'subsample': 0.8, 'learning_rate': 0.1051, 'n_estimators': 529}. Best is trial 29 with value: 0.6861904761904764.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-01-12 01:52:26,780]\u001b[0m Trial 41 finished with value: 0.6820952380952382 and parameters: {'lambda': 0.012041246302698917, 'alpha': 0.005755556753698326, 'colsample_bytree': 0.3, 'subsample': 0.9, 'learning_rate': 0.1401, 'n_estimators': 679}. Best is trial 29 with value: 0.6861904761904764.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-01-12 01:52:30,094]\u001b[0m Trial 42 finished with value: 0.6821904761904761 and parameters: {'lambda': 0.00976530253589791, 'alpha': 0.004521658633426094, 'colsample_bytree': 0.3, 'subsample': 0.9, 'learning_rate': 0.1401, 'n_estimators': 692}. Best is trial 29 with value: 0.6861904761904764.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-01-12 01:52:31,968]\u001b[0m Trial 43 finished with value: 0.6820952380952382 and parameters: {'lambda': 0.009533938648370993, 'alpha': 0.005142380479852608, 'colsample_bytree': 0.4, 'subsample': 0.9, 'learning_rate': 0.1201, 'n_estimators': 779}. Best is trial 29 with value: 0.6861904761904764.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-01-12 01:52:34,015]\u001b[0m Trial 44 finished with value: 0.701714285714286 and parameters: {'lambda': 0.008556178294461857, 'alpha': 0.00559859295117001, 'colsample_bytree': 0.3, 'subsample': 1.0, 'learning_rate': 0.1601, 'n_estimators': 792}. Best is trial 44 with value: 0.701714285714286.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-01-12 01:52:35,874]\u001b[0m Trial 45 finished with value: 0.7003809523809525 and parameters: {'lambda': 0.002736395942107596, 'alpha': 0.010967284413723879, 'colsample_bytree': 0.3, 'subsample': 1.0, 'learning_rate': 0.1601, 'n_estimators': 687}. Best is trial 44 with value: 0.701714285714286.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-01-12 01:52:38,163]\u001b[0m Trial 46 finished with value: 0.6960952380952382 and parameters: {'lambda': 0.0028166231869091456, 'alpha': 0.009994188044722196, 'colsample_bytree': 0.3, 'subsample': 1.0, 'learning_rate': 0.1651, 'n_estimators': 830}. Best is trial 44 with value: 0.701714285714286.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-01-12 01:52:40,457]\u001b[0m Trial 47 finished with value: 0.6947619047619049 and parameters: {'lambda': 0.0019027548784550043, 'alpha': 0.012393652417147363, 'colsample_bytree': 0.3, 'subsample': 1.0, 'learning_rate': 0.0651, 'n_estimators': 836}. Best is trial 44 with value: 0.701714285714286.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-01-12 01:52:42,704]\u001b[0m Trial 48 finished with value: 0.6960952380952381 and parameters: {'lambda': 0.0024183815673537484, 'alpha': 0.011729643522042612, 'colsample_bytree': 0.3, 'subsample': 1.0, 'learning_rate': 0.1851, 'n_estimators': 846}. Best is trial 44 with value: 0.701714285714286.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-01-12 01:52:44,291]\u001b[0m Trial 49 finished with value: 0.6551428571428572 and parameters: {'lambda': 0.0019408046467350051, 'alpha': 1.0433113847404174, 'colsample_bytree': 0.3, 'subsample': 1.0, 'learning_rate': 0.1851, 'n_estimators': 854}. Best is trial 44 with value: 0.701714285714286.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-01-12 01:52:46,542]\u001b[0m Trial 50 finished with value: 0.7002857142857144 and parameters: {'lambda': 0.0033591891295767654, 'alpha': 0.01382541664678391, 'colsample_bytree': 0.3, 'subsample': 1.0, 'learning_rate': 0.1601, 'n_estimators': 874}. Best is trial 44 with value: 0.701714285714286.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-01-12 01:52:48,705]\u001b[0m Trial 51 finished with value: 0.7017142857142857 and parameters: {'lambda': 0.0034229051056133657, 'alpha': 0.012871271791450633, 'colsample_bytree': 0.3, 'subsample': 1.0, 'learning_rate': 0.1601, 'n_estimators': 866}. Best is trial 44 with value: 0.701714285714286.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-01-12 01:52:51,053]\u001b[0m Trial 52 finished with value: 0.7001904761904763 and parameters: {'lambda': 0.004225220871455537, 'alpha': 0.011370294688030805, 'colsample_bytree': 0.3, 'subsample': 1.0, 'learning_rate': 0.1601, 'n_estimators': 890}. Best is trial 44 with value: 0.701714285714286.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-01-12 01:52:53,527]\u001b[0m Trial 53 finished with value: 0.6960000000000002 and parameters: {'lambda': 0.004103597114144333, 'alpha': 0.04967022533268807, 'colsample_bytree': 0.3, 'subsample': 1.0, 'learning_rate': 0.1601, 'n_estimators': 920}. Best is trial 44 with value: 0.701714285714286.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-01-12 01:52:55,907]\u001b[0m Trial 54 finished with value: 0.7031428571428572 and parameters: {'lambda': 0.004043834319918063, 'alpha': 0.029633425764158693, 'colsample_bytree': 0.3, 'subsample': 1.0, 'learning_rate': 0.1601, 'n_estimators': 894}. Best is trial 54 with value: 0.7031428571428572.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-01-12 01:52:58,610]\u001b[0m Trial 55 finished with value: 0.6975238095238098 and parameters: {'lambda': 0.004980224075064425, 'alpha': 0.03510787695470061, 'colsample_bytree': 0.3, 'subsample': 1.0, 'learning_rate': 0.1551, 'n_estimators': 995}. Best is trial 54 with value: 0.7031428571428572.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-01-12 01:53:00,935]\u001b[0m Trial 56 finished with value: 0.7102857142857144 and parameters: {'lambda': 0.0013221304985698086, 'alpha': 0.02305461805888264, 'colsample_bytree': 0.3, 'subsample': 1.0, 'learning_rate': 0.15009999999999998, 'n_estimators': 884}. Best is trial 56 with value: 0.7102857142857144.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-01-12 01:53:03,490]\u001b[0m Trial 57 finished with value: 0.6793333333333333 and parameters: {'lambda': 0.0012446922418356734, 'alpha': 0.022077479688830965, 'colsample_bytree': 0.4, 'subsample': 1.0, 'learning_rate': 0.15009999999999998, 'n_estimators': 962}. Best is trial 56 with value: 0.7102857142857144.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-01-12 01:53:05,883]\u001b[0m Trial 58 finished with value: 0.6791428571428573 and parameters: {'lambda': 0.006622004577595627, 'alpha': 0.1431496104944084, 'colsample_bytree': 0.3, 'subsample': 1.0, 'learning_rate': 0.1651, 'n_estimators': 885}. Best is trial 56 with value: 0.7102857142857144.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-01-12 01:53:08,000]\u001b[0m Trial 59 finished with value: 0.6751428571428572 and parameters: {'lambda': 0.0014168536815106854, 'alpha': 0.02621704841078774, 'colsample_bytree': 0.5, 'subsample': 1.0, 'learning_rate': 0.15009999999999998, 'n_estimators': 803}. Best is trial 56 with value: 0.7102857142857144.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-01-12 01:53:10,527]\u001b[0m Trial 60 finished with value: 0.677904761904762 and parameters: {'lambda': 0.003453061915516729, 'alpha': 0.06591221885128822, 'colsample_bytree': 0.4, 'subsample': 1.0, 'learning_rate': 0.1701, 'n_estimators': 955}. Best is trial 56 with value: 0.7102857142857144.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-01-12 01:53:12,750]\u001b[0m Trial 61 finished with value: 0.6932380952380953 and parameters: {'lambda': 0.006241233717411143, 'alpha': 0.008377211507259008, 'colsample_bytree': 0.3, 'subsample': 1.0, 'learning_rate': 0.1601, 'n_estimators': 885}. Best is trial 56 with value: 0.7102857142857144.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-01-12 01:53:15,123]\u001b[0m Trial 62 finished with value: 0.7001904761904763 and parameters: {'lambda': 0.00199673319822298, 'alpha': 0.01284143905578283, 'colsample_bytree': 0.3, 'subsample': 1.0, 'learning_rate': 0.1601, 'n_estimators': 875}. Best is trial 56 with value: 0.7102857142857144.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-01-12 01:53:17,298]\u001b[0m Trial 63 finished with value: 0.6935238095238097 and parameters: {'lambda': 0.0018104838952691495, 'alpha': 0.014581416070468362, 'colsample_bytree': 0.3, 'subsample': 1.0, 'learning_rate': 0.18009999999999998, 'n_estimators': 804}. Best is trial 56 with value: 0.7102857142857144.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-01-12 01:53:19,428]\u001b[0m Trial 64 finished with value: 0.7004761904761907 and parameters: {'lambda': 0.0024756254478756406, 'alpha': 0.052568127938742146, 'colsample_bytree': 0.3, 'subsample': 1.0, 'learning_rate': 0.14509999999999998, 'n_estimators': 764}. Best is trial 56 with value: 0.7102857142857144.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-01-12 01:53:21,329]\u001b[0m Trial 65 finished with value: 0.6792380952380952 and parameters: {'lambda': 0.0028689485895962183, 'alpha': 0.04629073394230276, 'colsample_bytree': 0.9000000000000001, 'subsample': 0.9, 'learning_rate': 0.1351, 'n_estimators': 765}. Best is trial 56 with value: 0.7102857142857144.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-01-12 01:53:22,970]\u001b[0m Trial 66 finished with value: 0.6595238095238096 and parameters: {'lambda': 0.001014578900194637, 'alpha': 0.36043897298369987, 'colsample_bytree': 0.4, 'subsample': 1.0, 'learning_rate': 0.14509999999999998, 'n_estimators': 761}. Best is trial 56 with value: 0.7102857142857144.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-01-12 01:53:25,064]\u001b[0m Trial 67 finished with value: 0.6751428571428572 and parameters: {'lambda': 0.01737522874540943, 'alpha': 0.05780931059819181, 'colsample_bytree': 1.0, 'subsample': 0.9, 'learning_rate': 0.15009999999999998, 'n_estimators': 815}. Best is trial 56 with value: 0.7102857142857144.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-01-12 01:53:27,445]\u001b[0m Trial 68 finished with value: 0.6863809523809524 and parameters: {'lambda': 0.0015222664201042758, 'alpha': 0.11020953113272494, 'colsample_bytree': 0.3, 'subsample': 1.0, 'learning_rate': 0.1301, 'n_estimators': 936}. Best is trial 56 with value: 0.7102857142857144.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-01-12 01:53:29,694]\u001b[0m Trial 69 finished with value: 0.6778095238095238 and parameters: {'lambda': 0.003426341240967464, 'alpha': 0.03256146187092011, 'colsample_bytree': 0.4, 'subsample': 1.0, 'learning_rate': 0.1751, 'n_estimators': 866}. Best is trial 56 with value: 0.7102857142857144.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-01-12 01:53:31,832]\u001b[0m Trial 70 finished with value: 0.6820952380952382 and parameters: {'lambda': 0.005384501751833538, 'alpha': 0.022922639033061288, 'colsample_bytree': 0.4, 'subsample': 0.9, 'learning_rate': 0.14509999999999998, 'n_estimators': 905}. Best is trial 56 with value: 0.7102857142857144.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-01-12 01:53:34,361]\u001b[0m Trial 71 finished with value: 0.6932380952380954 and parameters: {'lambda': 0.0038325905699101567, 'alpha': 0.02051598231771764, 'colsample_bytree': 0.3, 'subsample': 1.0, 'learning_rate': 0.1651, 'n_estimators': 965}. Best is trial 56 with value: 0.7102857142857144.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-01-12 01:53:36,703]\u001b[0m Trial 72 finished with value: 0.7002857142857144 and parameters: {'lambda': 0.0024577069483295065, 'alpha': 0.007109582478627625, 'colsample_bytree': 0.3, 'subsample': 1.0, 'learning_rate': 0.1551, 'n_estimators': 896}. Best is trial 56 with value: 0.7102857142857144.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-01-12 01:53:38,713]\u001b[0m Trial 73 finished with value: 0.6973333333333335 and parameters: {'lambda': 0.0024282570038449054, 'alpha': 0.08294927790166803, 'colsample_bytree': 0.3, 'subsample': 1.0, 'learning_rate': 0.1551, 'n_estimators': 752}. Best is trial 56 with value: 0.7102857142857144.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-01-12 01:53:40,765]\u001b[0m Trial 74 finished with value: 0.6973333333333335 and parameters: {'lambda': 0.008296731719590096, 'alpha': 0.0073542298983549645, 'colsample_bytree': 0.3, 'subsample': 1.0, 'learning_rate': 0.1701, 'n_estimators': 787}. Best is trial 56 with value: 0.7102857142857144.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-01-12 01:53:42,888]\u001b[0m Trial 75 finished with value: 0.678952380952381 and parameters: {'lambda': 0.013459544298683093, 'alpha': 0.01606555197132388, 'colsample_bytree': 0.3, 'subsample': 0.5, 'learning_rate': 0.1251, 'n_estimators': 938}. Best is trial 56 with value: 0.7102857142857144.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-01-12 01:53:45,243]\u001b[0m Trial 76 finished with value: 0.6835238095238096 and parameters: {'lambda': 0.002432929541319386, 'alpha': 0.03867844669314933, 'colsample_bytree': 0.4, 'subsample': 1.0, 'learning_rate': 0.1551, 'n_estimators': 905}. Best is trial 56 with value: 0.7102857142857144.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-01-12 01:53:46,786]\u001b[0m Trial 77 finished with value: 0.6908571428571428 and parameters: {'lambda': 0.0014775448337385007, 'alpha': 0.008379965030471833, 'colsample_bytree': 0.3, 'subsample': 0.9, 'learning_rate': 0.1901, 'n_estimators': 647}. Best is trial 56 with value: 0.7102857142857144.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-01-12 01:53:48,713]\u001b[0m Trial 78 finished with value: 0.6807619047619049 and parameters: {'lambda': 0.006701372418938602, 'alpha': 0.004045620666985065, 'colsample_bytree': 0.4, 'subsample': 0.9, 'learning_rate': 0.14509999999999998, 'n_estimators': 820}. Best is trial 56 with value: 0.7102857142857144.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-01-12 01:53:50,849]\u001b[0m Trial 79 finished with value: 0.6876190476190479 and parameters: {'lambda': 0.003127746609011728, 'alpha': 0.025715495289677936, 'colsample_bytree': 0.3, 'subsample': 1.0, 'learning_rate': 0.18009999999999998, 'n_estimators': 858}. Best is trial 56 with value: 0.7102857142857144.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-01-12 01:53:52,896]\u001b[0m Trial 80 finished with value: 0.6960952380952383 and parameters: {'lambda': 0.0011720575701298413, 'alpha': 0.016807260672059614, 'colsample_bytree': 0.3, 'subsample': 1.0, 'learning_rate': 0.1651, 'n_estimators': 797}. Best is trial 56 with value: 0.7102857142857144.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-01-12 01:53:55,044]\u001b[0m Trial 81 finished with value: 0.7044761904761907 and parameters: {'lambda': 0.0020203854446397642, 'alpha': 0.013357193776383159, 'colsample_bytree': 0.3, 'subsample': 1.0, 'learning_rate': 0.1601, 'n_estimators': 877}. Best is trial 56 with value: 0.7102857142857144.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-01-12 01:53:57,400]\u001b[0m Trial 82 finished with value: 0.698857142857143 and parameters: {'lambda': 0.005019268124724571, 'alpha': 0.009246692653937827, 'colsample_bytree': 0.3, 'subsample': 1.0, 'learning_rate': 0.1701, 'n_estimators': 903}. Best is trial 56 with value: 0.7102857142857144.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-01-12 01:53:59,710]\u001b[0m Trial 83 finished with value: 0.6962857142857143 and parameters: {'lambda': 0.002471192899337615, 'alpha': 0.014195787739054177, 'colsample_bytree': 0.3, 'subsample': 1.0, 'learning_rate': 0.1351, 'n_estimators': 863}. Best is trial 56 with value: 0.7102857142857144.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-01-12 01:54:01,031]\u001b[0m Trial 84 finished with value: 0.6265714285714286 and parameters: {'lambda': 0.0020518609785551635, 'alpha': 2.3474089145676693, 'colsample_bytree': 0.3, 'subsample': 1.0, 'learning_rate': 0.1551, 'n_estimators': 709}. Best is trial 56 with value: 0.7102857142857144.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-01-12 01:54:03,502]\u001b[0m Trial 85 finished with value: 0.6877142857142857 and parameters: {'lambda': 0.0016715687766010845, 'alpha': 0.007252154293450322, 'colsample_bytree': 0.4, 'subsample': 1.0, 'learning_rate': 0.1401, 'n_estimators': 973}. Best is trial 56 with value: 0.7102857142857144.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-01-12 01:54:05,680]\u001b[0m Trial 86 finished with value: 0.6807619047619048 and parameters: {'lambda': 0.004042017054172613, 'alpha': 0.019549267963618795, 'colsample_bytree': 0.3, 'subsample': 0.9, 'learning_rate': 0.15009999999999998, 'n_estimators': 938}. Best is trial 56 with value: 0.7102857142857144.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-01-12 01:54:07,852]\u001b[0m Trial 87 finished with value: 0.7031428571428572 and parameters: {'lambda': 0.023473634497896897, 'alpha': 0.005636601005747783, 'colsample_bytree': 0.3, 'subsample': 1.0, 'learning_rate': 0.1601, 'n_estimators': 848}. Best is trial 56 with value: 0.7102857142857144.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-01-12 01:54:10,073]\u001b[0m Trial 88 finished with value: 0.6862857142857144 and parameters: {'lambda': 0.03357853084274716, 'alpha': 0.004764047018815245, 'colsample_bytree': 0.4, 'subsample': 1.0, 'learning_rate': 0.1751, 'n_estimators': 843}. Best is trial 56 with value: 0.7102857142857144.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-01-12 01:54:12,340]\u001b[0m Trial 89 finished with value: 0.7031428571428572 and parameters: {'lambda': 0.00851847070190272, 'alpha': 0.010913691529586302, 'colsample_bytree': 0.3, 'subsample': 1.0, 'learning_rate': 0.1651, 'n_estimators': 816}. Best is trial 56 with value: 0.7102857142857144.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-01-12 01:54:14,158]\u001b[0m Trial 90 finished with value: 0.6907619047619049 and parameters: {'lambda': 0.026298523095546197, 'alpha': 0.002337637077580732, 'colsample_bytree': 0.3, 'subsample': 0.9, 'learning_rate': 0.18009999999999998, 'n_estimators': 767}. Best is trial 56 with value: 0.7102857142857144.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-01-12 01:54:16,189]\u001b[0m Trial 91 finished with value: 0.6889523809523811 and parameters: {'lambda': 0.007679646889123362, 'alpha': 0.003095610150491639, 'colsample_bytree': 0.3, 'subsample': 1.0, 'learning_rate': 0.1651, 'n_estimators': 817}. Best is trial 56 with value: 0.7102857142857144.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-01-12 01:54:18,346]\u001b[0m Trial 92 finished with value: 0.698857142857143 and parameters: {'lambda': 0.019627147648464925, 'alpha': 0.010308846754474606, 'colsample_bytree': 0.3, 'subsample': 1.0, 'learning_rate': 0.14509999999999998, 'n_estimators': 789}. Best is trial 56 with value: 0.7102857142857144.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-01-12 01:54:20,399]\u001b[0m Trial 93 finished with value: 0.6989523809523811 and parameters: {'lambda': 0.012104952676441646, 'alpha': 0.03039331547668624, 'colsample_bytree': 0.3, 'subsample': 1.0, 'learning_rate': 0.1601, 'n_estimators': 742}. Best is trial 56 with value: 0.7102857142857144.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-01-12 01:54:21,764]\u001b[0m Trial 94 finished with value: 0.7060000000000001 and parameters: {'lambda': 0.005758744911796952, 'alpha': 0.00592458636159379, 'colsample_bytree': 0.3, 'subsample': 1.0, 'learning_rate': 0.1551, 'n_estimators': 489}. Best is trial 56 with value: 0.7102857142857144.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-01-12 01:54:23,361]\u001b[0m Trial 95 finished with value: 0.7003809523809525 and parameters: {'lambda': 0.05944768953566761, 'alpha': 0.00537721962184014, 'colsample_bytree': 0.3, 'subsample': 1.0, 'learning_rate': 0.15009999999999998, 'n_estimators': 559}. Best is trial 56 with value: 0.7102857142857144.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-01-12 01:54:24,709]\u001b[0m Trial 96 finished with value: 0.6947619047619048 and parameters: {'lambda': 0.04615810486191638, 'alpha': 0.005041871944751029, 'colsample_bytree': 0.3, 'subsample': 1.0, 'learning_rate': 0.15009999999999998, 'n_estimators': 482}. Best is trial 56 with value: 0.7102857142857144.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-01-12 01:54:25,993]\u001b[0m Trial 97 finished with value: 0.6821904761904762 and parameters: {'lambda': 0.009891164357898056, 'alpha': 0.0036417886687594215, 'colsample_bytree': 0.4, 'subsample': 1.0, 'learning_rate': 0.1701, 'n_estimators': 462}. Best is trial 56 with value: 0.7102857142857144.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-01-12 01:54:28,093]\u001b[0m Trial 98 finished with value: 0.6793333333333336 and parameters: {'lambda': 0.07346609827384647, 'alpha': 0.0017648041937854684, 'colsample_bytree': 0.3, 'subsample': 0.9, 'learning_rate': 0.1351, 'n_estimators': 557}. Best is trial 56 with value: 0.7102857142857144.\u001b[0m\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_30036\\2666013998.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
      "E:\\C++\\anaconda\\envs\\hydrogel\\lib\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [0.0001, 0.2] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.1951].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2024-01-12 01:54:32,881]\u001b[0m Trial 99 finished with value: 0.6862857142857142 and parameters: {'lambda': 0.005843712147701568, 'alpha': 0.010227730927162207, 'colsample_bytree': 0.4, 'subsample': 1.0, 'learning_rate': 0.1651, 'n_estimators': 681}. Best is trial 56 with value: 0.7102857142857144.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "#Tuning hyperparameters\n",
    "#Step 1. Define an objective function to be maximized.\n",
    "def objective(trial):\n",
    "    param = {\n",
    "        'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
    "        'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
    "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.3,1.0,step=0.1),\n",
    "        'subsample': trial.suggest_float('subsample', 0.4, 1.0, step=0.1),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.0001, 0.2, step=0.005),\n",
    "        'n_estimators': trial.suggest_int(\"n_estimators\",50,1000,1)\n",
    "        #'min_child_weight': trial.suggest_int('min_child_weight', 1, 300),\n",
    "    }\n",
    "    model = xgb.XGBClassifier(**param,random_state=1,n_jobs=8)\n",
    "\n",
    " \n",
    "# Step 2: Scoring method:\n",
    "    score = model_selection.cross_val_score(model, X, y, n_jobs=8, scoring=\"accuracy\",cv=Cv_optuna)\n",
    "    accuracy = score.mean()\n",
    "    return accuracy\n",
    "\n",
    "# Step 3: Running it\n",
    "study = optuna.create_study(direction=\"maximize\",sampler=optuna.samplers.TPESampler(seed=0))\n",
    "study.optimize(objective, n_trials=100, show_progress_bar=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "61fd4c6f-d6af-4f71-8f40-73e5cb7f1a34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best parameters are : \n",
      "{'lambda': 0.0013221304985698086, 'alpha': 0.02305461805888264, 'colsample_bytree': 0.3, 'subsample': 1.0, 'learning_rate': 0.15009999999999998, 'n_estimators': 884}\n"
     ]
    }
   ],
   "source": [
    "# Getting the best parameters:\n",
    "print(f\"The best parameters are : \\n{study.best_params}\")\n",
    "# Setting the best model\n",
    "clf=xgb.XGBClassifier(alpha = study.best_params['alpha']\n",
    "              ,colsample_bytree = study.best_params['colsample_bytree']\n",
    "              ,subsample = study.best_params['subsample']\n",
    "              ,n_estimators = study.best_params['n_estimators']\n",
    "              ,learning_rate= study.best_params['learning_rate'], n_jobs=8\n",
    "              ,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "4b5d7bd3-660b-42d3-9546-2633863cc8ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mean</th>\n",
       "      <th>Se</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Accuracy_test</th>\n",
       "      <td>0.682000</td>\n",
       "      <td>0.015467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Accuracy_train</th>\n",
       "      <td>0.978164</td>\n",
       "      <td>0.001539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1 Score</th>\n",
       "      <td>0.710276</td>\n",
       "      <td>0.015000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Precision</th>\n",
       "      <td>0.693874</td>\n",
       "      <td>0.013624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recall</th>\n",
       "      <td>0.748214</td>\n",
       "      <td>0.023279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Roc_auc</th>\n",
       "      <td>0.752117</td>\n",
       "      <td>0.018448</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Mean        Se\n",
       "Accuracy_test   0.682000  0.015467\n",
       "Accuracy_train  0.978164  0.001539\n",
       "F1 Score        0.710276  0.015000\n",
       "Precision       0.693874  0.013624\n",
       "Recall          0.748214  0.023279\n",
       "Roc_auc         0.752117  0.018448"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Model2=Model_results(clf,X,y,Cv_model)\n",
    "Model2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "a8261ab4-67a6-445c-8d21-feddad6b3796",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th>Method</th>\n",
       "      <th colspan=\"4\" halign=\"left\">XGB</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model</th>\n",
       "      <th colspan=\"2\" halign=\"left\">Model 1</th>\n",
       "      <th colspan=\"2\" halign=\"left\">Model 2</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Values</th>\n",
       "      <th>Mean</th>\n",
       "      <th>Se</th>\n",
       "      <th>Mean</th>\n",
       "      <th>Se</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Accuracy_test</th>\n",
       "      <td>0.662476</td>\n",
       "      <td>0.016918</td>\n",
       "      <td>0.682000</td>\n",
       "      <td>0.015467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Accuracy_train</th>\n",
       "      <td>0.978164</td>\n",
       "      <td>0.001539</td>\n",
       "      <td>0.978164</td>\n",
       "      <td>0.001539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1 Score</th>\n",
       "      <td>0.693483</td>\n",
       "      <td>0.017356</td>\n",
       "      <td>0.710276</td>\n",
       "      <td>0.015000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Precision</th>\n",
       "      <td>0.671509</td>\n",
       "      <td>0.015551</td>\n",
       "      <td>0.693874</td>\n",
       "      <td>0.013624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recall</th>\n",
       "      <td>0.737143</td>\n",
       "      <td>0.025112</td>\n",
       "      <td>0.748214</td>\n",
       "      <td>0.023279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Roc_auc</th>\n",
       "      <td>0.749660</td>\n",
       "      <td>0.017686</td>\n",
       "      <td>0.752117</td>\n",
       "      <td>0.018448</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Method               XGB                              \n",
       "Model            Model 1             Model 2          \n",
       "Values              Mean        Se      Mean        Se\n",
       "Accuracy_test   0.662476  0.016918  0.682000  0.015467\n",
       "Accuracy_train  0.978164  0.001539  0.978164  0.001539\n",
       "F1 Score        0.693483  0.017356  0.710276  0.015000\n",
       "Precision       0.671509  0.015551  0.693874  0.013624\n",
       "Recall          0.737143  0.025112  0.748214  0.023279\n",
       "Roc_auc         0.749660  0.017686  0.752117  0.018448"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Saving the data of model performance\n",
    "Model_data=pd.concat([Model1,Model2],axis=1)\n",
    "Model_data.columns = [['XGB']*4,['Model 1','Model 1', 'Model 2','Model 2'], ['Mean', 'Se', 'Mean', 'Se']]  \n",
    "Model_data.columns.names=['Method','Model','Values']\n",
    "Model_data.to_csv(\"./Results/XGB_model_mlrem_data.csv\",sep=',')\n",
    "Model_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec50adff-12d7-4284-a740-a33a46351d03",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hydrogel",
   "language": "python",
   "name": "hydrogel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
